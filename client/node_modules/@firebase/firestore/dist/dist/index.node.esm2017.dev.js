"use strict";Object.defineProperty(exports,"__esModule",{value:true});exports.registerFirestore=registerFirestore;var _app=_interopRequireDefault(require("@firebase/app"));var _logger=require("@firebase/logger");var _util=require("util");var _crypto=require("crypto");var _util2=require("@firebase/util");var _protoLoader=require("@grpc/proto-loader");var _grpcJs=require("@grpc/grpc-js");var _path3=require("path");var _package=require("@grpc/grpc-js/package.json");var _component=require("@firebase/component");function _interopRequireDefault(obj){return obj&&obj.__esModule?obj:{"default":obj};}function _slicedToArray(arr,i){return _arrayWithHoles(arr)||_iterableToArrayLimit(arr,i)||_nonIterableRest();}function _nonIterableRest(){throw new TypeError("Invalid attempt to destructure non-iterable instance");}function _iterableToArrayLimit(arr,i){if(!(Symbol.iterator in Object(arr)||Object.prototype.toString.call(arr)==="[object Arguments]")){return;}var _arr=[];var _n=true;var _d=false;var _e=undefined;try{for(var _i=arr[Symbol.iterator](),_s;!(_n=(_s=_i.next()).done);_n=true){_arr.push(_s.value);if(i&&_arr.length===i)break;}}catch(err){_d=true;_e=err;}finally{try{if(!_n&&_i["return"]!=null)_i["return"]();}finally{if(_d)throw _e;}}return _arr;}function _arrayWithHoles(arr){if(Array.isArray(arr))return arr;}function _defineProperty(obj,key,value){if(key in obj){Object.defineProperty(obj,key,{value:value,enumerable:true,configurable:true,writable:true});}else{obj[key]=value;}return obj;}function _get(target,property,receiver){if(typeof Reflect!=="undefined"&&Reflect.get){_get=Reflect.get;}else{_get=function _get(target,property,receiver){var base=_superPropBase(target,property);if(!base)return;var desc=Object.getOwnPropertyDescriptor(base,property);if(desc.get){return desc.get.call(receiver);}return desc.value;};}return _get(target,property,receiver||target);}function _superPropBase(object,property){while(!Object.prototype.hasOwnProperty.call(object,property)){object=_getPrototypeOf(object);if(object===null)break;}return object;}function _defineProperties(target,props){for(var i=0;i<props.length;i++){var descriptor=props[i];descriptor.enumerable=descriptor.enumerable||false;descriptor.configurable=true;if("value"in descriptor)descriptor.writable=true;Object.defineProperty(target,descriptor.key,descriptor);}}function _createClass(Constructor,protoProps,staticProps){if(protoProps)_defineProperties(Constructor.prototype,protoProps);if(staticProps)_defineProperties(Constructor,staticProps);return Constructor;}function _toConsumableArray(arr){return _arrayWithoutHoles(arr)||_iterableToArray(arr)||_nonIterableSpread();}function _nonIterableSpread(){throw new TypeError("Invalid attempt to spread non-iterable instance");}function _iterableToArray(iter){if(Symbol.iterator in Object(iter)||Object.prototype.toString.call(iter)==="[object Arguments]")return Array.from(iter);}function _arrayWithoutHoles(arr){if(Array.isArray(arr)){for(var i=0,arr2=new Array(arr.length);i<arr.length;i++){arr2[i]=arr[i];}return arr2;}}function _typeof(obj){if(typeof Symbol==="function"&&typeof Symbol.iterator==="symbol"){_typeof=function _typeof(obj){return typeof obj;};}else{_typeof=function _typeof(obj){return obj&&typeof Symbol==="function"&&obj.constructor===Symbol&&obj!==Symbol.prototype?"symbol":typeof obj;};}return _typeof(obj);}function _classCallCheck(instance,Constructor){if(!(instance instanceof Constructor)){throw new TypeError("Cannot call a class as a function");}}function _possibleConstructorReturn(self,call){if(call&&(_typeof(call)==="object"||typeof call==="function")){return call;}return _assertThisInitialized(self);}function _assertThisInitialized(self){if(self===void 0){throw new ReferenceError("this hasn't been initialised - super() hasn't been called");}return self;}function _inherits(subClass,superClass){if(typeof superClass!=="function"&&superClass!==null){throw new TypeError("Super expression must either be null or a function");}subClass.prototype=Object.create(superClass&&superClass.prototype,{constructor:{value:subClass,writable:true,configurable:true}});if(superClass)_setPrototypeOf(subClass,superClass);}function _wrapNativeSuper(Class){var _cache=typeof Map==="function"?new Map():undefined;_wrapNativeSuper=function _wrapNativeSuper(Class){if(Class===null||!_isNativeFunction(Class))return Class;if(typeof Class!=="function"){throw new TypeError("Super expression must either be null or a function");}if(typeof _cache!=="undefined"){if(_cache.has(Class))return _cache.get(Class);_cache.set(Class,Wrapper);}function Wrapper(){return _construct(Class,arguments,_getPrototypeOf(this).constructor);}Wrapper.prototype=Object.create(Class.prototype,{constructor:{value:Wrapper,enumerable:false,writable:true,configurable:true}});return _setPrototypeOf(Wrapper,Class);};return _wrapNativeSuper(Class);}function isNativeReflectConstruct(){if(typeof Reflect==="undefined"||!Reflect.construct)return false;if(Reflect.construct.sham)return false;if(typeof Proxy==="function")return true;try{Date.prototype.toString.call(Reflect.construct(Date,[],function(){}));return true;}catch(e){return false;}}function _construct(Parent,args,Class){if(isNativeReflectConstruct()){_construct=Reflect.construct;}else{_construct=function _construct(Parent,args,Class){var a=[null];a.push.apply(a,args);var Constructor=Function.bind.apply(Parent,a);var instance=new Constructor();if(Class)_setPrototypeOf(instance,Class.prototype);return instance;};}return _construct.apply(null,arguments);}function _isNativeFunction(fn){return Function.toString.call(fn).indexOf("[native code]")!==-1;}function _setPrototypeOf(o,p){_setPrototypeOf=Object.setPrototypeOf||function _setPrototypeOf(o,p){o.__proto__=p;return o;};return _setPrototypeOf(o,p);}function _getPrototypeOf(o){_getPrototypeOf=Object.setPrototypeOf?Object.getPrototypeOf:function _getPrototypeOf(o){return o.__proto__||Object.getPrototypeOf(o);};return _getPrototypeOf(o);}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var Code={// Causes are copied from:
// https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h
/** Not an error; returned on success. */OK:'ok',/** The operation was cancelled (typically by the caller). */CANCELLED:'cancelled',/** Unknown error or an error from a different error domain. */UNKNOWN:'unknown',/**
     * Client specified an invalid argument. Note that this differs from
     * FAILED_PRECONDITION. INVALID_ARGUMENT indicates arguments that are
     * problematic regardless of the state of the system (e.g., a malformed file
     * name).
     */INVALID_ARGUMENT:'invalid-argument',/**
     * Deadline expired before operation could complete. For operations that
     * change the state of the system, this error may be returned even if the
     * operation has completed successfully. For example, a successful response
     * from a server could have been delayed long enough for the deadline to
     * expire.
     */DEADLINE_EXCEEDED:'deadline-exceeded',/** Some requested entity (e.g., file or directory) was not found. */NOT_FOUND:'not-found',/**
     * Some entity that we attempted to create (e.g., file or directory) already
     * exists.
     */ALREADY_EXISTS:'already-exists',/**
     * The caller does not have permission to execute the specified operation.
     * PERMISSION_DENIED must not be used for rejections caused by exhausting
     * some resource (use RESOURCE_EXHAUSTED instead for those errors).
     * PERMISSION_DENIED must not be used if the caller can not be identified
     * (use UNAUTHENTICATED instead for those errors).
     */PERMISSION_DENIED:'permission-denied',/**
     * The request does not have valid authentication credentials for the
     * operation.
     */UNAUTHENTICATED:'unauthenticated',/**
     * Some resource has been exhausted, perhaps a per-user quota, or perhaps the
     * entire file system is out of space.
     */RESOURCE_EXHAUSTED:'resource-exhausted',/**
     * Operation was rejected because the system is not in a state required for
     * the operation's execution. For example, directory to be deleted may be
     * non-empty, an rmdir operation is applied to a non-directory, etc.
     *
     * A litmus test that may help a service implementor in deciding
     * between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE:
     *  (a) Use UNAVAILABLE if the client can retry just the failing call.
     *  (b) Use ABORTED if the client should retry at a higher-level
     *      (e.g., restarting a read-modify-write sequence).
     *  (c) Use FAILED_PRECONDITION if the client should not retry until
     *      the system state has been explicitly fixed. E.g., if an "rmdir"
     *      fails because the directory is non-empty, FAILED_PRECONDITION
     *      should be returned since the client should not retry unless
     *      they have first fixed up the directory by deleting files from it.
     *  (d) Use FAILED_PRECONDITION if the client performs conditional
     *      REST Get/Update/Delete on a resource and the resource on the
     *      server does not match the condition. E.g., conflicting
     *      read-modify-write on the same resource.
     */FAILED_PRECONDITION:'failed-precondition',/**
     * The operation was aborted, typically due to a concurrency issue like
     * sequencer check failures, transaction aborts, etc.
     *
     * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,
     * and UNAVAILABLE.
     */ABORTED:'aborted',/**
     * Operation was attempted past the valid range. E.g., seeking or reading
     * past end of file.
     *
     * Unlike INVALID_ARGUMENT, this error indicates a problem that may be fixed
     * if the system state changes. For example, a 32-bit file system will
     * generate INVALID_ARGUMENT if asked to read at an offset that is not in the
     * range [0,2^32-1], but it will generate OUT_OF_RANGE if asked to read from
     * an offset past the current file size.
     *
     * There is a fair bit of overlap between FAILED_PRECONDITION and
     * OUT_OF_RANGE. We recommend using OUT_OF_RANGE (the more specific error)
     * when it applies so that callers who are iterating through a space can
     * easily look for an OUT_OF_RANGE error to detect when they are done.
     */OUT_OF_RANGE:'out-of-range',/** Operation is not implemented or not supported/enabled in this service. */UNIMPLEMENTED:'unimplemented',/**
     * Internal errors. Means some invariants expected by underlying System has
     * been broken. If you see one of these errors, Something is very broken.
     */INTERNAL:'internal',/**
     * The service is currently unavailable. This is a most likely a transient
     * condition and may be corrected by retrying with a backoff.
     *
     * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,
     * and UNAVAILABLE.
     */UNAVAILABLE:'unavailable',/** Unrecoverable data loss or corruption. */DATA_LOSS:'data-loss'};/** An error returned by a Firestore operation. */var FirestoreError=/*#__PURE__*/function(_Error){_inherits(FirestoreError,_Error);function FirestoreError(code,message){var _this;_classCallCheck(this,FirestoreError);_this=_possibleConstructorReturn(this,_getPrototypeOf(FirestoreError).call(this,message));_this.code=code;_this.message=message;_this.name='FirebaseError';// HACK: We write a toString property directly because Error is not a real
// class and so inheritance does not work correctly. We could alternatively
// do the same "back-door inheritance" trick that FirebaseError does.
_this.toString=function(){return"".concat(_this.name,": [code=").concat(_this.code,"]: ").concat(_this.message);};return _this;}return FirestoreError;}(_wrapNativeSuper(Error));/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */function decodeBase64(encoded){// Node actually doesn't validate base64 strings.
// A quick sanity check that is not a fool-proof validation
if(/[^-A-Za-z0-9+/=]/.test(encoded)){throw new FirestoreError(Code.INVALID_ARGUMENT,'Not a valid Base64 string: '+encoded);}return new Buffer(encoded,'base64').toString('binary');}/** Converts a binary string to a Base64 encoded string. */function encodeBase64(raw){return new Buffer(raw,'binary').toString('base64');}var version="7.22.0";/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /** Formats an object as a JSON string, suitable for logging. */function formatJSON(value){// util.inspect() results in much more readable output than JSON.stringify()
return(0,_util.inspect)(value,{depth:100});}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var logClient=new _logger.Logger('@firebase/firestore');// Helper methods are needed because variables can't be exported as read/write
function getLogLevel(){return logClient.logLevel;}/**
 * Sets the verbosity of Cloud Firestore logs (debug, error, or silent).
 *
 * @param logLevel
 *   The verbosity you set for activity and error logging. Can be any of
 *   the following values:
 *
 *   <ul>
 *     <li>`debug` for the most verbose logging level, primarily for
 *     debugging.</li>
 *     <li>`error` to log errors only.</li>
 *     <li><code>`silent` to turn off logging.</li>
 *   </ul>
 */function _setLogLevel(logLevel){logClient.setLogLevel(logLevel);}function logDebug(msg){if(logClient.logLevel<=_logger.LogLevel.DEBUG){for(var _len=arguments.length,obj=new Array(_len>1?_len-1:0),_key2=1;_key2<_len;_key2++){obj[_key2-1]=arguments[_key2];}var args=obj.map(argToString);logClient.debug.apply(logClient,["Firestore (".concat(version,"): ").concat(msg)].concat(_toConsumableArray(args)));}}function logError(msg){if(logClient.logLevel<=_logger.LogLevel.ERROR){for(var _len2=arguments.length,obj=new Array(_len2>1?_len2-1:0),_key3=1;_key3<_len2;_key3++){obj[_key3-1]=arguments[_key3];}var args=obj.map(argToString);logClient.error.apply(logClient,["Firestore (".concat(version,"): ").concat(msg)].concat(_toConsumableArray(args)));}}function logWarn(msg){if(logClient.logLevel<=_logger.LogLevel.WARN){for(var _len3=arguments.length,obj=new Array(_len3>1?_len3-1:0),_key4=1;_key4<_len3;_key4++){obj[_key4-1]=arguments[_key4];}var args=obj.map(argToString);logClient.warn.apply(logClient,["Firestore (".concat(version,"): ").concat(msg)].concat(_toConsumableArray(args)));}}/**
 * Converts an additional log parameter to a string representation.
 */function argToString(obj){if(typeof obj==='string'){return obj;}else{try{return formatJSON(obj);}catch(e){// Converting to JSON failed, just log the object directly
return obj;}}}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Unconditionally fails, throwing an Error with the given message.
 * Messages are stripped in production builds.
 *
 * Returns `never` and can be used in expressions:
 * @example
 * let futureVar = fail('not implemented yet');
 */function fail(){var failure=arguments.length>0&&arguments[0]!==undefined?arguments[0]:'Unexpected state';// Log the failure in addition to throw an exception, just in case the
// exception is swallowed.
var message="FIRESTORE (".concat(version,") INTERNAL ASSERTION FAILED: ")+failure;logError(message);// NOTE: We don't use FirestoreError here because these are internal failures
// that cannot be handled by the user. (Also it would create a circular
// dependency between the error and assert modules which doesn't work.)
throw new Error(message);}/**
 * Fails if the given assertion condition is false, throwing an Error with the
 * given message if it did.
 *
 * Messages are stripped in production builds.
 */function hardAssert(assertion,message){if(!assertion){fail();}}/**
 * Casts `obj` to `T`. In non-production builds, verifies that `obj` is an
 * instance of `T` before casting.
 */function debugCast(obj,// eslint-disable-next-line @typescript-eslint/no-explicit-any
constructor){return obj;}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */function objectSize(obj){var count=0;for(var key in obj){if(Object.prototype.hasOwnProperty.call(obj,key)){count++;}}return count;}function _forEach(obj,fn){for(var key in obj){if(Object.prototype.hasOwnProperty.call(obj,key)){fn(key,obj[key]);}}}function _isEmpty(obj){for(var key in obj){if(Object.prototype.hasOwnProperty.call(obj,key)){return false;}}return true;}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var DOCUMENT_KEY_NAME='__name__';/**
 * Path represents an ordered sequence of string segments.
 */var BasePath=/*#__PURE__*/function(){function BasePath(segments,offset,length){_classCallCheck(this,BasePath);if(offset===undefined){offset=0;}else if(offset>segments.length){fail();}if(length===undefined){length=segments.length-offset;}else if(length>segments.length-offset){fail();}this.segments=segments;this.offset=offset;this.len=length;}_createClass(BasePath,[{key:"isEqual",value:function isEqual(other){return BasePath.comparator(this,other)===0;}},{key:"child",value:function child(nameOrPath){var segments=this.segments.slice(this.offset,this.limit());if(nameOrPath instanceof BasePath){nameOrPath.forEach(function(segment){segments.push(segment);});}else{segments.push(nameOrPath);}return this.construct(segments);}/** The index of one past the last segment of the path. */},{key:"limit",value:function limit(){return this.offset+this.length;}},{key:"popFirst",value:function popFirst(size){size=size===undefined?1:size;return this.construct(this.segments,this.offset+size,this.length-size);}},{key:"popLast",value:function popLast(){return this.construct(this.segments,this.offset,this.length-1);}},{key:"firstSegment",value:function firstSegment(){return this.segments[this.offset];}},{key:"lastSegment",value:function lastSegment(){return this.get(this.length-1);}},{key:"get",value:function get(index){return this.segments[this.offset+index];}},{key:"isEmpty",value:function isEmpty(){return this.length===0;}},{key:"isPrefixOf",value:function isPrefixOf(other){if(other.length<this.length){return false;}for(var i=0;i<this.length;i++){if(this.get(i)!==other.get(i)){return false;}}return true;}},{key:"isImmediateParentOf",value:function isImmediateParentOf(potentialChild){if(this.length+1!==potentialChild.length){return false;}for(var i=0;i<this.length;i++){if(this.get(i)!==potentialChild.get(i)){return false;}}return true;}},{key:"forEach",value:function forEach(fn){for(var i=this.offset,end=this.limit();i<end;i++){fn(this.segments[i]);}}},{key:"toArray",value:function toArray(){return this.segments.slice(this.offset,this.limit());}},{key:"length",get:function get(){return this.len;}}],[{key:"comparator",value:function comparator(p1,p2){var len=Math.min(p1.length,p2.length);for(var i=0;i<len;i++){var left=p1.get(i);var right=p2.get(i);if(left<right){return-1;}if(left>right){return 1;}}if(p1.length<p2.length){return-1;}if(p1.length>p2.length){return 1;}return 0;}}]);return BasePath;}();/**
 * A slash-separated path for navigating resources (documents and collections)
 * within Firestore.
 */var ResourcePath=/*#__PURE__*/function(_BasePath){_inherits(ResourcePath,_BasePath);function ResourcePath(){_classCallCheck(this,ResourcePath);return _possibleConstructorReturn(this,_getPrototypeOf(ResourcePath).apply(this,arguments));}_createClass(ResourcePath,[{key:"construct",value:function construct(segments,offset,length){return new ResourcePath(segments,offset,length);}},{key:"canonicalString",value:function canonicalString(){// NOTE: The client is ignorant of any path segments containing escape
// sequences (e.g. __id123__) and just passes them through raw (they exist
// for legacy reasons and should not be used frequently).
return this.toArray().join('/');}},{key:"toString",value:function toString(){return this.canonicalString();}/**
     * Creates a resource path from the given slash-delimited string. If multiple
     * arguments are provided, all components are combined. Leading and trailing
     * slashes from all components are ignored.
     */}],[{key:"fromString",value:function fromString(){// NOTE: The client is ignorant of any path segments containing escape
// sequences (e.g. __id123__) and just passes them through raw (they exist
// for legacy reasons and should not be used frequently).
var segments=[];for(var _len4=arguments.length,pathComponents=new Array(_len4),_key5=0;_key5<_len4;_key5++){pathComponents[_key5]=arguments[_key5];}for(var _i=0,_pathComponents=pathComponents;_i<_pathComponents.length;_i++){var path=_pathComponents[_i];if(path.indexOf('//')>=0){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid segment (".concat(path,"). Paths must not contain // in them."));}// Strip leading and traling slashed.
segments.push.apply(segments,_toConsumableArray(path.split('/').filter(function(segment){return segment.length>0;})));}return new ResourcePath(segments);}},{key:"emptyPath",value:function emptyPath(){return new ResourcePath([]);}}]);return ResourcePath;}(BasePath);var identifierRegExp=/^[_a-zA-Z][_a-zA-Z0-9]*$/;/** A dot-separated path for navigating sub-objects within a document. */var FieldPath=/*#__PURE__*/function(_BasePath2){_inherits(FieldPath,_BasePath2);function FieldPath(){_classCallCheck(this,FieldPath);return _possibleConstructorReturn(this,_getPrototypeOf(FieldPath).apply(this,arguments));}_createClass(FieldPath,[{key:"construct",value:function construct(segments,offset,length){return new FieldPath(segments,offset,length);}/**
     * Returns true if the string could be used as a segment in a field path
     * without escaping.
     */},{key:"canonicalString",value:function canonicalString(){return this.toArray().map(function(str){str=str.replace('\\','\\\\').replace('`','\\`');if(!FieldPath.isValidIdentifier(str)){str='`'+str+'`';}return str;}).join('.');}},{key:"toString",value:function toString(){return this.canonicalString();}/**
     * Returns true if this field references the key of a document.
     */},{key:"isKeyField",value:function isKeyField(){return this.length===1&&this.get(0)===DOCUMENT_KEY_NAME;}/**
     * The field designating the key of a document.
     */}],[{key:"isValidIdentifier",value:function isValidIdentifier(segment){return identifierRegExp.test(segment);}},{key:"keyField",value:function keyField(){return new FieldPath([DOCUMENT_KEY_NAME]);}/**
     * Parses a field string from the given server-formatted string.
     *
     * - Splitting the empty string is not allowed (for now at least).
     * - Empty segments within the string (e.g. if there are two consecutive
     *   separators) are not allowed.
     *
     * TODO(b/37244157): we should make this more strict. Right now, it allows
     * non-identifier path components, even if they aren't escaped.
     */},{key:"fromServerFormat",value:function fromServerFormat(path){var segments=[];var current='';var i=0;var addCurrentSegment=function addCurrentSegment(){if(current.length===0){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid field path (".concat(path,"). Paths must not be empty, begin ")+"with '.', end with '.', or contain '..'");}segments.push(current);current='';};var inBackticks=false;while(i<path.length){var c=path[i];if(c==='\\'){if(i+1===path.length){throw new FirestoreError(Code.INVALID_ARGUMENT,'Path has trailing escape character: '+path);}var next=path[i+1];if(!(next==='\\'||next==='.'||next==='`')){throw new FirestoreError(Code.INVALID_ARGUMENT,'Path has invalid escape sequence: '+path);}current+=next;i+=2;}else if(c==='`'){inBackticks=!inBackticks;i++;}else if(c==='.'&&!inBackticks){addCurrentSegment();i++;}else{current+=c;i++;}}addCurrentSegment();if(inBackticks){throw new FirestoreError(Code.INVALID_ARGUMENT,'Unterminated ` in path: '+path);}return new FieldPath(segments);}},{key:"emptyPath",value:function emptyPath(){return new FieldPath([]);}}]);return FieldPath;}(BasePath);/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var DocumentKey=/*#__PURE__*/function(){function DocumentKey(path){_classCallCheck(this,DocumentKey);this.path=path;}_createClass(DocumentKey,[{key:"hasCollectionId",/** Returns true if the document is in the specified collectionId. */value:function hasCollectionId(collectionId){return this.path.length>=2&&this.path.get(this.path.length-2)===collectionId;}},{key:"isEqual",value:function isEqual(other){return other!==null&&ResourcePath.comparator(this.path,other.path)===0;}},{key:"toString",value:function toString(){return this.path.toString();}}],[{key:"fromPath",value:function fromPath(path){return new DocumentKey(ResourcePath.fromString(path));}},{key:"fromName",value:function fromName(name){return new DocumentKey(ResourcePath.fromString(name).popFirst(5));}},{key:"comparator",value:function comparator(k1,k2){return ResourcePath.comparator(k1.path,k2.path);}},{key:"isDocumentKey",value:function isDocumentKey(path){return path.length%2===0;}/**
     * Creates and returns a new document key with the given segments.
     *
     * @param segments The segments of the path to the document
     * @return A new instance of DocumentKey
     */},{key:"fromSegments",value:function fromSegments(segments){return new DocumentKey(new ResourcePath(segments.slice()));}}]);return DocumentKey;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Validates that no arguments were passed in the invocation of functionName.
 *
 * Forward the magic "arguments" variable as second parameter on which the
 * parameter validation is performed:
 * validateNoArgs('myFunction', arguments);
 */function validateNoArgs(functionName,args){if(args.length!==0){throw new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(functionName,"() does not support arguments, ")+'but was called with '+formatPlural(args.length,'argument')+'.');}}/**
 * Validates the invocation of functionName has the exact number of arguments.
 *
 * Forward the magic "arguments" variable as second parameter on which the
 * parameter validation is performed:
 * validateExactNumberOfArgs('myFunction', arguments, 2);
 */function validateExactNumberOfArgs(functionName,args,numberOfArgs){if(args.length!==numberOfArgs){throw new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(functionName,"() requires ")+formatPlural(numberOfArgs,'argument')+', but was called with '+formatPlural(args.length,'argument')+'.');}}/**
 * Validates the invocation of functionName has at least the provided number of
 * arguments (but can have many more).
 *
 * Forward the magic "arguments" variable as second parameter on which the
 * parameter validation is performed:
 * validateAtLeastNumberOfArgs('myFunction', arguments, 2);
 */function validateAtLeastNumberOfArgs(functionName,args,minNumberOfArgs){if(args.length<minNumberOfArgs){throw new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(functionName,"() requires at least ")+formatPlural(minNumberOfArgs,'argument')+', but was called with '+formatPlural(args.length,'argument')+'.');}}/**
 * Validates the invocation of functionName has number of arguments between
 * the values provided.
 *
 * Forward the magic "arguments" variable as second parameter on which the
 * parameter validation is performed:
 * validateBetweenNumberOfArgs('myFunction', arguments, 2, 3);
 */function validateBetweenNumberOfArgs(functionName,args,minNumberOfArgs,maxNumberOfArgs){if(args.length<minNumberOfArgs||args.length>maxNumberOfArgs){throw new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(functionName,"() requires between ").concat(minNumberOfArgs," and ")+"".concat(maxNumberOfArgs," arguments, but was called with ")+formatPlural(args.length,'argument')+'.');}}/**
 * Validates the provided argument is an array and has as least the expected
 * number of elements.
 */function validateNamedArrayAtLeastNumberOfElements(functionName,value,name,minNumberOfElements){if(!(value instanceof Array)||value.length<minNumberOfElements){throw new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(functionName,"() requires its ").concat(name," argument to be an ")+'array with at least '+"".concat(formatPlural(minNumberOfElements,'element'),"."));}}/**
 * Validates the provided positional argument has the native JavaScript type
 * using typeof checks.
 */function validateArgType(functionName,type,position,argument){validateType(functionName,type,"".concat(ordinal(position)," argument"),argument);}/**
 * Validates the provided argument has the native JavaScript type using
 * typeof checks or is undefined.
 */function validateOptionalArgType(functionName,type,position,argument){if(argument!==undefined){validateArgType(functionName,type,position,argument);}}/**
 * Validates the provided named option has the native JavaScript type using
 * typeof checks.
 */function validateNamedType(functionName,type,optionName,argument){validateType(functionName,type,"".concat(optionName," option"),argument);}/**
 * Validates the provided named option has the native JavaScript type using
 * typeof checks or is undefined.
 */function validateNamedOptionalType(functionName,type,optionName,argument){if(argument!==undefined){validateNamedType(functionName,type,optionName,argument);}}function validateArrayElements(functionName,optionName,typeDescription,argument,validator){if(!(argument instanceof Array)){throw new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(functionName,"() requires its ").concat(optionName," ")+"option to be an array, but it was: ".concat(valueDescription(argument)));}for(var i=0;i<argument.length;++i){if(!validator(argument[i])){throw new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(functionName,"() requires all ").concat(optionName," ")+"elements to be ".concat(typeDescription,", but the value at index ").concat(i," ")+"was: ".concat(valueDescription(argument[i])));}}}function validateOptionalArrayElements(functionName,optionName,typeDescription,argument,validator){if(argument!==undefined){validateArrayElements(functionName,optionName,typeDescription,argument,validator);}}/**
 * Validates that the provided named option equals one of the expected values.
 */function validateNamedPropertyEquals(functionName,inputName,optionName,input,expected){var expectedDescription=[];var _iteratorNormalCompletion=true;var _didIteratorError=false;var _iteratorError=undefined;try{for(var _iterator=expected[Symbol.iterator](),_step;!(_iteratorNormalCompletion=(_step=_iterator.next()).done);_iteratorNormalCompletion=true){var val=_step.value;if(val===input){return;}expectedDescription.push(valueDescription(val));}}catch(err){_didIteratorError=true;_iteratorError=err;}finally{try{if(!_iteratorNormalCompletion&&_iterator["return"]!=null){_iterator["return"]();}}finally{if(_didIteratorError){throw _iteratorError;}}}var actualDescription=valueDescription(input);throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid value ".concat(actualDescription," provided to function ").concat(functionName,"() for option ")+"\"".concat(optionName,"\". Acceptable values: ").concat(expectedDescription.join(', ')));}/**
 * Validates that the provided named option equals one of the expected values or
 * is undefined.
 */function validateNamedOptionalPropertyEquals(functionName,inputName,optionName,input,expected){if(input!==undefined){validateNamedPropertyEquals(functionName,inputName,optionName,input,expected);}}/**
 * Validates that the provided argument is a valid enum.
 *
 * @param functionName Function making the validation call.
 * @param enums Array containing all possible values for the enum.
 * @param position Position of the argument in `functionName`.
 * @param argument Argument to validate.
 * @return The value as T if the argument can be converted.
 */function validateStringEnum(functionName,enums,position,argument){if(!enums.some(function(element){return element===argument;})){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid value ".concat(valueDescription(argument)," provided to function ")+"".concat(functionName,"() for its ").concat(ordinal(position)," argument. Acceptable ")+"values: ".concat(enums.join(', ')));}return argument;}/** Helper to validate the type of a provided input. */function validateType(functionName,type,inputName,input){var valid=false;if(type==='object'){valid=isPlainObject(input);}else if(type==='non-empty string'){valid=typeof input==='string'&&input!=='';}else{valid=_typeof(input)===type;}if(!valid){var description=valueDescription(input);throw new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(functionName,"() requires its ").concat(inputName," ")+"to be of type ".concat(type,", but it was: ").concat(description));}}/**
 * Returns true if it's a non-null object without a custom prototype
 * (i.e. excludes Array, Date, etc.).
 */function isPlainObject(input){return _typeof(input)==='object'&&input!==null&&(Object.getPrototypeOf(input)===Object.prototype||Object.getPrototypeOf(input)===null);}/** Returns a string describing the type / value of the provided input. */function valueDescription(input){if(input===undefined){return'undefined';}else if(input===null){return'null';}else if(typeof input==='string'){if(input.length>20){input="".concat(input.substring(0,20),"...");}return JSON.stringify(input);}else if(typeof input==='number'||typeof input==='boolean'){return''+input;}else if(_typeof(input)==='object'){if(input instanceof Array){return'an array';}else{var customObjectName=tryGetCustomObjectType(input);if(customObjectName){return"a custom ".concat(customObjectName," object");}else{return'an object';}}}else if(typeof input==='function'){return'a function';}else{return fail();}}/** Hacky method to try to get the constructor name for an object. */function tryGetCustomObjectType(input){if(input.constructor){var funcNameRegex=/function\s+([^\s(]+)\s*\(/;var results=funcNameRegex.exec(input.constructor.toString());if(results&&results.length>1){return results[1];}}return null;}/** Validates the provided argument is defined. */function validateDefined(functionName,position,argument){if(argument===undefined){throw new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(functionName,"() requires a valid ").concat(ordinal(position)," ")+"argument, but it was undefined.");}}/**
 * Validates the provided positional argument is an object, and its keys and
 * values match the expected keys and types provided in optionTypes.
 */function validateOptionNames(functionName,options,optionNames){_forEach(options,function(key,_){if(optionNames.indexOf(key)<0){throw new FirestoreError(Code.INVALID_ARGUMENT,"Unknown option '".concat(key,"' passed to function ").concat(functionName,"(). ")+'Available options: '+optionNames.join(', '));}});}/**
 * Helper method to throw an error that the provided argument did not pass
 * an instanceof check.
 */function invalidClassError(functionName,type,position,argument){var description=valueDescription(argument);return new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(functionName,"() requires its ").concat(ordinal(position)," ")+"argument to be a ".concat(type,", but it was: ").concat(description));}function validatePositiveNumber(functionName,position,n){if(n<=0){throw new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(functionName,"() requires its ").concat(ordinal(position)," argument to be a positive number, but it was: ").concat(n,"."));}}/** Converts a number to its english word representation */function ordinal(num){switch(num){case 1:return'first';case 2:return'second';case 3:return'third';default:return num+'th';}}/**
 * Formats the given word as plural conditionally given the preceding number.
 */function formatPlural(num,str){return"".concat(num," ").concat(str)+(num===1?'':'s');}/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Generates `nBytes` of random bytes.
 *
 * If `nBytes < 0` , an error will be thrown.
 */function randomBytes(nBytes){return(0,_crypto.randomBytes)(nBytes);}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var AutoId=/*#__PURE__*/function(){function AutoId(){_classCallCheck(this,AutoId);}_createClass(AutoId,null,[{key:"newId",value:function newId(){// Alphanumeric characters
var chars='ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';// The largest byte value that is a multiple of `char.length`.
var maxMultiple=Math.floor(256/chars.length)*chars.length;var autoId='';var targetLength=20;while(autoId.length<targetLength){var bytes=randomBytes(40);for(var i=0;i<bytes.length;++i){// Only accept values that are [0, maxMultiple), this ensures they can
// be evenly mapped to indices of `chars` via a modulo operation.
if(autoId.length<targetLength&&bytes[i]<maxMultiple){autoId+=chars.charAt(bytes[i]%chars.length);}}}return autoId;}}]);return AutoId;}();function primitiveComparator(left,right){if(left<right){return-1;}if(left>right){return 1;}return 0;}/** Helper to compare arrays using isEqual(). */function arrayEquals(left,right,comparator){if(left.length!==right.length){return false;}return left.every(function(value,index){return comparator(value,right[index]);});}/**
 * Returns the immediate lexicographically-following string. This is useful to
 * construct an inclusive range for indexeddb iterators.
 */function immediateSuccessor(s){// Return the input string, with an additional NUL byte appended.
return s+'\0';}/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Immutable class that represents a "proto" byte string.
 *
 * Proto byte strings can either be Base64-encoded strings or Uint8Arrays when
 * sent on the wire. This class abstracts away this differentiation by holding
 * the proto byte string in a common class that must be converted into a string
 * before being sent as a proto.
 */var ByteString=/*#__PURE__*/function(){function ByteString(binaryString){_classCallCheck(this,ByteString);this.binaryString=binaryString;}_createClass(ByteString,[{key:"toBase64",value:function toBase64(){return encodeBase64(this.binaryString);}},{key:"toUint8Array",value:function toUint8Array(){return uint8ArrayFromBinaryString(this.binaryString);}},{key:"approximateByteSize",value:function approximateByteSize(){return this.binaryString.length*2;}},{key:"compareTo",value:function compareTo(other){return primitiveComparator(this.binaryString,other.binaryString);}},{key:"isEqual",value:function isEqual(other){return this.binaryString===other.binaryString;}}],[{key:"fromBase64String",value:function fromBase64String(base64){var binaryString=decodeBase64(base64);return new ByteString(binaryString);}},{key:"fromUint8Array",value:function fromUint8Array(array){var binaryString=binaryStringFromUint8Array(array);return new ByteString(binaryString);}}]);return ByteString;}();ByteString.EMPTY_BYTE_STRING=new ByteString('');/**
 * Helper function to convert an Uint8array to a binary string.
 */function binaryStringFromUint8Array(array){var binaryString='';for(var i=0;i<array.length;++i){binaryString+=String.fromCharCode(array[i]);}return binaryString;}/**
 * Helper function to convert a binary string to an Uint8Array.
 */function uint8ArrayFromBinaryString(binaryString){var buffer=new Uint8Array(binaryString.length);for(var i=0;i<binaryString.length;i++){buffer[i]=binaryString.charCodeAt(i);}return buffer;}/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * An immutable object representing an array of bytes.
 */var Bytes=/*#__PURE__*/function(){function Bytes(byteString){_classCallCheck(this,Bytes);this._byteString=byteString;}/**
     * Creates a new `Bytes` object from the given Base64 string, converting it to
     * bytes.
     *
     * @param base64 The Base64 string used to create the `Bytes` object.
     */_createClass(Bytes,[{key:"toBase64",/**
     * Returns the underlying bytes as a Base64-encoded string.
     *
     * @return The Base64-encoded string created from the `Bytes` object.
     */value:function toBase64(){return this._byteString.toBase64();}/**
     * Returns the underlying bytes in a new `Uint8Array`.
     *
     * @return The Uint8Array created from the `Bytes` object.
     */},{key:"toUint8Array",value:function toUint8Array(){return this._byteString.toUint8Array();}/**
     * Returns a string representation of the `Bytes` object.
     *
     * @return A string representation of the `Bytes` object.
     */},{key:"toString",value:function toString(){return'Bytes(base64: '+this.toBase64()+')';}/**
     * Returns true if this `Bytes` object is equal to the provided one.
     *
     * @param other The `Bytes` object to compare against.
     * @return true if this `Bytes` object is equal to the provided one.
     */},{key:"isEqual",value:function isEqual(other){return this._byteString.isEqual(other._byteString);}}],[{key:"fromBase64String",value:function fromBase64String(base64){try{return new Bytes(ByteString.fromBase64String(base64));}catch(e){throw new FirestoreError(Code.INVALID_ARGUMENT,'Failed to construct Bytes from Base64 string: '+e);}}/**
     * Creates a new `Bytes` object from the given Uint8Array.
     *
     * @param array The Uint8Array used to create the `Bytes` object.
     */},{key:"fromUint8Array",value:function fromUint8Array(array){return new Bytes(ByteString.fromUint8Array(array));}}]);return Bytes;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /** Helper function to assert Uint8Array is available at runtime. */function assertUint8ArrayAvailable(){if(typeof Uint8Array==='undefined'){throw new FirestoreError(Code.UNIMPLEMENTED,'Uint8Arrays are not available in this environment.');}}/**
 * Immutable class holding a blob (binary data).
 *
 * This class is directly exposed in the public API. It extends the Bytes class
 * of the firestore-exp API to support `instanceof Bytes` checks during user
 * data conversion.
 *
 * Note that while you can't hide the constructor in JavaScript code, we are
 * using the hack above to make sure no-one outside this module can call it.
 */var Blob=/*#__PURE__*/function(_Bytes){_inherits(Blob,_Bytes);function Blob(){_classCallCheck(this,Blob);return _possibleConstructorReturn(this,_getPrototypeOf(Blob).apply(this,arguments));}_createClass(Blob,[{key:"toBase64",value:function toBase64(){validateExactNumberOfArgs('Blob.toBase64',arguments,0);return _get(_getPrototypeOf(Blob.prototype),"toBase64",this).call(this);}},{key:"toUint8Array",value:function toUint8Array(){validateExactNumberOfArgs('Blob.toUint8Array',arguments,0);assertUint8ArrayAvailable();return _get(_getPrototypeOf(Blob.prototype),"toUint8Array",this).call(this);}},{key:"toString",value:function toString(){return'Blob(base64: '+this.toBase64()+')';}}],[{key:"fromBase64String",value:function fromBase64String(base64){validateExactNumberOfArgs('Blob.fromBase64String',arguments,1);validateArgType('Blob.fromBase64String','string',1,base64);try{return new Blob(ByteString.fromBase64String(base64));}catch(e){throw new FirestoreError(Code.INVALID_ARGUMENT,'Failed to construct Blob from Base64 string: '+e);}}},{key:"fromUint8Array",value:function fromUint8Array(array){validateExactNumberOfArgs('Blob.fromUint8Array',arguments,1);assertUint8ArrayAvailable();if(!(array instanceof Uint8Array)){throw invalidClassError('Blob.fromUint8Array','Uint8Array',1,array);}return new Blob(ByteString.fromUint8Array(array));}}]);return Blob;}(Bytes);/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var DatabaseInfo=/**
     * Constructs a DatabaseInfo using the provided host, databaseId and
     * persistenceKey.
     *
     * @param databaseId The database to use.
     * @param persistenceKey A unique identifier for this Firestore's local
     * storage (used in conjunction with the databaseId).
     * @param host The Firestore backend host to connect to.
     * @param ssl Whether to use SSL when connecting.
     * @param forceLongPolling Whether to use the forceLongPolling option
     * when using WebChannel as the network transport.
     */function DatabaseInfo(databaseId,persistenceKey,host,ssl,forceLongPolling){_classCallCheck(this,DatabaseInfo);this.databaseId=databaseId;this.persistenceKey=persistenceKey;this.host=host;this.ssl=ssl;this.forceLongPolling=forceLongPolling;};/** The default database name for a project. */var DEFAULT_DATABASE_NAME='(default)';/** Represents the database ID a Firestore client is associated with. */var DatabaseId=/*#__PURE__*/function(){function DatabaseId(projectId,database){_classCallCheck(this,DatabaseId);this.projectId=projectId;this.database=database?database:DEFAULT_DATABASE_NAME;}_createClass(DatabaseId,[{key:"isEqual",value:function isEqual(other){return other instanceof DatabaseId&&other.projectId===this.projectId&&other.database===this.database;}},{key:"compareTo",value:function compareTo(other){return primitiveComparator(this.projectId,other.projectId)||primitiveComparator(this.database,other.database);}},{key:"isDefaultDatabase",get:function get(){return this.database===DEFAULT_DATABASE_NAME;}}]);return DatabaseId;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Simple wrapper around a nullable UID. Mostly exists to make code more
 * readable.
 */var User=/*#__PURE__*/function(){function User(uid){_classCallCheck(this,User);this.uid=uid;}_createClass(User,[{key:"isAuthenticated",value:function isAuthenticated(){return this.uid!=null;}/**
     * Returns a key representing this user, suitable for inclusion in a
     * dictionary.
     */},{key:"toKey",value:function toKey(){if(this.isAuthenticated()){return'uid:'+this.uid;}else{return'anonymous-user';}}},{key:"isEqual",value:function isEqual(otherUser){return otherUser.uid===this.uid;}}]);return User;}();/** A user with a null UID. */User.UNAUTHENTICATED=new User(null);// TODO(mikelehen): Look into getting a proper uid-equivalent for
// non-FirebaseAuth providers.
User.GOOGLE_CREDENTIALS=new User('google-credentials-uid');User.FIRST_PARTY=new User('first-party-uid');/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * `ListenSequence` is a monotonic sequence. It is initialized with a minimum value to
 * exceed. All subsequent calls to next will return increasing values. If provided with a
 * `SequenceNumberSyncer`, it will additionally bump its next value when told of a new value, as
 * well as write out sequence numbers that it produces via `next()`.
 */var ListenSequence=/*#__PURE__*/function(){function ListenSequence(previousValue,sequenceNumberSyncer){var _this2=this;_classCallCheck(this,ListenSequence);this.previousValue=previousValue;if(sequenceNumberSyncer){sequenceNumberSyncer.sequenceNumberHandler=function(sequenceNumber){return _this2.setPreviousValue(sequenceNumber);};this.writeNewSequenceNumber=function(sequenceNumber){return sequenceNumberSyncer.writeSequenceNumber(sequenceNumber);};}}_createClass(ListenSequence,[{key:"setPreviousValue",value:function setPreviousValue(externalPreviousValue){this.previousValue=Math.max(externalPreviousValue,this.previousValue);return this.previousValue;}},{key:"next",value:function next(){var nextValue=++this.previousValue;if(this.writeNewSequenceNumber){this.writeNewSequenceNumber(nextValue);}return nextValue;}}]);return ListenSequence;}();ListenSequence.INVALID=-1;/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ // An immutable sorted map implementation, based on a Left-leaning Red-Black
// tree.
var SortedMap=/*#__PURE__*/function(){function SortedMap(comparator,root){_classCallCheck(this,SortedMap);this.comparator=comparator;this.root=root?root:LLRBNode.EMPTY;}// Returns a copy of the map, with the specified key/value added or replaced.
_createClass(SortedMap,[{key:"insert",value:function insert(key,value){return new SortedMap(this.comparator,this.root.insert(key,value,this.comparator).copy(null,null,LLRBNode.BLACK,null,null));}// Returns a copy of the map, with the specified key removed.
},{key:"remove",value:function remove(key){return new SortedMap(this.comparator,this.root.remove(key,this.comparator).copy(null,null,LLRBNode.BLACK,null,null));}// Returns the value of the node with the given key, or null.
},{key:"get",value:function get(key){var node=this.root;while(!node.isEmpty()){var cmp=this.comparator(key,node.key);if(cmp===0){return node.value;}else if(cmp<0){node=node.left;}else if(cmp>0){node=node.right;}}return null;}// Returns the index of the element in this sorted map, or -1 if it doesn't
// exist.
},{key:"indexOf",value:function indexOf(key){// Number of nodes that were pruned when descending right
var prunedNodes=0;var node=this.root;while(!node.isEmpty()){var cmp=this.comparator(key,node.key);if(cmp===0){return prunedNodes+node.left.size;}else if(cmp<0){node=node.left;}else{// Count all nodes left of the node plus the node itself
prunedNodes+=node.left.size+1;node=node.right;}}// Node not found
return-1;}},{key:"isEmpty",value:function isEmpty(){return this.root.isEmpty();}// Returns the total number of nodes in the map.
},{key:"minKey",// Returns the minimum key in the map.
value:function minKey(){return this.root.minKey();}// Returns the maximum key in the map.
},{key:"maxKey",value:function maxKey(){return this.root.maxKey();}// Traverses the map in key order and calls the specified action function
// for each key/value pair. If action returns true, traversal is aborted.
// Returns the first truthy value returned by action, or the last falsey
// value returned by action.
},{key:"inorderTraversal",value:function inorderTraversal(action){return this.root.inorderTraversal(action);}},{key:"forEach",value:function forEach(fn){this.inorderTraversal(function(k,v){fn(k,v);return false;});}},{key:"toString",value:function toString(){var descriptions=[];this.inorderTraversal(function(k,v){descriptions.push("".concat(k,":").concat(v));return false;});return"{".concat(descriptions.join(', '),"}");}// Traverses the map in reverse key order and calls the specified action
// function for each key/value pair. If action returns true, traversal is
// aborted.
// Returns the first truthy value returned by action, or the last falsey
// value returned by action.
},{key:"reverseTraversal",value:function reverseTraversal(action){return this.root.reverseTraversal(action);}// Returns an iterator over the SortedMap.
},{key:"getIterator",value:function getIterator(){return new SortedMapIterator(this.root,null,this.comparator,false);}},{key:"getIteratorFrom",value:function getIteratorFrom(key){return new SortedMapIterator(this.root,key,this.comparator,false);}},{key:"getReverseIterator",value:function getReverseIterator(){return new SortedMapIterator(this.root,null,this.comparator,true);}},{key:"getReverseIteratorFrom",value:function getReverseIteratorFrom(key){return new SortedMapIterator(this.root,key,this.comparator,true);}},{key:"size",get:function get(){return this.root.size;}}]);return SortedMap;}();// end SortedMap
// An iterator over an LLRBNode.
var SortedMapIterator=/*#__PURE__*/function(){function SortedMapIterator(node,startKey,comparator,isReverse){_classCallCheck(this,SortedMapIterator);this.isReverse=isReverse;this.nodeStack=[];var cmp=1;while(!node.isEmpty()){cmp=startKey?comparator(node.key,startKey):1;// flip the comparison if we're going in reverse
if(isReverse){cmp*=-1;}if(cmp<0){// This node is less than our start key. ignore it
if(this.isReverse){node=node.left;}else{node=node.right;}}else if(cmp===0){// This node is exactly equal to our start key. Push it on the stack,
// but stop iterating;
this.nodeStack.push(node);break;}else{// This node is greater than our start key, add it to the stack and move
// to the next one
this.nodeStack.push(node);if(this.isReverse){node=node.right;}else{node=node.left;}}}}_createClass(SortedMapIterator,[{key:"getNext",value:function getNext(){var node=this.nodeStack.pop();var result={key:node.key,value:node.value};if(this.isReverse){node=node.left;while(!node.isEmpty()){this.nodeStack.push(node);node=node.right;}}else{node=node.right;while(!node.isEmpty()){this.nodeStack.push(node);node=node.left;}}return result;}},{key:"hasNext",value:function hasNext(){return this.nodeStack.length>0;}},{key:"peek",value:function peek(){if(this.nodeStack.length===0){return null;}var node=this.nodeStack[this.nodeStack.length-1];return{key:node.key,value:node.value};}}]);return SortedMapIterator;}();// end SortedMapIterator
// Represents a node in a Left-leaning Red-Black tree.
var LLRBNode=/*#__PURE__*/function(){function LLRBNode(key,value,color,left,right){_classCallCheck(this,LLRBNode);this.key=key;this.value=value;this.color=color!=null?color:LLRBNode.RED;this.left=left!=null?left:LLRBNode.EMPTY;this.right=right!=null?right:LLRBNode.EMPTY;this.size=this.left.size+1+this.right.size;}// Returns a copy of the current node, optionally replacing pieces of it.
_createClass(LLRBNode,[{key:"copy",value:function copy(key,value,color,left,right){return new LLRBNode(key!=null?key:this.key,value!=null?value:this.value,color!=null?color:this.color,left!=null?left:this.left,right!=null?right:this.right);}},{key:"isEmpty",value:function isEmpty(){return false;}// Traverses the tree in key order and calls the specified action function
// for each node. If action returns true, traversal is aborted.
// Returns the first truthy value returned by action, or the last falsey
// value returned by action.
},{key:"inorderTraversal",value:function inorderTraversal(action){return this.left.inorderTraversal(action)||action(this.key,this.value)||this.right.inorderTraversal(action);}// Traverses the tree in reverse key order and calls the specified action
// function for each node. If action returns true, traversal is aborted.
// Returns the first truthy value returned by action, or the last falsey
// value returned by action.
},{key:"reverseTraversal",value:function reverseTraversal(action){return this.right.reverseTraversal(action)||action(this.key,this.value)||this.left.reverseTraversal(action);}// Returns the minimum node in the tree.
},{key:"min",value:function min(){if(this.left.isEmpty()){return this;}else{return this.left.min();}}// Returns the maximum key in the tree.
},{key:"minKey",value:function minKey(){return this.min().key;}// Returns the maximum key in the tree.
},{key:"maxKey",value:function maxKey(){if(this.right.isEmpty()){return this.key;}else{return this.right.maxKey();}}// Returns new tree, with the key/value added.
},{key:"insert",value:function insert(key,value,comparator){var n=this;var cmp=comparator(key,n.key);if(cmp<0){n=n.copy(null,null,null,n.left.insert(key,value,comparator),null);}else if(cmp===0){n=n.copy(null,value,null,null,null);}else{n=n.copy(null,null,null,null,n.right.insert(key,value,comparator));}return n.fixUp();}},{key:"removeMin",value:function removeMin(){if(this.left.isEmpty()){return LLRBNode.EMPTY;}var n=this;if(!n.left.isRed()&&!n.left.left.isRed()){n=n.moveRedLeft();}n=n.copy(null,null,null,n.left.removeMin(),null);return n.fixUp();}// Returns new tree, with the specified item removed.
},{key:"remove",value:function remove(key,comparator){var smallest;var n=this;if(comparator(key,n.key)<0){if(!n.left.isEmpty()&&!n.left.isRed()&&!n.left.left.isRed()){n=n.moveRedLeft();}n=n.copy(null,null,null,n.left.remove(key,comparator),null);}else{if(n.left.isRed()){n=n.rotateRight();}if(!n.right.isEmpty()&&!n.right.isRed()&&!n.right.left.isRed()){n=n.moveRedRight();}if(comparator(key,n.key)===0){if(n.right.isEmpty()){return LLRBNode.EMPTY;}else{smallest=n.right.min();n=n.copy(smallest.key,smallest.value,null,null,n.right.removeMin());}}n=n.copy(null,null,null,null,n.right.remove(key,comparator));}return n.fixUp();}},{key:"isRed",value:function isRed(){return this.color;}// Returns new tree after performing any needed rotations.
},{key:"fixUp",value:function fixUp(){var n=this;if(n.right.isRed()&&!n.left.isRed()){n=n.rotateLeft();}if(n.left.isRed()&&n.left.left.isRed()){n=n.rotateRight();}if(n.left.isRed()&&n.right.isRed()){n=n.colorFlip();}return n;}},{key:"moveRedLeft",value:function moveRedLeft(){var n=this.colorFlip();if(n.right.left.isRed()){n=n.copy(null,null,null,null,n.right.rotateRight());n=n.rotateLeft();n=n.colorFlip();}return n;}},{key:"moveRedRight",value:function moveRedRight(){var n=this.colorFlip();if(n.left.left.isRed()){n=n.rotateRight();n=n.colorFlip();}return n;}},{key:"rotateLeft",value:function rotateLeft(){var nl=this.copy(null,null,LLRBNode.RED,null,this.right.left);return this.right.copy(null,null,this.color,nl,null);}},{key:"rotateRight",value:function rotateRight(){var nr=this.copy(null,null,LLRBNode.RED,this.left.right,null);return this.left.copy(null,null,this.color,null,nr);}},{key:"colorFlip",value:function colorFlip(){var left=this.left.copy(null,null,!this.left.color,null,null);var right=this.right.copy(null,null,!this.right.color,null,null);return this.copy(null,null,!this.color,left,right);}// For testing.
},{key:"checkMaxDepth",value:function checkMaxDepth(){var blackDepth=this.check();if(Math.pow(2.0,blackDepth)<=this.size+1){return true;}else{return false;}}// In a balanced RB tree, the black-depth (number of black nodes) from root to
// leaves is equal on both sides.  This function verifies that or asserts.
},{key:"check",value:function check(){if(this.isRed()&&this.left.isRed()){throw fail();}if(this.right.isRed()){throw fail();}var blackDepth=this.left.check();if(blackDepth!==this.right.check()){throw fail();}else{return blackDepth+(this.isRed()?0:1);}}}]);return LLRBNode;}();// end LLRBNode
// Empty node is shared between all LLRB trees.
// eslint-disable-next-line @typescript-eslint/no-explicit-any
LLRBNode.EMPTY=null;LLRBNode.RED=true;LLRBNode.BLACK=false;// Represents an empty node (a leaf node in the Red-Black Tree).
var LLRBEmptyNode=/*#__PURE__*/function(){function LLRBEmptyNode(){_classCallCheck(this,LLRBEmptyNode);this.size=0;}_createClass(LLRBEmptyNode,[{key:"copy",// Returns a copy of the current node.
value:function copy(key,value,color,left,right){return this;}// Returns a copy of the tree, with the specified key/value added.
},{key:"insert",value:function insert(key,value,comparator){return new LLRBNode(key,value);}// Returns a copy of the tree, with the specified key removed.
},{key:"remove",value:function remove(key,comparator){return this;}},{key:"isEmpty",value:function isEmpty(){return true;}},{key:"inorderTraversal",value:function inorderTraversal(action){return false;}},{key:"reverseTraversal",value:function reverseTraversal(action){return false;}},{key:"minKey",value:function minKey(){return null;}},{key:"maxKey",value:function maxKey(){return null;}},{key:"isRed",value:function isRed(){return false;}// For testing.
},{key:"checkMaxDepth",value:function checkMaxDepth(){return true;}},{key:"check",value:function check(){return 0;}},{key:"key",get:function get(){throw fail();}},{key:"value",get:function get(){throw fail();}},{key:"color",get:function get(){throw fail();}},{key:"left",get:function get(){throw fail();}},{key:"right",get:function get(){throw fail();}}]);return LLRBEmptyNode;}();// end LLRBEmptyNode
LLRBNode.EMPTY=new LLRBEmptyNode();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * SortedSet is an immutable (copy-on-write) collection that holds elements
 * in order specified by the provided comparator.
 *
 * NOTE: if provided comparator returns 0 for two elements, we consider them to
 * be equal!
 */var SortedSet=/*#__PURE__*/function(){function SortedSet(comparator){_classCallCheck(this,SortedSet);this.comparator=comparator;this.data=new SortedMap(this.comparator);}_createClass(SortedSet,[{key:"has",value:function has(elem){return this.data.get(elem)!==null;}},{key:"first",value:function first(){return this.data.minKey();}},{key:"last",value:function last(){return this.data.maxKey();}},{key:"indexOf",value:function indexOf(elem){return this.data.indexOf(elem);}/** Iterates elements in order defined by "comparator" */},{key:"forEach",value:function forEach(cb){this.data.inorderTraversal(function(k,v){cb(k);return false;});}/** Iterates over `elem`s such that: range[0] <= elem < range[1]. */},{key:"forEachInRange",value:function forEachInRange(range,cb){var iter=this.data.getIteratorFrom(range[0]);while(iter.hasNext()){var elem=iter.getNext();if(this.comparator(elem.key,range[1])>=0){return;}cb(elem.key);}}/**
     * Iterates over `elem`s such that: start <= elem until false is returned.
     */},{key:"forEachWhile",value:function forEachWhile(cb,start){var iter;if(start!==undefined){iter=this.data.getIteratorFrom(start);}else{iter=this.data.getIterator();}while(iter.hasNext()){var elem=iter.getNext();var result=cb(elem.key);if(!result){return;}}}/** Finds the least element greater than or equal to `elem`. */},{key:"firstAfterOrEqual",value:function firstAfterOrEqual(elem){var iter=this.data.getIteratorFrom(elem);return iter.hasNext()?iter.getNext().key:null;}},{key:"getIterator",value:function getIterator(){return new SortedSetIterator(this.data.getIterator());}},{key:"getIteratorFrom",value:function getIteratorFrom(key){return new SortedSetIterator(this.data.getIteratorFrom(key));}/** Inserts or updates an element */},{key:"add",value:function add(elem){return this.copy(this.data.remove(elem).insert(elem,true));}/** Deletes an element */},{key:"delete",value:function _delete(elem){if(!this.has(elem)){return this;}return this.copy(this.data.remove(elem));}},{key:"isEmpty",value:function isEmpty(){return this.data.isEmpty();}},{key:"unionWith",value:function unionWith(other){var result=this;// Make sure `result` always refers to the larger one of the two sets.
if(result.size<other.size){result=other;other=this;}other.forEach(function(elem){result=result.add(elem);});return result;}},{key:"isEqual",value:function isEqual(other){if(!(other instanceof SortedSet)){return false;}if(this.size!==other.size){return false;}var thisIt=this.data.getIterator();var otherIt=other.data.getIterator();while(thisIt.hasNext()){var thisElem=thisIt.getNext().key;var otherElem=otherIt.getNext().key;if(this.comparator(thisElem,otherElem)!==0){return false;}}return true;}},{key:"toArray",value:function toArray(){var res=[];this.forEach(function(targetId){res.push(targetId);});return res;}},{key:"toString",value:function toString(){var result=[];this.forEach(function(elem){return result.push(elem);});return'SortedSet('+result.toString()+')';}},{key:"copy",value:function copy(data){var result=new SortedSet(this.comparator);result.data=data;return result;}},{key:"size",get:function get(){return this.data.size;}}]);return SortedSet;}();var SortedSetIterator=/*#__PURE__*/function(){function SortedSetIterator(iter){_classCallCheck(this,SortedSetIterator);this.iter=iter;}_createClass(SortedSetIterator,[{key:"getNext",value:function getNext(){return this.iter.getNext().key;}},{key:"hasNext",value:function hasNext(){return this.iter.hasNext();}}]);return SortedSetIterator;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var EMPTY_MAYBE_DOCUMENT_MAP=new SortedMap(DocumentKey.comparator);function maybeDocumentMap(){return EMPTY_MAYBE_DOCUMENT_MAP;}function nullableMaybeDocumentMap(){return maybeDocumentMap();}var EMPTY_DOCUMENT_MAP=new SortedMap(DocumentKey.comparator);function documentMap(){return EMPTY_DOCUMENT_MAP;}var EMPTY_DOCUMENT_VERSION_MAP=new SortedMap(DocumentKey.comparator);function documentVersionMap(){return EMPTY_DOCUMENT_VERSION_MAP;}var EMPTY_DOCUMENT_KEY_SET=new SortedSet(DocumentKey.comparator);function documentKeySet(){var set=EMPTY_DOCUMENT_KEY_SET;for(var _len5=arguments.length,keys=new Array(_len5),_key6=0;_key6<_len5;_key6++){keys[_key6]=arguments[_key6];}for(var _i2=0,_keys=keys;_i2<_keys.length;_i2++){var key=_keys[_i2];set=set.add(key);}return set;}var EMPTY_TARGET_ID_SET=new SortedSet(primitiveComparator);function targetIdSet(){return EMPTY_TARGET_ID_SET;}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Returns whether a variable is either undefined or null.
 */function isNullOrUndefined(value){return value===null||value===undefined;}/** Returns whether the value represents -0. */function isNegativeZero(value){// Detect if the value is -0.0. Based on polyfill from
// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is
return value===0&&1/value===1/-0;}/**
 * Returns whether a value is an integer and in the safe integer range
 * @param value The value to test for being an integer and in the safe range
 */function isSafeInteger(value){return typeof value==='number'&&Number.isInteger(value)&&!isNegativeZero(value)&&value<=Number.MAX_SAFE_INTEGER&&value>=Number.MIN_SAFE_INTEGER;}/**
 * @license
 * Copyright 2019 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ // The format of the LocalStorage key that stores the client state is:
//     firestore_clients_<persistence_prefix>_<instance_key>
var CLIENT_STATE_KEY_PREFIX='firestore_clients';/** Assembles the key for a client state in WebStorage */function createWebStorageClientStateKey(persistenceKey,clientId){return"".concat(CLIENT_STATE_KEY_PREFIX,"_").concat(persistenceKey,"_").concat(clientId);}// The format of the WebStorage key that stores the mutation state is:
//     firestore_mutations_<persistence_prefix>_<batch_id>
//     (for unauthenticated users)
// or: firestore_mutations_<persistence_prefix>_<batch_id>_<user_uid>
//
// 'user_uid' is last to avoid needing to escape '_' characters that it might
// contain.
var MUTATION_BATCH_KEY_PREFIX='firestore_mutations';/** Assembles the key for a mutation batch in WebStorage */function createWebStorageMutationBatchKey(persistenceKey,user,batchId){var mutationKey="".concat(MUTATION_BATCH_KEY_PREFIX,"_").concat(persistenceKey,"_").concat(batchId);if(user.isAuthenticated()){mutationKey+="_".concat(user.uid);}return mutationKey;}// The format of the WebStorage key that stores a query target's metadata is:
//     firestore_targets_<persistence_prefix>_<target_id>
var QUERY_TARGET_KEY_PREFIX='firestore_targets';/** Assembles the key for a query state in WebStorage */function createWebStorageQueryTargetMetadataKey(persistenceKey,targetId){return"".concat(QUERY_TARGET_KEY_PREFIX,"_").concat(persistenceKey,"_").concat(targetId);}// The WebStorage prefix that stores the primary tab's online state. The
// format of the key is:
//     firestore_online_state_<persistence_prefix>
var ONLINE_STATE_KEY_PREFIX='firestore_online_state';/** Assembles the key for the online state of the primary tab. */function createWebStorageOnlineStateKey(persistenceKey){return"".concat(ONLINE_STATE_KEY_PREFIX,"_").concat(persistenceKey);}// The WebStorage key prefix for the key that stores the last sequence number allocated. The key
// looks like 'firestore_sequence_number_<persistence_prefix>'.
var SEQUENCE_NUMBER_KEY_PREFIX='firestore_sequence_number';/** Assembles the key for the current sequence number. */function createWebStorageSequenceNumberKey(persistenceKey){return"".concat(SEQUENCE_NUMBER_KEY_PREFIX,"_").concat(persistenceKey);}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG='SharedClientState';/**
 * Holds the state of a mutation batch, including its user ID, batch ID and
 * whether the batch is 'pending', 'acknowledged' or 'rejected'.
 */ // Visible for testing
var MutationMetadata=/*#__PURE__*/function(){function MutationMetadata(user,batchId,state,error){_classCallCheck(this,MutationMetadata);this.user=user;this.batchId=batchId;this.state=state;this.error=error;}/**
     * Parses a MutationMetadata from its JSON representation in WebStorage.
     * Logs a warning and returns null if the format of the data is not valid.
     */_createClass(MutationMetadata,[{key:"toWebStorageJSON",value:function toWebStorageJSON(){var batchMetadata={state:this.state,updateTimeMs:Date.now()// Modify the existing value to trigger update.
};if(this.error){batchMetadata.error={code:this.error.code,message:this.error.message};}return JSON.stringify(batchMetadata);}}],[{key:"fromWebStorageEntry",value:function fromWebStorageEntry(user,batchId,value){var mutationBatch=JSON.parse(value);var validData=_typeof(mutationBatch)==='object'&&['pending','acknowledged','rejected'].indexOf(mutationBatch.state)!==-1&&(mutationBatch.error===undefined||_typeof(mutationBatch.error)==='object');var firestoreError=undefined;if(validData&&mutationBatch.error){validData=typeof mutationBatch.error.message==='string'&&typeof mutationBatch.error.code==='string';if(validData){firestoreError=new FirestoreError(mutationBatch.error.code,mutationBatch.error.message);}}if(validData){return new MutationMetadata(user,batchId,mutationBatch.state,firestoreError);}else{logError(LOG_TAG,"Failed to parse mutation state for ID '".concat(batchId,"': ").concat(value));return null;}}}]);return MutationMetadata;}();/**
 * Holds the state of a query target, including its target ID and whether the
 * target is 'not-current', 'current' or 'rejected'.
 */ // Visible for testing
var QueryTargetMetadata=/*#__PURE__*/function(){function QueryTargetMetadata(targetId,state,error){_classCallCheck(this,QueryTargetMetadata);this.targetId=targetId;this.state=state;this.error=error;}/**
     * Parses a QueryTargetMetadata from its JSON representation in WebStorage.
     * Logs a warning and returns null if the format of the data is not valid.
     */_createClass(QueryTargetMetadata,[{key:"toWebStorageJSON",value:function toWebStorageJSON(){var targetState={state:this.state,updateTimeMs:Date.now()// Modify the existing value to trigger update.
};if(this.error){targetState.error={code:this.error.code,message:this.error.message};}return JSON.stringify(targetState);}}],[{key:"fromWebStorageEntry",value:function fromWebStorageEntry(targetId,value){var targetState=JSON.parse(value);var validData=_typeof(targetState)==='object'&&['not-current','current','rejected'].indexOf(targetState.state)!==-1&&(targetState.error===undefined||_typeof(targetState.error)==='object');var firestoreError=undefined;if(validData&&targetState.error){validData=typeof targetState.error.message==='string'&&typeof targetState.error.code==='string';if(validData){firestoreError=new FirestoreError(targetState.error.code,targetState.error.message);}}if(validData){return new QueryTargetMetadata(targetId,targetState.state,firestoreError);}else{logError(LOG_TAG,"Failed to parse target state for ID '".concat(targetId,"': ").concat(value));return null;}}}]);return QueryTargetMetadata;}();/**
 * This class represents the immutable ClientState for a client read from
 * WebStorage, containing the list of active query targets.
 */var RemoteClientState=/*#__PURE__*/function(){function RemoteClientState(clientId,activeTargetIds){_classCallCheck(this,RemoteClientState);this.clientId=clientId;this.activeTargetIds=activeTargetIds;}/**
     * Parses a RemoteClientState from the JSON representation in WebStorage.
     * Logs a warning and returns null if the format of the data is not valid.
     */_createClass(RemoteClientState,null,[{key:"fromWebStorageEntry",value:function fromWebStorageEntry(clientId,value){var clientState=JSON.parse(value);var validData=_typeof(clientState)==='object'&&clientState.activeTargetIds instanceof Array;var activeTargetIdsSet=targetIdSet();for(var i=0;validData&&i<clientState.activeTargetIds.length;++i){validData=isSafeInteger(clientState.activeTargetIds[i]);activeTargetIdsSet=activeTargetIdsSet.add(clientState.activeTargetIds[i]);}if(validData){return new RemoteClientState(clientId,activeTargetIdsSet);}else{logError(LOG_TAG,"Failed to parse client data for instance '".concat(clientId,"': ").concat(value));return null;}}}]);return RemoteClientState;}();/**
 * This class represents the online state for all clients participating in
 * multi-tab. The online state is only written to by the primary client, and
 * used in secondary clients to update their query views.
 */var SharedOnlineState=/*#__PURE__*/function(){function SharedOnlineState(clientId,onlineState){_classCallCheck(this,SharedOnlineState);this.clientId=clientId;this.onlineState=onlineState;}/**
     * Parses a SharedOnlineState from its JSON representation in WebStorage.
     * Logs a warning and returns null if the format of the data is not valid.
     */_createClass(SharedOnlineState,null,[{key:"fromWebStorageEntry",value:function fromWebStorageEntry(value){var onlineState=JSON.parse(value);var validData=_typeof(onlineState)==='object'&&['Unknown','Online','Offline'].indexOf(onlineState.onlineState)!==-1&&typeof onlineState.clientId==='string';if(validData){return new SharedOnlineState(onlineState.clientId,onlineState.onlineState);}else{logError(LOG_TAG,"Failed to parse online state: ".concat(value));return null;}}}]);return SharedOnlineState;}();/**
 * Metadata state of the local client. Unlike `RemoteClientState`, this class is
 * mutable and keeps track of all pending mutations, which allows us to
 * update the range of pending mutation batch IDs as new mutations are added or
 * removed.
 *
 * The data in `LocalClientState` is not read from WebStorage and instead
 * updated via its instance methods. The updated state can be serialized via
 * `toWebStorageJSON()`.
 */ // Visible for testing.
var LocalClientState=/*#__PURE__*/function(){function LocalClientState(){_classCallCheck(this,LocalClientState);this.activeTargetIds=targetIdSet();}_createClass(LocalClientState,[{key:"addQueryTarget",value:function addQueryTarget(targetId){this.activeTargetIds=this.activeTargetIds.add(targetId);}},{key:"removeQueryTarget",value:function removeQueryTarget(targetId){this.activeTargetIds=this.activeTargetIds["delete"](targetId);}/**
     * Converts this entry into a JSON-encoded format we can use for WebStorage.
     * Does not encode `clientId` as it is part of the key in WebStorage.
     */},{key:"toWebStorageJSON",value:function toWebStorageJSON(){var data={activeTargetIds:this.activeTargetIds.toArray(),updateTimeMs:Date.now()// Modify the existing value to trigger update.
};return JSON.stringify(data);}}]);return LocalClientState;}();/**
 * `WebStorageSharedClientState` uses WebStorage (window.localStorage) as the
 * backing store for the SharedClientState. It keeps track of all active
 * clients and supports modifications of the local client's data.
 */var WebStorageSharedClientState=/*#__PURE__*/function(){function WebStorageSharedClientState(window,queue,persistenceKey,localClientId,initialUser){_classCallCheck(this,WebStorageSharedClientState);this.window=window;this.queue=queue;this.persistenceKey=persistenceKey;this.localClientId=localClientId;this.syncEngine=null;this.onlineStateHandler=null;this.sequenceNumberHandler=null;this.storageListener=this.handleWebStorageEvent.bind(this);this.activeClients=new SortedMap(primitiveComparator);this.started=false;/**
         * Captures WebStorage events that occur before `start()` is called. These
         * events are replayed once `WebStorageSharedClientState` is started.
         */this.earlyEvents=[];// Escape the special characters mentioned here:
// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions
var escapedPersistenceKey=persistenceKey.replace(/[.*+?^${}()|[\]\\]/g,'\\$&');this.storage=this.window.localStorage;this.currentUser=initialUser;this.localClientStorageKey=createWebStorageClientStateKey(this.persistenceKey,this.localClientId);this.sequenceNumberKey=createWebStorageSequenceNumberKey(this.persistenceKey);this.activeClients=this.activeClients.insert(this.localClientId,new LocalClientState());this.clientStateKeyRe=new RegExp("^".concat(CLIENT_STATE_KEY_PREFIX,"_").concat(escapedPersistenceKey,"_([^_]*)$"));this.mutationBatchKeyRe=new RegExp("^".concat(MUTATION_BATCH_KEY_PREFIX,"_").concat(escapedPersistenceKey,"_(\\d+)(?:_(.*))?$"));this.queryTargetKeyRe=new RegExp("^".concat(QUERY_TARGET_KEY_PREFIX,"_").concat(escapedPersistenceKey,"_(\\d+)$"));this.onlineStateKey=createWebStorageOnlineStateKey(this.persistenceKey);// Rather than adding the storage observer during start(), we add the
// storage observer during initialization. This ensures that we collect
// events before other components populate their initial state (during their
// respective start() calls). Otherwise, we might for example miss a
// mutation that is added after LocalStore's start() processed the existing
// mutations but before we observe WebStorage events.
this.window.addEventListener('storage',this.storageListener);}/** Returns 'true' if WebStorage is available in the current environment. */_createClass(WebStorageSharedClientState,[{key:"start",value:function start(){var _this3=this;var existingClients,_iteratorNormalCompletion2,_didIteratorError2,_iteratorError2,_iterator2,_step2,clientId,storageItem,clientState,onlineStateJSON,onlineState,_iteratorNormalCompletion3,_didIteratorError3,_iteratorError3,_iterator3,_step3,event;return regeneratorRuntime.async(function start$(_context){while(1){switch(_context.prev=_context.next){case 0:_context.next=2;return regeneratorRuntime.awrap(this.syncEngine.getActiveClients());case 2:existingClients=_context.sent;_iteratorNormalCompletion2=true;_didIteratorError2=false;_iteratorError2=undefined;_context.prev=6;_iterator2=existingClients[Symbol.iterator]();case 8:if(_iteratorNormalCompletion2=(_step2=_iterator2.next()).done){_context.next=17;break;}clientId=_step2.value;if(!(clientId===this.localClientId)){_context.next=12;break;}return _context.abrupt("continue",14);case 12:storageItem=this.getItem(createWebStorageClientStateKey(this.persistenceKey,clientId));if(storageItem){clientState=RemoteClientState.fromWebStorageEntry(clientId,storageItem);if(clientState){this.activeClients=this.activeClients.insert(clientState.clientId,clientState);}}case 14:_iteratorNormalCompletion2=true;_context.next=8;break;case 17:_context.next=23;break;case 19:_context.prev=19;_context.t0=_context["catch"](6);_didIteratorError2=true;_iteratorError2=_context.t0;case 23:_context.prev=23;_context.prev=24;if(!_iteratorNormalCompletion2&&_iterator2["return"]!=null){_iterator2["return"]();}case 26:_context.prev=26;if(!_didIteratorError2){_context.next=29;break;}throw _iteratorError2;case 29:return _context.finish(26);case 30:return _context.finish(23);case 31:this.persistClientState();// Check if there is an existing online state and call the callback handler
// if applicable.
onlineStateJSON=this.storage.getItem(this.onlineStateKey);if(onlineStateJSON){onlineState=this.fromWebStorageOnlineState(onlineStateJSON);if(onlineState){this.handleOnlineStateEvent(onlineState);}}_iteratorNormalCompletion3=true;_didIteratorError3=false;_iteratorError3=undefined;_context.prev=37;for(_iterator3=this.earlyEvents[Symbol.iterator]();!(_iteratorNormalCompletion3=(_step3=_iterator3.next()).done);_iteratorNormalCompletion3=true){event=_step3.value;this.handleWebStorageEvent(event);}_context.next=45;break;case 41:_context.prev=41;_context.t1=_context["catch"](37);_didIteratorError3=true;_iteratorError3=_context.t1;case 45:_context.prev=45;_context.prev=46;if(!_iteratorNormalCompletion3&&_iterator3["return"]!=null){_iterator3["return"]();}case 48:_context.prev=48;if(!_didIteratorError3){_context.next=51;break;}throw _iteratorError3;case 51:return _context.finish(48);case 52:return _context.finish(45);case 53:this.earlyEvents=[];// Register a window unload hook to remove the client metadata entry from
// WebStorage even if `shutdown()` was not called.
this.window.addEventListener('unload',function(){return _this3.shutdown();});this.started=true;case 56:case"end":return _context.stop();}}},null,this,[[6,19,23,31],[24,,26,30],[37,41,45,53],[46,,48,52]]);}},{key:"writeSequenceNumber",value:function writeSequenceNumber(sequenceNumber){this.setItem(this.sequenceNumberKey,JSON.stringify(sequenceNumber));}},{key:"getAllActiveQueryTargets",value:function getAllActiveQueryTargets(){return this.extractActiveQueryTargets(this.activeClients);}},{key:"isActiveQueryTarget",value:function isActiveQueryTarget(targetId){var found=false;this.activeClients.forEach(function(key,value){if(value.activeTargetIds.has(targetId)){found=true;}});return found;}},{key:"addPendingMutation",value:function addPendingMutation(batchId){this.persistMutationState(batchId,'pending');}},{key:"updateMutationState",value:function updateMutationState(batchId,state,error){this.persistMutationState(batchId,state,error);// Once a final mutation result is observed by other clients, they no longer
// access the mutation's metadata entry. Since WebStorage replays events
// in order, it is safe to delete the entry right after updating it.
this.removeMutationState(batchId);}},{key:"addLocalQueryTarget",value:function addLocalQueryTarget(targetId){var queryState='not-current';// Lookup an existing query state if the target ID was already registered
// by another tab
if(this.isActiveQueryTarget(targetId)){var storageItem=this.storage.getItem(createWebStorageQueryTargetMetadataKey(this.persistenceKey,targetId));if(storageItem){var metadata=QueryTargetMetadata.fromWebStorageEntry(targetId,storageItem);if(metadata){queryState=metadata.state;}}}this.localClientState.addQueryTarget(targetId);this.persistClientState();return queryState;}},{key:"removeLocalQueryTarget",value:function removeLocalQueryTarget(targetId){this.localClientState.removeQueryTarget(targetId);this.persistClientState();}},{key:"isLocalQueryTarget",value:function isLocalQueryTarget(targetId){return this.localClientState.activeTargetIds.has(targetId);}},{key:"clearQueryState",value:function clearQueryState(targetId){this.removeItem(createWebStorageQueryTargetMetadataKey(this.persistenceKey,targetId));}},{key:"updateQueryState",value:function updateQueryState(targetId,state,error){this.persistQueryTargetState(targetId,state,error);}},{key:"handleUserChange",value:function handleUserChange(user,removedBatchIds,addedBatchIds){var _this4=this;removedBatchIds.forEach(function(batchId){_this4.removeMutationState(batchId);});this.currentUser=user;addedBatchIds.forEach(function(batchId){_this4.addPendingMutation(batchId);});}},{key:"setOnlineState",value:function setOnlineState(onlineState){this.persistOnlineState(onlineState);}},{key:"shutdown",value:function shutdown(){if(this.started){this.window.removeEventListener('storage',this.storageListener);this.removeItem(this.localClientStorageKey);this.started=false;}}},{key:"getItem",value:function getItem(key){var value=this.storage.getItem(key);logDebug(LOG_TAG,'READ',key,value);return value;}},{key:"setItem",value:function setItem(key,value){logDebug(LOG_TAG,'SET',key,value);this.storage.setItem(key,value);}},{key:"removeItem",value:function removeItem(key){logDebug(LOG_TAG,'REMOVE',key);this.storage.removeItem(key);}},{key:"handleWebStorageEvent",value:function handleWebStorageEvent(event){var _this5=this;// Note: The function is typed to take Event to be interface-compatible with
// `Window.addEventListener`.
var storageEvent=event;if(storageEvent.storageArea===this.storage){logDebug(LOG_TAG,'EVENT',storageEvent.key,storageEvent.newValue);if(storageEvent.key===this.localClientStorageKey){logError('Received WebStorage notification for local change. Another client might have '+'garbage-collected our state');return;}this.queue.enqueueRetryable(function _callee(){var clientState,clientId,mutationMetadata,queryTargetMetadata,onlineState,sequenceNumber;return regeneratorRuntime.async(function _callee$(_context2){while(1){switch(_context2.prev=_context2.next){case 0:if(_this5.started){_context2.next=3;break;}_this5.earlyEvents.push(storageEvent);return _context2.abrupt("return");case 3:if(!(storageEvent.key===null)){_context2.next=5;break;}return _context2.abrupt("return");case 5:if(!_this5.clientStateKeyRe.test(storageEvent.key)){_context2.next=16;break;}if(!(storageEvent.newValue!=null)){_context2.next=12;break;}clientState=_this5.fromWebStorageClientState(storageEvent.key,storageEvent.newValue);if(!clientState){_context2.next=10;break;}return _context2.abrupt("return",_this5.handleClientStateEvent(clientState.clientId,clientState));case 10:_context2.next=14;break;case 12:clientId=_this5.fromWebStorageClientStateKey(storageEvent.key);return _context2.abrupt("return",_this5.handleClientStateEvent(clientId,null));case 14:_context2.next=38;break;case 16:if(!_this5.mutationBatchKeyRe.test(storageEvent.key)){_context2.next=23;break;}if(!(storageEvent.newValue!==null)){_context2.next=21;break;}mutationMetadata=_this5.fromWebStorageMutationMetadata(storageEvent.key,storageEvent.newValue);if(!mutationMetadata){_context2.next=21;break;}return _context2.abrupt("return",_this5.handleMutationBatchEvent(mutationMetadata));case 21:_context2.next=38;break;case 23:if(!_this5.queryTargetKeyRe.test(storageEvent.key)){_context2.next=30;break;}if(!(storageEvent.newValue!==null)){_context2.next=28;break;}queryTargetMetadata=_this5.fromWebStorageQueryTargetMetadata(storageEvent.key,storageEvent.newValue);if(!queryTargetMetadata){_context2.next=28;break;}return _context2.abrupt("return",_this5.handleQueryTargetEvent(queryTargetMetadata));case 28:_context2.next=38;break;case 30:if(!(storageEvent.key===_this5.onlineStateKey)){_context2.next=37;break;}if(!(storageEvent.newValue!==null)){_context2.next=35;break;}onlineState=_this5.fromWebStorageOnlineState(storageEvent.newValue);if(!onlineState){_context2.next=35;break;}return _context2.abrupt("return",_this5.handleOnlineStateEvent(onlineState));case 35:_context2.next=38;break;case 37:if(storageEvent.key===_this5.sequenceNumberKey){sequenceNumber=fromWebStorageSequenceNumber(storageEvent.newValue);if(sequenceNumber!==ListenSequence.INVALID){_this5.sequenceNumberHandler(sequenceNumber);}}case 38:case"end":return _context2.stop();}}});});}}},{key:"persistClientState",value:function persistClientState(){this.setItem(this.localClientStorageKey,this.localClientState.toWebStorageJSON());}},{key:"persistMutationState",value:function persistMutationState(batchId,state,error){var mutationState=new MutationMetadata(this.currentUser,batchId,state,error);var mutationKey=createWebStorageMutationBatchKey(this.persistenceKey,this.currentUser,batchId);this.setItem(mutationKey,mutationState.toWebStorageJSON());}},{key:"removeMutationState",value:function removeMutationState(batchId){var mutationKey=createWebStorageMutationBatchKey(this.persistenceKey,this.currentUser,batchId);this.removeItem(mutationKey);}},{key:"persistOnlineState",value:function persistOnlineState(onlineState){var entry={clientId:this.localClientId,onlineState:onlineState};this.storage.setItem(this.onlineStateKey,JSON.stringify(entry));}},{key:"persistQueryTargetState",value:function persistQueryTargetState(targetId,state,error){var targetKey=createWebStorageQueryTargetMetadataKey(this.persistenceKey,targetId);var targetMetadata=new QueryTargetMetadata(targetId,state,error);this.setItem(targetKey,targetMetadata.toWebStorageJSON());}/**
     * Parses a client state key in WebStorage. Returns null if the key does not
     * match the expected key format.
     */},{key:"fromWebStorageClientStateKey",value:function fromWebStorageClientStateKey(key){var match=this.clientStateKeyRe.exec(key);return match?match[1]:null;}/**
     * Parses a client state in WebStorage. Returns 'null' if the value could not
     * be parsed.
     */},{key:"fromWebStorageClientState",value:function fromWebStorageClientState(key,value){var clientId=this.fromWebStorageClientStateKey(key);return RemoteClientState.fromWebStorageEntry(clientId,value);}/**
     * Parses a mutation batch state in WebStorage. Returns 'null' if the value
     * could not be parsed.
     */},{key:"fromWebStorageMutationMetadata",value:function fromWebStorageMutationMetadata(key,value){var match=this.mutationBatchKeyRe.exec(key);var batchId=Number(match[1]);var userId=match[2]!==undefined?match[2]:null;return MutationMetadata.fromWebStorageEntry(new User(userId),batchId,value);}/**
     * Parses a query target state from WebStorage. Returns 'null' if the value
     * could not be parsed.
     */},{key:"fromWebStorageQueryTargetMetadata",value:function fromWebStorageQueryTargetMetadata(key,value){var match=this.queryTargetKeyRe.exec(key);var targetId=Number(match[1]);return QueryTargetMetadata.fromWebStorageEntry(targetId,value);}/**
     * Parses an online state from WebStorage. Returns 'null' if the value
     * could not be parsed.
     */},{key:"fromWebStorageOnlineState",value:function fromWebStorageOnlineState(value){return SharedOnlineState.fromWebStorageEntry(value);}},{key:"handleMutationBatchEvent",value:function handleMutationBatchEvent(mutationBatch){return regeneratorRuntime.async(function handleMutationBatchEvent$(_context3){while(1){switch(_context3.prev=_context3.next){case 0:if(!(mutationBatch.user.uid!==this.currentUser.uid)){_context3.next=3;break;}logDebug(LOG_TAG,"Ignoring mutation for non-active user ".concat(mutationBatch.user.uid));return _context3.abrupt("return");case 3:return _context3.abrupt("return",this.syncEngine.applyBatchState(mutationBatch.batchId,mutationBatch.state,mutationBatch.error));case 4:case"end":return _context3.stop();}}},null,this);}},{key:"handleQueryTargetEvent",value:function handleQueryTargetEvent(targetMetadata){return this.syncEngine.applyTargetState(targetMetadata.targetId,targetMetadata.state,targetMetadata.error);}},{key:"handleClientStateEvent",value:function handleClientStateEvent(clientId,clientState){var _this6=this;var updatedClients=clientState?this.activeClients.insert(clientId,clientState):this.activeClients.remove(clientId);var existingTargets=this.extractActiveQueryTargets(this.activeClients);var newTargets=this.extractActiveQueryTargets(updatedClients);var addedTargets=[];var removedTargets=[];newTargets.forEach(function(targetId){if(!existingTargets.has(targetId)){addedTargets.push(targetId);}});existingTargets.forEach(function(targetId){if(!newTargets.has(targetId)){removedTargets.push(targetId);}});return this.syncEngine.applyActiveTargetsChange(addedTargets,removedTargets).then(function(){_this6.activeClients=updatedClients;});}},{key:"handleOnlineStateEvent",value:function handleOnlineStateEvent(onlineState){// We check whether the client that wrote this online state is still active
// by comparing its client ID to the list of clients kept active in
// IndexedDb. If a client does not update their IndexedDb client state
// within 5 seconds, it is considered inactive and we don't emit an online
// state event.
if(this.activeClients.get(onlineState.clientId)){this.onlineStateHandler(onlineState.onlineState);}}},{key:"extractActiveQueryTargets",value:function extractActiveQueryTargets(clients){var activeTargets=targetIdSet();clients.forEach(function(kev,value){activeTargets=activeTargets.unionWith(value.activeTargetIds);});return activeTargets;}},{key:"localClientState",get:function get(){return this.activeClients.get(this.localClientId);}}],[{key:"isAvailable",value:function isAvailable(window){return!!(window&&window.localStorage);}}]);return WebStorageSharedClientState;}();function fromWebStorageSequenceNumber(seqString){var sequenceNumber=ListenSequence.INVALID;if(seqString!=null){try{var parsed=JSON.parse(seqString);hardAssert(typeof parsed==='number');sequenceNumber=parsed;}catch(e){logError(LOG_TAG,'Failed to read sequence number from WebStorage',e);}}return sequenceNumber;}/**
 * `MemorySharedClientState` is a simple implementation of SharedClientState for
 * clients using memory persistence. The state in this class remains fully
 * isolated and no synchronization is performed.
 */var MemorySharedClientState=/*#__PURE__*/function(){function MemorySharedClientState(){_classCallCheck(this,MemorySharedClientState);this.localState=new LocalClientState();this.queryState={};this.onlineStateHandler=null;this.sequenceNumberHandler=null;}_createClass(MemorySharedClientState,[{key:"addPendingMutation",value:function addPendingMutation(batchId){// No op.
}},{key:"updateMutationState",value:function updateMutationState(batchId,state,error){// No op.
}},{key:"addLocalQueryTarget",value:function addLocalQueryTarget(targetId){this.localState.addQueryTarget(targetId);return this.queryState[targetId]||'not-current';}},{key:"updateQueryState",value:function updateQueryState(targetId,state,error){this.queryState[targetId]=state;}},{key:"removeLocalQueryTarget",value:function removeLocalQueryTarget(targetId){this.localState.removeQueryTarget(targetId);}},{key:"isLocalQueryTarget",value:function isLocalQueryTarget(targetId){return this.localState.activeTargetIds.has(targetId);}},{key:"clearQueryState",value:function clearQueryState(targetId){delete this.queryState[targetId];}},{key:"getAllActiveQueryTargets",value:function getAllActiveQueryTargets(){return this.localState.activeTargetIds;}},{key:"isActiveQueryTarget",value:function isActiveQueryTarget(targetId){return this.localState.activeTargetIds.has(targetId);}},{key:"start",value:function start(){this.localState=new LocalClientState();return Promise.resolve();}},{key:"handleUserChange",value:function handleUserChange(user,removedBatchIds,addedBatchIds){// No op.
}},{key:"setOnlineState",value:function setOnlineState(onlineState){// No op.
}},{key:"shutdown",value:function shutdown(){}},{key:"writeSequenceNumber",value:function writeSequenceNumber(sequenceNumber){}}]);return MemorySharedClientState;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ // The earlist date supported by Firestore timestamps (0001-01-01T00:00:00Z).
var MIN_SECONDS=-62135596800;/**
 * A `Timestamp` represents a point in time independent of any time zone or
 * calendar, represented as seconds and fractions of seconds at nanosecond
 * resolution in UTC Epoch time.
 *
 * It is encoded using the Proleptic Gregorian Calendar which extends the
 * Gregorian calendar backwards to year one. It is encoded assuming all minutes
 * are 60 seconds long, i.e. leap seconds are "smeared" so that no leap second
 * table is needed for interpretation. Range is from 0001-01-01T00:00:00Z to
 * 9999-12-31T23:59:59.999999999Z.
 *
 * @see https://github.com/google/protobuf/blob/master/src/google/protobuf/timestamp.proto
 */var Timestamp=/*#__PURE__*/function(){/**
     * Creates a new timestamp.
     *
     * @param seconds The number of seconds of UTC time since Unix epoch
     *     1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to
     *     9999-12-31T23:59:59Z inclusive.
     * @param nanoseconds The non-negative fractions of a second at nanosecond
     *     resolution. Negative second values with fractions must still have
     *     non-negative nanoseconds values that count forward in time. Must be
     *     from 0 to 999,999,999 inclusive.
     */function Timestamp(seconds,nanoseconds){_classCallCheck(this,Timestamp);this.seconds=seconds;this.nanoseconds=nanoseconds;if(nanoseconds<0){throw new FirestoreError(Code.INVALID_ARGUMENT,'Timestamp nanoseconds out of range: '+nanoseconds);}if(nanoseconds>=1e9){throw new FirestoreError(Code.INVALID_ARGUMENT,'Timestamp nanoseconds out of range: '+nanoseconds);}if(seconds<MIN_SECONDS){throw new FirestoreError(Code.INVALID_ARGUMENT,'Timestamp seconds out of range: '+seconds);}// This will break in the year 10,000.
if(seconds>=253402300800){throw new FirestoreError(Code.INVALID_ARGUMENT,'Timestamp seconds out of range: '+seconds);}}/**
     * Creates a new timestamp with the current date, with millisecond precision.
     *
     * @return a new timestamp representing the current date.
     */_createClass(Timestamp,[{key:"toDate",/**
     * Converts a `Timestamp` to a JavaScript `Date` object. This conversion causes
     * a loss of precision since `Date` objects only support millisecond precision.
     *
     * @return JavaScript `Date` object representing the same point in time as
     *     this `Timestamp`, with millisecond precision.
     */value:function toDate(){return new Date(this.toMillis());}/**
     * Converts a `Timestamp` to a numeric timestamp (in milliseconds since
     * epoch). This operation causes a loss of precision.
     *
     * @return The point in time corresponding to this timestamp, represented as
     *     the number of milliseconds since Unix epoch 1970-01-01T00:00:00Z.
     */},{key:"toMillis",value:function toMillis(){return this.seconds*1000+this.nanoseconds/1e6;}},{key:"_compareTo",value:function _compareTo(other){if(this.seconds===other.seconds){return primitiveComparator(this.nanoseconds,other.nanoseconds);}return primitiveComparator(this.seconds,other.seconds);}/**
     * Returns true if this `Timestamp` is equal to the provided one.
     *
     * @param other The `Timestamp` to compare against.
     * @return true if this `Timestamp` is equal to the provided one.
     */},{key:"isEqual",value:function isEqual(other){return other.seconds===this.seconds&&other.nanoseconds===this.nanoseconds;}},{key:"toString",value:function toString(){return'Timestamp(seconds='+this.seconds+', nanoseconds='+this.nanoseconds+')';}},{key:"toJSON",value:function toJSON(){return{seconds:this.seconds,nanoseconds:this.nanoseconds};}/**
     * Converts this object to a primitive string, which allows Timestamp objects to be compared
     * using the `>`, `<=`, `>=` and `>` operators.
     */},{key:"valueOf",value:function valueOf(){// This method returns a string of the form <seconds>.<nanoseconds> where <seconds> is
// translated to have a non-negative value and both <seconds> and <nanoseconds> are left-padded
// with zeroes to be a consistent length. Strings with this format then have a lexiographical
// ordering that matches the expected ordering. The <seconds> translation is done to avoid
// having a leading negative sign (i.e. a leading '-' character) in its string representation,
// which would affect its lexiographical ordering.
var adjustedSeconds=this.seconds-MIN_SECONDS;// Note: Up to 12 decimal digits are required to represent all valid 'seconds' values.
var formattedSeconds=String(adjustedSeconds).padStart(12,'0');var formattedNanoseconds=String(this.nanoseconds).padStart(9,'0');return formattedSeconds+'.'+formattedNanoseconds;}}],[{key:"now",value:function now(){return Timestamp.fromMillis(Date.now());}/**
     * Creates a new timestamp from the given date.
     *
     * @param date The date to initialize the `Timestamp` from.
     * @return A new `Timestamp` representing the same point in time as the given
     *     date.
     */},{key:"fromDate",value:function fromDate(date){return Timestamp.fromMillis(date.getTime());}/**
     * Creates a new timestamp from the given number of milliseconds.
     *
     * @param milliseconds Number of milliseconds since Unix epoch
     *     1970-01-01T00:00:00Z.
     * @return A new `Timestamp` representing the same point in time as the given
     *     number of milliseconds.
     */},{key:"fromMillis",value:function fromMillis(milliseconds){var seconds=Math.floor(milliseconds/1000);var nanos=(milliseconds-seconds*1000)*1e6;return new Timestamp(seconds,nanos);}}]);return Timestamp;}();/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Represents a locally-applied ServerTimestamp.
 *
 * Server Timestamps are backed by MapValues that contain an internal field
 * `__type__` with a value of `server_timestamp`. The previous value and local
 * write time are stored in its `__previous_value__` and `__local_write_time__`
 * fields respectively.
 *
 * Notes:
 * - ServerTimestampValue instances are created as the result of applying a
 *   TransformMutation (see TransformMutation.applyTo()). They can only exist in
 *   the local view of a document. Therefore they do not need to be parsed or
 *   serialized.
 * - When evaluated locally (e.g. for snapshot.data()), they by default
 *   evaluate to `null`. This behavior can be configured by passing custom
 *   FieldValueOptions to value().
 * - With respect to other ServerTimestampValues, they sort by their
 *   localWriteTime.
 */var SERVER_TIMESTAMP_SENTINEL='server_timestamp';var TYPE_KEY='__type__';var PREVIOUS_VALUE_KEY='__previous_value__';var LOCAL_WRITE_TIME_KEY='__local_write_time__';function isServerTimestamp(value){var _a,_b;var type=(_b=(((_a=value===null||value===void 0?void 0:value.mapValue)===null||_a===void 0?void 0:_a.fields)||{})[TYPE_KEY])===null||_b===void 0?void 0:_b.stringValue;return type===SERVER_TIMESTAMP_SENTINEL;}/**
 * Creates a new ServerTimestamp proto value (using the internal format).
 */function serverTimestamp(localWriteTime,previousValue){var _fields;var mapValue={fields:(_fields={},_defineProperty(_fields,TYPE_KEY,{stringValue:SERVER_TIMESTAMP_SENTINEL}),_defineProperty(_fields,LOCAL_WRITE_TIME_KEY,{timestampValue:{seconds:localWriteTime.seconds,nanos:localWriteTime.nanoseconds}}),_fields)};if(previousValue){mapValue.fields[PREVIOUS_VALUE_KEY]=previousValue;}return{mapValue:mapValue};}/**
 * Returns the value of the field before this ServerTimestamp was set.
 *
 * Preserving the previous values allows the user to display the last resoled
 * value until the backend responds with the timestamp.
 */function getPreviousValue(value){var previousValue=value.mapValue.fields[PREVIOUS_VALUE_KEY];if(isServerTimestamp(previousValue)){return getPreviousValue(previousValue);}return previousValue;}/**
 * Returns the local time at which this timestamp was first set.
 */function getLocalWriteTime(value){var localWriteTime=normalizeTimestamp(value.mapValue.fields[LOCAL_WRITE_TIME_KEY].timestampValue);return new Timestamp(localWriteTime.seconds,localWriteTime.nanos);}/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ // A RegExp matching ISO 8601 UTC timestamps with optional fraction.
var ISO_TIMESTAMP_REG_EXP=new RegExp(/^\d{4}-\d\d-\d\dT\d\d:\d\d:\d\d(?:\.(\d+))?Z$/);/** Extracts the backend's type order for the provided value. */function typeOrder(value){if('nullValue'in value){return 0/* NullValue */;}else if('booleanValue'in value){return 1/* BooleanValue */;}else if('integerValue'in value||'doubleValue'in value){return 2/* NumberValue */;}else if('timestampValue'in value){return 3/* TimestampValue */;}else if('stringValue'in value){return 5/* StringValue */;}else if('bytesValue'in value){return 6/* BlobValue */;}else if('referenceValue'in value){return 7/* RefValue */;}else if('geoPointValue'in value){return 8/* GeoPointValue */;}else if('arrayValue'in value){return 9/* ArrayValue */;}else if('mapValue'in value){if(isServerTimestamp(value)){return 4/* ServerTimestampValue */;}return 10/* ObjectValue */;}else{return fail();}}/** Tests `left` and `right` for equality based on the backend semantics. */function valueEquals(left,right){var leftType=typeOrder(left);var rightType=typeOrder(right);if(leftType!==rightType){return false;}switch(leftType){case 0/* NullValue */:return true;case 1/* BooleanValue */:return left.booleanValue===right.booleanValue;case 4/* ServerTimestampValue */:return getLocalWriteTime(left).isEqual(getLocalWriteTime(right));case 3/* TimestampValue */:return timestampEquals(left,right);case 5/* StringValue */:return left.stringValue===right.stringValue;case 6/* BlobValue */:return blobEquals(left,right);case 7/* RefValue */:return left.referenceValue===right.referenceValue;case 8/* GeoPointValue */:return geoPointEquals(left,right);case 2/* NumberValue */:return numberEquals(left,right);case 9/* ArrayValue */:return arrayEquals(left.arrayValue.values||[],right.arrayValue.values||[],valueEquals);case 10/* ObjectValue */:return objectEquals(left,right);default:return fail();}}function timestampEquals(left,right){if(typeof left.timestampValue==='string'&&typeof right.timestampValue==='string'&&left.timestampValue.length===right.timestampValue.length){// Use string equality for ISO 8601 timestamps
return left.timestampValue===right.timestampValue;}var leftTimestamp=normalizeTimestamp(left.timestampValue);var rightTimestamp=normalizeTimestamp(right.timestampValue);return leftTimestamp.seconds===rightTimestamp.seconds&&leftTimestamp.nanos===rightTimestamp.nanos;}function geoPointEquals(left,right){return normalizeNumber(left.geoPointValue.latitude)===normalizeNumber(right.geoPointValue.latitude)&&normalizeNumber(left.geoPointValue.longitude)===normalizeNumber(right.geoPointValue.longitude);}function blobEquals(left,right){return normalizeByteString(left.bytesValue).isEqual(normalizeByteString(right.bytesValue));}function numberEquals(left,right){if('integerValue'in left&&'integerValue'in right){return normalizeNumber(left.integerValue)===normalizeNumber(right.integerValue);}else if('doubleValue'in left&&'doubleValue'in right){var n1=normalizeNumber(left.doubleValue);var n2=normalizeNumber(right.doubleValue);if(n1===n2){return isNegativeZero(n1)===isNegativeZero(n2);}else{return isNaN(n1)&&isNaN(n2);}}return false;}function objectEquals(left,right){var leftMap=left.mapValue.fields||{};var rightMap=right.mapValue.fields||{};if(objectSize(leftMap)!==objectSize(rightMap)){return false;}for(var key in leftMap){if(leftMap.hasOwnProperty(key)){if(rightMap[key]===undefined||!valueEquals(leftMap[key],rightMap[key])){return false;}}}return true;}/** Returns true if the ArrayValue contains the specified element. */function arrayValueContains(haystack,needle){return(haystack.values||[]).find(function(v){return valueEquals(v,needle);})!==undefined;}function valueCompare(left,right){var leftType=typeOrder(left);var rightType=typeOrder(right);if(leftType!==rightType){return primitiveComparator(leftType,rightType);}switch(leftType){case 0/* NullValue */:return 0;case 1/* BooleanValue */:return primitiveComparator(left.booleanValue,right.booleanValue);case 2/* NumberValue */:return compareNumbers(left,right);case 3/* TimestampValue */:return compareTimestamps(left.timestampValue,right.timestampValue);case 4/* ServerTimestampValue */:return compareTimestamps(getLocalWriteTime(left),getLocalWriteTime(right));case 5/* StringValue */:return primitiveComparator(left.stringValue,right.stringValue);case 6/* BlobValue */:return compareBlobs(left.bytesValue,right.bytesValue);case 7/* RefValue */:return compareReferences(left.referenceValue,right.referenceValue);case 8/* GeoPointValue */:return compareGeoPoints(left.geoPointValue,right.geoPointValue);case 9/* ArrayValue */:return compareArrays(left.arrayValue,right.arrayValue);case 10/* ObjectValue */:return compareMaps(left.mapValue,right.mapValue);default:throw fail();}}function compareNumbers(left,right){var leftNumber=normalizeNumber(left.integerValue||left.doubleValue);var rightNumber=normalizeNumber(right.integerValue||right.doubleValue);if(leftNumber<rightNumber){return-1;}else if(leftNumber>rightNumber){return 1;}else if(leftNumber===rightNumber){return 0;}else{// one or both are NaN.
if(isNaN(leftNumber)){return isNaN(rightNumber)?0:-1;}else{return 1;}}}function compareTimestamps(left,right){if(typeof left==='string'&&typeof right==='string'&&left.length===right.length){return primitiveComparator(left,right);}var leftTimestamp=normalizeTimestamp(left);var rightTimestamp=normalizeTimestamp(right);var comparison=primitiveComparator(leftTimestamp.seconds,rightTimestamp.seconds);if(comparison!==0){return comparison;}return primitiveComparator(leftTimestamp.nanos,rightTimestamp.nanos);}function compareReferences(leftPath,rightPath){var leftSegments=leftPath.split('/');var rightSegments=rightPath.split('/');for(var i=0;i<leftSegments.length&&i<rightSegments.length;i++){var comparison=primitiveComparator(leftSegments[i],rightSegments[i]);if(comparison!==0){return comparison;}}return primitiveComparator(leftSegments.length,rightSegments.length);}function compareGeoPoints(left,right){var comparison=primitiveComparator(normalizeNumber(left.latitude),normalizeNumber(right.latitude));if(comparison!==0){return comparison;}return primitiveComparator(normalizeNumber(left.longitude),normalizeNumber(right.longitude));}function compareBlobs(left,right){var leftBytes=normalizeByteString(left);var rightBytes=normalizeByteString(right);return leftBytes.compareTo(rightBytes);}function compareArrays(left,right){var leftArray=left.values||[];var rightArray=right.values||[];for(var i=0;i<leftArray.length&&i<rightArray.length;++i){var compare=valueCompare(leftArray[i],rightArray[i]);if(compare){return compare;}}return primitiveComparator(leftArray.length,rightArray.length);}function compareMaps(left,right){var leftMap=left.fields||{};var leftKeys=Object.keys(leftMap);var rightMap=right.fields||{};var rightKeys=Object.keys(rightMap);// Even though MapValues are likely sorted correctly based on their insertion
// order (e.g. when received from the backend), local modifications can bring
// elements out of order. We need to re-sort the elements to ensure that
// canonical IDs are independent of insertion order.
leftKeys.sort();rightKeys.sort();for(var i=0;i<leftKeys.length&&i<rightKeys.length;++i){var keyCompare=primitiveComparator(leftKeys[i],rightKeys[i]);if(keyCompare!==0){return keyCompare;}var compare=valueCompare(leftMap[leftKeys[i]],rightMap[rightKeys[i]]);if(compare!==0){return compare;}}return primitiveComparator(leftKeys.length,rightKeys.length);}/**
 * Generates the canonical ID for the provided field value (as used in Target
 * serialization).
 */function canonicalId(value){return canonifyValue(value);}function canonifyValue(value){if('nullValue'in value){return'null';}else if('booleanValue'in value){return''+value.booleanValue;}else if('integerValue'in value){return''+value.integerValue;}else if('doubleValue'in value){return''+value.doubleValue;}else if('timestampValue'in value){return canonifyTimestamp(value.timestampValue);}else if('stringValue'in value){return value.stringValue;}else if('bytesValue'in value){return canonifyByteString(value.bytesValue);}else if('referenceValue'in value){return canonifyReference(value.referenceValue);}else if('geoPointValue'in value){return canonifyGeoPoint(value.geoPointValue);}else if('arrayValue'in value){return canonifyArray(value.arrayValue);}else if('mapValue'in value){return canonifyMap(value.mapValue);}else{return fail();}}function canonifyByteString(byteString){return normalizeByteString(byteString).toBase64();}function canonifyTimestamp(timestamp){var normalizedTimestamp=normalizeTimestamp(timestamp);return"time(".concat(normalizedTimestamp.seconds,",").concat(normalizedTimestamp.nanos,")");}function canonifyGeoPoint(geoPoint){return"geo(".concat(geoPoint.latitude,",").concat(geoPoint.longitude,")");}function canonifyReference(referenceValue){return DocumentKey.fromName(referenceValue).toString();}function canonifyMap(mapValue){// Iteration order in JavaScript is not guaranteed. To ensure that we generate
// matching canonical IDs for identical maps, we need to sort the keys.
var sortedKeys=Object.keys(mapValue.fields||{}).sort();var result='{';var first=true;var _iteratorNormalCompletion4=true;var _didIteratorError4=false;var _iteratorError4=undefined;try{for(var _iterator4=sortedKeys[Symbol.iterator](),_step4;!(_iteratorNormalCompletion4=(_step4=_iterator4.next()).done);_iteratorNormalCompletion4=true){var key=_step4.value;if(!first){result+=',';}else{first=false;}result+="".concat(key,":").concat(canonifyValue(mapValue.fields[key]));}}catch(err){_didIteratorError4=true;_iteratorError4=err;}finally{try{if(!_iteratorNormalCompletion4&&_iterator4["return"]!=null){_iterator4["return"]();}}finally{if(_didIteratorError4){throw _iteratorError4;}}}return result+'}';}function canonifyArray(arrayValue){var result='[';var first=true;var _iteratorNormalCompletion5=true;var _didIteratorError5=false;var _iteratorError5=undefined;try{for(var _iterator5=(arrayValue.values||[])[Symbol.iterator](),_step5;!(_iteratorNormalCompletion5=(_step5=_iterator5.next()).done);_iteratorNormalCompletion5=true){var value=_step5.value;if(!first){result+=',';}else{first=false;}result+=canonifyValue(value);}}catch(err){_didIteratorError5=true;_iteratorError5=err;}finally{try{if(!_iteratorNormalCompletion5&&_iterator5["return"]!=null){_iterator5["return"]();}}finally{if(_didIteratorError5){throw _iteratorError5;}}}return result+']';}/**
 * Converts the possible Proto values for a timestamp value into a "seconds and
 * nanos" representation.
 */function normalizeTimestamp(date){hardAssert(!!date);// The json interface (for the browser) will return an iso timestamp string,
// while the proto js library (for node) will return a
// google.protobuf.Timestamp instance.
if(typeof date==='string'){// The date string can have higher precision (nanos) than the Date class
// (millis), so we do some custom parsing here.
// Parse the nanos right out of the string.
var nanos=0;var fraction=ISO_TIMESTAMP_REG_EXP.exec(date);hardAssert(!!fraction);if(fraction[1]){// Pad the fraction out to 9 digits (nanos).
var nanoStr=fraction[1];nanoStr=(nanoStr+'000000000').substr(0,9);nanos=Number(nanoStr);}// Parse the date to get the seconds.
var parsedDate=new Date(date);var seconds=Math.floor(parsedDate.getTime()/1000);return{seconds:seconds,nanos:nanos};}else{// TODO(b/37282237): Use strings for Proto3 timestamps
// assert(!this.options.useProto3Json,
//   'The timestamp instance format requires Proto JS.');
var _seconds=normalizeNumber(date.seconds);var _nanos=normalizeNumber(date.nanos);return{seconds:_seconds,nanos:_nanos};}}/**
 * Converts the possible Proto types for numbers into a JavaScript number.
 * Returns 0 if the value is not numeric.
 */function normalizeNumber(value){// TODO(bjornick): Handle int64 greater than 53 bits.
if(typeof value==='number'){return value;}else if(typeof value==='string'){return Number(value);}else{return 0;}}/** Converts the possible Proto types for Blobs into a ByteString. */function normalizeByteString(blob){if(typeof blob==='string'){return ByteString.fromBase64String(blob);}else{return ByteString.fromUint8Array(blob);}}/** Returns a reference value for the provided database and key. */function refValue(databaseId,key){return{referenceValue:"projects/".concat(databaseId.projectId,"/databases/").concat(databaseId.database,"/documents/").concat(key.path.canonicalString())};}/** Returns true if `value` is an IntegerValue . */function isInteger(value){return!!value&&'integerValue'in value;}/** Returns true if `value` is a DoubleValue. */function isDouble(value){return!!value&&'doubleValue'in value;}/** Returns true if `value` is either an IntegerValue or a DoubleValue. */function isNumber(value){return isInteger(value)||isDouble(value);}/** Returns true if `value` is an ArrayValue. */function isArray(value){return!!value&&'arrayValue'in value;}/** Returns true if `value` is a NullValue. */function isNullValue(value){return!!value&&'nullValue'in value;}/** Returns true if `value` is NaN. */function isNanValue(value){return!!value&&'doubleValue'in value&&isNaN(Number(value.doubleValue));}/** Returns true if `value` is a MapValue. */function isMapValue(value){return!!value&&'mapValue'in value;}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * The result of a lookup for a given path may be an existing document or a
 * marker that this document does not exist at a given version.
 */var MaybeDocument=function MaybeDocument(key,version){_classCallCheck(this,MaybeDocument);this.key=key;this.version=version;};/**
 * Represents a document in Firestore with a key, version, data and whether the
 * data has local mutations applied to it.
 */var Document=/*#__PURE__*/function(_MaybeDocument){_inherits(Document,_MaybeDocument);function Document(key,version,objectValue,options){var _this7;_classCallCheck(this,Document);_this7=_possibleConstructorReturn(this,_getPrototypeOf(Document).call(this,key,version));_this7.objectValue=objectValue;_this7.hasLocalMutations=!!options.hasLocalMutations;_this7.hasCommittedMutations=!!options.hasCommittedMutations;return _this7;}_createClass(Document,[{key:"field",value:function field(path){return this.objectValue.field(path);}},{key:"data",value:function data(){return this.objectValue;}},{key:"toProto",value:function toProto(){return this.objectValue.proto;}},{key:"isEqual",value:function isEqual(other){return other instanceof Document&&this.key.isEqual(other.key)&&this.version.isEqual(other.version)&&this.hasLocalMutations===other.hasLocalMutations&&this.hasCommittedMutations===other.hasCommittedMutations&&this.objectValue.isEqual(other.objectValue);}},{key:"toString",value:function toString(){return"Document(".concat(this.key,", ").concat(this.version,", ").concat(this.objectValue.toString(),", ")+"{hasLocalMutations: ".concat(this.hasLocalMutations,"}), ")+"{hasCommittedMutations: ".concat(this.hasCommittedMutations,"})");}},{key:"hasPendingWrites",get:function get(){return this.hasLocalMutations||this.hasCommittedMutations;}}]);return Document;}(MaybeDocument);/**
 * Compares the value for field `field` in the provided documents. Throws if
 * the field does not exist in both documents.
 */function compareDocumentsByField(field,d1,d2){var v1=d1.field(field);var v2=d2.field(field);if(v1!==null&&v2!==null){return valueCompare(v1,v2);}else{return fail();}}/**
 * A class representing a deleted document.
 * Version is set to 0 if we don't point to any specific time, otherwise it
 * denotes time we know it didn't exist at.
 */var NoDocument=/*#__PURE__*/function(_MaybeDocument2){_inherits(NoDocument,_MaybeDocument2);function NoDocument(key,version,options){var _this8;_classCallCheck(this,NoDocument);_this8=_possibleConstructorReturn(this,_getPrototypeOf(NoDocument).call(this,key,version));_this8.hasCommittedMutations=!!(options&&options.hasCommittedMutations);return _this8;}_createClass(NoDocument,[{key:"toString",value:function toString(){return"NoDocument(".concat(this.key,", ").concat(this.version,")");}},{key:"isEqual",value:function isEqual(other){return other instanceof NoDocument&&other.hasCommittedMutations===this.hasCommittedMutations&&other.version.isEqual(this.version)&&other.key.isEqual(this.key);}},{key:"hasPendingWrites",get:function get(){return this.hasCommittedMutations;}}]);return NoDocument;}(MaybeDocument);/**
 * A class representing an existing document whose data is unknown (e.g. a
 * document that was updated without a known base document).
 */var UnknownDocument=/*#__PURE__*/function(_MaybeDocument3){_inherits(UnknownDocument,_MaybeDocument3);function UnknownDocument(){_classCallCheck(this,UnknownDocument);return _possibleConstructorReturn(this,_getPrototypeOf(UnknownDocument).apply(this,arguments));}_createClass(UnknownDocument,[{key:"toString",value:function toString(){return"UnknownDocument(".concat(this.key,", ").concat(this.version,")");}},{key:"isEqual",value:function isEqual(other){return other instanceof UnknownDocument&&other.version.isEqual(this.version)&&other.key.isEqual(this.key);}},{key:"hasPendingWrites",get:function get(){return true;}}]);return UnknownDocument;}(MaybeDocument);/**
 * @license
 * Copyright 2019 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ // Visible for testing
var TargetImpl=function TargetImpl(path){var collectionGroup=arguments.length>1&&arguments[1]!==undefined?arguments[1]:null;var orderBy=arguments.length>2&&arguments[2]!==undefined?arguments[2]:[];var filters=arguments.length>3&&arguments[3]!==undefined?arguments[3]:[];var limit=arguments.length>4&&arguments[4]!==undefined?arguments[4]:null;var startAt=arguments.length>5&&arguments[5]!==undefined?arguments[5]:null;var endAt=arguments.length>6&&arguments[6]!==undefined?arguments[6]:null;_classCallCheck(this,TargetImpl);this.path=path;this.collectionGroup=collectionGroup;this.orderBy=orderBy;this.filters=filters;this.limit=limit;this.startAt=startAt;this.endAt=endAt;this.memoizedCanonicalId=null;};/**
 * Initializes a Target with a path and optional additional query constraints.
 * Path must currently be empty if this is a collection group query.
 *
 * NOTE: you should always construct `Target` from `Query.toTarget` instead of
 * using this factory method, because `Query` provides an implicit `orderBy`
 * property.
 */function newTarget(path){var collectionGroup=arguments.length>1&&arguments[1]!==undefined?arguments[1]:null;var orderBy=arguments.length>2&&arguments[2]!==undefined?arguments[2]:[];var filters=arguments.length>3&&arguments[3]!==undefined?arguments[3]:[];var limit=arguments.length>4&&arguments[4]!==undefined?arguments[4]:null;var startAt=arguments.length>5&&arguments[5]!==undefined?arguments[5]:null;var endAt=arguments.length>6&&arguments[6]!==undefined?arguments[6]:null;return new TargetImpl(path,collectionGroup,orderBy,filters,limit,startAt,endAt);}function canonifyTarget(target){var targetImpl=debugCast(target);if(targetImpl.memoizedCanonicalId===null){var _canonicalId=targetImpl.path.canonicalString();if(targetImpl.collectionGroup!==null){_canonicalId+='|cg:'+targetImpl.collectionGroup;}_canonicalId+='|f:';_canonicalId+=targetImpl.filters.map(function(f){return canonifyFilter(f);}).join(',');_canonicalId+='|ob:';_canonicalId+=targetImpl.orderBy.map(function(o){return canonifyOrderBy(o);}).join(',');if(!isNullOrUndefined(targetImpl.limit)){_canonicalId+='|l:';_canonicalId+=targetImpl.limit;}if(targetImpl.startAt){_canonicalId+='|lb:';_canonicalId+=canonifyBound(targetImpl.startAt);}if(targetImpl.endAt){_canonicalId+='|ub:';_canonicalId+=canonifyBound(targetImpl.endAt);}targetImpl.memoizedCanonicalId=_canonicalId;}return targetImpl.memoizedCanonicalId;}function stringifyTarget(target){var str=target.path.canonicalString();if(target.collectionGroup!==null){str+=' collectionGroup='+target.collectionGroup;}if(target.filters.length>0){str+=", filters: [".concat(target.filters.map(function(f){return stringifyFilter(f);}).join(', '),"]");}if(!isNullOrUndefined(target.limit)){str+=', limit: '+target.limit;}if(target.orderBy.length>0){str+=", orderBy: [".concat(target.orderBy.map(function(o){return stringifyOrderBy(o);}).join(', '),"]");}if(target.startAt){str+=', startAt: '+canonifyBound(target.startAt);}if(target.endAt){str+=', endAt: '+canonifyBound(target.endAt);}return"Target(".concat(str,")");}function targetEquals(left,right){if(left.limit!==right.limit){return false;}if(left.orderBy.length!==right.orderBy.length){return false;}for(var i=0;i<left.orderBy.length;i++){if(!orderByEquals(left.orderBy[i],right.orderBy[i])){return false;}}if(left.filters.length!==right.filters.length){return false;}for(var _i3=0;_i3<left.filters.length;_i3++){if(!filterEquals(left.filters[_i3],right.filters[_i3])){return false;}}if(left.collectionGroup!==right.collectionGroup){return false;}if(!left.path.isEqual(right.path)){return false;}if(!boundEquals(left.startAt,right.startAt)){return false;}return boundEquals(left.endAt,right.endAt);}function isDocumentTarget(target){return DocumentKey.isDocumentKey(target.path)&&target.collectionGroup===null&&target.filters.length===0;}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Query encapsulates all the query attributes we support in the SDK. It can
 * be run against the LocalStore, as well as be converted to a `Target` to
 * query the RemoteStore results.
 *
 * Visible for testing.
 */var QueryImpl=/**
     * Initializes a Query with a path and optional additional query constraints.
     * Path must currently be empty if this is a collection group query.
     */function QueryImpl(path){var collectionGroup=arguments.length>1&&arguments[1]!==undefined?arguments[1]:null;var explicitOrderBy=arguments.length>2&&arguments[2]!==undefined?arguments[2]:[];var filters=arguments.length>3&&arguments[3]!==undefined?arguments[3]:[];var limit=arguments.length>4&&arguments[4]!==undefined?arguments[4]:null;var limitType=arguments.length>5&&arguments[5]!==undefined?arguments[5]:"F";var startAt=arguments.length>6&&arguments[6]!==undefined?arguments[6]:null;var endAt=arguments.length>7&&arguments[7]!==undefined?arguments[7]:null;_classCallCheck(this,QueryImpl);this.path=path;this.collectionGroup=collectionGroup;this.explicitOrderBy=explicitOrderBy;this.filters=filters;this.limit=limit;this.limitType=limitType;this.startAt=startAt;this.endAt=endAt;this.memoizedOrderBy=null;// The corresponding `Target` of this `Query` instance.
this.memoizedTarget=null;if(this.startAt);if(this.endAt);};/** Creates a new Query instance with the options provided. */function newQuery(path,collectionGroup,explicitOrderBy,filters,limit,limitType,startAt,endAt){return new QueryImpl(path,collectionGroup,explicitOrderBy,filters,limit,limitType,startAt,endAt);}/** Creates a new Query for a query that matches all documents at `path` */function newQueryForPath(path){return new QueryImpl(path);}/**
 * Helper to convert a collection group query into a collection query at a
 * specific path. This is used when executing collection group queries, since
 * we have to split the query into a set of collection queries at multiple
 * paths.
 */function asCollectionQueryAtPath(query,path){return new QueryImpl(path,/*collectionGroup=*/null,query.explicitOrderBy.slice(),query.filters.slice(),query.limit,query.limitType,query.startAt,query.endAt);}/**
 * Returns true if this query does not specify any query constraints that
 * could remove results.
 */function matchesAllDocuments(query){return query.filters.length===0&&query.limit===null&&query.startAt==null&&query.endAt==null&&(query.explicitOrderBy.length===0||query.explicitOrderBy.length===1&&query.explicitOrderBy[0].field.isKeyField());}function hasLimitToFirst(query){return!isNullOrUndefined(query.limit)&&query.limitType==="F"/* First */;}function hasLimitToLast(query){return!isNullOrUndefined(query.limit)&&query.limitType==="L"/* Last */;}function getFirstOrderByField(query){return query.explicitOrderBy.length>0?query.explicitOrderBy[0].field:null;}function getInequalityFilterField(query){var _iteratorNormalCompletion6=true;var _didIteratorError6=false;var _iteratorError6=undefined;try{for(var _iterator6=query.filters[Symbol.iterator](),_step6;!(_iteratorNormalCompletion6=(_step6=_iterator6.next()).done);_iteratorNormalCompletion6=true){var filter=_step6.value;if(filter.isInequality()){return filter.field;}}}catch(err){_didIteratorError6=true;_iteratorError6=err;}finally{try{if(!_iteratorNormalCompletion6&&_iterator6["return"]!=null){_iterator6["return"]();}}finally{if(_didIteratorError6){throw _iteratorError6;}}}return null;}/**
 * Checks if any of the provided Operators are included in the query and
 * returns the first one that is, or null if none are.
 */function findFilterOperator(query,operators){var _iteratorNormalCompletion7=true;var _didIteratorError7=false;var _iteratorError7=undefined;try{for(var _iterator7=query.filters[Symbol.iterator](),_step7;!(_iteratorNormalCompletion7=(_step7=_iterator7.next()).done);_iteratorNormalCompletion7=true){var filter=_step7.value;if(operators.indexOf(filter.op)>=0){return filter.op;}}}catch(err){_didIteratorError7=true;_iteratorError7=err;}finally{try{if(!_iteratorNormalCompletion7&&_iterator7["return"]!=null){_iterator7["return"]();}}finally{if(_didIteratorError7){throw _iteratorError7;}}}return null;}/**
 * Creates a new Query for a collection group query that matches all documents
 * within the provided collection group.
 */function newQueryForCollectionGroup(collectionId){return new QueryImpl(ResourcePath.emptyPath(),collectionId);}/**
 * Returns whether the query matches a single document by path (rather than a
 * collection).
 */function isDocumentQuery(query){return DocumentKey.isDocumentKey(query.path)&&query.collectionGroup===null&&query.filters.length===0;}/**
 * Returns whether the query matches a collection group rather than a specific
 * collection.
 */function isCollectionGroupQuery(query){return query.collectionGroup!==null;}/**
 * Returns the implicit order by constraint that is used to execute the Query,
 * which can be different from the order by constraints the user provided (e.g.
 * the SDK and backend always orders by `__name__`).
 */function queryOrderBy(query){var queryImpl=debugCast(query);if(queryImpl.memoizedOrderBy===null){queryImpl.memoizedOrderBy=[];var inequalityField=getInequalityFilterField(queryImpl);var firstOrderByField=getFirstOrderByField(queryImpl);if(inequalityField!==null&&firstOrderByField===null){// In order to implicitly add key ordering, we must also add the
// inequality filter field for it to be a valid query.
// Note that the default inequality field and key ordering is ascending.
if(!inequalityField.isKeyField()){queryImpl.memoizedOrderBy.push(new OrderBy(inequalityField));}queryImpl.memoizedOrderBy.push(new OrderBy(FieldPath.keyField(),"asc"/* ASCENDING */));}else{var foundKeyOrdering=false;var _iteratorNormalCompletion8=true;var _didIteratorError8=false;var _iteratorError8=undefined;try{for(var _iterator8=queryImpl.explicitOrderBy[Symbol.iterator](),_step8;!(_iteratorNormalCompletion8=(_step8=_iterator8.next()).done);_iteratorNormalCompletion8=true){var orderBy=_step8.value;queryImpl.memoizedOrderBy.push(orderBy);if(orderBy.field.isKeyField()){foundKeyOrdering=true;}}}catch(err){_didIteratorError8=true;_iteratorError8=err;}finally{try{if(!_iteratorNormalCompletion8&&_iterator8["return"]!=null){_iterator8["return"]();}}finally{if(_didIteratorError8){throw _iteratorError8;}}}if(!foundKeyOrdering){// The order of the implicit key ordering always matches the last
// explicit order by
var lastDirection=queryImpl.explicitOrderBy.length>0?queryImpl.explicitOrderBy[queryImpl.explicitOrderBy.length-1].dir:"asc"/* ASCENDING */;queryImpl.memoizedOrderBy.push(new OrderBy(FieldPath.keyField(),lastDirection));}}}return queryImpl.memoizedOrderBy;}/**
 * Converts this `Query` instance to it's corresponding `Target` representation.
 */function queryToTarget(query){var queryImpl=debugCast(query);if(!queryImpl.memoizedTarget){if(queryImpl.limitType==="F"/* First */){queryImpl.memoizedTarget=newTarget(queryImpl.path,queryImpl.collectionGroup,queryOrderBy(queryImpl),queryImpl.filters,queryImpl.limit,queryImpl.startAt,queryImpl.endAt);}else{// Flip the orderBy directions since we want the last results
var orderBys=[];var _iteratorNormalCompletion9=true;var _didIteratorError9=false;var _iteratorError9=undefined;try{for(var _iterator9=queryOrderBy(queryImpl)[Symbol.iterator](),_step9;!(_iteratorNormalCompletion9=(_step9=_iterator9.next()).done);_iteratorNormalCompletion9=true){var orderBy=_step9.value;var dir=orderBy.dir==="desc"/* DESCENDING */?"asc"/* ASCENDING */:"desc"/* DESCENDING */;orderBys.push(new OrderBy(orderBy.field,dir));}// We need to swap the cursors to match the now-flipped query ordering.
}catch(err){_didIteratorError9=true;_iteratorError9=err;}finally{try{if(!_iteratorNormalCompletion9&&_iterator9["return"]!=null){_iterator9["return"]();}}finally{if(_didIteratorError9){throw _iteratorError9;}}}var startAt=queryImpl.endAt?new Bound(queryImpl.endAt.position,!queryImpl.endAt.before):null;var endAt=queryImpl.startAt?new Bound(queryImpl.startAt.position,!queryImpl.startAt.before):null;// Now return as a LimitType.First query.
queryImpl.memoizedTarget=newTarget(queryImpl.path,queryImpl.collectionGroup,orderBys,queryImpl.filters,queryImpl.limit,startAt,endAt);}}return queryImpl.memoizedTarget;}function queryWithAddedFilter(query,filter){var newFilters=query.filters.concat([filter]);return new QueryImpl(query.path,query.collectionGroup,query.explicitOrderBy.slice(),newFilters,query.limit,query.limitType,query.startAt,query.endAt);}function queryWithAddedOrderBy(query,orderBy){// TODO(dimond): validate that orderBy does not list the same key twice.
var newOrderBy=query.explicitOrderBy.concat([orderBy]);return new QueryImpl(query.path,query.collectionGroup,newOrderBy,query.filters.slice(),query.limit,query.limitType,query.startAt,query.endAt);}function queryWithLimit(query,limit,limitType){return new QueryImpl(query.path,query.collectionGroup,query.explicitOrderBy.slice(),query.filters.slice(),limit,limitType,query.startAt,query.endAt);}function queryWithStartAt(query,bound){return new QueryImpl(query.path,query.collectionGroup,query.explicitOrderBy.slice(),query.filters.slice(),query.limit,query.limitType,bound,query.endAt);}function queryWithEndAt(query,bound){return new QueryImpl(query.path,query.collectionGroup,query.explicitOrderBy.slice(),query.filters.slice(),query.limit,query.limitType,query.startAt,bound);}function queryEquals(left,right){return targetEquals(queryToTarget(left),queryToTarget(right))&&left.limitType===right.limitType;}// TODO(b/29183165): This is used to get a unique string from a query to, for
// example, use as a dictionary key, but the implementation is subject to
// collisions. Make it collision-free.
function canonifyQuery(query){return"".concat(canonifyTarget(queryToTarget(query)),"|lt:").concat(query.limitType);}function stringifyQuery(query){return"Query(target=".concat(stringifyTarget(queryToTarget(query)),"; limitType=").concat(query.limitType,")");}/** Returns whether `doc` matches the constraints of `query`. */function queryMatches(query,doc){return queryMatchesPathAndCollectionGroup(query,doc)&&queryMatchesOrderBy(query,doc)&&queryMatchesFilters(query,doc)&&queryMatchesBounds(query,doc);}function queryMatchesPathAndCollectionGroup(query,doc){var docPath=doc.key.path;if(query.collectionGroup!==null){// NOTE: this.path is currently always empty since we don't expose Collection
// Group queries rooted at a document path yet.
return doc.key.hasCollectionId(query.collectionGroup)&&query.path.isPrefixOf(docPath);}else if(DocumentKey.isDocumentKey(query.path)){// exact match for document queries
return query.path.isEqual(docPath);}else{// shallow ancestor queries by default
return query.path.isImmediateParentOf(docPath);}}/**
 * A document must have a value for every ordering clause in order to show up
 * in the results.
 */function queryMatchesOrderBy(query,doc){var _iteratorNormalCompletion10=true;var _didIteratorError10=false;var _iteratorError10=undefined;try{for(var _iterator10=query.explicitOrderBy[Symbol.iterator](),_step10;!(_iteratorNormalCompletion10=(_step10=_iterator10.next()).done);_iteratorNormalCompletion10=true){var orderBy=_step10.value;// order by key always matches
if(!orderBy.field.isKeyField()&&doc.field(orderBy.field)===null){return false;}}}catch(err){_didIteratorError10=true;_iteratorError10=err;}finally{try{if(!_iteratorNormalCompletion10&&_iterator10["return"]!=null){_iterator10["return"]();}}finally{if(_didIteratorError10){throw _iteratorError10;}}}return true;}function queryMatchesFilters(query,doc){var _iteratorNormalCompletion11=true;var _didIteratorError11=false;var _iteratorError11=undefined;try{for(var _iterator11=query.filters[Symbol.iterator](),_step11;!(_iteratorNormalCompletion11=(_step11=_iterator11.next()).done);_iteratorNormalCompletion11=true){var filter=_step11.value;if(!filter.matches(doc)){return false;}}}catch(err){_didIteratorError11=true;_iteratorError11=err;}finally{try{if(!_iteratorNormalCompletion11&&_iterator11["return"]!=null){_iterator11["return"]();}}finally{if(_didIteratorError11){throw _iteratorError11;}}}return true;}/** Makes sure a document is within the bounds, if provided. */function queryMatchesBounds(query,doc){if(query.startAt&&!sortsBeforeDocument(query.startAt,queryOrderBy(query),doc)){return false;}if(query.endAt&&sortsBeforeDocument(query.endAt,queryOrderBy(query),doc)){return false;}return true;}/**
 * Returns a new comparator function that can be used to compare two documents
 * based on the Query's ordering constraint.
 */function newQueryComparator(query){return function(d1,d2){var comparedOnKeyField=false;var _iteratorNormalCompletion12=true;var _didIteratorError12=false;var _iteratorError12=undefined;try{for(var _iterator12=queryOrderBy(query)[Symbol.iterator](),_step12;!(_iteratorNormalCompletion12=(_step12=_iterator12.next()).done);_iteratorNormalCompletion12=true){var orderBy=_step12.value;var comp=compareDocs(orderBy,d1,d2);if(comp!==0){return comp;}comparedOnKeyField=comparedOnKeyField||orderBy.field.isKeyField();}}catch(err){_didIteratorError12=true;_iteratorError12=err;}finally{try{if(!_iteratorNormalCompletion12&&_iterator12["return"]!=null){_iterator12["return"]();}}finally{if(_didIteratorError12){throw _iteratorError12;}}}return 0;};}var Filter=function Filter(){_classCallCheck(this,Filter);};var FieldFilter=/*#__PURE__*/function(_Filter){_inherits(FieldFilter,_Filter);function FieldFilter(field,op,value){var _this9;_classCallCheck(this,FieldFilter);_this9=_possibleConstructorReturn(this,_getPrototypeOf(FieldFilter).call(this));_this9.field=field;_this9.op=op;_this9.value=value;return _this9;}/**
     * Creates a filter based on the provided arguments.
     */_createClass(FieldFilter,[{key:"matches",value:function matches(doc){var other=doc.field(this.field);// Types do not have to match in NOT_EQUAL filters.
if(this.op==="!="/* NOT_EQUAL */){return other!==null&&this.matchesComparison(valueCompare(other,this.value));}// Only compare types with matching backend order (such as double and int).
return other!==null&&typeOrder(this.value)===typeOrder(other)&&this.matchesComparison(valueCompare(other,this.value));}},{key:"matchesComparison",value:function matchesComparison(comparison){switch(this.op){case"<"/* LESS_THAN */:return comparison<0;case"<="/* LESS_THAN_OR_EQUAL */:return comparison<=0;case"=="/* EQUAL */:return comparison===0;case"!="/* NOT_EQUAL */:return comparison!==0;case">"/* GREATER_THAN */:return comparison>0;case">="/* GREATER_THAN_OR_EQUAL */:return comparison>=0;default:return fail();}}},{key:"isInequality",value:function isInequality(){return["<"/* LESS_THAN */,"<="/* LESS_THAN_OR_EQUAL */,">"/* GREATER_THAN */,">="/* GREATER_THAN_OR_EQUAL */,"!="/* NOT_EQUAL */,"not-in"/* NOT_IN */].indexOf(this.op)>=0;}}],[{key:"create",value:function create(field,op,value){if(field.isKeyField()){if(op==="in"/* IN */||op==="not-in"/* NOT_IN */){return this.createKeyFieldInFilter(field,op,value);}else{return new KeyFieldFilter(field,op,value);}}else if(isNullValue(value)){if(op!=="=="/* EQUAL */&&op!=="!="/* NOT_EQUAL */){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid query. Null only supports '==' and '!=' comparisons.");}return new FieldFilter(field,op,value);}else if(isNanValue(value)){if(op!=="=="/* EQUAL */&&op!=="!="/* NOT_EQUAL */){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid query. NaN only supports '==' and '!=' comparisons.");}return new FieldFilter(field,op,value);}else if(op==="array-contains"/* ARRAY_CONTAINS */){return new ArrayContainsFilter(field,value);}else if(op==="in"/* IN */){return new InFilter(field,value);}else if(op==="not-in"/* NOT_IN */){return new NotInFilter(field,value);}else if(op==="array-contains-any"/* ARRAY_CONTAINS_ANY */){return new ArrayContainsAnyFilter(field,value);}else{return new FieldFilter(field,op,value);}}},{key:"createKeyFieldInFilter",value:function createKeyFieldInFilter(field,op,value){return op==="in"/* IN */?new KeyFieldInFilter(field,value):new KeyFieldNotInFilter(field,value);}}]);return FieldFilter;}(Filter);function canonifyFilter(filter){// TODO(b/29183165): Technically, this won't be unique if two values have
// the same description, such as the int 3 and the string "3". So we should
// add the types in here somehow, too.
return filter.field.canonicalString()+filter.op.toString()+canonicalId(filter.value);}function filterEquals(f1,f2){return f1.op===f2.op&&f1.field.isEqual(f2.field)&&valueEquals(f1.value,f2.value);}/** Returns a debug description for `filter`. */function stringifyFilter(filter){return"".concat(filter.field.canonicalString()," ").concat(filter.op," ").concat(canonicalId(filter.value));}/** Filter that matches on key fields (i.e. '__name__'). */var KeyFieldFilter=/*#__PURE__*/function(_FieldFilter){_inherits(KeyFieldFilter,_FieldFilter);function KeyFieldFilter(field,op,value){var _this10;_classCallCheck(this,KeyFieldFilter);_this10=_possibleConstructorReturn(this,_getPrototypeOf(KeyFieldFilter).call(this,field,op,value));_this10.key=DocumentKey.fromName(value.referenceValue);return _this10;}_createClass(KeyFieldFilter,[{key:"matches",value:function matches(doc){var comparison=DocumentKey.comparator(doc.key,this.key);return this.matchesComparison(comparison);}}]);return KeyFieldFilter;}(FieldFilter);/** Filter that matches on key fields within an array. */var KeyFieldInFilter=/*#__PURE__*/function(_FieldFilter2){_inherits(KeyFieldInFilter,_FieldFilter2);function KeyFieldInFilter(field,value){var _this11;_classCallCheck(this,KeyFieldInFilter);_this11=_possibleConstructorReturn(this,_getPrototypeOf(KeyFieldInFilter).call(this,field,"in"/* IN */,value));_this11.keys=extractDocumentKeysFromArrayValue("in"/* IN */,value);return _this11;}_createClass(KeyFieldInFilter,[{key:"matches",value:function matches(doc){return this.keys.some(function(key){return key.isEqual(doc.key);});}}]);return KeyFieldInFilter;}(FieldFilter);/** Filter that matches on key fields not present within an array. */var KeyFieldNotInFilter=/*#__PURE__*/function(_FieldFilter3){_inherits(KeyFieldNotInFilter,_FieldFilter3);function KeyFieldNotInFilter(field,value){var _this12;_classCallCheck(this,KeyFieldNotInFilter);_this12=_possibleConstructorReturn(this,_getPrototypeOf(KeyFieldNotInFilter).call(this,field,"not-in"/* NOT_IN */,value));_this12.keys=extractDocumentKeysFromArrayValue("not-in"/* NOT_IN */,value);return _this12;}_createClass(KeyFieldNotInFilter,[{key:"matches",value:function matches(doc){return!this.keys.some(function(key){return key.isEqual(doc.key);});}}]);return KeyFieldNotInFilter;}(FieldFilter);function extractDocumentKeysFromArrayValue(op,value){var _a;return(((_a=value.arrayValue)===null||_a===void 0?void 0:_a.values)||[]).map(function(v){return DocumentKey.fromName(v.referenceValue);});}/** A Filter that implements the array-contains operator. */var ArrayContainsFilter=/*#__PURE__*/function(_FieldFilter4){_inherits(ArrayContainsFilter,_FieldFilter4);function ArrayContainsFilter(field,value){_classCallCheck(this,ArrayContainsFilter);return _possibleConstructorReturn(this,_getPrototypeOf(ArrayContainsFilter).call(this,field,"array-contains"/* ARRAY_CONTAINS */,value));}_createClass(ArrayContainsFilter,[{key:"matches",value:function matches(doc){var other=doc.field(this.field);return isArray(other)&&arrayValueContains(other.arrayValue,this.value);}}]);return ArrayContainsFilter;}(FieldFilter);/** A Filter that implements the IN operator. */var InFilter=/*#__PURE__*/function(_FieldFilter5){_inherits(InFilter,_FieldFilter5);function InFilter(field,value){_classCallCheck(this,InFilter);return _possibleConstructorReturn(this,_getPrototypeOf(InFilter).call(this,field,"in"/* IN */,value));}_createClass(InFilter,[{key:"matches",value:function matches(doc){var other=doc.field(this.field);return other!==null&&arrayValueContains(this.value.arrayValue,other);}}]);return InFilter;}(FieldFilter);/** A Filter that implements the not-in operator. */var NotInFilter=/*#__PURE__*/function(_FieldFilter6){_inherits(NotInFilter,_FieldFilter6);function NotInFilter(field,value){_classCallCheck(this,NotInFilter);return _possibleConstructorReturn(this,_getPrototypeOf(NotInFilter).call(this,field,"not-in"/* NOT_IN */,value));}_createClass(NotInFilter,[{key:"matches",value:function matches(doc){if(arrayValueContains(this.value.arrayValue,{nullValue:'NULL_VALUE'})){return false;}var other=doc.field(this.field);return other!==null&&!arrayValueContains(this.value.arrayValue,other);}}]);return NotInFilter;}(FieldFilter);/** A Filter that implements the array-contains-any operator. */var ArrayContainsAnyFilter=/*#__PURE__*/function(_FieldFilter7){_inherits(ArrayContainsAnyFilter,_FieldFilter7);function ArrayContainsAnyFilter(field,value){_classCallCheck(this,ArrayContainsAnyFilter);return _possibleConstructorReturn(this,_getPrototypeOf(ArrayContainsAnyFilter).call(this,field,"array-contains-any"/* ARRAY_CONTAINS_ANY */,value));}_createClass(ArrayContainsAnyFilter,[{key:"matches",value:function matches(doc){var _this13=this;var other=doc.field(this.field);if(!isArray(other)||!other.arrayValue.values){return false;}return other.arrayValue.values.some(function(val){return arrayValueContains(_this13.value.arrayValue,val);});}}]);return ArrayContainsAnyFilter;}(FieldFilter);/**
 * Represents a bound of a query.
 *
 * The bound is specified with the given components representing a position and
 * whether it's just before or just after the position (relative to whatever the
 * query order is).
 *
 * The position represents a logical index position for a query. It's a prefix
 * of values for the (potentially implicit) order by clauses of a query.
 *
 * Bound provides a function to determine whether a document comes before or
 * after a bound. This is influenced by whether the position is just before or
 * just after the provided values.
 */var Bound=function Bound(position,before){_classCallCheck(this,Bound);this.position=position;this.before=before;};function canonifyBound(bound){// TODO(b/29183165): Make this collision robust.
return"".concat(bound.before?'b':'a',":").concat(bound.position.map(function(p){return canonicalId(p);}).join(','));}/**
 * Returns true if a document sorts before a bound using the provided sort
 * order.
 */function sortsBeforeDocument(bound,orderBy,doc){var comparison=0;for(var i=0;i<bound.position.length;i++){var orderByComponent=orderBy[i];var component=bound.position[i];if(orderByComponent.field.isKeyField()){comparison=DocumentKey.comparator(DocumentKey.fromName(component.referenceValue),doc.key);}else{var docValue=doc.field(orderByComponent.field);comparison=valueCompare(component,docValue);}if(orderByComponent.dir==="desc"/* DESCENDING */){comparison=comparison*-1;}if(comparison!==0){break;}}return bound.before?comparison<=0:comparison<0;}function boundEquals(left,right){if(left===null){return right===null;}else if(right===null){return false;}if(left.before!==right.before||left.position.length!==right.position.length){return false;}for(var i=0;i<left.position.length;i++){var leftPosition=left.position[i];var rightPosition=right.position[i];if(!valueEquals(leftPosition,rightPosition)){return false;}}return true;}/**
 * An ordering on a field, in some Direction. Direction defaults to ASCENDING.
 */var OrderBy=function OrderBy(field)/* ASCENDING */{var dir=arguments.length>1&&arguments[1]!==undefined?arguments[1]:"asc";_classCallCheck(this,OrderBy);this.field=field;this.dir=dir;};function compareDocs(orderBy,d1,d2){var comparison=orderBy.field.isKeyField()?DocumentKey.comparator(d1.key,d2.key):compareDocumentsByField(orderBy.field,d1,d2);switch(orderBy.dir){case"asc"/* ASCENDING */:return comparison;case"desc"/* DESCENDING */:return-1*comparison;default:return fail();}}function canonifyOrderBy(orderBy){// TODO(b/29183165): Make this collision robust.
return orderBy.field.canonicalString()+orderBy.dir;}function stringifyOrderBy(orderBy){return"".concat(orderBy.field.canonicalString()," (").concat(orderBy.dir,")");}function orderByEquals(left,right){return left.dir===right.dir&&left.field.isEqual(right.field);}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * A version of a document in Firestore. This corresponds to the version
 * timestamp, such as update_time or read_time.
 */var SnapshotVersion=/*#__PURE__*/function(){function SnapshotVersion(timestamp){_classCallCheck(this,SnapshotVersion);this.timestamp=timestamp;}_createClass(SnapshotVersion,[{key:"compareTo",value:function compareTo(other){return this.timestamp._compareTo(other.timestamp);}},{key:"isEqual",value:function isEqual(other){return this.timestamp.isEqual(other.timestamp);}/** Returns a number representation of the version for use in spec tests. */},{key:"toMicroseconds",value:function toMicroseconds(){// Convert to microseconds.
return this.timestamp.seconds*1e6+this.timestamp.nanoseconds/1000;}},{key:"toString",value:function toString(){return'SnapshotVersion('+this.timestamp.toString()+')';}},{key:"toTimestamp",value:function toTimestamp(){return this.timestamp;}}],[{key:"fromTimestamp",value:function fromTimestamp(value){return new SnapshotVersion(value);}},{key:"min",value:function min(){return new SnapshotVersion(new Timestamp(0,0));}}]);return SnapshotVersion;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * An ObjectValue represents a MapValue in the Firestore Proto and offers the
 * ability to add and remove fields (via the ObjectValueBuilder).
 */var ObjectValue=/*#__PURE__*/function(){function ObjectValue(proto){_classCallCheck(this,ObjectValue);this.proto=proto;}_createClass(ObjectValue,[{key:"field",/**
     * Returns the value at the given path or null.
     *
     * @param path the path to search
     * @return The value at the path or if there it doesn't exist.
     */value:function field(path){if(path.isEmpty()){return this.proto;}else{var value=this.proto;for(var i=0;i<path.length-1;++i){if(!value.mapValue.fields){return null;}value=value.mapValue.fields[path.get(i)];if(!isMapValue(value)){return null;}}value=(value.mapValue.fields||{})[path.lastSegment()];return value||null;}}},{key:"isEqual",value:function isEqual(other){return valueEquals(this.proto,other.proto);}}],[{key:"empty",value:function empty(){return new ObjectValue({mapValue:{}});}}]);return ObjectValue;}();/**
 * An ObjectValueBuilder provides APIs to set and delete fields from an
 * ObjectValue.
 */var ObjectValueBuilder=/*#__PURE__*/function(){/**
     * @param baseObject The object to mutate.
     */function ObjectValueBuilder(){var baseObject=arguments.length>0&&arguments[0]!==undefined?arguments[0]:ObjectValue.empty();_classCallCheck(this,ObjectValueBuilder);this.baseObject=baseObject;/** A map that contains the accumulated changes in this builder. */this.overlayMap=new Map();}/**
     * Sets the field to the provided value.
     *
     * @param path The field path to set.
     * @param value The value to set.
     * @return The current Builder instance.
     */_createClass(ObjectValueBuilder,[{key:"set",value:function set(path,value){this.setOverlay(path,value);return this;}/**
     * Removes the field at the specified path. If there is no field at the
     * specified path, nothing is changed.
     *
     * @param path The field path to remove.
     * @return The current Builder instance.
     */},{key:"delete",value:function _delete(path){this.setOverlay(path,null);return this;}/**
     * Adds `value` to the overlay map at `path`. Creates nested map entries if
     * needed.
     */},{key:"setOverlay",value:function setOverlay(path,value){var currentLevel=this.overlayMap;for(var i=0;i<path.length-1;++i){var currentSegment=path.get(i);var currentValue=currentLevel.get(currentSegment);if(currentValue instanceof Map){// Re-use a previously created map
currentLevel=currentValue;}else if(currentValue&&typeOrder(currentValue)===10/* ObjectValue */){// Convert the existing Protobuf MapValue into a map
currentValue=new Map(Object.entries(currentValue.mapValue.fields||{}));currentLevel.set(currentSegment,currentValue);currentLevel=currentValue;}else{// Create an empty map to represent the current nesting level
currentValue=new Map();currentLevel.set(currentSegment,currentValue);currentLevel=currentValue;}}currentLevel.set(path.lastSegment(),value);}/** Returns an ObjectValue with all mutations applied. */},{key:"build",value:function build(){var mergedResult=this.applyOverlay(FieldPath.emptyPath(),this.overlayMap);if(mergedResult!=null){return new ObjectValue(mergedResult);}else{return this.baseObject;}}/**
     * Applies any overlays from `currentOverlays` that exist at `currentPath`
     * and returns the merged data at `currentPath` (or null if there were no
     * changes).
     *
     * @param currentPath The path at the current nesting level. Can be set to
     * FieldValue.emptyPath() to represent the root.
     * @param currentOverlays The overlays at the current nesting level in the
     * same format as `overlayMap`.
     * @return The merged data at `currentPath` or null if no modifications
     * were applied.
     */},{key:"applyOverlay",value:function applyOverlay(currentPath,currentOverlays){var _this14=this;var modified=false;var existingValue=this.baseObject.field(currentPath);var resultAtPath=isMapValue(existingValue)?// If there is already data at the current path, base our
Object.assign({},existingValue.mapValue.fields):{};currentOverlays.forEach(function(value,pathSegment){if(value instanceof Map){var nested=_this14.applyOverlay(currentPath.child(pathSegment),value);if(nested!=null){resultAtPath[pathSegment]=nested;modified=true;}}else if(value!==null){resultAtPath[pathSegment]=value;modified=true;}else if(resultAtPath.hasOwnProperty(pathSegment)){delete resultAtPath[pathSegment];modified=true;}});return modified?{mapValue:{fields:resultAtPath}}:null;}}]);return ObjectValueBuilder;}();/**
 * Returns a FieldMask built from all fields in a MapValue.
 */function extractFieldMask(value){var fields=[];_forEach(value.fields||{},function(key,value){var currentPath=new FieldPath([key]);if(isMapValue(value)){var nestedMask=extractFieldMask(value.mapValue);var nestedFields=nestedMask.fields;if(nestedFields.length===0){// Preserve the empty map by adding it to the FieldMask.
fields.push(currentPath);}else{// For nested and non-empty ObjectValues, add the FieldPath of the
// leaf nodes.
var _iteratorNormalCompletion13=true;var _didIteratorError13=false;var _iteratorError13=undefined;try{for(var _iterator13=nestedFields[Symbol.iterator](),_step13;!(_iteratorNormalCompletion13=(_step13=_iterator13.next()).done);_iteratorNormalCompletion13=true){var nestedPath=_step13.value;fields.push(currentPath.child(nestedPath));}}catch(err){_didIteratorError13=true;_iteratorError13=err;}finally{try{if(!_iteratorNormalCompletion13&&_iterator13["return"]!=null){_iterator13["return"]();}}finally{if(_didIteratorError13){throw _iteratorError13;}}}}}else{// For nested and non-empty ObjectValues, add the FieldPath of the leaf
// nodes.
fields.push(currentPath);}});return new FieldMask(fields);}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var ExistenceFilter=// TODO(b/33078163): just use simplest form of existence filter for now
function ExistenceFilter(count){_classCallCheck(this,ExistenceFilter);this.count=count;};/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Error Codes describing the different ways GRPC can fail. These are copied
 * directly from GRPC's sources here:
 *
 * https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h
 *
 * Important! The names of these identifiers matter because the string forms
 * are used for reverse lookups from the webchannel stream. Do NOT change the
 * names of these identifiers or change this into a const enum.
 */var RpcCode;(function(RpcCode){RpcCode[RpcCode["OK"]=0]="OK";RpcCode[RpcCode["CANCELLED"]=1]="CANCELLED";RpcCode[RpcCode["UNKNOWN"]=2]="UNKNOWN";RpcCode[RpcCode["INVALID_ARGUMENT"]=3]="INVALID_ARGUMENT";RpcCode[RpcCode["DEADLINE_EXCEEDED"]=4]="DEADLINE_EXCEEDED";RpcCode[RpcCode["NOT_FOUND"]=5]="NOT_FOUND";RpcCode[RpcCode["ALREADY_EXISTS"]=6]="ALREADY_EXISTS";RpcCode[RpcCode["PERMISSION_DENIED"]=7]="PERMISSION_DENIED";RpcCode[RpcCode["UNAUTHENTICATED"]=16]="UNAUTHENTICATED";RpcCode[RpcCode["RESOURCE_EXHAUSTED"]=8]="RESOURCE_EXHAUSTED";RpcCode[RpcCode["FAILED_PRECONDITION"]=9]="FAILED_PRECONDITION";RpcCode[RpcCode["ABORTED"]=10]="ABORTED";RpcCode[RpcCode["OUT_OF_RANGE"]=11]="OUT_OF_RANGE";RpcCode[RpcCode["UNIMPLEMENTED"]=12]="UNIMPLEMENTED";RpcCode[RpcCode["INTERNAL"]=13]="INTERNAL";RpcCode[RpcCode["UNAVAILABLE"]=14]="UNAVAILABLE";RpcCode[RpcCode["DATA_LOSS"]=15]="DATA_LOSS";})(RpcCode||(RpcCode={}));/**
 * Determines whether an error code represents a permanent error when received
 * in response to a non-write operation.
 *
 * See isPermanentWriteError for classifying write errors.
 */function isPermanentError(code){switch(code){case Code.OK:return fail();case Code.CANCELLED:case Code.UNKNOWN:case Code.DEADLINE_EXCEEDED:case Code.RESOURCE_EXHAUSTED:case Code.INTERNAL:case Code.UNAVAILABLE:// Unauthenticated means something went wrong with our token and we need
// to retry with new credentials which will happen automatically.
case Code.UNAUTHENTICATED:return false;case Code.INVALID_ARGUMENT:case Code.NOT_FOUND:case Code.ALREADY_EXISTS:case Code.PERMISSION_DENIED:case Code.FAILED_PRECONDITION:// Aborted might be retried in some scenarios, but that is dependant on
// the context and should handled individually by the calling code.
// See https://cloud.google.com/apis/design/errors.
case Code.ABORTED:case Code.OUT_OF_RANGE:case Code.UNIMPLEMENTED:case Code.DATA_LOSS:return true;default:return fail();}}/**
 * Determines whether an error code represents a permanent error when received
 * in response to a write operation.
 *
 * Write operations must be handled specially because as of b/119437764, ABORTED
 * errors on the write stream should be retried too (even though ABORTED errors
 * are not generally retryable).
 *
 * Note that during the initial handshake on the write stream an ABORTED error
 * signals that we should discard our stream token (i.e. it is permanent). This
 * means a handshake error should be classified with isPermanentError, above.
 */function isPermanentWriteError(code){return isPermanentError(code)&&code!==Code.ABORTED;}/**
 * Maps an error Code from GRPC status code number, like 0, 1, or 14. These
 * are not the same as HTTP status codes.
 *
 * @returns The Code equivalent to the given GRPC status code. Fails if there
 *     is no match.
 */function mapCodeFromRpcCode(code){if(code===undefined){// This shouldn't normally happen, but in certain error cases (like trying
// to send invalid proto messages) we may get an error with no GRPC code.
logError('GRPC error has no .code');return Code.UNKNOWN;}switch(code){case RpcCode.OK:return Code.OK;case RpcCode.CANCELLED:return Code.CANCELLED;case RpcCode.UNKNOWN:return Code.UNKNOWN;case RpcCode.DEADLINE_EXCEEDED:return Code.DEADLINE_EXCEEDED;case RpcCode.RESOURCE_EXHAUSTED:return Code.RESOURCE_EXHAUSTED;case RpcCode.INTERNAL:return Code.INTERNAL;case RpcCode.UNAVAILABLE:return Code.UNAVAILABLE;case RpcCode.UNAUTHENTICATED:return Code.UNAUTHENTICATED;case RpcCode.INVALID_ARGUMENT:return Code.INVALID_ARGUMENT;case RpcCode.NOT_FOUND:return Code.NOT_FOUND;case RpcCode.ALREADY_EXISTS:return Code.ALREADY_EXISTS;case RpcCode.PERMISSION_DENIED:return Code.PERMISSION_DENIED;case RpcCode.FAILED_PRECONDITION:return Code.FAILED_PRECONDITION;case RpcCode.ABORTED:return Code.ABORTED;case RpcCode.OUT_OF_RANGE:return Code.OUT_OF_RANGE;case RpcCode.UNIMPLEMENTED:return Code.UNIMPLEMENTED;case RpcCode.DATA_LOSS:return Code.DATA_LOSS;default:return fail();}}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * An event from the RemoteStore. It is split into targetChanges (changes to the
 * state or the set of documents in our watched targets) and documentUpdates
 * (changes to the actual documents).
 */var RemoteEvent=/*#__PURE__*/function(){function RemoteEvent(/**
     * The snapshot version this event brings us up to, or MIN if not set.
     */snapshotVersion,/**
     * A map from target to changes to the target. See TargetChange.
     */targetChanges,/**
     * A set of targets that is known to be inconsistent. Listens for these
     * targets should be re-established without resume tokens.
     */targetMismatches,/**
     * A set of which documents have changed or been deleted, along with the
     * doc's new values (if not deleted).
     */documentUpdates,/**
     * A set of which document updates are due only to limbo resolution targets.
     */resolvedLimboDocuments){_classCallCheck(this,RemoteEvent);this.snapshotVersion=snapshotVersion;this.targetChanges=targetChanges;this.targetMismatches=targetMismatches;this.documentUpdates=documentUpdates;this.resolvedLimboDocuments=resolvedLimboDocuments;}/**
     * HACK: Views require RemoteEvents in order to determine whether the view is
     * CURRENT, but secondary tabs don't receive remote events. So this method is
     * used to create a synthesized RemoteEvent that can be used to apply a
     * CURRENT status change to a View, for queries executed in a different tab.
     */ // PORTING NOTE: Multi-tab only
_createClass(RemoteEvent,null,[{key:"createSynthesizedRemoteEventForCurrentChange",value:function createSynthesizedRemoteEventForCurrentChange(targetId,current){var targetChanges=new Map();targetChanges.set(targetId,TargetChange.createSynthesizedTargetChangeForCurrentChange(targetId,current));return new RemoteEvent(SnapshotVersion.min(),targetChanges,targetIdSet(),maybeDocumentMap(),documentKeySet());}}]);return RemoteEvent;}();/**
 * A TargetChange specifies the set of changes for a specific target as part of
 * a RemoteEvent. These changes track which documents are added, modified or
 * removed, as well as the target's resume token and whether the target is
 * marked CURRENT.
 * The actual changes *to* documents are not part of the TargetChange since
 * documents may be part of multiple targets.
 */var TargetChange=/*#__PURE__*/function(){function TargetChange(/**
     * An opaque, server-assigned token that allows watching a query to be resumed
     * after disconnecting without retransmitting all the data that matches the
     * query. The resume token essentially identifies a point in time from which
     * the server should resume sending results.
     */resumeToken,/**
     * The "current" (synced) status of this target. Note that "current"
     * has special meaning in the RPC protocol that implies that a target is
     * both up-to-date and consistent with the rest of the watch stream.
     */current,/**
     * The set of documents that were newly assigned to this target as part of
     * this remote event.
     */addedDocuments,/**
     * The set of documents that were already assigned to this target but received
     * an update during this remote event.
     */modifiedDocuments,/**
     * The set of documents that were removed from this target as part of this
     * remote event.
     */removedDocuments){_classCallCheck(this,TargetChange);this.resumeToken=resumeToken;this.current=current;this.addedDocuments=addedDocuments;this.modifiedDocuments=modifiedDocuments;this.removedDocuments=removedDocuments;}/**
     * This method is used to create a synthesized TargetChanges that can be used to
     * apply a CURRENT status change to a View (for queries executed in a different
     * tab) or for new queries (to raise snapshots with correct CURRENT status).
     */_createClass(TargetChange,null,[{key:"createSynthesizedTargetChangeForCurrentChange",value:function createSynthesizedTargetChangeForCurrentChange(targetId,current){return new TargetChange(ByteString.EMPTY_BYTE_STRING,current,documentKeySet(),documentKeySet(),documentKeySet());}}]);return TargetChange;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Represents a changed document and a list of target ids to which this change
 * applies.
 *
 * If document has been deleted NoDocument will be provided.
 */var DocumentWatchChange=function DocumentWatchChange(/** The new document applies to all of these targets. */updatedTargetIds,/** The new document is removed from all of these targets. */removedTargetIds,/** The key of the document for this change. */key,/**
     * The new document or NoDocument if it was deleted. Is null if the
     * document went out of view without the server sending a new document.
     */newDoc){_classCallCheck(this,DocumentWatchChange);this.updatedTargetIds=updatedTargetIds;this.removedTargetIds=removedTargetIds;this.key=key;this.newDoc=newDoc;};var ExistenceFilterChange=function ExistenceFilterChange(targetId,existenceFilter){_classCallCheck(this,ExistenceFilterChange);this.targetId=targetId;this.existenceFilter=existenceFilter;};var WatchTargetChange=function WatchTargetChange(/** What kind of change occurred to the watch target. */state,/** The target IDs that were added/removed/set. */targetIds){var resumeToken=arguments.length>2&&arguments[2]!==undefined?arguments[2]:ByteString.EMPTY_BYTE_STRING;var cause=arguments.length>3&&arguments[3]!==undefined?arguments[3]:null;_classCallCheck(this,WatchTargetChange);this.state=state;this.targetIds=targetIds;this.resumeToken=resumeToken;this.cause=cause;};/** Tracks the internal state of a Watch target. */var TargetState=/*#__PURE__*/function(){function TargetState(){_classCallCheck(this,TargetState);/**
         * The number of pending responses (adds or removes) that we are waiting on.
         * We only consider targets active that have no pending responses.
         */this.pendingResponses=0;/**
         * Keeps track of the document changes since the last raised snapshot.
         *
         * These changes are continuously updated as we receive document updates and
         * always reflect the current set of changes against the last issued snapshot.
         */this.documentChanges=snapshotChangesMap();/** See public getters for explanations of these fields. */this._resumeToken=ByteString.EMPTY_BYTE_STRING;this._current=false;/**
         * Whether this target state should be included in the next snapshot. We
         * initialize to true so that newly-added targets are included in the next
         * RemoteEvent.
         */this._hasPendingChanges=true;}/**
     * Whether this target has been marked 'current'.
     *
     * 'Current' has special meaning in the RPC protocol: It implies that the
     * Watch backend has sent us all changes up to the point at which the target
     * was added and that the target is consistent with the rest of the watch
     * stream.
     */_createClass(TargetState,[{key:"updateResumeToken",/**
     * Applies the resume token to the TargetChange, but only when it has a new
     * value. Empty resumeTokens are discarded.
     */value:function updateResumeToken(resumeToken){if(resumeToken.approximateByteSize()>0){this._hasPendingChanges=true;this._resumeToken=resumeToken;}}/**
     * Creates a target change from the current set of changes.
     *
     * To reset the document changes after raising this snapshot, call
     * `clearPendingChanges()`.
     */},{key:"toTargetChange",value:function toTargetChange(){var addedDocuments=documentKeySet();var modifiedDocuments=documentKeySet();var removedDocuments=documentKeySet();this.documentChanges.forEach(function(key,changeType){switch(changeType){case 0/* Added */:addedDocuments=addedDocuments.add(key);break;case 2/* Modified */:modifiedDocuments=modifiedDocuments.add(key);break;case 1/* Removed */:removedDocuments=removedDocuments.add(key);break;default:fail();}});return new TargetChange(this._resumeToken,this._current,addedDocuments,modifiedDocuments,removedDocuments);}/**
     * Resets the document changes and sets `hasPendingChanges` to false.
     */},{key:"clearPendingChanges",value:function clearPendingChanges(){this._hasPendingChanges=false;this.documentChanges=snapshotChangesMap();}},{key:"addDocumentChange",value:function addDocumentChange(key,changeType){this._hasPendingChanges=true;this.documentChanges=this.documentChanges.insert(key,changeType);}},{key:"removeDocumentChange",value:function removeDocumentChange(key){this._hasPendingChanges=true;this.documentChanges=this.documentChanges.remove(key);}},{key:"recordPendingTargetRequest",value:function recordPendingTargetRequest(){this.pendingResponses+=1;}},{key:"recordTargetResponse",value:function recordTargetResponse(){this.pendingResponses-=1;}},{key:"markCurrent",value:function markCurrent(){this._hasPendingChanges=true;this._current=true;}},{key:"current",get:function get(){return this._current;}/** The last resume token sent to us for this target. */},{key:"resumeToken",get:function get(){return this._resumeToken;}/** Whether this target has pending target adds or target removes. */},{key:"isPending",get:function get(){return this.pendingResponses!==0;}/** Whether we have modified any state that should trigger a snapshot. */},{key:"hasPendingChanges",get:function get(){return this._hasPendingChanges;}}]);return TargetState;}();var LOG_TAG$1='WatchChangeAggregator';/**
 * A helper class to accumulate watch changes into a RemoteEvent.
 */var WatchChangeAggregator=/*#__PURE__*/function(){function WatchChangeAggregator(metadataProvider){_classCallCheck(this,WatchChangeAggregator);this.metadataProvider=metadataProvider;/** The internal state of all tracked targets. */this.targetStates=new Map();/** Keeps track of the documents to update since the last raised snapshot. */this.pendingDocumentUpdates=maybeDocumentMap();/** A mapping of document keys to their set of target IDs. */this.pendingDocumentTargetMapping=documentTargetMap();/**
         * A list of targets with existence filter mismatches. These targets are
         * known to be inconsistent and their listens needs to be re-established by
         * RemoteStore.
         */this.pendingTargetResets=new SortedSet(primitiveComparator);}/**
     * Processes and adds the DocumentWatchChange to the current set of changes.
     */_createClass(WatchChangeAggregator,[{key:"handleDocumentChange",value:function handleDocumentChange(docChange){var _iteratorNormalCompletion14=true;var _didIteratorError14=false;var _iteratorError14=undefined;try{for(var _iterator14=docChange.updatedTargetIds[Symbol.iterator](),_step14;!(_iteratorNormalCompletion14=(_step14=_iterator14.next()).done);_iteratorNormalCompletion14=true){var targetId=_step14.value;if(docChange.newDoc instanceof Document){this.addDocumentToTarget(targetId,docChange.newDoc);}else if(docChange.newDoc instanceof NoDocument){this.removeDocumentFromTarget(targetId,docChange.key,docChange.newDoc);}}}catch(err){_didIteratorError14=true;_iteratorError14=err;}finally{try{if(!_iteratorNormalCompletion14&&_iterator14["return"]!=null){_iterator14["return"]();}}finally{if(_didIteratorError14){throw _iteratorError14;}}}var _iteratorNormalCompletion15=true;var _didIteratorError15=false;var _iteratorError15=undefined;try{for(var _iterator15=docChange.removedTargetIds[Symbol.iterator](),_step15;!(_iteratorNormalCompletion15=(_step15=_iterator15.next()).done);_iteratorNormalCompletion15=true){var _targetId=_step15.value;this.removeDocumentFromTarget(_targetId,docChange.key,docChange.newDoc);}}catch(err){_didIteratorError15=true;_iteratorError15=err;}finally{try{if(!_iteratorNormalCompletion15&&_iterator15["return"]!=null){_iterator15["return"]();}}finally{if(_didIteratorError15){throw _iteratorError15;}}}}/** Processes and adds the WatchTargetChange to the current set of changes. */},{key:"handleTargetChange",value:function handleTargetChange(targetChange){var _this15=this;this.forEachTarget(targetChange,function(targetId){var targetState=_this15.ensureTargetState(targetId);switch(targetChange.state){case 0/* NoChange */:if(_this15.isActiveTarget(targetId)){targetState.updateResumeToken(targetChange.resumeToken);}break;case 1/* Added */:// We need to decrement the number of pending acks needed from watch
// for this targetId.
targetState.recordTargetResponse();if(!targetState.isPending){// We have a freshly added target, so we need to reset any state
// that we had previously. This can happen e.g. when remove and add
// back a target for existence filter mismatches.
targetState.clearPendingChanges();}targetState.updateResumeToken(targetChange.resumeToken);break;case 2/* Removed */:// We need to keep track of removed targets to we can post-filter and
// remove any target changes.
// We need to decrement the number of pending acks needed from watch
// for this targetId.
targetState.recordTargetResponse();if(!targetState.isPending){_this15.removeTarget(targetId);}break;case 3/* Current */:if(_this15.isActiveTarget(targetId)){targetState.markCurrent();targetState.updateResumeToken(targetChange.resumeToken);}break;case 4/* Reset */:if(_this15.isActiveTarget(targetId)){// Reset the target and synthesizes removes for all existing
// documents. The backend will re-add any documents that still
// match the target before it sends the next global snapshot.
_this15.resetTarget(targetId);targetState.updateResumeToken(targetChange.resumeToken);}break;default:fail();}});}/**
     * Iterates over all targetIds that the watch change applies to: either the
     * targetIds explicitly listed in the change or the targetIds of all currently
     * active targets.
     */},{key:"forEachTarget",value:function forEachTarget(targetChange,fn){var _this16=this;if(targetChange.targetIds.length>0){targetChange.targetIds.forEach(fn);}else{this.targetStates.forEach(function(_,targetId){if(_this16.isActiveTarget(targetId)){fn(targetId);}});}}/**
     * Handles existence filters and synthesizes deletes for filter mismatches.
     * Targets that are invalidated by filter mismatches are added to
     * `pendingTargetResets`.
     */},{key:"handleExistenceFilter",value:function handleExistenceFilter(watchChange){var targetId=watchChange.targetId;var expectedCount=watchChange.existenceFilter.count;var targetData=this.targetDataForActiveTarget(targetId);if(targetData){var target=targetData.target;if(isDocumentTarget(target)){if(expectedCount===0){// The existence filter told us the document does not exist. We deduce
// that this document does not exist and apply a deleted document to
// our updates. Without applying this deleted document there might be
// another query that will raise this document as part of a snapshot
// until it is resolved, essentially exposing inconsistency between
// queries.
var key=new DocumentKey(target.path);this.removeDocumentFromTarget(targetId,key,new NoDocument(key,SnapshotVersion.min()));}else{hardAssert(expectedCount===1);}}else{var currentSize=this.getCurrentDocumentCountForTarget(targetId);if(currentSize!==expectedCount){// Existence filter mismatch: We reset the mapping and raise a new
// snapshot with `isFromCache:true`.
this.resetTarget(targetId);this.pendingTargetResets=this.pendingTargetResets.add(targetId);}}}}/**
     * Converts the currently accumulated state into a remote event at the
     * provided snapshot version. Resets the accumulated changes before returning.
     */},{key:"createRemoteEvent",value:function createRemoteEvent(snapshotVersion){var _this17=this;var targetChanges=new Map();this.targetStates.forEach(function(targetState,targetId){var targetData=_this17.targetDataForActiveTarget(targetId);if(targetData){if(targetState.current&&isDocumentTarget(targetData.target)){// Document queries for document that don't exist can produce an empty
// result set. To update our local cache, we synthesize a document
// delete if we have not previously received the document. This
// resolves the limbo state of the document, removing it from
// limboDocumentRefs.
//
// TODO(dimond): Ideally we would have an explicit lookup target
// instead resulting in an explicit delete message and we could
// remove this special logic.
var key=new DocumentKey(targetData.target.path);if(_this17.pendingDocumentUpdates.get(key)===null&&!_this17.targetContainsDocument(targetId,key)){_this17.removeDocumentFromTarget(targetId,key,new NoDocument(key,snapshotVersion));}}if(targetState.hasPendingChanges){targetChanges.set(targetId,targetState.toTargetChange());targetState.clearPendingChanges();}}});var resolvedLimboDocuments=documentKeySet();// We extract the set of limbo-only document updates as the GC logic
// special-cases documents that do not appear in the target cache.
//
// TODO(gsoltis): Expand on this comment once GC is available in the JS
// client.
this.pendingDocumentTargetMapping.forEach(function(key,targets){var isOnlyLimboTarget=true;targets.forEachWhile(function(targetId){var targetData=_this17.targetDataForActiveTarget(targetId);if(targetData&&targetData.purpose!==2/* LimboResolution */){isOnlyLimboTarget=false;return false;}return true;});if(isOnlyLimboTarget){resolvedLimboDocuments=resolvedLimboDocuments.add(key);}});var remoteEvent=new RemoteEvent(snapshotVersion,targetChanges,this.pendingTargetResets,this.pendingDocumentUpdates,resolvedLimboDocuments);this.pendingDocumentUpdates=maybeDocumentMap();this.pendingDocumentTargetMapping=documentTargetMap();this.pendingTargetResets=new SortedSet(primitiveComparator);return remoteEvent;}/**
     * Adds the provided document to the internal list of document updates and
     * its document key to the given target's mapping.
     */ // Visible for testing.
},{key:"addDocumentToTarget",value:function addDocumentToTarget(targetId,document){if(!this.isActiveTarget(targetId)){return;}var changeType=this.targetContainsDocument(targetId,document.key)?2/* Modified */:0/* Added */;var targetState=this.ensureTargetState(targetId);targetState.addDocumentChange(document.key,changeType);this.pendingDocumentUpdates=this.pendingDocumentUpdates.insert(document.key,document);this.pendingDocumentTargetMapping=this.pendingDocumentTargetMapping.insert(document.key,this.ensureDocumentTargetMapping(document.key).add(targetId));}/**
     * Removes the provided document from the target mapping. If the
     * document no longer matches the target, but the document's state is still
     * known (e.g. we know that the document was deleted or we received the change
     * that caused the filter mismatch), the new document can be provided
     * to update the remote document cache.
     */ // Visible for testing.
},{key:"removeDocumentFromTarget",value:function removeDocumentFromTarget(targetId,key,updatedDocument){if(!this.isActiveTarget(targetId)){return;}var targetState=this.ensureTargetState(targetId);if(this.targetContainsDocument(targetId,key)){targetState.addDocumentChange(key,1/* Removed */);}else{// The document may have entered and left the target before we raised a
// snapshot, so we can just ignore the change.
targetState.removeDocumentChange(key);}this.pendingDocumentTargetMapping=this.pendingDocumentTargetMapping.insert(key,this.ensureDocumentTargetMapping(key)["delete"](targetId));if(updatedDocument){this.pendingDocumentUpdates=this.pendingDocumentUpdates.insert(key,updatedDocument);}}},{key:"removeTarget",value:function removeTarget(targetId){this.targetStates["delete"](targetId);}/**
     * Returns the current count of documents in the target. This includes both
     * the number of documents that the LocalStore considers to be part of the
     * target as well as any accumulated changes.
     */},{key:"getCurrentDocumentCountForTarget",value:function getCurrentDocumentCountForTarget(targetId){var targetState=this.ensureTargetState(targetId);var targetChange=targetState.toTargetChange();return this.metadataProvider.getRemoteKeysForTarget(targetId).size+targetChange.addedDocuments.size-targetChange.removedDocuments.size;}/**
     * Increment the number of acks needed from watch before we can consider the
     * server to be 'in-sync' with the client's active targets.
     */},{key:"recordPendingTargetRequest",value:function recordPendingTargetRequest(targetId){// For each request we get we need to record we need a response for it.
var targetState=this.ensureTargetState(targetId);targetState.recordPendingTargetRequest();}},{key:"ensureTargetState",value:function ensureTargetState(targetId){var result=this.targetStates.get(targetId);if(!result){result=new TargetState();this.targetStates.set(targetId,result);}return result;}},{key:"ensureDocumentTargetMapping",value:function ensureDocumentTargetMapping(key){var targetMapping=this.pendingDocumentTargetMapping.get(key);if(!targetMapping){targetMapping=new SortedSet(primitiveComparator);this.pendingDocumentTargetMapping=this.pendingDocumentTargetMapping.insert(key,targetMapping);}return targetMapping;}/**
     * Verifies that the user is still interested in this target (by calling
     * `getTargetDataForTarget()`) and that we are not waiting for pending ADDs
     * from watch.
     */},{key:"isActiveTarget",value:function isActiveTarget(targetId){var targetActive=this.targetDataForActiveTarget(targetId)!==null;if(!targetActive){logDebug(LOG_TAG$1,'Detected inactive target',targetId);}return targetActive;}/**
     * Returns the TargetData for an active target (i.e. a target that the user
     * is still interested in that has no outstanding target change requests).
     */},{key:"targetDataForActiveTarget",value:function targetDataForActiveTarget(targetId){var targetState=this.targetStates.get(targetId);return targetState&&targetState.isPending?null:this.metadataProvider.getTargetDataForTarget(targetId);}/**
     * Resets the state of a Watch target to its initial state (e.g. sets
     * 'current' to false, clears the resume token and removes its target mapping
     * from all documents).
     */},{key:"resetTarget",value:function resetTarget(targetId){var _this18=this;this.targetStates.set(targetId,new TargetState());// Trigger removal for any documents currently mapped to this target.
// These removals will be part of the initial snapshot if Watch does not
// resend these documents.
var existingKeys=this.metadataProvider.getRemoteKeysForTarget(targetId);existingKeys.forEach(function(key){_this18.removeDocumentFromTarget(targetId,key,/*updatedDocument=*/null);});}/**
     * Returns whether the LocalStore considers the document to be part of the
     * specified target.
     */},{key:"targetContainsDocument",value:function targetContainsDocument(targetId,key){var existingKeys=this.metadataProvider.getRemoteKeysForTarget(targetId);return existingKeys.has(key);}}]);return WatchChangeAggregator;}();function documentTargetMap(){return new SortedMap(DocumentKey.comparator);}function snapshotChangesMap(){return new SortedMap(DocumentKey.comparator);}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var DIRECTIONS=function(){var dirs={};dirs["asc"/* ASCENDING */]='ASCENDING';dirs["desc"/* DESCENDING */]='DESCENDING';return dirs;}();var OPERATORS=function(){var ops={};ops["<"/* LESS_THAN */]='LESS_THAN';ops["<="/* LESS_THAN_OR_EQUAL */]='LESS_THAN_OR_EQUAL';ops[">"/* GREATER_THAN */]='GREATER_THAN';ops[">="/* GREATER_THAN_OR_EQUAL */]='GREATER_THAN_OR_EQUAL';ops["=="/* EQUAL */]='EQUAL';ops["!="/* NOT_EQUAL */]='NOT_EQUAL';ops["array-contains"/* ARRAY_CONTAINS */]='ARRAY_CONTAINS';ops["in"/* IN */]='IN';ops["not-in"/* NOT_IN */]='NOT_IN';ops["array-contains-any"/* ARRAY_CONTAINS_ANY */]='ARRAY_CONTAINS_ANY';return ops;}();function assertPresent(value,description){}/**
 * This class generates JsonObject values for the Datastore API suitable for
 * sending to either GRPC stub methods or via the JSON/HTTP REST API.
 *
 * The serializer supports both Protobuf.js and Proto3 JSON formats. By
 * setting `useProto3Json` to true, the serializer will use the Proto3 JSON
 * format.
 *
 * For a description of the Proto3 JSON format check
 * https://developers.google.com/protocol-buffers/docs/proto3#json
 *
 * TODO(klimt): We can remove the databaseId argument if we keep the full
 * resource name in documents.
 */var JsonProtoSerializer=function JsonProtoSerializer(databaseId,useProto3Json){_classCallCheck(this,JsonProtoSerializer);this.databaseId=databaseId;this.useProto3Json=useProto3Json;};function fromRpcStatus(status){var code=status.code===undefined?Code.UNKNOWN:mapCodeFromRpcCode(status.code);return new FirestoreError(code,status.message||'');}/**
 * Returns a value for a number (or null) that's appropriate to put into
 * a google.protobuf.Int32Value proto.
 * DO NOT USE THIS FOR ANYTHING ELSE.
 * This method cheats. It's typed as returning "number" because that's what
 * our generated proto interfaces say Int32Value must be. But GRPC actually
 * expects a { value: <number> } struct.
 */function toInt32Proto(serializer,val){if(serializer.useProto3Json||isNullOrUndefined(val)){return val;}else{return{value:val};}}/**
 * Returns a number (or null) from a google.protobuf.Int32Value proto.
 */function fromInt32Proto(val){var result;if(_typeof(val)==='object'){result=val.value;}else{result=val;}return isNullOrUndefined(result)?null:result;}/**
 * Returns an IntegerValue for `value`.
 */function toInteger(value){return{integerValue:''+value};}/**
 * Returns an DoubleValue for `value` that is encoded based the serializer's
 * `useProto3Json` setting.
 */function toDouble(serializer,value){if(serializer.useProto3Json){if(isNaN(value)){return{doubleValue:'NaN'};}else if(value===Infinity){return{doubleValue:'Infinity'};}else if(value===-Infinity){return{doubleValue:'-Infinity'};}}return{doubleValue:isNegativeZero(value)?'-0':value};}/**
 * Returns a value for a number that's appropriate to put into a proto.
 * The return value is an IntegerValue if it can safely represent the value,
 * otherwise a DoubleValue is returned.
 */function toNumber(serializer,value){return isSafeInteger(value)?toInteger(value):toDouble(serializer,value);}/**
 * Returns a value for a Date that's appropriate to put into a proto.
 */function toTimestamp(serializer,timestamp){if(serializer.useProto3Json){// Serialize to ISO-8601 date format, but with full nano resolution.
// Since JS Date has only millis, let's only use it for the seconds and
// then manually add the fractions to the end.
var jsDateStr=new Date(timestamp.seconds*1000).toISOString();// Remove .xxx frac part and Z in the end.
var strUntilSeconds=jsDateStr.replace(/\.\d*/,'').replace('Z','');// Pad the fraction out to 9 digits (nanos).
var nanoStr=('000000000'+timestamp.nanoseconds).slice(-9);return"".concat(strUntilSeconds,".").concat(nanoStr,"Z");}else{return{seconds:''+timestamp.seconds,nanos:timestamp.nanoseconds// eslint-disable-next-line @typescript-eslint/no-explicit-any
};}}function fromTimestamp(date){var timestamp=normalizeTimestamp(date);return new Timestamp(timestamp.seconds,timestamp.nanos);}/**
 * Returns a value for bytes that's appropriate to put in a proto.
 *
 * Visible for testing.
 */function toBytes(serializer,bytes){if(serializer.useProto3Json){return bytes.toBase64();}else{return bytes.toUint8Array();}}/**
 * Returns a ByteString based on the proto string value.
 */function fromBytes(serializer,value){if(serializer.useProto3Json){hardAssert(value===undefined||typeof value==='string');return ByteString.fromBase64String(value?value:'');}else{hardAssert(value===undefined||value instanceof Uint8Array);return ByteString.fromUint8Array(value?value:new Uint8Array());}}function toVersion(serializer,version){return toTimestamp(serializer,version.toTimestamp());}function fromVersion(version){hardAssert(!!version);return SnapshotVersion.fromTimestamp(fromTimestamp(version));}function toResourceName(databaseId,path){return fullyQualifiedPrefixPath(databaseId).child('documents').child(path).canonicalString();}function fromResourceName(name){var resource=ResourcePath.fromString(name);hardAssert(isValidResourceName(resource));return resource;}function toName(serializer,key){return toResourceName(serializer.databaseId,key.path);}function fromName(serializer,name){var resource=fromResourceName(name);hardAssert(resource.get(1)===serializer.databaseId.projectId);hardAssert(!resource.get(3)&&!serializer.databaseId.database||resource.get(3)===serializer.databaseId.database);return new DocumentKey(extractLocalPathFromResourceName(resource));}function toQueryPath(serializer,path){return toResourceName(serializer.databaseId,path);}function fromQueryPath(name){var resourceName=fromResourceName(name);// In v1beta1 queries for collections at the root did not have a trailing
// "/documents". In v1 all resource paths contain "/documents". Preserve the
// ability to read the v1beta1 form for compatibility with queries persisted
// in the local target cache.
if(resourceName.length===4){return ResourcePath.emptyPath();}return extractLocalPathFromResourceName(resourceName);}function getEncodedDatabaseId(serializer){var path=new ResourcePath(['projects',serializer.databaseId.projectId,'databases',serializer.databaseId.database]);return path.canonicalString();}function fullyQualifiedPrefixPath(databaseId){return new ResourcePath(['projects',databaseId.projectId,'databases',databaseId.database]);}function extractLocalPathFromResourceName(resourceName){hardAssert(resourceName.length>4&&resourceName.get(4)==='documents');return resourceName.popFirst(5);}/** Creates a Document proto from key and fields (but no create/update time) */function toMutationDocument(serializer,key,fields){return{name:toName(serializer,key),fields:fields.proto.mapValue.fields};}function toDocument(serializer,document){return{name:toName(serializer,document.key),fields:document.toProto().mapValue.fields,updateTime:toTimestamp(serializer,document.version.toTimestamp())};}function fromDocument(serializer,document,hasCommittedMutations){var key=fromName(serializer,document.name);var version=fromVersion(document.updateTime);var data=new ObjectValue({mapValue:{fields:document.fields}});return new Document(key,version,data,{hasCommittedMutations:!!hasCommittedMutations});}function fromFound(serializer,doc){hardAssert(!!doc.found);assertPresent(doc.found.name);assertPresent(doc.found.updateTime);var key=fromName(serializer,doc.found.name);var version=fromVersion(doc.found.updateTime);var data=new ObjectValue({mapValue:{fields:doc.found.fields}});return new Document(key,version,data,{});}function fromMissing(serializer,result){hardAssert(!!result.missing);hardAssert(!!result.readTime);var key=fromName(serializer,result.missing);var version=fromVersion(result.readTime);return new NoDocument(key,version);}function fromMaybeDocument(serializer,result){if('found'in result){return fromFound(serializer,result);}else if('missing'in result){return fromMissing(serializer,result);}return fail();}function fromWatchChange(serializer,change){var watchChange;if('targetChange'in change){assertPresent(change.targetChange);// proto3 default value is unset in JSON (undefined), so use 'NO_CHANGE'
// if unset
var state=fromWatchTargetChangeState(change.targetChange.targetChangeType||'NO_CHANGE');var targetIds=change.targetChange.targetIds||[];var resumeToken=fromBytes(serializer,change.targetChange.resumeToken);var causeProto=change.targetChange.cause;var cause=causeProto&&fromRpcStatus(causeProto);watchChange=new WatchTargetChange(state,targetIds,resumeToken,cause||null);}else if('documentChange'in change){assertPresent(change.documentChange);var entityChange=change.documentChange;assertPresent(entityChange.document);assertPresent(entityChange.document.name);assertPresent(entityChange.document.updateTime);var key=fromName(serializer,entityChange.document.name);var _version=fromVersion(entityChange.document.updateTime);var data=new ObjectValue({mapValue:{fields:entityChange.document.fields}});var doc=new Document(key,_version,data,{});var updatedTargetIds=entityChange.targetIds||[];var removedTargetIds=entityChange.removedTargetIds||[];watchChange=new DocumentWatchChange(updatedTargetIds,removedTargetIds,doc.key,doc);}else if('documentDelete'in change){assertPresent(change.documentDelete);var docDelete=change.documentDelete;assertPresent(docDelete.document);var _key7=fromName(serializer,docDelete.document);var _version2=docDelete.readTime?fromVersion(docDelete.readTime):SnapshotVersion.min();var _doc=new NoDocument(_key7,_version2);var _removedTargetIds=docDelete.removedTargetIds||[];watchChange=new DocumentWatchChange([],_removedTargetIds,_doc.key,_doc);}else if('documentRemove'in change){assertPresent(change.documentRemove);var docRemove=change.documentRemove;assertPresent(docRemove.document);var _key8=fromName(serializer,docRemove.document);var _removedTargetIds2=docRemove.removedTargetIds||[];watchChange=new DocumentWatchChange([],_removedTargetIds2,_key8,null);}else if('filter'in change){// TODO(dimond): implement existence filter parsing with strategy.
assertPresent(change.filter);var filter=change.filter;assertPresent(filter.targetId);var count=filter.count||0;var existenceFilter=new ExistenceFilter(count);var targetId=filter.targetId;watchChange=new ExistenceFilterChange(targetId,existenceFilter);}else{return fail();}return watchChange;}function fromWatchTargetChangeState(state){if(state==='NO_CHANGE'){return 0/* NoChange */;}else if(state==='ADD'){return 1/* Added */;}else if(state==='REMOVE'){return 2/* Removed */;}else if(state==='CURRENT'){return 3/* Current */;}else if(state==='RESET'){return 4/* Reset */;}else{return fail();}}function versionFromListenResponse(change){// We have only reached a consistent snapshot for the entire stream if there
// is a read_time set and it applies to all targets (i.e. the list of
// targets is empty). The backend is guaranteed to send such responses.
if(!('targetChange'in change)){return SnapshotVersion.min();}var targetChange=change.targetChange;if(targetChange.targetIds&&targetChange.targetIds.length){return SnapshotVersion.min();}if(!targetChange.readTime){return SnapshotVersion.min();}return fromVersion(targetChange.readTime);}function toMutation(serializer,mutation){var result;if(mutation instanceof SetMutation){result={update:toMutationDocument(serializer,mutation.key,mutation.value)};}else if(mutation instanceof DeleteMutation){result={"delete":toName(serializer,mutation.key)};}else if(mutation instanceof PatchMutation){result={update:toMutationDocument(serializer,mutation.key,mutation.data),updateMask:toDocumentMask(mutation.fieldMask)};}else if(mutation instanceof TransformMutation){result={transform:{document:toName(serializer,mutation.key),fieldTransforms:mutation.fieldTransforms.map(function(transform){return toFieldTransform(serializer,transform);})}};}else if(mutation instanceof VerifyMutation){result={verify:toName(serializer,mutation.key)};}else{return fail();}if(!mutation.precondition.isNone){result.currentDocument=toPrecondition(serializer,mutation.precondition);}return result;}function fromMutation(serializer,proto){var precondition=proto.currentDocument?fromPrecondition(proto.currentDocument):Precondition.none();if(proto.update){assertPresent(proto.update.name);var key=fromName(serializer,proto.update.name);var value=new ObjectValue({mapValue:{fields:proto.update.fields}});if(proto.updateMask){var fieldMask=fromDocumentMask(proto.updateMask);return new PatchMutation(key,value,fieldMask,precondition);}else{return new SetMutation(key,value,precondition);}}else if(proto["delete"]){var _key9=fromName(serializer,proto["delete"]);return new DeleteMutation(_key9,precondition);}else if(proto.transform){var _key10=fromName(serializer,proto.transform.document);var fieldTransforms=proto.transform.fieldTransforms.map(function(transform){return fromFieldTransform(serializer,transform);});hardAssert(precondition.exists===true);return new TransformMutation(_key10,fieldTransforms);}else if(proto.verify){var _key11=fromName(serializer,proto.verify);return new VerifyMutation(_key11,precondition);}else{return fail();}}function toPrecondition(serializer,precondition){if(precondition.updateTime!==undefined){return{updateTime:toVersion(serializer,precondition.updateTime)};}else if(precondition.exists!==undefined){return{exists:precondition.exists};}else{return fail();}}function fromPrecondition(precondition){if(precondition.updateTime!==undefined){return Precondition.updateTime(fromVersion(precondition.updateTime));}else if(precondition.exists!==undefined){return Precondition.exists(precondition.exists);}else{return Precondition.none();}}function fromWriteResult(proto,commitTime){// NOTE: Deletes don't have an updateTime.
var version=proto.updateTime?fromVersion(proto.updateTime):fromVersion(commitTime);if(version.isEqual(SnapshotVersion.min())){// The Firestore Emulator currently returns an update time of 0 for
// deletes of non-existing documents (rather than null). This breaks the
// test "get deleted doc while offline with source=cache" as NoDocuments
// with version 0 are filtered by IndexedDb's RemoteDocumentCache.
// TODO(#2149): Remove this when Emulator is fixed
version=fromVersion(commitTime);}var transformResults=null;if(proto.transformResults&&proto.transformResults.length>0){transformResults=proto.transformResults;}return new MutationResult(version,transformResults);}function fromWriteResults(protos,commitTime){if(protos&&protos.length>0){hardAssert(commitTime!==undefined);return protos.map(function(proto){return fromWriteResult(proto,commitTime);});}else{return[];}}function toFieldTransform(serializer,fieldTransform){var transform=fieldTransform.transform;if(transform instanceof ServerTimestampTransform){return{fieldPath:fieldTransform.field.canonicalString(),setToServerValue:'REQUEST_TIME'};}else if(transform instanceof ArrayUnionTransformOperation){return{fieldPath:fieldTransform.field.canonicalString(),appendMissingElements:{values:transform.elements}};}else if(transform instanceof ArrayRemoveTransformOperation){return{fieldPath:fieldTransform.field.canonicalString(),removeAllFromArray:{values:transform.elements}};}else if(transform instanceof NumericIncrementTransformOperation){return{fieldPath:fieldTransform.field.canonicalString(),increment:transform.operand};}else{throw fail();}}function fromFieldTransform(serializer,proto){var transform=null;if('setToServerValue'in proto){hardAssert(proto.setToServerValue==='REQUEST_TIME');transform=new ServerTimestampTransform();}else if('appendMissingElements'in proto){var values=proto.appendMissingElements.values||[];transform=new ArrayUnionTransformOperation(values);}else if('removeAllFromArray'in proto){var _values=proto.removeAllFromArray.values||[];transform=new ArrayRemoveTransformOperation(_values);}else if('increment'in proto){transform=new NumericIncrementTransformOperation(serializer,proto.increment);}else{fail();}var fieldPath=FieldPath.fromServerFormat(proto.fieldPath);return new FieldTransform(fieldPath,transform);}function toDocumentsTarget(serializer,target){return{documents:[toQueryPath(serializer,target.path)]};}function fromDocumentsTarget(documentsTarget){var count=documentsTarget.documents.length;hardAssert(count===1);var name=documentsTarget.documents[0];return queryToTarget(newQueryForPath(fromQueryPath(name)));}function toQueryTarget(serializer,target){// Dissect the path into parent, collectionId, and optional key filter.
var result={structuredQuery:{}};var path=target.path;if(target.collectionGroup!==null){result.parent=toQueryPath(serializer,path);result.structuredQuery.from=[{collectionId:target.collectionGroup,allDescendants:true}];}else{result.parent=toQueryPath(serializer,path.popLast());result.structuredQuery.from=[{collectionId:path.lastSegment()}];}var where=toFilter(target.filters);if(where){result.structuredQuery.where=where;}var orderBy=toOrder(target.orderBy);if(orderBy){result.structuredQuery.orderBy=orderBy;}var limit=toInt32Proto(serializer,target.limit);if(limit!==null){result.structuredQuery.limit=limit;}if(target.startAt){result.structuredQuery.startAt=toCursor(target.startAt);}if(target.endAt){result.structuredQuery.endAt=toCursor(target.endAt);}return result;}function fromQueryTarget(target){var path=fromQueryPath(target.parent);var query=target.structuredQuery;var fromCount=query.from?query.from.length:0;var collectionGroup=null;if(fromCount>0){hardAssert(fromCount===1);var from=query.from[0];if(from.allDescendants){collectionGroup=from.collectionId;}else{path=path.child(from.collectionId);}}var filterBy=[];if(query.where){filterBy=fromFilter(query.where);}var orderBy=[];if(query.orderBy){orderBy=fromOrder(query.orderBy);}var limit=null;if(query.limit){limit=fromInt32Proto(query.limit);}var startAt=null;if(query.startAt){startAt=fromCursor(query.startAt);}var endAt=null;if(query.endAt){endAt=fromCursor(query.endAt);}return queryToTarget(newQuery(path,collectionGroup,orderBy,filterBy,limit,"F"/* First */,startAt,endAt));}function toListenRequestLabels(serializer,targetData){var value=toLabel(serializer,targetData.purpose);if(value==null){return null;}else{return{'goog-listen-tags':value};}}function toLabel(serializer,purpose){switch(purpose){case 0/* Listen */:return null;case 1/* ExistenceFilterMismatch */:return'existence-filter-mismatch';case 2/* LimboResolution */:return'limbo-document';default:return fail();}}function toTarget(serializer,targetData){var result;var target=targetData.target;if(isDocumentTarget(target)){result={documents:toDocumentsTarget(serializer,target)};}else{result={query:toQueryTarget(serializer,target)};}result.targetId=targetData.targetId;if(targetData.resumeToken.approximateByteSize()>0){result.resumeToken=toBytes(serializer,targetData.resumeToken);}return result;}function toFilter(filters){if(filters.length===0){return;}var protos=filters.map(function(filter){return toUnaryOrFieldFilter(filter);});if(protos.length===1){return protos[0];}return{compositeFilter:{op:'AND',filters:protos}};}function fromFilter(filter){if(!filter){return[];}else if(filter.unaryFilter!==undefined){return[fromUnaryFilter(filter)];}else if(filter.fieldFilter!==undefined){return[fromFieldFilter(filter)];}else if(filter.compositeFilter!==undefined){return filter.compositeFilter.filters.map(function(f){return fromFilter(f);}).reduce(function(accum,current){return accum.concat(current);});}else{return fail();}}function toOrder(orderBys){if(orderBys.length===0){return;}return orderBys.map(function(order){return toPropertyOrder(order);});}function fromOrder(orderBys){return orderBys.map(function(order){return fromPropertyOrder(order);});}function toCursor(cursor){return{before:cursor.before,values:cursor.position};}function fromCursor(cursor){var before=!!cursor.before;var position=cursor.values||[];return new Bound(position,before);}// visible for testing
function toDirection(dir){return DIRECTIONS[dir];}// visible for testing
function fromDirection(dir){switch(dir){case'ASCENDING':return"asc"/* ASCENDING */;case'DESCENDING':return"desc"/* DESCENDING */;default:return undefined;}}// visible for testing
function toOperatorName(op){return OPERATORS[op];}function fromOperatorName(op){switch(op){case'EQUAL':return"=="/* EQUAL */;case'NOT_EQUAL':return"!="/* NOT_EQUAL */;case'GREATER_THAN':return">"/* GREATER_THAN */;case'GREATER_THAN_OR_EQUAL':return">="/* GREATER_THAN_OR_EQUAL */;case'LESS_THAN':return"<"/* LESS_THAN */;case'LESS_THAN_OR_EQUAL':return"<="/* LESS_THAN_OR_EQUAL */;case'ARRAY_CONTAINS':return"array-contains"/* ARRAY_CONTAINS */;case'IN':return"in"/* IN */;case'NOT_IN':return"not-in"/* NOT_IN */;case'ARRAY_CONTAINS_ANY':return"array-contains-any"/* ARRAY_CONTAINS_ANY */;case'OPERATOR_UNSPECIFIED':return fail();default:return fail();}}function toFieldPathReference(path){return{fieldPath:path.canonicalString()};}function fromFieldPathReference(fieldReference){return FieldPath.fromServerFormat(fieldReference.fieldPath);}// visible for testing
function toPropertyOrder(orderBy){return{field:toFieldPathReference(orderBy.field),direction:toDirection(orderBy.dir)};}function fromPropertyOrder(orderBy){return new OrderBy(fromFieldPathReference(orderBy.field),fromDirection(orderBy.direction));}function fromFieldFilter(filter){return FieldFilter.create(fromFieldPathReference(filter.fieldFilter.field),fromOperatorName(filter.fieldFilter.op),filter.fieldFilter.value);}// visible for testing
function toUnaryOrFieldFilter(filter){if(filter.op==="=="/* EQUAL */){if(isNanValue(filter.value)){return{unaryFilter:{field:toFieldPathReference(filter.field),op:'IS_NAN'}};}else if(isNullValue(filter.value)){return{unaryFilter:{field:toFieldPathReference(filter.field),op:'IS_NULL'}};}}else if(filter.op==="!="/* NOT_EQUAL */){if(isNanValue(filter.value)){return{unaryFilter:{field:toFieldPathReference(filter.field),op:'IS_NOT_NAN'}};}else if(isNullValue(filter.value)){return{unaryFilter:{field:toFieldPathReference(filter.field),op:'IS_NOT_NULL'}};}}return{fieldFilter:{field:toFieldPathReference(filter.field),op:toOperatorName(filter.op),value:filter.value}};}function fromUnaryFilter(filter){switch(filter.unaryFilter.op){case'IS_NAN':var nanField=fromFieldPathReference(filter.unaryFilter.field);return FieldFilter.create(nanField,"=="/* EQUAL */,{doubleValue:NaN});case'IS_NULL':var nullField=fromFieldPathReference(filter.unaryFilter.field);return FieldFilter.create(nullField,"=="/* EQUAL */,{nullValue:'NULL_VALUE'});case'IS_NOT_NAN':var notNanField=fromFieldPathReference(filter.unaryFilter.field);return FieldFilter.create(notNanField,"!="/* NOT_EQUAL */,{doubleValue:NaN});case'IS_NOT_NULL':var notNullField=fromFieldPathReference(filter.unaryFilter.field);return FieldFilter.create(notNullField,"!="/* NOT_EQUAL */,{nullValue:'NULL_VALUE'});case'OPERATOR_UNSPECIFIED':return fail();default:return fail();}}function toDocumentMask(fieldMask){var canonicalFields=[];fieldMask.fields.forEach(function(field){return canonicalFields.push(field.canonicalString());});return{fieldPaths:canonicalFields};}function fromDocumentMask(proto){var paths=proto.fieldPaths||[];return new FieldMask(paths.map(function(path){return FieldPath.fromServerFormat(path);}));}function isValidResourceName(path){// Resource names have at least 4 components (project ID, database ID)
return path.length>=4&&path.get(0)==='projects'&&path.get(2)==='databases';}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /** Represents a transform within a TransformMutation. */var TransformOperation=function TransformOperation(){_classCallCheck(this,TransformOperation);// Make sure that the structural type of `TransformOperation` is unique.
// See https://github.com/microsoft/TypeScript/issues/5451
this._=undefined;};/**
 * Computes the local transform result against the provided `previousValue`,
 * optionally using the provided localWriteTime.
 */function applyTransformOperationToLocalView(transform,previousValue,localWriteTime){if(transform instanceof ServerTimestampTransform){return serverTimestamp(localWriteTime,previousValue);}else if(transform instanceof ArrayUnionTransformOperation){return applyArrayUnionTransformOperation(transform,previousValue);}else if(transform instanceof ArrayRemoveTransformOperation){return applyArrayRemoveTransformOperation(transform,previousValue);}else{return applyNumericIncrementTransformOperationToLocalView(transform,previousValue);}}/**
 * Computes a final transform result after the transform has been acknowledged
 * by the server, potentially using the server-provided transformResult.
 */function applyTransformOperationToRemoteDocument(transform,previousValue,transformResult){// The server just sends null as the transform result for array operations,
// so we have to calculate a result the same as we do for local
// applications.
if(transform instanceof ArrayUnionTransformOperation){return applyArrayUnionTransformOperation(transform,previousValue);}else if(transform instanceof ArrayRemoveTransformOperation){return applyArrayRemoveTransformOperation(transform,previousValue);}return transformResult;}/**
 * If this transform operation is not idempotent, returns the base value to
 * persist for this transform. If a base value is returned, the transform
 * operation is always applied to this base value, even if document has
 * already been updated.
 *
 * Base values provide consistent behavior for non-idempotent transforms and
 * allow us to return the same latency-compensated value even if the backend
 * has already applied the transform operation. The base value is null for
 * idempotent transforms, as they can be re-played even if the backend has
 * already applied them.
 *
 * @return a base value to store along with the mutation, or null for
 * idempotent transforms.
 */function computeTransformOperationBaseValue(transform,previousValue){if(transform instanceof NumericIncrementTransformOperation){return isNumber(previousValue)?previousValue:{integerValue:0};}return null;}function transformOperationEquals(left,right){if(left instanceof ArrayUnionTransformOperation&&right instanceof ArrayUnionTransformOperation){return arrayEquals(left.elements,right.elements,valueEquals);}else if(left instanceof ArrayRemoveTransformOperation&&right instanceof ArrayRemoveTransformOperation){return arrayEquals(left.elements,right.elements,valueEquals);}else if(left instanceof NumericIncrementTransformOperation&&right instanceof NumericIncrementTransformOperation){return valueEquals(left.operand,right.operand);}return left instanceof ServerTimestampTransform&&right instanceof ServerTimestampTransform;}/** Transforms a value into a server-generated timestamp. */var ServerTimestampTransform=/*#__PURE__*/function(_TransformOperation){_inherits(ServerTimestampTransform,_TransformOperation);function ServerTimestampTransform(){_classCallCheck(this,ServerTimestampTransform);return _possibleConstructorReturn(this,_getPrototypeOf(ServerTimestampTransform).apply(this,arguments));}return ServerTimestampTransform;}(TransformOperation);/** Transforms an array value via a union operation. */var ArrayUnionTransformOperation=/*#__PURE__*/function(_TransformOperation2){_inherits(ArrayUnionTransformOperation,_TransformOperation2);function ArrayUnionTransformOperation(elements){var _this19;_classCallCheck(this,ArrayUnionTransformOperation);_this19=_possibleConstructorReturn(this,_getPrototypeOf(ArrayUnionTransformOperation).call(this));_this19.elements=elements;return _this19;}return ArrayUnionTransformOperation;}(TransformOperation);function applyArrayUnionTransformOperation(transform,previousValue){var values=coercedFieldValuesArray(previousValue);var _iteratorNormalCompletion16=true;var _didIteratorError16=false;var _iteratorError16=undefined;try{var _loop=function _loop(){var toUnion=_step16.value;if(!values.some(function(element){return valueEquals(element,toUnion);})){values.push(toUnion);}};for(var _iterator16=transform.elements[Symbol.iterator](),_step16;!(_iteratorNormalCompletion16=(_step16=_iterator16.next()).done);_iteratorNormalCompletion16=true){_loop();}}catch(err){_didIteratorError16=true;_iteratorError16=err;}finally{try{if(!_iteratorNormalCompletion16&&_iterator16["return"]!=null){_iterator16["return"]();}}finally{if(_didIteratorError16){throw _iteratorError16;}}}return{arrayValue:{values:values}};}/** Transforms an array value via a remove operation. */var ArrayRemoveTransformOperation=/*#__PURE__*/function(_TransformOperation3){_inherits(ArrayRemoveTransformOperation,_TransformOperation3);function ArrayRemoveTransformOperation(elements){var _this20;_classCallCheck(this,ArrayRemoveTransformOperation);_this20=_possibleConstructorReturn(this,_getPrototypeOf(ArrayRemoveTransformOperation).call(this));_this20.elements=elements;return _this20;}return ArrayRemoveTransformOperation;}(TransformOperation);function applyArrayRemoveTransformOperation(transform,previousValue){var values=coercedFieldValuesArray(previousValue);var _iteratorNormalCompletion17=true;var _didIteratorError17=false;var _iteratorError17=undefined;try{var _loop2=function _loop2(){var toRemove=_step17.value;values=values.filter(function(element){return!valueEquals(element,toRemove);});};for(var _iterator17=transform.elements[Symbol.iterator](),_step17;!(_iteratorNormalCompletion17=(_step17=_iterator17.next()).done);_iteratorNormalCompletion17=true){_loop2();}}catch(err){_didIteratorError17=true;_iteratorError17=err;}finally{try{if(!_iteratorNormalCompletion17&&_iterator17["return"]!=null){_iterator17["return"]();}}finally{if(_didIteratorError17){throw _iteratorError17;}}}return{arrayValue:{values:values}};}/**
 * Implements the backend semantics for locally computed NUMERIC_ADD (increment)
 * transforms. Converts all field values to integers or doubles, but unlike the
 * backend does not cap integer values at 2^63. Instead, JavaScript number
 * arithmetic is used and precision loss can occur for values greater than 2^53.
 */var NumericIncrementTransformOperation=/*#__PURE__*/function(_TransformOperation4){_inherits(NumericIncrementTransformOperation,_TransformOperation4);function NumericIncrementTransformOperation(serializer,operand){var _this21;_classCallCheck(this,NumericIncrementTransformOperation);_this21=_possibleConstructorReturn(this,_getPrototypeOf(NumericIncrementTransformOperation).call(this));_this21.serializer=serializer;_this21.operand=operand;return _this21;}return NumericIncrementTransformOperation;}(TransformOperation);function applyNumericIncrementTransformOperationToLocalView(transform,previousValue){// PORTING NOTE: Since JavaScript's integer arithmetic is limited to 53 bit
// precision and resolves overflows by reducing precision, we do not
// manually cap overflows at 2^63.
var baseValue=computeTransformOperationBaseValue(transform,previousValue);var sum=asNumber(baseValue)+asNumber(transform.operand);if(isInteger(baseValue)&&isInteger(transform.operand)){return toInteger(sum);}else{return toDouble(transform.serializer,sum);}}function asNumber(value){return normalizeNumber(value.integerValue||value.doubleValue);}function coercedFieldValuesArray(value){return isArray(value)&&value.arrayValue.values?value.arrayValue.values.slice():[];}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Provides a set of fields that can be used to partially patch a document.
 * FieldMask is used in conjunction with ObjectValue.
 * Examples:
 *   foo - Overwrites foo entirely with the provided value. If foo is not
 *         present in the companion ObjectValue, the field is deleted.
 *   foo.bar - Overwrites only the field bar of the object foo.
 *             If foo is not an object, foo is replaced with an object
 *             containing foo
 */var FieldMask=/*#__PURE__*/function(){function FieldMask(fields){_classCallCheck(this,FieldMask);this.fields=fields;// TODO(dimond): validation of FieldMask
// Sort the field mask to support `FieldMask.isEqual()` and assert below.
fields.sort(FieldPath.comparator);}/**
     * Verifies that `fieldPath` is included by at least one field in this field
     * mask.
     *
     * This is an O(n) operation, where `n` is the size of the field mask.
     */_createClass(FieldMask,[{key:"covers",value:function covers(fieldPath){var _iteratorNormalCompletion18=true;var _didIteratorError18=false;var _iteratorError18=undefined;try{for(var _iterator18=this.fields[Symbol.iterator](),_step18;!(_iteratorNormalCompletion18=(_step18=_iterator18.next()).done);_iteratorNormalCompletion18=true){var fieldMaskPath=_step18.value;if(fieldMaskPath.isPrefixOf(fieldPath)){return true;}}}catch(err){_didIteratorError18=true;_iteratorError18=err;}finally{try{if(!_iteratorNormalCompletion18&&_iterator18["return"]!=null){_iterator18["return"]();}}finally{if(_didIteratorError18){throw _iteratorError18;}}}return false;}},{key:"isEqual",value:function isEqual(other){return arrayEquals(this.fields,other.fields,function(l,r){return l.isEqual(r);});}}]);return FieldMask;}();/** A field path and the TransformOperation to perform upon it. */var FieldTransform=function FieldTransform(field,transform){_classCallCheck(this,FieldTransform);this.field=field;this.transform=transform;};function fieldTransformEquals(left,right){return left.field.isEqual(right.field)&&transformOperationEquals(left.transform,right.transform);}/** The result of successfully applying a mutation to the backend. */var MutationResult=function MutationResult(/**
     * The version at which the mutation was committed:
     *
     * - For most operations, this is the updateTime in the WriteResult.
     * - For deletes, the commitTime of the WriteResponse (because deletes are
     *   not stored and have no updateTime).
     *
     * Note that these versions can be different: No-op writes will not change
     * the updateTime even though the commitTime advances.
     */version,/**
     * The resulting fields returned from the backend after a
     * TransformMutation has been committed. Contains one FieldValue for each
     * FieldTransform that was in the mutation.
     *
     * Will be null if the mutation was not a TransformMutation.
     */transformResults){_classCallCheck(this,MutationResult);this.version=version;this.transformResults=transformResults;};/**
 * Encodes a precondition for a mutation. This follows the model that the
 * backend accepts with the special case of an explicit "empty" precondition
 * (meaning no precondition).
 */var Precondition=/*#__PURE__*/function(){function Precondition(updateTime,exists){_classCallCheck(this,Precondition);this.updateTime=updateTime;this.exists=exists;}/** Creates a new empty Precondition. */_createClass(Precondition,[{key:"isEqual",value:function isEqual(other){return this.exists===other.exists&&(this.updateTime?!!other.updateTime&&this.updateTime.isEqual(other.updateTime):!other.updateTime);}},{key:"isNone",/** Returns whether this Precondition is empty. */get:function get(){return this.updateTime===undefined&&this.exists===undefined;}}],[{key:"none",value:function none(){return new Precondition();}/** Creates a new Precondition with an exists flag. */},{key:"exists",value:function exists(_exists){return new Precondition(undefined,_exists);}/** Creates a new Precondition based on a version a document exists at. */},{key:"updateTime",value:function updateTime(version){return new Precondition(version);}}]);return Precondition;}();/**
 * Returns true if the preconditions is valid for the given document
 * (or null if no document is available).
 */function preconditionIsValidForDocument(precondition,maybeDoc){if(precondition.updateTime!==undefined){return maybeDoc instanceof Document&&maybeDoc.version.isEqual(precondition.updateTime);}else if(precondition.exists!==undefined){return precondition.exists===maybeDoc instanceof Document;}else{return true;}}/**
 * A mutation describes a self-contained change to a document. Mutations can
 * create, replace, delete, and update subsets of documents.
 *
 * Mutations not only act on the value of the document but also its version.
 *
 * For local mutations (mutations that haven't been committed yet), we preserve
 * the existing version for Set, Patch, and Transform mutations. For Delete
 * mutations, we reset the version to 0.
 *
 * Here's the expected transition table.
 *
 * MUTATION           APPLIED TO            RESULTS IN
 *
 * SetMutation        Document(v3)          Document(v3)
 * SetMutation        NoDocument(v3)        Document(v0)
 * SetMutation        null                  Document(v0)
 * PatchMutation      Document(v3)          Document(v3)
 * PatchMutation      NoDocument(v3)        NoDocument(v3)
 * PatchMutation      null                  null
 * TransformMutation  Document(v3)          Document(v3)
 * TransformMutation  NoDocument(v3)        NoDocument(v3)
 * TransformMutation  null                  null
 * DeleteMutation     Document(v3)          NoDocument(v0)
 * DeleteMutation     NoDocument(v3)        NoDocument(v0)
 * DeleteMutation     null                  NoDocument(v0)
 *
 * For acknowledged mutations, we use the updateTime of the WriteResponse as
 * the resulting version for Set, Patch, and Transform mutations. As deletes
 * have no explicit update time, we use the commitTime of the WriteResponse for
 * Delete mutations.
 *
 * If a mutation is acknowledged by the backend but fails the precondition check
 * locally, we return an `UnknownDocument` and rely on Watch to send us the
 * updated version.
 *
 * Note that TransformMutations don't create Documents (in the case of being
 * applied to a NoDocument), even though they would on the backend. This is
 * because the client always combines the TransformMutation with a SetMutation
 * or PatchMutation and we only want to apply the transform if the prior
 * mutation resulted in a Document (always true for a SetMutation, but not
 * necessarily for a PatchMutation).
 *
 * ## Subclassing Notes
 *
 * Subclasses of Mutation need to implement applyToRemoteDocument() and
 * applyToLocalView() to implement the actual behavior of applying the mutation
 * to some source document.
 */var Mutation=function Mutation(){_classCallCheck(this,Mutation);};/**
 * Applies this mutation to the given MaybeDocument or null for the purposes
 * of computing a new remote document. If the input document doesn't match the
 * expected state (e.g. it is null or outdated), an `UnknownDocument` can be
 * returned.
 *
 * @param mutation The mutation to apply.
 * @param maybeDoc The document to mutate. The input document can be null if
 *     the client has no knowledge of the pre-mutation state of the document.
 * @param mutationResult The result of applying the mutation from the backend.
 * @return The mutated document. The returned document may be an
 *     UnknownDocument if the mutation could not be applied to the locally
 *     cached base document.
 */function applyMutationToRemoteDocument(mutation,maybeDoc,mutationResult){if(mutation instanceof SetMutation){return applySetMutationToRemoteDocument(mutation,maybeDoc,mutationResult);}else if(mutation instanceof PatchMutation){return applyPatchMutationToRemoteDocument(mutation,maybeDoc,mutationResult);}else if(mutation instanceof TransformMutation){return applyTransformMutationToRemoteDocument(mutation,maybeDoc,mutationResult);}else{return applyDeleteMutationToRemoteDocument(mutation,maybeDoc,mutationResult);}}/**
 * Applies this mutation to the given MaybeDocument or null for the purposes
 * of computing the new local view of a document. Both the input and returned
 * documents can be null.
 *
 * @param mutation The mutation to apply.
 * @param maybeDoc The document to mutate. The input document can be null if
 *     the client has no knowledge of the pre-mutation state of the document.
 * @param baseDoc The state of the document prior to this mutation batch. The
 *     input document can be null if the client has no knowledge of the
 *     pre-mutation state of the document.
 * @param localWriteTime A timestamp indicating the local write time of the
 *     batch this mutation is a part of.
 * @return The mutated document. The returned document may be null, but only
 *     if maybeDoc was null and the mutation would not create a new document.
 */function applyMutationToLocalView(mutation,maybeDoc,baseDoc,localWriteTime){if(mutation instanceof SetMutation){return applySetMutationToLocalView(mutation,maybeDoc);}else if(mutation instanceof PatchMutation){return applyPatchMutationToLocalView(mutation,maybeDoc);}else if(mutation instanceof TransformMutation){return applyTransformMutationToLocalView(mutation,maybeDoc,localWriteTime,baseDoc);}else{return applyDeleteMutationToLocalView(mutation,maybeDoc);}}/**
 * If this mutation is not idempotent, returns the base value to persist with
 * this mutation. If a base value is returned, the mutation is always applied
 * to this base value, even if document has already been updated.
 *
 * The base value is a sparse object that consists of only the document
 * fields for which this mutation contains a non-idempotent transformation
 * (e.g. a numeric increment). The provided value guarantees consistent
 * behavior for non-idempotent transforms and allow us to return the same
 * latency-compensated value even if the backend has already applied the
 * mutation. The base value is null for idempotent mutations, as they can be
 * re-played even if the backend has already applied them.
 *
 * @return a base value to store along with the mutation, or null for
 * idempotent mutations.
 */function extractMutationBaseValue(mutation,maybeDoc){if(mutation instanceof TransformMutation){return extractTransformMutationBaseValue(mutation,maybeDoc);}return null;}function mutationEquals(left,right){if(left.type!==right.type){return false;}if(!left.key.isEqual(right.key)){return false;}if(!left.precondition.isEqual(right.precondition)){return false;}if(left.type===0/* Set */){return left.value.isEqual(right.value);}if(left.type===1/* Patch */){return left.data.isEqual(right.data)&&left.fieldMask.isEqual(right.fieldMask);}if(left.type===2/* Transform */){return arrayEquals(left.fieldTransforms,left.fieldTransforms,function(l,r){return fieldTransformEquals(l,r);});}return true;}/**
 * Returns the version from the given document for use as the result of a
 * mutation. Mutations are defined to return the version of the base document
 * only if it is an existing document. Deleted and unknown documents have a
 * post-mutation version of SnapshotVersion.min().
 */function getPostMutationVersion(maybeDoc){if(maybeDoc instanceof Document){return maybeDoc.version;}else{return SnapshotVersion.min();}}/**
 * A mutation that creates or replaces the document at the given key with the
 * object value contents.
 */var SetMutation=/*#__PURE__*/function(_Mutation){_inherits(SetMutation,_Mutation);function SetMutation(key,value,precondition){var _this22;_classCallCheck(this,SetMutation);_this22=_possibleConstructorReturn(this,_getPrototypeOf(SetMutation).call(this));_this22.key=key;_this22.value=value;_this22.precondition=precondition;_this22.type=0/* Set */;return _this22;}return SetMutation;}(Mutation);function applySetMutationToRemoteDocument(mutation,maybeDoc,mutationResult){// Unlike applySetMutationToLocalView, if we're applying a mutation to a
// remote document the server has accepted the mutation so the precondition
// must have held.
return new Document(mutation.key,mutationResult.version,mutation.value,{hasCommittedMutations:true});}function applySetMutationToLocalView(mutation,maybeDoc){if(!preconditionIsValidForDocument(mutation.precondition,maybeDoc)){return maybeDoc;}var version=getPostMutationVersion(maybeDoc);return new Document(mutation.key,version,mutation.value,{hasLocalMutations:true});}/**
 * A mutation that modifies fields of the document at the given key with the
 * given values. The values are applied through a field mask:
 *
 *  * When a field is in both the mask and the values, the corresponding field
 *    is updated.
 *  * When a field is in neither the mask nor the values, the corresponding
 *    field is unmodified.
 *  * When a field is in the mask but not in the values, the corresponding field
 *    is deleted.
 *  * When a field is not in the mask but is in the values, the values map is
 *    ignored.
 */var PatchMutation=/*#__PURE__*/function(_Mutation2){_inherits(PatchMutation,_Mutation2);function PatchMutation(key,data,fieldMask,precondition){var _this23;_classCallCheck(this,PatchMutation);_this23=_possibleConstructorReturn(this,_getPrototypeOf(PatchMutation).call(this));_this23.key=key;_this23.data=data;_this23.fieldMask=fieldMask;_this23.precondition=precondition;_this23.type=1/* Patch */;return _this23;}return PatchMutation;}(Mutation);function applyPatchMutationToRemoteDocument(mutation,maybeDoc,mutationResult){if(!preconditionIsValidForDocument(mutation.precondition,maybeDoc)){// Since the mutation was not rejected, we know that the  precondition
// matched on the backend. We therefore must not have the expected version
// of the document in our cache and return an UnknownDocument with the
// known updateTime.
return new UnknownDocument(mutation.key,mutationResult.version);}var newData=patchDocument(mutation,maybeDoc);return new Document(mutation.key,mutationResult.version,newData,{hasCommittedMutations:true});}function applyPatchMutationToLocalView(mutation,maybeDoc){if(!preconditionIsValidForDocument(mutation.precondition,maybeDoc)){return maybeDoc;}var version=getPostMutationVersion(maybeDoc);var newData=patchDocument(mutation,maybeDoc);return new Document(mutation.key,version,newData,{hasLocalMutations:true});}/**
 * Patches the data of document if available or creates a new document. Note
 * that this does not check whether or not the precondition of this patch
 * holds.
 */function patchDocument(mutation,maybeDoc){var data;if(maybeDoc instanceof Document){data=maybeDoc.data();}else{data=ObjectValue.empty();}return patchObject(mutation,data);}function patchObject(mutation,data){var builder=new ObjectValueBuilder(data);mutation.fieldMask.fields.forEach(function(fieldPath){if(!fieldPath.isEmpty()){var newValue=mutation.data.field(fieldPath);if(newValue!==null){builder.set(fieldPath,newValue);}else{builder["delete"](fieldPath);}}});return builder.build();}/**
 * A mutation that modifies specific fields of the document with transform
 * operations. Currently the only supported transform is a server timestamp, but
 * IP Address, increment(n), etc. could be supported in the future.
 *
 * It is somewhat similar to a PatchMutation in that it patches specific fields
 * and has no effect when applied to a null or NoDocument (see comment on
 * Mutation for rationale).
 */var TransformMutation=/*#__PURE__*/function(_Mutation3){_inherits(TransformMutation,_Mutation3);function TransformMutation(key,fieldTransforms){var _this24;_classCallCheck(this,TransformMutation);_this24=_possibleConstructorReturn(this,_getPrototypeOf(TransformMutation).call(this));_this24.key=key;_this24.fieldTransforms=fieldTransforms;_this24.type=2/* Transform */;// NOTE: We set a precondition of exists: true as a safety-check, since we
// always combine TransformMutations with a SetMutation or PatchMutation which
// (if successful) should end up with an existing document.
_this24.precondition=Precondition.exists(true);return _this24;}return TransformMutation;}(Mutation);function applyTransformMutationToRemoteDocument(mutation,maybeDoc,mutationResult){hardAssert(mutationResult.transformResults!=null);if(!preconditionIsValidForDocument(mutation.precondition,maybeDoc)){// Since the mutation was not rejected, we know that the  precondition
// matched on the backend. We therefore must not have the expected version
// of the document in our cache and return an UnknownDocument with the
// known updateTime.
return new UnknownDocument(mutation.key,mutationResult.version);}var doc=requireDocument(mutation,maybeDoc);var transformResults=serverTransformResults(mutation.fieldTransforms,maybeDoc,mutationResult.transformResults);var version=mutationResult.version;var newData=transformObject(mutation,doc.data(),transformResults);return new Document(mutation.key,version,newData,{hasCommittedMutations:true});}function applyTransformMutationToLocalView(mutation,maybeDoc,localWriteTime,baseDoc){if(!preconditionIsValidForDocument(mutation.precondition,maybeDoc)){return maybeDoc;}var doc=requireDocument(mutation,maybeDoc);var transformResults=localTransformResults(mutation.fieldTransforms,localWriteTime,maybeDoc,baseDoc);var newData=transformObject(mutation,doc.data(),transformResults);return new Document(mutation.key,doc.version,newData,{hasLocalMutations:true});}function extractTransformMutationBaseValue(mutation,maybeDoc){var baseObject=null;var _iteratorNormalCompletion19=true;var _didIteratorError19=false;var _iteratorError19=undefined;try{for(var _iterator19=mutation.fieldTransforms[Symbol.iterator](),_step19;!(_iteratorNormalCompletion19=(_step19=_iterator19.next()).done);_iteratorNormalCompletion19=true){var fieldTransform=_step19.value;var existingValue=maybeDoc instanceof Document?maybeDoc.field(fieldTransform.field):undefined;var coercedValue=computeTransformOperationBaseValue(fieldTransform.transform,existingValue||null);if(coercedValue!=null){if(baseObject==null){baseObject=new ObjectValueBuilder().set(fieldTransform.field,coercedValue);}else{baseObject=baseObject.set(fieldTransform.field,coercedValue);}}}}catch(err){_didIteratorError19=true;_iteratorError19=err;}finally{try{if(!_iteratorNormalCompletion19&&_iterator19["return"]!=null){_iterator19["return"]();}}finally{if(_didIteratorError19){throw _iteratorError19;}}}return baseObject?baseObject.build():null;}/**
 * Asserts that the given MaybeDocument is actually a Document and verifies
 * that it matches the key for this mutation. Since we only support
 * transformations with precondition exists this method is guaranteed to be
 * safe.
 */function requireDocument(mutation,maybeDoc){return maybeDoc;}/**
 * Creates a list of "transform results" (a transform result is a field value
 * representing the result of applying a transform) for use after a
 * TransformMutation has been acknowledged by the server.
 *
 * @param fieldTransforms The field transforms to apply the result to.
 * @param baseDoc The document prior to applying this mutation batch.
 * @param serverTransformResults The transform results received by the server.
 * @return The transform results list.
 */function serverTransformResults(fieldTransforms,baseDoc,serverTransformResults){var transformResults=[];hardAssert(fieldTransforms.length===serverTransformResults.length);for(var i=0;i<serverTransformResults.length;i++){var fieldTransform=fieldTransforms[i];var transform=fieldTransform.transform;var previousValue=null;if(baseDoc instanceof Document){previousValue=baseDoc.field(fieldTransform.field);}transformResults.push(applyTransformOperationToRemoteDocument(transform,previousValue,serverTransformResults[i]));}return transformResults;}/**
 * Creates a list of "transform results" (a transform result is a field value
 * representing the result of applying a transform) for use when applying a
 * TransformMutation locally.
 *
 * @param fieldTransforms The field transforms to apply the result to.
 * @param localWriteTime The local time of the transform mutation (used to
 *     generate ServerTimestampValues).
 * @param maybeDoc The current state of the document after applying all
 *     previous mutations.
 * @param baseDoc The document prior to applying this mutation batch.
 * @return The transform results list.
 */function localTransformResults(fieldTransforms,localWriteTime,maybeDoc,baseDoc){var transformResults=[];var _iteratorNormalCompletion20=true;var _didIteratorError20=false;var _iteratorError20=undefined;try{for(var _iterator20=fieldTransforms[Symbol.iterator](),_step20;!(_iteratorNormalCompletion20=(_step20=_iterator20.next()).done);_iteratorNormalCompletion20=true){var fieldTransform=_step20.value;var transform=fieldTransform.transform;var previousValue=null;if(maybeDoc instanceof Document){previousValue=maybeDoc.field(fieldTransform.field);}if(previousValue===null&&baseDoc instanceof Document){// If the current document does not contain a value for the mutated
// field, use the value that existed before applying this mutation
// batch. This solves an edge case where a PatchMutation clears the
// values in a nested map before the TransformMutation is applied.
previousValue=baseDoc.field(fieldTransform.field);}transformResults.push(applyTransformOperationToLocalView(transform,previousValue,localWriteTime));}}catch(err){_didIteratorError20=true;_iteratorError20=err;}finally{try{if(!_iteratorNormalCompletion20&&_iterator20["return"]!=null){_iterator20["return"]();}}finally{if(_didIteratorError20){throw _iteratorError20;}}}return transformResults;}function transformObject(mutation,data,transformResults){var builder=new ObjectValueBuilder(data);for(var i=0;i<mutation.fieldTransforms.length;i++){var fieldTransform=mutation.fieldTransforms[i];builder.set(fieldTransform.field,transformResults[i]);}return builder.build();}/** A mutation that deletes the document at the given key. */var DeleteMutation=/*#__PURE__*/function(_Mutation4){_inherits(DeleteMutation,_Mutation4);function DeleteMutation(key,precondition){var _this25;_classCallCheck(this,DeleteMutation);_this25=_possibleConstructorReturn(this,_getPrototypeOf(DeleteMutation).call(this));_this25.key=key;_this25.precondition=precondition;_this25.type=3/* Delete */;return _this25;}return DeleteMutation;}(Mutation);function applyDeleteMutationToRemoteDocument(mutation,maybeDoc,mutationResult){// Unlike applyToLocalView, if we're applying a mutation to a remote
// document the server has accepted the mutation so the precondition must
// have held.
return new NoDocument(mutation.key,mutationResult.version,{hasCommittedMutations:true});}function applyDeleteMutationToLocalView(mutation,maybeDoc){if(!preconditionIsValidForDocument(mutation.precondition,maybeDoc)){return maybeDoc;}return new NoDocument(mutation.key,SnapshotVersion.min());}/**
 * A mutation that verifies the existence of the document at the given key with
 * the provided precondition.
 *
 * The `verify` operation is only used in Transactions, and this class serves
 * primarily to facilitate serialization into protos.
 */var VerifyMutation=/*#__PURE__*/function(_Mutation5){_inherits(VerifyMutation,_Mutation5);function VerifyMutation(key,precondition){var _this26;_classCallCheck(this,VerifyMutation);_this26=_possibleConstructorReturn(this,_getPrototypeOf(VerifyMutation).call(this));_this26.key=key;_this26.precondition=precondition;_this26.type=4/* Verify */;return _this26;}return VerifyMutation;}(Mutation);/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var BATCHID_UNKNOWN=-1;/**
 * A batch of mutations that will be sent as one unit to the backend.
 */var MutationBatch=/*#__PURE__*/function(){/**
     * @param batchId The unique ID of this mutation batch.
     * @param localWriteTime The original write time of this mutation.
     * @param baseMutations Mutations that are used to populate the base
     * values when this mutation is applied locally. This can be used to locally
     * overwrite values that are persisted in the remote document cache. Base
     * mutations are never sent to the backend.
     * @param mutations The user-provided mutations in this mutation batch.
     * User-provided mutations are applied both locally and remotely on the
     * backend.
     */function MutationBatch(batchId,localWriteTime,baseMutations,mutations){_classCallCheck(this,MutationBatch);this.batchId=batchId;this.localWriteTime=localWriteTime;this.baseMutations=baseMutations;this.mutations=mutations;}/**
     * Applies all the mutations in this MutationBatch to the specified document
     * to create a new remote document
     *
     * @param docKey The key of the document to apply mutations to.
     * @param maybeDoc The document to apply mutations to.
     * @param batchResult The result of applying the MutationBatch to the
     * backend.
     */_createClass(MutationBatch,[{key:"applyToRemoteDocument",value:function applyToRemoteDocument(docKey,maybeDoc,batchResult){var mutationResults=batchResult.mutationResults;for(var i=0;i<this.mutations.length;i++){var mutation=this.mutations[i];if(mutation.key.isEqual(docKey)){var mutationResult=mutationResults[i];maybeDoc=applyMutationToRemoteDocument(mutation,maybeDoc,mutationResult);}}return maybeDoc;}/**
     * Computes the local view of a document given all the mutations in this
     * batch.
     *
     * @param docKey The key of the document to apply mutations to.
     * @param maybeDoc The document to apply mutations to.
     */},{key:"applyToLocalView",value:function applyToLocalView(docKey,maybeDoc){// First, apply the base state. This allows us to apply non-idempotent
// transform against a consistent set of values.
var _iteratorNormalCompletion21=true;var _didIteratorError21=false;var _iteratorError21=undefined;try{for(var _iterator21=this.baseMutations[Symbol.iterator](),_step21;!(_iteratorNormalCompletion21=(_step21=_iterator21.next()).done);_iteratorNormalCompletion21=true){var mutation=_step21.value;if(mutation.key.isEqual(docKey)){maybeDoc=applyMutationToLocalView(mutation,maybeDoc,maybeDoc,this.localWriteTime);}}}catch(err){_didIteratorError21=true;_iteratorError21=err;}finally{try{if(!_iteratorNormalCompletion21&&_iterator21["return"]!=null){_iterator21["return"]();}}finally{if(_didIteratorError21){throw _iteratorError21;}}}var baseDoc=maybeDoc;// Second, apply all user-provided mutations.
var _iteratorNormalCompletion22=true;var _didIteratorError22=false;var _iteratorError22=undefined;try{for(var _iterator22=this.mutations[Symbol.iterator](),_step22;!(_iteratorNormalCompletion22=(_step22=_iterator22.next()).done);_iteratorNormalCompletion22=true){var _mutation=_step22.value;if(_mutation.key.isEqual(docKey)){maybeDoc=applyMutationToLocalView(_mutation,maybeDoc,baseDoc,this.localWriteTime);}}}catch(err){_didIteratorError22=true;_iteratorError22=err;}finally{try{if(!_iteratorNormalCompletion22&&_iterator22["return"]!=null){_iterator22["return"]();}}finally{if(_didIteratorError22){throw _iteratorError22;}}}return maybeDoc;}/**
     * Computes the local view for all provided documents given the mutations in
     * this batch.
     */},{key:"applyToLocalDocumentSet",value:function applyToLocalDocumentSet(maybeDocs){var _this27=this;// TODO(mrschmidt): This implementation is O(n^2). If we apply the mutations
// directly (as done in `applyToLocalView()`), we can reduce the complexity
// to O(n).
var mutatedDocuments=maybeDocs;this.mutations.forEach(function(m){var mutatedDocument=_this27.applyToLocalView(m.key,maybeDocs.get(m.key));if(mutatedDocument){mutatedDocuments=mutatedDocuments.insert(m.key,mutatedDocument);}});return mutatedDocuments;}},{key:"keys",value:function keys(){return this.mutations.reduce(function(keys,m){return keys.add(m.key);},documentKeySet());}},{key:"isEqual",value:function isEqual(other){return this.batchId===other.batchId&&arrayEquals(this.mutations,other.mutations,function(l,r){return mutationEquals(l,r);})&&arrayEquals(this.baseMutations,other.baseMutations,function(l,r){return mutationEquals(l,r);});}}]);return MutationBatch;}();/** The result of applying a mutation batch to the backend. */var MutationBatchResult=/*#__PURE__*/function(){function MutationBatchResult(batch,commitVersion,mutationResults,/**
     * A pre-computed mapping from each mutated document to the resulting
     * version.
     */docVersions){_classCallCheck(this,MutationBatchResult);this.batch=batch;this.commitVersion=commitVersion;this.mutationResults=mutationResults;this.docVersions=docVersions;}/**
     * Creates a new MutationBatchResult for the given batch and results. There
     * must be one result for each mutation in the batch. This static factory
     * caches a document=>version mapping (docVersions).
     */_createClass(MutationBatchResult,null,[{key:"from",value:function from(batch,commitVersion,results){hardAssert(batch.mutations.length===results.length);var versionMap=documentVersionMap();var mutations=batch.mutations;for(var i=0;i<mutations.length;i++){versionMap=versionMap.insert(mutations[i].key,results[i].version);}return new MutationBatchResult(batch,commitVersion,results,versionMap);}}]);return MutationBatchResult;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * A map implementation that uses objects as keys. Objects must have an
 * associated equals function and must be immutable. Entries in the map are
 * stored together with the key being produced from the mapKeyFn. This map
 * automatically handles collisions of keys.
 */var ObjectMap=/*#__PURE__*/function(){function ObjectMap(mapKeyFn,equalsFn){_classCallCheck(this,ObjectMap);this.mapKeyFn=mapKeyFn;this.equalsFn=equalsFn;/**
         * The inner map for a key -> value pair. Due to the possibility of
         * collisions we keep a list of entries that we do a linear search through
         * to find an actual match. Note that collisions should be rare, so we still
         * expect near constant time lookups in practice.
         */this.inner={};}/** Get a value for this key, or undefined if it does not exist. */_createClass(ObjectMap,[{key:"get",value:function get(key){var id=this.mapKeyFn(key);var matches=this.inner[id];if(matches===undefined){return undefined;}var _iteratorNormalCompletion23=true;var _didIteratorError23=false;var _iteratorError23=undefined;try{for(var _iterator23=matches[Symbol.iterator](),_step23;!(_iteratorNormalCompletion23=(_step23=_iterator23.next()).done);_iteratorNormalCompletion23=true){var _step23$value=_slicedToArray(_step23.value,2),otherKey=_step23$value[0],value=_step23$value[1];if(this.equalsFn(otherKey,key)){return value;}}}catch(err){_didIteratorError23=true;_iteratorError23=err;}finally{try{if(!_iteratorNormalCompletion23&&_iterator23["return"]!=null){_iterator23["return"]();}}finally{if(_didIteratorError23){throw _iteratorError23;}}}return undefined;}},{key:"has",value:function has(key){return this.get(key)!==undefined;}/** Put this key and value in the map. */},{key:"set",value:function set(key,value){var id=this.mapKeyFn(key);var matches=this.inner[id];if(matches===undefined){this.inner[id]=[[key,value]];return;}for(var i=0;i<matches.length;i++){if(this.equalsFn(matches[i][0],key)){matches[i]=[key,value];return;}}matches.push([key,value]);}/**
     * Remove this key from the map. Returns a boolean if anything was deleted.
     */},{key:"delete",value:function _delete(key){var id=this.mapKeyFn(key);var matches=this.inner[id];if(matches===undefined){return false;}for(var i=0;i<matches.length;i++){if(this.equalsFn(matches[i][0],key)){if(matches.length===1){delete this.inner[id];}else{matches.splice(i,1);}return true;}}return false;}},{key:"forEach",value:function forEach(fn){_forEach(this.inner,function(_,entries){var _iteratorNormalCompletion24=true;var _didIteratorError24=false;var _iteratorError24=undefined;try{for(var _iterator24=entries[Symbol.iterator](),_step24;!(_iteratorNormalCompletion24=(_step24=_iterator24.next()).done);_iteratorNormalCompletion24=true){var _step24$value=_slicedToArray(_step24.value,2),k=_step24$value[0],v=_step24$value[1];fn(k,v);}}catch(err){_didIteratorError24=true;_iteratorError24=err;}finally{try{if(!_iteratorNormalCompletion24&&_iterator24["return"]!=null){_iterator24["return"]();}}finally{if(_didIteratorError24){throw _iteratorError24;}}}});}},{key:"isEmpty",value:function isEmpty(){return _isEmpty(this.inner);}}]);return ObjectMap;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * PersistencePromise<> is essentially a re-implementation of Promise<> except
 * it has a .next() method instead of .then() and .next() and .catch() callbacks
 * are executed synchronously when a PersistencePromise resolves rather than
 * asynchronously (Promise<> implementations use setImmediate() or similar).
 *
 * This is necessary to interoperate with IndexedDB which will automatically
 * commit transactions if control is returned to the event loop without
 * synchronously initiating another operation on the transaction.
 *
 * NOTE: .then() and .catch() only allow a single consumer, unlike normal
 * Promises.
 */var PersistencePromise=/*#__PURE__*/function(){function PersistencePromise(callback){var _this28=this;_classCallCheck(this,PersistencePromise);// NOTE: next/catchCallback will always point to our own wrapper functions,
// not the user's raw next() or catch() callbacks.
this.nextCallback=null;this.catchCallback=null;// When the operation resolves, we'll set result or error and mark isDone.
this.result=undefined;this.error=undefined;this.isDone=false;// Set to true when .then() or .catch() are called and prevents additional
// chaining.
this.callbackAttached=false;callback(function(value){_this28.isDone=true;_this28.result=value;if(_this28.nextCallback){// value should be defined unless T is Void, but we can't express
// that in the type system.
_this28.nextCallback(value);}},function(error){_this28.isDone=true;_this28.error=error;if(_this28.catchCallback){_this28.catchCallback(error);}});}_createClass(PersistencePromise,[{key:"catch",value:function _catch(fn){return this.next(undefined,fn);}},{key:"next",value:function next(nextFn,catchFn){var _this29=this;if(this.callbackAttached){fail();}this.callbackAttached=true;if(this.isDone){if(!this.error){return this.wrapSuccess(nextFn,this.result);}else{return this.wrapFailure(catchFn,this.error);}}else{return new PersistencePromise(function(resolve,reject){_this29.nextCallback=function(value){_this29.wrapSuccess(nextFn,value).next(resolve,reject);};_this29.catchCallback=function(error){_this29.wrapFailure(catchFn,error).next(resolve,reject);};});}}},{key:"toPromise",value:function toPromise(){var _this30=this;return new Promise(function(resolve,reject){_this30.next(resolve,reject);});}},{key:"wrapUserFunction",value:function wrapUserFunction(fn){try{var result=fn();if(result instanceof PersistencePromise){return result;}else{return PersistencePromise.resolve(result);}}catch(e){return PersistencePromise.reject(e);}}},{key:"wrapSuccess",value:function wrapSuccess(nextFn,value){if(nextFn){return this.wrapUserFunction(function(){return nextFn(value);});}else{// If there's no nextFn, then R must be the same as T
return PersistencePromise.resolve(value);}}},{key:"wrapFailure",value:function wrapFailure(catchFn,error){if(catchFn){return this.wrapUserFunction(function(){return catchFn(error);});}else{return PersistencePromise.reject(error);}}}],[{key:"resolve",value:function resolve(result){return new PersistencePromise(function(resolve,reject){resolve(result);});}},{key:"reject",value:function reject(error){return new PersistencePromise(function(resolve,reject){reject(error);});}},{key:"waitFor",value:function waitFor(// Accept all Promise types in waitFor().
// eslint-disable-next-line @typescript-eslint/no-explicit-any
all){return new PersistencePromise(function(resolve,reject){var expectedCount=0;var resolvedCount=0;var done=false;all.forEach(function(element){++expectedCount;element.next(function(){++resolvedCount;if(done&&resolvedCount===expectedCount){resolve();}},function(err){return reject(err);});});done=true;if(resolvedCount===expectedCount){resolve();}});}/**
     * Given an array of predicate functions that asynchronously evaluate to a
     * boolean, implements a short-circuiting `or` between the results. Predicates
     * will be evaluated until one of them returns `true`, then stop. The final
     * result will be whether any of them returned `true`.
     */},{key:"or",value:function or(predicates){var p=PersistencePromise.resolve(false);var _iteratorNormalCompletion25=true;var _didIteratorError25=false;var _iteratorError25=undefined;try{var _loop3=function _loop3(){var predicate=_step25.value;p=p.next(function(isTrue){if(isTrue){return PersistencePromise.resolve(isTrue);}else{return predicate();}});};for(var _iterator25=predicates[Symbol.iterator](),_step25;!(_iteratorNormalCompletion25=(_step25=_iterator25.next()).done);_iteratorNormalCompletion25=true){_loop3();}}catch(err){_didIteratorError25=true;_iteratorError25=err;}finally{try{if(!_iteratorNormalCompletion25&&_iterator25["return"]!=null){_iterator25["return"]();}}finally{if(_didIteratorError25){throw _iteratorError25;}}}return p;}},{key:"forEach",value:function forEach(collection,f){var _this31=this;var promises=[];collection.forEach(function(r,s){promises.push(f.call(_this31,r,s));});return this.waitFor(promises);}}]);return PersistencePromise;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * A readonly view of the local state of all documents we're tracking (i.e. we
 * have a cached version in remoteDocumentCache or local mutations for the
 * document). The view is computed by applying the mutations in the
 * MutationQueue to the RemoteDocumentCache.
 */var LocalDocumentsView=/*#__PURE__*/function(){function LocalDocumentsView(remoteDocumentCache,mutationQueue,indexManager){_classCallCheck(this,LocalDocumentsView);this.remoteDocumentCache=remoteDocumentCache;this.mutationQueue=mutationQueue;this.indexManager=indexManager;}/**
     * Get the local view of the document identified by `key`.
     *
     * @return Local view of the document or null if we don't have any cached
     * state for it.
     */_createClass(LocalDocumentsView,[{key:"getDocument",value:function getDocument(transaction,key){var _this32=this;return this.mutationQueue.getAllMutationBatchesAffectingDocumentKey(transaction,key).next(function(batches){return _this32.getDocumentInternal(transaction,key,batches);});}/** Internal version of `getDocument` that allows reusing batches. */},{key:"getDocumentInternal",value:function getDocumentInternal(transaction,key,inBatches){return this.remoteDocumentCache.getEntry(transaction,key).next(function(doc){var _iteratorNormalCompletion26=true;var _didIteratorError26=false;var _iteratorError26=undefined;try{for(var _iterator26=inBatches[Symbol.iterator](),_step26;!(_iteratorNormalCompletion26=(_step26=_iterator26.next()).done);_iteratorNormalCompletion26=true){var batch=_step26.value;doc=batch.applyToLocalView(key,doc);}}catch(err){_didIteratorError26=true;_iteratorError26=err;}finally{try{if(!_iteratorNormalCompletion26&&_iterator26["return"]!=null){_iterator26["return"]();}}finally{if(_didIteratorError26){throw _iteratorError26;}}}return doc;});}// Returns the view of the given `docs` as they would appear after applying
// all mutations in the given `batches`.
},{key:"applyLocalMutationsToDocuments",value:function applyLocalMutationsToDocuments(transaction,docs,batches){var results=nullableMaybeDocumentMap();docs.forEach(function(key,localView){var _iteratorNormalCompletion27=true;var _didIteratorError27=false;var _iteratorError27=undefined;try{for(var _iterator27=batches[Symbol.iterator](),_step27;!(_iteratorNormalCompletion27=(_step27=_iterator27.next()).done);_iteratorNormalCompletion27=true){var batch=_step27.value;localView=batch.applyToLocalView(key,localView);}}catch(err){_didIteratorError27=true;_iteratorError27=err;}finally{try{if(!_iteratorNormalCompletion27&&_iterator27["return"]!=null){_iterator27["return"]();}}finally{if(_didIteratorError27){throw _iteratorError27;}}}results=results.insert(key,localView);});return results;}/**
     * Gets the local view of the documents identified by `keys`.
     *
     * If we don't have cached state for a document in `keys`, a NoDocument will
     * be stored for that key in the resulting set.
     */},{key:"getDocuments",value:function getDocuments(transaction,keys){var _this33=this;return this.remoteDocumentCache.getEntries(transaction,keys).next(function(docs){return _this33.getLocalViewOfDocuments(transaction,docs);});}/**
     * Similar to `getDocuments`, but creates the local view from the given
     * `baseDocs` without retrieving documents from the local store.
     */},{key:"getLocalViewOfDocuments",value:function getLocalViewOfDocuments(transaction,baseDocs){var _this34=this;return this.mutationQueue.getAllMutationBatchesAffectingDocumentKeys(transaction,baseDocs).next(function(batches){var docs=_this34.applyLocalMutationsToDocuments(transaction,baseDocs,batches);var results=maybeDocumentMap();docs.forEach(function(key,maybeDoc){// TODO(http://b/32275378): Don't conflate missing / deleted.
if(!maybeDoc){maybeDoc=new NoDocument(key,SnapshotVersion.min());}results=results.insert(key,maybeDoc);});return results;});}/**
     * Performs a query against the local view of all documents.
     *
     * @param transaction The persistence transaction.
     * @param query The query to match documents against.
     * @param sinceReadTime If not set to SnapshotVersion.min(), return only
     *     documents that have been read since this snapshot version (exclusive).
     */},{key:"getDocumentsMatchingQuery",value:function getDocumentsMatchingQuery(transaction,query,sinceReadTime){if(isDocumentQuery(query)){return this.getDocumentsMatchingDocumentQuery(transaction,query.path);}else if(isCollectionGroupQuery(query)){return this.getDocumentsMatchingCollectionGroupQuery(transaction,query,sinceReadTime);}else{return this.getDocumentsMatchingCollectionQuery(transaction,query,sinceReadTime);}}},{key:"getDocumentsMatchingDocumentQuery",value:function getDocumentsMatchingDocumentQuery(transaction,docPath){// Just do a simple document lookup.
return this.getDocument(transaction,new DocumentKey(docPath)).next(function(maybeDoc){var result=documentMap();if(maybeDoc instanceof Document){result=result.insert(maybeDoc.key,maybeDoc);}return result;});}},{key:"getDocumentsMatchingCollectionGroupQuery",value:function getDocumentsMatchingCollectionGroupQuery(transaction,query,sinceReadTime){var _this35=this;var collectionId=query.collectionGroup;var results=documentMap();return this.indexManager.getCollectionParents(transaction,collectionId).next(function(parents){// Perform a collection query against each parent that contains the
// collectionId and aggregate the results.
return PersistencePromise.forEach(parents,function(parent){var collectionQuery=asCollectionQueryAtPath(query,parent.child(collectionId));return _this35.getDocumentsMatchingCollectionQuery(transaction,collectionQuery,sinceReadTime).next(function(r){r.forEach(function(key,doc){results=results.insert(key,doc);});});}).next(function(){return results;});});}},{key:"getDocumentsMatchingCollectionQuery",value:function getDocumentsMatchingCollectionQuery(transaction,query,sinceReadTime){var _this36=this;// Query the remote documents and overlay mutations.
var results;var mutationBatches;return this.remoteDocumentCache.getDocumentsMatchingQuery(transaction,query,sinceReadTime).next(function(queryResults){results=queryResults;return _this36.mutationQueue.getAllMutationBatchesAffectingQuery(transaction,query);}).next(function(matchingMutationBatches){mutationBatches=matchingMutationBatches;// It is possible that a PatchMutation can make a document match a query, even if
// the version in the RemoteDocumentCache is not a match yet (waiting for server
// to ack). To handle this, we find all document keys affected by the PatchMutations
// that are not in `result` yet, and back fill them via `remoteDocumentCache.getEntries`,
// otherwise those `PatchMutations` will be ignored because no base document can be found,
// and lead to missing result for the query.
return _this36.addMissingBaseDocuments(transaction,mutationBatches,results).next(function(mergedDocuments){results=mergedDocuments;var _iteratorNormalCompletion28=true;var _didIteratorError28=false;var _iteratorError28=undefined;try{for(var _iterator28=mutationBatches[Symbol.iterator](),_step28;!(_iteratorNormalCompletion28=(_step28=_iterator28.next()).done);_iteratorNormalCompletion28=true){var batch=_step28.value;var _iteratorNormalCompletion29=true;var _didIteratorError29=false;var _iteratorError29=undefined;try{for(var _iterator29=batch.mutations[Symbol.iterator](),_step29;!(_iteratorNormalCompletion29=(_step29=_iterator29.next()).done);_iteratorNormalCompletion29=true){var mutation=_step29.value;var key=mutation.key;var baseDoc=results.get(key);var mutatedDoc=applyMutationToLocalView(mutation,baseDoc,baseDoc,batch.localWriteTime);if(mutatedDoc instanceof Document){results=results.insert(key,mutatedDoc);}else{results=results.remove(key);}}}catch(err){_didIteratorError29=true;_iteratorError29=err;}finally{try{if(!_iteratorNormalCompletion29&&_iterator29["return"]!=null){_iterator29["return"]();}}finally{if(_didIteratorError29){throw _iteratorError29;}}}}}catch(err){_didIteratorError28=true;_iteratorError28=err;}finally{try{if(!_iteratorNormalCompletion28&&_iterator28["return"]!=null){_iterator28["return"]();}}finally{if(_didIteratorError28){throw _iteratorError28;}}}});}).next(function(){// Finally, filter out any documents that don't actually match
// the query.
results.forEach(function(key,doc){if(!queryMatches(query,doc)){results=results.remove(key);}});return results;});}},{key:"addMissingBaseDocuments",value:function addMissingBaseDocuments(transaction,matchingMutationBatches,existingDocuments){var missingBaseDocEntriesForPatching=documentKeySet();var _iteratorNormalCompletion30=true;var _didIteratorError30=false;var _iteratorError30=undefined;try{for(var _iterator30=matchingMutationBatches[Symbol.iterator](),_step30;!(_iteratorNormalCompletion30=(_step30=_iterator30.next()).done);_iteratorNormalCompletion30=true){var batch=_step30.value;var _iteratorNormalCompletion31=true;var _didIteratorError31=false;var _iteratorError31=undefined;try{for(var _iterator31=batch.mutations[Symbol.iterator](),_step31;!(_iteratorNormalCompletion31=(_step31=_iterator31.next()).done);_iteratorNormalCompletion31=true){var mutation=_step31.value;if(mutation instanceof PatchMutation&&existingDocuments.get(mutation.key)===null){missingBaseDocEntriesForPatching=missingBaseDocEntriesForPatching.add(mutation.key);}}}catch(err){_didIteratorError31=true;_iteratorError31=err;}finally{try{if(!_iteratorNormalCompletion31&&_iterator31["return"]!=null){_iterator31["return"]();}}finally{if(_didIteratorError31){throw _iteratorError31;}}}}}catch(err){_didIteratorError30=true;_iteratorError30=err;}finally{try{if(!_iteratorNormalCompletion30&&_iterator30["return"]!=null){_iterator30["return"]();}}finally{if(_didIteratorError30){throw _iteratorError30;}}}var mergedDocuments=existingDocuments;return this.remoteDocumentCache.getEntries(transaction,missingBaseDocEntriesForPatching).next(function(missingBaseDocs){missingBaseDocs.forEach(function(key,doc){if(doc!==null&&doc instanceof Document){mergedDocuments=mergedDocuments.insert(key,doc);}});return mergedDocuments;});}}]);return LocalDocumentsView;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var PRIMARY_LEASE_LOST_ERROR_MSG='The current tab is not in the required state to perform this operation. '+'It might be necessary to refresh the browser tab.';/**
 * A base class representing a persistence transaction, encapsulating both the
 * transaction's sequence numbers as well as a list of onCommitted listeners.
 *
 * When you call Persistence.runTransaction(), it will create a transaction and
 * pass it to your callback. You then pass it to any method that operates
 * on persistence.
 */var PersistenceTransaction=/*#__PURE__*/function(){function PersistenceTransaction(){_classCallCheck(this,PersistenceTransaction);this.onCommittedListeners=[];}_createClass(PersistenceTransaction,[{key:"addOnCommittedListener",value:function addOnCommittedListener(listener){this.onCommittedListeners.push(listener);}},{key:"raiseOnCommittedEvent",value:function raiseOnCommittedEvent(){this.onCommittedListeners.forEach(function(listener){return listener();});}}]);return PersistenceTransaction;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * An immutable set of metadata that the local store tracks for each target.
 */var TargetData=/*#__PURE__*/function(){function TargetData(/** The target being listened to. */target,/**
     * The target ID to which the target corresponds; Assigned by the
     * LocalStore for user listens and by the SyncEngine for limbo watches.
     */targetId,/** The purpose of the target. */purpose,/**
     * The sequence number of the last transaction during which this target data
     * was modified.
     */sequenceNumber){var snapshotVersion=arguments.length>4&&arguments[4]!==undefined?arguments[4]:SnapshotVersion.min();var lastLimboFreeSnapshotVersion=arguments.length>5&&arguments[5]!==undefined?arguments[5]:SnapshotVersion.min();var resumeToken=arguments.length>6&&arguments[6]!==undefined?arguments[6]:ByteString.EMPTY_BYTE_STRING;_classCallCheck(this,TargetData);this.target=target;this.targetId=targetId;this.purpose=purpose;this.sequenceNumber=sequenceNumber;this.snapshotVersion=snapshotVersion;this.lastLimboFreeSnapshotVersion=lastLimboFreeSnapshotVersion;this.resumeToken=resumeToken;}/** Creates a new target data instance with an updated sequence number. */_createClass(TargetData,[{key:"withSequenceNumber",value:function withSequenceNumber(sequenceNumber){return new TargetData(this.target,this.targetId,this.purpose,sequenceNumber,this.snapshotVersion,this.lastLimboFreeSnapshotVersion,this.resumeToken);}/**
     * Creates a new target data instance with an updated resume token and
     * snapshot version.
     */},{key:"withResumeToken",value:function withResumeToken(resumeToken,snapshotVersion){return new TargetData(this.target,this.targetId,this.purpose,this.sequenceNumber,snapshotVersion,this.lastLimboFreeSnapshotVersion,resumeToken);}/**
     * Creates a new target data instance with an updated last limbo free
     * snapshot version number.
     */},{key:"withLastLimboFreeSnapshotVersion",value:function withLastLimboFreeSnapshotVersion(lastLimboFreeSnapshotVersion){return new TargetData(this.target,this.targetId,this.purpose,this.sequenceNumber,this.snapshotVersion,lastLimboFreeSnapshotVersion,this.resumeToken);}}]);return TargetData;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var escapeChar="\x01";var encodedSeparatorChar="\x01";var encodedNul="\x10";var encodedEscape="\x11";/**
 * Encodes a resource path into a IndexedDb-compatible string form.
 */function encodeResourcePath(path){var result='';for(var i=0;i<path.length;i++){if(result.length>0){result=encodeSeparator(result);}result=encodeSegment(path.get(i),result);}return encodeSeparator(result);}/** Encodes a single segment of a resource path into the given result */function encodeSegment(segment,resultBuf){var result=resultBuf;var length=segment.length;for(var i=0;i<length;i++){var c=segment.charAt(i);switch(c){case'\0':result+=escapeChar+encodedNul;break;case escapeChar:result+=escapeChar+encodedEscape;break;default:result+=c;}}return result;}/** Encodes a path separator into the given result */function encodeSeparator(result){return result+escapeChar+encodedSeparatorChar;}/**
 * Decodes the given IndexedDb-compatible string form of a resource path into
 * a ResourcePath instance. Note that this method is not suitable for use with
 * decoding resource names from the server; those are One Platform format
 * strings.
 */function decodeResourcePath(path){// Event the empty path must encode as a path of at least length 2. A path
// with exactly 2 must be the empty path.
var length=path.length;hardAssert(length>=2);if(length===2){hardAssert(path.charAt(0)===escapeChar&&path.charAt(1)===encodedSeparatorChar);return ResourcePath.emptyPath();}// Escape characters cannot exist past the second-to-last position in the
// source value.
var lastReasonableEscapeIndex=length-2;var segments=[];var segmentBuilder='';for(var start=0;start<length;){// The last two characters of a valid encoded path must be a separator, so
// there must be an end to this segment.
var end=path.indexOf(escapeChar,start);if(end<0||end>lastReasonableEscapeIndex){fail();}var next=path.charAt(end+1);switch(next){case encodedSeparatorChar:var currentPiece=path.substring(start,end);var segment=void 0;if(segmentBuilder.length===0){// Avoid copying for the common case of a segment that excludes \0
// and \001
segment=currentPiece;}else{segmentBuilder+=currentPiece;segment=segmentBuilder;segmentBuilder='';}segments.push(segment);break;case encodedNul:segmentBuilder+=path.substring(start,end);segmentBuilder+='\0';break;case encodedEscape:// The escape character can be used in the output to encode itself.
segmentBuilder+=path.substring(start,end+1);break;default:fail();}start=end+2;}return new ResourcePath(segments);}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /** Serializer for values stored in the LocalStore. */var LocalSerializer=function LocalSerializer(remoteSerializer){_classCallCheck(this,LocalSerializer);this.remoteSerializer=remoteSerializer;};/** Decodes a remote document from storage locally to a Document. */function fromDbRemoteDocument(localSerializer,remoteDoc){if(remoteDoc.document){return fromDocument(localSerializer.remoteSerializer,remoteDoc.document,!!remoteDoc.hasCommittedMutations);}else if(remoteDoc.noDocument){var key=DocumentKey.fromSegments(remoteDoc.noDocument.path);var _version3=fromDbTimestamp(remoteDoc.noDocument.readTime);return new NoDocument(key,_version3,{hasCommittedMutations:!!remoteDoc.hasCommittedMutations});}else if(remoteDoc.unknownDocument){var _key12=DocumentKey.fromSegments(remoteDoc.unknownDocument.path);var _version4=fromDbTimestamp(remoteDoc.unknownDocument.version);return new UnknownDocument(_key12,_version4);}else{return fail();}}/** Encodes a document for storage locally. */function toDbRemoteDocument(localSerializer,maybeDoc,readTime){var dbReadTime=toDbTimestampKey(readTime);var parentPath=maybeDoc.key.path.popLast().toArray();if(maybeDoc instanceof Document){var doc=toDocument(localSerializer.remoteSerializer,maybeDoc);var hasCommittedMutations=maybeDoc.hasCommittedMutations;return new DbRemoteDocument(/* unknownDocument= */null,/* noDocument= */null,doc,hasCommittedMutations,dbReadTime,parentPath);}else if(maybeDoc instanceof NoDocument){var path=maybeDoc.key.path.toArray();var _readTime=toDbTimestamp(maybeDoc.version);var _hasCommittedMutations=maybeDoc.hasCommittedMutations;return new DbRemoteDocument(/* unknownDocument= */null,new DbNoDocument(path,_readTime),/* document= */null,_hasCommittedMutations,dbReadTime,parentPath);}else if(maybeDoc instanceof UnknownDocument){var _path2=maybeDoc.key.path.toArray();var _readTime2=toDbTimestamp(maybeDoc.version);return new DbRemoteDocument(new DbUnknownDocument(_path2,_readTime2),/* noDocument= */null,/* document= */null,/* hasCommittedMutations= */true,dbReadTime,parentPath);}else{return fail();}}function toDbTimestampKey(snapshotVersion){var timestamp=snapshotVersion.toTimestamp();return[timestamp.seconds,timestamp.nanoseconds];}function fromDbTimestampKey(dbTimestampKey){var timestamp=new Timestamp(dbTimestampKey[0],dbTimestampKey[1]);return SnapshotVersion.fromTimestamp(timestamp);}function toDbTimestamp(snapshotVersion){var timestamp=snapshotVersion.toTimestamp();return new DbTimestamp(timestamp.seconds,timestamp.nanoseconds);}function fromDbTimestamp(dbTimestamp){var timestamp=new Timestamp(dbTimestamp.seconds,dbTimestamp.nanoseconds);return SnapshotVersion.fromTimestamp(timestamp);}/** Encodes a batch of mutations into a DbMutationBatch for local storage. */function toDbMutationBatch(localSerializer,userId,batch){var serializedBaseMutations=batch.baseMutations.map(function(m){return toMutation(localSerializer.remoteSerializer,m);});var serializedMutations=batch.mutations.map(function(m){return toMutation(localSerializer.remoteSerializer,m);});return new DbMutationBatch(userId,batch.batchId,batch.localWriteTime.toMillis(),serializedBaseMutations,serializedMutations);}/** Decodes a DbMutationBatch into a MutationBatch */function fromDbMutationBatch(localSerializer,dbBatch){var baseMutations=(dbBatch.baseMutations||[]).map(function(m){return fromMutation(localSerializer.remoteSerializer,m);});var mutations=dbBatch.mutations.map(function(m){return fromMutation(localSerializer.remoteSerializer,m);});var timestamp=Timestamp.fromMillis(dbBatch.localWriteTimeMs);return new MutationBatch(dbBatch.batchId,timestamp,baseMutations,mutations);}/** Decodes a DbTarget into TargetData */function fromDbTarget(dbTarget){var version=fromDbTimestamp(dbTarget.readTime);var lastLimboFreeSnapshotVersion=dbTarget.lastLimboFreeSnapshotVersion!==undefined?fromDbTimestamp(dbTarget.lastLimboFreeSnapshotVersion):SnapshotVersion.min();var target;if(isDocumentQuery$1(dbTarget.query)){target=fromDocumentsTarget(dbTarget.query);}else{target=fromQueryTarget(dbTarget.query);}return new TargetData(target,dbTarget.targetId,0/* Listen */,dbTarget.lastListenSequenceNumber,version,lastLimboFreeSnapshotVersion,ByteString.fromBase64String(dbTarget.resumeToken));}/** Encodes TargetData into a DbTarget for storage locally. */function toDbTarget(localSerializer,targetData){var dbTimestamp=toDbTimestamp(targetData.snapshotVersion);var dbLastLimboFreeTimestamp=toDbTimestamp(targetData.lastLimboFreeSnapshotVersion);var queryProto;if(isDocumentTarget(targetData.target)){queryProto=toDocumentsTarget(localSerializer.remoteSerializer,targetData.target);}else{queryProto=toQueryTarget(localSerializer.remoteSerializer,targetData.target);}// We can't store the resumeToken as a ByteString in IndexedDb, so we
// convert it to a base64 string for storage.
var resumeToken=targetData.resumeToken.toBase64();// lastListenSequenceNumber is always 0 until we do real GC.
return new DbTarget(targetData.targetId,canonifyTarget(targetData.target),dbTimestamp,resumeToken,targetData.sequenceNumber,dbLastLimboFreeTimestamp,queryProto);}/**
 * A helper function for figuring out what kind of query has been stored.
 */function isDocumentQuery$1(dbQuery){return dbQuery.documents!==undefined;}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /** A mutation queue for a specific user, backed by IndexedDB. */var IndexedDbMutationQueue=/*#__PURE__*/function(){function IndexedDbMutationQueue(/**
     * The normalized userId (e.g. null UID => "" userId) used to store /
     * retrieve mutations.
     */userId,serializer,indexManager,referenceDelegate){_classCallCheck(this,IndexedDbMutationQueue);this.userId=userId;this.serializer=serializer;this.indexManager=indexManager;this.referenceDelegate=referenceDelegate;/**
         * Caches the document keys for pending mutation batches. If the mutation
         * has been removed from IndexedDb, the cached value may continue to
         * be used to retrieve the batch's document keys. To remove a cached value
         * locally, `removeCachedMutationKeys()` should be invoked either directly
         * or through `removeMutationBatches()`.
         *
         * With multi-tab, when the primary client acknowledges or rejects a mutation,
         * this cache is used by secondary clients to invalidate the local
         * view of the documents that were previously affected by the mutation.
         */ // PORTING NOTE: Multi-tab only.
this.documentKeysByBatchId={};}/**
     * Creates a new mutation queue for the given user.
     * @param user The user for which to create a mutation queue.
     * @param serializer The serializer to use when persisting to IndexedDb.
     */_createClass(IndexedDbMutationQueue,[{key:"checkEmpty",value:function checkEmpty(transaction){var empty=true;var range=IDBKeyRange.bound([this.userId,Number.NEGATIVE_INFINITY],[this.userId,Number.POSITIVE_INFINITY]);return mutationsStore(transaction).iterate({index:DbMutationBatch.userMutationsIndex,range:range},function(key,value,control){empty=false;control.done();}).next(function(){return empty;});}},{key:"addMutationBatch",value:function addMutationBatch(transaction,localWriteTime,baseMutations,mutations){var _this37=this;var documentStore=documentMutationsStore(transaction);var mutationStore=mutationsStore(transaction);// The IndexedDb implementation in Chrome (and Firefox) does not handle
// compound indices that include auto-generated keys correctly. To ensure
// that the index entry is added correctly in all browsers, we perform two
// writes: The first write is used to retrieve the next auto-generated Batch
// ID, and the second write populates the index and stores the actual
// mutation batch.
// See: https://bugs.chromium.org/p/chromium/issues/detail?id=701972
// We write an empty object to obtain key
// eslint-disable-next-line @typescript-eslint/no-explicit-any
return mutationStore.add({}).next(function(batchId){hardAssert(typeof batchId==='number');var batch=new MutationBatch(batchId,localWriteTime,baseMutations,mutations);var dbBatch=toDbMutationBatch(_this37.serializer,_this37.userId,batch);var promises=[];var collectionParents=new SortedSet(function(l,r){return primitiveComparator(l.canonicalString(),r.canonicalString());});var _iteratorNormalCompletion32=true;var _didIteratorError32=false;var _iteratorError32=undefined;try{for(var _iterator32=mutations[Symbol.iterator](),_step32;!(_iteratorNormalCompletion32=(_step32=_iterator32.next()).done);_iteratorNormalCompletion32=true){var mutation=_step32.value;var indexKey=DbDocumentMutation.key(_this37.userId,mutation.key.path,batchId);collectionParents=collectionParents.add(mutation.key.path.popLast());promises.push(mutationStore.put(dbBatch));promises.push(documentStore.put(indexKey,DbDocumentMutation.PLACEHOLDER));}}catch(err){_didIteratorError32=true;_iteratorError32=err;}finally{try{if(!_iteratorNormalCompletion32&&_iterator32["return"]!=null){_iterator32["return"]();}}finally{if(_didIteratorError32){throw _iteratorError32;}}}collectionParents.forEach(function(parent){promises.push(_this37.indexManager.addToCollectionParentIndex(transaction,parent));});transaction.addOnCommittedListener(function(){_this37.documentKeysByBatchId[batchId]=batch.keys();});return PersistencePromise.waitFor(promises).next(function(){return batch;});});}},{key:"lookupMutationBatch",value:function lookupMutationBatch(transaction,batchId){var _this38=this;return mutationsStore(transaction).get(batchId).next(function(dbBatch){if(dbBatch){hardAssert(dbBatch.userId===_this38.userId);return fromDbMutationBatch(_this38.serializer,dbBatch);}return null;});}/**
     * Returns the document keys for the mutation batch with the given batchId.
     * For primary clients, this method returns `null` after
     * `removeMutationBatches()` has been called. Secondary clients return a
     * cached result until `removeCachedMutationKeys()` is invoked.
     */ // PORTING NOTE: Multi-tab only.
},{key:"lookupMutationKeys",value:function lookupMutationKeys(transaction,batchId){var _this39=this;if(this.documentKeysByBatchId[batchId]){return PersistencePromise.resolve(this.documentKeysByBatchId[batchId]);}else{return this.lookupMutationBatch(transaction,batchId).next(function(batch){if(batch){var keys=batch.keys();_this39.documentKeysByBatchId[batchId]=keys;return keys;}else{return null;}});}}},{key:"getNextMutationBatchAfterBatchId",value:function getNextMutationBatchAfterBatchId(transaction,batchId){var _this40=this;var nextBatchId=batchId+1;var range=IDBKeyRange.lowerBound([this.userId,nextBatchId]);var foundBatch=null;return mutationsStore(transaction).iterate({index:DbMutationBatch.userMutationsIndex,range:range},function(key,dbBatch,control){if(dbBatch.userId===_this40.userId){hardAssert(dbBatch.batchId>=nextBatchId);foundBatch=fromDbMutationBatch(_this40.serializer,dbBatch);}control.done();}).next(function(){return foundBatch;});}},{key:"getHighestUnacknowledgedBatchId",value:function getHighestUnacknowledgedBatchId(transaction){var range=IDBKeyRange.upperBound([this.userId,Number.POSITIVE_INFINITY]);var batchId=BATCHID_UNKNOWN;return mutationsStore(transaction).iterate({index:DbMutationBatch.userMutationsIndex,range:range,reverse:true},function(key,dbBatch,control){batchId=dbBatch.batchId;control.done();}).next(function(){return batchId;});}},{key:"getAllMutationBatches",value:function getAllMutationBatches(transaction){var _this41=this;var range=IDBKeyRange.bound([this.userId,BATCHID_UNKNOWN],[this.userId,Number.POSITIVE_INFINITY]);return mutationsStore(transaction).loadAll(DbMutationBatch.userMutationsIndex,range).next(function(dbBatches){return dbBatches.map(function(dbBatch){return fromDbMutationBatch(_this41.serializer,dbBatch);});});}},{key:"getAllMutationBatchesAffectingDocumentKey",value:function getAllMutationBatchesAffectingDocumentKey(transaction,documentKey){var _this42=this;// Scan the document-mutation index starting with a prefix starting with
// the given documentKey.
var indexPrefix=DbDocumentMutation.prefixForPath(this.userId,documentKey.path);var indexStart=IDBKeyRange.lowerBound(indexPrefix);var results=[];return documentMutationsStore(transaction).iterate({range:indexStart},function(indexKey,_,control){var _indexKey=_slicedToArray(indexKey,3),userID=_indexKey[0],encodedPath=_indexKey[1],batchId=_indexKey[2];// Only consider rows matching exactly the specific key of
// interest. Note that because we order by path first, and we
// order terminators before path separators, we'll encounter all
// the index rows for documentKey contiguously. In particular, all
// the rows for documentKey will occur before any rows for
// documents nested in a subcollection beneath documentKey so we
// can stop as soon as we hit any such row.
var path=decodeResourcePath(encodedPath);if(userID!==_this42.userId||!documentKey.path.isEqual(path)){control.done();return;}// Look up the mutation batch in the store.
return mutationsStore(transaction).get(batchId).next(function(mutation){if(!mutation){throw fail();}hardAssert(mutation.userId===_this42.userId);results.push(fromDbMutationBatch(_this42.serializer,mutation));});}).next(function(){return results;});}},{key:"getAllMutationBatchesAffectingDocumentKeys",value:function getAllMutationBatchesAffectingDocumentKeys(transaction,documentKeys){var _this43=this;var uniqueBatchIDs=new SortedSet(primitiveComparator);var promises=[];documentKeys.forEach(function(documentKey){var indexStart=DbDocumentMutation.prefixForPath(_this43.userId,documentKey.path);var range=IDBKeyRange.lowerBound(indexStart);var promise=documentMutationsStore(transaction).iterate({range:range},function(indexKey,_,control){var _indexKey2=_slicedToArray(indexKey,3),userID=_indexKey2[0],encodedPath=_indexKey2[1],batchID=_indexKey2[2];// Only consider rows matching exactly the specific key of
// interest. Note that because we order by path first, and we
// order terminators before path separators, we'll encounter all
// the index rows for documentKey contiguously. In particular, all
// the rows for documentKey will occur before any rows for
// documents nested in a subcollection beneath documentKey so we
// can stop as soon as we hit any such row.
var path=decodeResourcePath(encodedPath);if(userID!==_this43.userId||!documentKey.path.isEqual(path)){control.done();return;}uniqueBatchIDs=uniqueBatchIDs.add(batchID);});promises.push(promise);});return PersistencePromise.waitFor(promises).next(function(){return _this43.lookupMutationBatches(transaction,uniqueBatchIDs);});}},{key:"getAllMutationBatchesAffectingQuery",value:function getAllMutationBatchesAffectingQuery(transaction,query){var _this44=this;var queryPath=query.path;var immediateChildrenLength=queryPath.length+1;// TODO(mcg): Actually implement a single-collection query
//
// This is actually executing an ancestor query, traversing the whole
// subtree below the collection which can be horrifically inefficient for
// some structures. The right way to solve this is to implement the full
// value index, but that's not in the cards in the near future so this is
// the best we can do for the moment.
//
// Since we don't yet index the actual properties in the mutations, our
// current approach is to just return all mutation batches that affect
// documents in the collection being queried.
var indexPrefix=DbDocumentMutation.prefixForPath(this.userId,queryPath);var indexStart=IDBKeyRange.lowerBound(indexPrefix);// Collect up unique batchIDs encountered during a scan of the index. Use a
// SortedSet to accumulate batch IDs so they can be traversed in order in a
// scan of the main table.
var uniqueBatchIDs=new SortedSet(primitiveComparator);return documentMutationsStore(transaction).iterate({range:indexStart},function(indexKey,_,control){var _indexKey3=_slicedToArray(indexKey,3),userID=_indexKey3[0],encodedPath=_indexKey3[1],batchID=_indexKey3[2];var path=decodeResourcePath(encodedPath);if(userID!==_this44.userId||!queryPath.isPrefixOf(path)){control.done();return;}// Rows with document keys more than one segment longer than the
// query path can't be matches. For example, a query on 'rooms'
// can't match the document /rooms/abc/messages/xyx.
// TODO(mcg): we'll need a different scanner when we implement
// ancestor queries.
if(path.length!==immediateChildrenLength){return;}uniqueBatchIDs=uniqueBatchIDs.add(batchID);}).next(function(){return _this44.lookupMutationBatches(transaction,uniqueBatchIDs);});}},{key:"lookupMutationBatches",value:function lookupMutationBatches(transaction,batchIDs){var _this45=this;var results=[];var promises=[];// TODO(rockwood): Implement this using iterate.
batchIDs.forEach(function(batchId){promises.push(mutationsStore(transaction).get(batchId).next(function(mutation){if(mutation===null){throw fail();}hardAssert(mutation.userId===_this45.userId);results.push(fromDbMutationBatch(_this45.serializer,mutation));}));});return PersistencePromise.waitFor(promises).next(function(){return results;});}},{key:"removeMutationBatch",value:function removeMutationBatch(transaction,batch){var _this46=this;return _removeMutationBatch(transaction.simpleDbTransaction,this.userId,batch).next(function(removedDocuments){transaction.addOnCommittedListener(function(){_this46.removeCachedMutationKeys(batch.batchId);});return PersistencePromise.forEach(removedDocuments,function(key){return _this46.referenceDelegate.markPotentiallyOrphaned(transaction,key);});});}/**
     * Clears the cached keys for a mutation batch. This method should be
     * called by secondary clients after they process mutation updates.
     *
     * Note that this method does not have to be called from primary clients as
     * the corresponding cache entries are cleared when an acknowledged or
     * rejected batch is removed from the mutation queue.
     */ // PORTING NOTE: Multi-tab only
},{key:"removeCachedMutationKeys",value:function removeCachedMutationKeys(batchId){delete this.documentKeysByBatchId[batchId];}},{key:"performConsistencyCheck",value:function performConsistencyCheck(txn){var _this47=this;return this.checkEmpty(txn).next(function(empty){if(!empty){return PersistencePromise.resolve();}// Verify that there are no entries in the documentMutations index if
// the queue is empty.
var startRange=IDBKeyRange.lowerBound(DbDocumentMutation.prefixForUser(_this47.userId));var danglingMutationReferences=[];return documentMutationsStore(txn).iterate({range:startRange},function(key,_,control){var userID=key[0];if(userID!==_this47.userId){control.done();return;}else{var path=decodeResourcePath(key[1]);danglingMutationReferences.push(path);}}).next(function(){hardAssert(danglingMutationReferences.length===0);});});}},{key:"containsKey",value:function containsKey(txn,key){return mutationQueueContainsKey(txn,this.userId,key);}// PORTING NOTE: Multi-tab only (state is held in memory in other clients).
/** Returns the mutation queue's metadata from IndexedDb. */},{key:"getMutationQueueMetadata",value:function getMutationQueueMetadata(transaction){var _this48=this;return mutationQueuesStore(transaction).get(this.userId).next(function(metadata){return metadata||new DbMutationQueue(_this48.userId,BATCHID_UNKNOWN,/*lastStreamToken=*/'');});}}],[{key:"forUser",value:function forUser(user,serializer,indexManager,referenceDelegate){// TODO(mcg): Figure out what constraints there are on userIDs
// In particular, are there any reserved characters? are empty ids allowed?
// For the moment store these together in the same mutations table assuming
// that empty userIDs aren't allowed.
hardAssert(user.uid!=='');var userId=user.isAuthenticated()?user.uid:'';return new IndexedDbMutationQueue(userId,serializer,indexManager,referenceDelegate);}}]);return IndexedDbMutationQueue;}();/**
 * @return true if the mutation queue for the given user contains a pending
 *         mutation for the given key.
 */function mutationQueueContainsKey(txn,userId,key){var indexKey=DbDocumentMutation.prefixForPath(userId,key.path);var encodedPath=indexKey[1];var startRange=IDBKeyRange.lowerBound(indexKey);var containsKey=false;return documentMutationsStore(txn).iterate({range:startRange,keysOnly:true},function(key,value,control){var _key13=_slicedToArray(key,3),userID=_key13[0],keyPath=_key13[1],/*batchID*/_=_key13[2];if(userID===userId&&keyPath===encodedPath){containsKey=true;}control.done();}).next(function(){return containsKey;});}/** Returns true if any mutation queue contains the given document. */function mutationQueuesContainKey(txn,docKey){var found=false;return mutationQueuesStore(txn).iterateSerial(function(userId){return mutationQueueContainsKey(txn,userId,docKey).next(function(containsKey){if(containsKey){found=true;}return PersistencePromise.resolve(!containsKey);});}).next(function(){return found;});}/**
 * Delete a mutation batch and the associated document mutations.
 * @return A PersistencePromise of the document mutations that were removed.
 */function _removeMutationBatch(txn,userId,batch){var mutationStore=txn.store(DbMutationBatch.store);var indexTxn=txn.store(DbDocumentMutation.store);var promises=[];var range=IDBKeyRange.only(batch.batchId);var numDeleted=0;var removePromise=mutationStore.iterate({range:range},function(key,value,control){numDeleted++;return control["delete"]();});promises.push(removePromise.next(function(){hardAssert(numDeleted===1);}));var removedDocuments=[];var _iteratorNormalCompletion33=true;var _didIteratorError33=false;var _iteratorError33=undefined;try{for(var _iterator33=batch.mutations[Symbol.iterator](),_step33;!(_iteratorNormalCompletion33=(_step33=_iterator33.next()).done);_iteratorNormalCompletion33=true){var mutation=_step33.value;var indexKey=DbDocumentMutation.key(userId,mutation.key.path,batch.batchId);promises.push(indexTxn["delete"](indexKey));removedDocuments.push(mutation.key);}}catch(err){_didIteratorError33=true;_iteratorError33=err;}finally{try{if(!_iteratorNormalCompletion33&&_iterator33["return"]!=null){_iterator33["return"]();}}finally{if(_didIteratorError33){throw _iteratorError33;}}}return PersistencePromise.waitFor(promises).next(function(){return removedDocuments;});}/**
 * Helper to get a typed SimpleDbStore for the mutations object store.
 */function mutationsStore(txn){return IndexedDbPersistence.getStore(txn,DbMutationBatch.store);}/**
 * Helper to get a typed SimpleDbStore for the mutationQueues object store.
 */function documentMutationsStore(txn){return IndexedDbPersistence.getStore(txn,DbDocumentMutation.store);}/**
 * Helper to get a typed SimpleDbStore for the mutationQueues object store.
 */function mutationQueuesStore(txn){return IndexedDbPersistence.getStore(txn,DbMutationQueue.store);}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * An in-memory buffer of entries to be written to a RemoteDocumentCache.
 * It can be used to batch up a set of changes to be written to the cache, but
 * additionally supports reading entries back with the `getEntry()` method,
 * falling back to the underlying RemoteDocumentCache if no entry is
 * buffered.
 *
 * Entries added to the cache *must* be read first. This is to facilitate
 * calculating the size delta of the pending changes.
 *
 * PORTING NOTE: This class was implemented then removed from other platforms.
 * If byte-counting ends up being needed on the other platforms, consider
 * porting this class as part of that implementation work.
 */var RemoteDocumentChangeBuffer=/*#__PURE__*/function(){function RemoteDocumentChangeBuffer(){_classCallCheck(this,RemoteDocumentChangeBuffer);// A mapping of document key to the new cache entry that should be written (or null if any
// existing cache entry should be removed).
this.changes=new ObjectMap(function(key){return key.toString();},function(l,r){return l.isEqual(r);});this.changesApplied=false;}_createClass(RemoteDocumentChangeBuffer,[{key:"addEntry",/**
     * Buffers a `RemoteDocumentCache.addEntry()` call.
     *
     * You can only modify documents that have already been retrieved via
     * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).
     */value:function addEntry(maybeDocument,readTime){this.assertNotApplied();this.readTime=readTime;this.changes.set(maybeDocument.key,maybeDocument);}/**
     * Buffers a `RemoteDocumentCache.removeEntry()` call.
     *
     * You can only remove documents that have already been retrieved via
     * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).
     */},{key:"removeEntry",value:function removeEntry(key,readTime){this.assertNotApplied();if(readTime){this.readTime=readTime;}this.changes.set(key,null);}/**
     * Looks up an entry in the cache. The buffered changes will first be checked,
     * and if no buffered change applies, this will forward to
     * `RemoteDocumentCache.getEntry()`.
     *
     * @param transaction The transaction in which to perform any persistence
     *     operations.
     * @param documentKey The key of the entry to look up.
     * @return The cached Document or NoDocument entry, or null if we have nothing
     * cached.
     */},{key:"getEntry",value:function getEntry(transaction,documentKey){this.assertNotApplied();var bufferedEntry=this.changes.get(documentKey);if(bufferedEntry!==undefined){return PersistencePromise.resolve(bufferedEntry);}else{return this.getFromCache(transaction,documentKey);}}/**
     * Looks up several entries in the cache, forwarding to
     * `RemoteDocumentCache.getEntry()`.
     *
     * @param transaction The transaction in which to perform any persistence
     *     operations.
     * @param documentKeys The keys of the entries to look up.
     * @return A map of cached `Document`s or `NoDocument`s, indexed by key. If an
     *     entry cannot be found, the corresponding key will be mapped to a null
     *     value.
     */},{key:"getEntries",value:function getEntries(transaction,documentKeys){return this.getAllFromCache(transaction,documentKeys);}/**
     * Applies buffered changes to the underlying RemoteDocumentCache, using
     * the provided transaction.
     */},{key:"apply",value:function apply(transaction){this.assertNotApplied();this.changesApplied=true;return this.applyChanges(transaction);}/** Helper to assert this.changes is not null  */},{key:"assertNotApplied",value:function assertNotApplied(){}},{key:"readTime",set:function set(value){this._readTime=value;},get:function get(){return this._readTime;}}]);return RemoteDocumentChangeBuffer;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var IndexedDbRemoteDocumentCache=/*#__PURE__*/function(){/**
     * @param {LocalSerializer} serializer The document serializer.
     * @param {IndexManager} indexManager The query indexes that need to be maintained.
     */function IndexedDbRemoteDocumentCache(serializer,indexManager){_classCallCheck(this,IndexedDbRemoteDocumentCache);this.serializer=serializer;this.indexManager=indexManager;}/**
     * Adds the supplied entries to the cache.
     *
     * All calls of `addEntry` are required to go through the RemoteDocumentChangeBuffer
     * returned by `newChangeBuffer()` to ensure proper accounting of metadata.
     */_createClass(IndexedDbRemoteDocumentCache,[{key:"addEntry",value:function addEntry(transaction,key,doc){var documentStore=remoteDocumentsStore(transaction);return documentStore.put(dbKey(key),doc);}/**
     * Removes a document from the cache.
     *
     * All calls of `removeEntry`  are required to go through the RemoteDocumentChangeBuffer
     * returned by `newChangeBuffer()` to ensure proper accounting of metadata.
     */},{key:"removeEntry",value:function removeEntry(transaction,documentKey){var store=remoteDocumentsStore(transaction);var key=dbKey(documentKey);return store["delete"](key);}/**
     * Updates the current cache size.
     *
     * Callers to `addEntry()` and `removeEntry()` *must* call this afterwards to update the
     * cache's metadata.
     */},{key:"updateMetadata",value:function updateMetadata(transaction,sizeDelta){var _this49=this;return this.getMetadata(transaction).next(function(metadata){metadata.byteSize+=sizeDelta;return _this49.setMetadata(transaction,metadata);});}},{key:"getEntry",value:function getEntry(transaction,documentKey){var _this50=this;return remoteDocumentsStore(transaction).get(dbKey(documentKey)).next(function(dbRemoteDoc){return _this50.maybeDecodeDocument(dbRemoteDoc);});}/**
     * Looks up an entry in the cache.
     *
     * @param documentKey The key of the entry to look up.
     * @return The cached MaybeDocument entry and its size, or null if we have nothing cached.
     */},{key:"getSizedEntry",value:function getSizedEntry(transaction,documentKey){var _this51=this;return remoteDocumentsStore(transaction).get(dbKey(documentKey)).next(function(dbRemoteDoc){var doc=_this51.maybeDecodeDocument(dbRemoteDoc);return doc?{maybeDocument:doc,size:dbDocumentSize(dbRemoteDoc)}:null;});}},{key:"getEntries",value:function getEntries(transaction,documentKeys){var _this52=this;var results=nullableMaybeDocumentMap();return this.forEachDbEntry(transaction,documentKeys,function(key,dbRemoteDoc){var doc=_this52.maybeDecodeDocument(dbRemoteDoc);results=results.insert(key,doc);}).next(function(){return results;});}/**
     * Looks up several entries in the cache.
     *
     * @param documentKeys The set of keys entries to look up.
     * @return A map of MaybeDocuments indexed by key (if a document cannot be
     *     found, the key will be mapped to null) and a map of sizes indexed by
     *     key (zero if the key cannot be found).
     */},{key:"getSizedEntries",value:function getSizedEntries(transaction,documentKeys){var _this53=this;var results=nullableMaybeDocumentMap();var sizeMap=new SortedMap(DocumentKey.comparator);return this.forEachDbEntry(transaction,documentKeys,function(key,dbRemoteDoc){var doc=_this53.maybeDecodeDocument(dbRemoteDoc);if(doc){results=results.insert(key,doc);sizeMap=sizeMap.insert(key,dbDocumentSize(dbRemoteDoc));}else{results=results.insert(key,null);sizeMap=sizeMap.insert(key,0);}}).next(function(){return{maybeDocuments:results,sizeMap:sizeMap};});}},{key:"forEachDbEntry",value:function forEachDbEntry(transaction,documentKeys,callback){if(documentKeys.isEmpty()){return PersistencePromise.resolve();}var range=IDBKeyRange.bound(documentKeys.first().path.toArray(),documentKeys.last().path.toArray());var keyIter=documentKeys.getIterator();var nextKey=keyIter.getNext();return remoteDocumentsStore(transaction).iterate({range:range},function(potentialKeyRaw,dbRemoteDoc,control){var potentialKey=DocumentKey.fromSegments(potentialKeyRaw);// Go through keys not found in cache.
while(nextKey&&DocumentKey.comparator(nextKey,potentialKey)<0){callback(nextKey,null);nextKey=keyIter.getNext();}if(nextKey&&nextKey.isEqual(potentialKey)){// Key found in cache.
callback(nextKey,dbRemoteDoc);nextKey=keyIter.hasNext()?keyIter.getNext():null;}// Skip to the next key (if there is one).
if(nextKey){control.skip(nextKey.path.toArray());}else{control.done();}}).next(function(){// The rest of the keys are not in the cache. One case where `iterate`
// above won't go through them is when the cache is empty.
while(nextKey){callback(nextKey,null);nextKey=keyIter.hasNext()?keyIter.getNext():null;}});}},{key:"getDocumentsMatchingQuery",value:function getDocumentsMatchingQuery(transaction,query,sinceReadTime){var _this54=this;var results=documentMap();var immediateChildrenPathLength=query.path.length+1;var iterationOptions={};if(sinceReadTime.isEqual(SnapshotVersion.min())){// Documents are ordered by key, so we can use a prefix scan to narrow
// down the documents we need to match the query against.
var startKey=query.path.toArray();iterationOptions.range=IDBKeyRange.lowerBound(startKey);}else{// Execute an index-free query and filter by read time. This is safe
// since all document changes to queries that have a
// lastLimboFreeSnapshotVersion (`sinceReadTime`) have a read time set.
var collectionKey=query.path.toArray();var readTimeKey=toDbTimestampKey(sinceReadTime);iterationOptions.range=IDBKeyRange.lowerBound([collectionKey,readTimeKey],/* open= */true);iterationOptions.index=DbRemoteDocument.collectionReadTimeIndex;}return remoteDocumentsStore(transaction).iterate(iterationOptions,function(key,dbRemoteDoc,control){// The query is actually returning any path that starts with the query
// path prefix which may include documents in subcollections. For
// example, a query on 'rooms' will return rooms/abc/messages/xyx but we
// shouldn't match it. Fix this by discarding rows with document keys
// more than one segment longer than the query path.
if(key.length!==immediateChildrenPathLength){return;}var maybeDoc=fromDbRemoteDocument(_this54.serializer,dbRemoteDoc);if(!query.path.isPrefixOf(maybeDoc.key.path)){control.done();}else if(maybeDoc instanceof Document&&queryMatches(query,maybeDoc)){results=results.insert(maybeDoc.key,maybeDoc);}}).next(function(){return results;});}/**
     * Returns the set of documents that have changed since the specified read
     * time.
     */ // PORTING NOTE: This is only used for multi-tab synchronization.
},{key:"getNewDocumentChanges",value:function getNewDocumentChanges(transaction,sinceReadTime){var _this55=this;var changedDocs=maybeDocumentMap();var lastReadTime=toDbTimestampKey(sinceReadTime);var documentsStore=remoteDocumentsStore(transaction);var range=IDBKeyRange.lowerBound(lastReadTime,true);return documentsStore.iterate({index:DbRemoteDocument.readTimeIndex,range:range},function(_,dbRemoteDoc){// Unlike `getEntry()` and others, `getNewDocumentChanges()` parses
// the documents directly since we want to keep sentinel deletes.
var doc=fromDbRemoteDocument(_this55.serializer,dbRemoteDoc);changedDocs=changedDocs.insert(doc.key,doc);lastReadTime=dbRemoteDoc.readTime;}).next(function(){return{changedDocs:changedDocs,readTime:fromDbTimestampKey(lastReadTime)};});}/**
     * Returns the read time of the most recently read document in the cache, or
     * SnapshotVersion.min() if not available.
     */ // PORTING NOTE: This is only used for multi-tab synchronization.
},{key:"getLastReadTime",value:function getLastReadTime(transaction){var documentsStore=remoteDocumentsStore(transaction);// If there are no existing entries, we return SnapshotVersion.min().
var readTime=SnapshotVersion.min();return documentsStore.iterate({index:DbRemoteDocument.readTimeIndex,reverse:true},function(key,dbRemoteDoc,control){if(dbRemoteDoc.readTime){readTime=fromDbTimestampKey(dbRemoteDoc.readTime);}control.done();}).next(function(){return readTime;});}},{key:"newChangeBuffer",value:function newChangeBuffer(options){return new IndexedDbRemoteDocumentCache.RemoteDocumentChangeBuffer(this,!!options&&options.trackRemovals);}},{key:"getSize",value:function getSize(txn){return this.getMetadata(txn).next(function(metadata){return metadata.byteSize;});}},{key:"getMetadata",value:function getMetadata(txn){return documentGlobalStore(txn).get(DbRemoteDocumentGlobal.key).next(function(metadata){hardAssert(!!metadata);return metadata;});}},{key:"setMetadata",value:function setMetadata(txn,metadata){return documentGlobalStore(txn).put(DbRemoteDocumentGlobal.key,metadata);}/**
     * Decodes `remoteDoc` and returns the document (or null, if the document
     * corresponds to the format used for sentinel deletes).
     */},{key:"maybeDecodeDocument",value:function maybeDecodeDocument(dbRemoteDoc){if(dbRemoteDoc){var doc=fromDbRemoteDocument(this.serializer,dbRemoteDoc);if(doc instanceof NoDocument&&doc.version.isEqual(SnapshotVersion.min())){// The document is a sentinel removal and should only be used in the
// `getNewDocumentChanges()`.
return null;}return doc;}return null;}}]);return IndexedDbRemoteDocumentCache;}();/**
 * Handles the details of adding and updating documents in the IndexedDbRemoteDocumentCache.
 *
 * Unlike the MemoryRemoteDocumentChangeBuffer, the IndexedDb implementation computes the size
 * delta for all submitted changes. This avoids having to re-read all documents from IndexedDb
 * when we apply the changes.
 */IndexedDbRemoteDocumentCache.RemoteDocumentChangeBuffer=/*#__PURE__*/function(_RemoteDocumentChange){_inherits(_class,_RemoteDocumentChange);/**
     * @param documentCache The IndexedDbRemoteDocumentCache to apply the changes to.
     * @param trackRemovals Whether to create sentinel deletes that can be tracked by
     * `getNewDocumentChanges()`.
     */function _class(documentCache,trackRemovals){var _this56;_classCallCheck(this,_class);_this56=_possibleConstructorReturn(this,_getPrototypeOf(_class).call(this));_this56.documentCache=documentCache;_this56.trackRemovals=trackRemovals;// A map of document sizes prior to applying the changes in this buffer.
_this56.documentSizes=new ObjectMap(function(key){return key.toString();},function(l,r){return l.isEqual(r);});return _this56;}_createClass(_class,[{key:"applyChanges",value:function applyChanges(transaction){var _this57=this;var promises=[];var sizeDelta=0;var collectionParents=new SortedSet(function(l,r){return primitiveComparator(l.canonicalString(),r.canonicalString());});this.changes.forEach(function(key,maybeDocument){var previousSize=_this57.documentSizes.get(key);if(maybeDocument){var doc=toDbRemoteDocument(_this57.documentCache.serializer,maybeDocument,_this57.readTime);collectionParents=collectionParents.add(key.path.popLast());var size=dbDocumentSize(doc);sizeDelta+=size-previousSize;promises.push(_this57.documentCache.addEntry(transaction,key,doc));}else{sizeDelta-=previousSize;if(_this57.trackRemovals){// In order to track removals, we store a "sentinel delete" in the
// RemoteDocumentCache. This entry is represented by a NoDocument
// with a version of 0 and ignored by `maybeDecodeDocument()` but
// preserved in `getNewDocumentChanges()`.
var deletedDoc=toDbRemoteDocument(_this57.documentCache.serializer,new NoDocument(key,SnapshotVersion.min()),_this57.readTime);promises.push(_this57.documentCache.addEntry(transaction,key,deletedDoc));}else{promises.push(_this57.documentCache.removeEntry(transaction,key));}}});collectionParents.forEach(function(parent){promises.push(_this57.documentCache.indexManager.addToCollectionParentIndex(transaction,parent));});promises.push(this.documentCache.updateMetadata(transaction,sizeDelta));return PersistencePromise.waitFor(promises);}},{key:"getFromCache",value:function getFromCache(transaction,documentKey){var _this58=this;// Record the size of everything we load from the cache so we can compute a delta later.
return this.documentCache.getSizedEntry(transaction,documentKey).next(function(getResult){if(getResult===null){_this58.documentSizes.set(documentKey,0);return null;}else{_this58.documentSizes.set(documentKey,getResult.size);return getResult.maybeDocument;}});}},{key:"getAllFromCache",value:function getAllFromCache(transaction,documentKeys){var _this59=this;// Record the size of everything we load from the cache so we can compute
// a delta later.
return this.documentCache.getSizedEntries(transaction,documentKeys).next(function(_ref){var maybeDocuments=_ref.maybeDocuments,sizeMap=_ref.sizeMap;// Note: `getAllFromCache` returns two maps instead of a single map from
// keys to `DocumentSizeEntry`s. This is to allow returning the
// `NullableMaybeDocumentMap` directly, without a conversion.
sizeMap.forEach(function(documentKey,size){_this59.documentSizes.set(documentKey,size);});return maybeDocuments;});}}]);return _class;}(RemoteDocumentChangeBuffer);function documentGlobalStore(txn){return IndexedDbPersistence.getStore(txn,DbRemoteDocumentGlobal.store);}/**
 * Helper to get a typed SimpleDbStore for the remoteDocuments object store.
 */function remoteDocumentsStore(txn){return IndexedDbPersistence.getStore(txn,DbRemoteDocument.store);}function dbKey(docKey){return docKey.path.toArray();}/**
 * Retrusn an approximate size for the given document.
 */function dbDocumentSize(doc){var value;if(doc.document){value=doc.document;}else if(doc.unknownDocument){value=doc.unknownDocument;}else if(doc.noDocument){value=doc.noDocument;}else{throw fail();}return JSON.stringify(value).length;}/**
 * @license
 * Copyright 2019 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * An in-memory implementation of IndexManager.
 */var MemoryIndexManager=/*#__PURE__*/function(){function MemoryIndexManager(){_classCallCheck(this,MemoryIndexManager);this.collectionParentIndex=new MemoryCollectionParentIndex();}_createClass(MemoryIndexManager,[{key:"addToCollectionParentIndex",value:function addToCollectionParentIndex(transaction,collectionPath){this.collectionParentIndex.add(collectionPath);return PersistencePromise.resolve();}},{key:"getCollectionParents",value:function getCollectionParents(transaction,collectionId){return PersistencePromise.resolve(this.collectionParentIndex.getEntries(collectionId));}}]);return MemoryIndexManager;}();/**
 * Internal implementation of the collection-parent index exposed by MemoryIndexManager.
 * Also used for in-memory caching by IndexedDbIndexManager and initial index population
 * in indexeddb_schema.ts
 */var MemoryCollectionParentIndex=/*#__PURE__*/function(){function MemoryCollectionParentIndex(){_classCallCheck(this,MemoryCollectionParentIndex);this.index={};}// Returns false if the entry already existed.
_createClass(MemoryCollectionParentIndex,[{key:"add",value:function add(collectionPath){var collectionId=collectionPath.lastSegment();var parentPath=collectionPath.popLast();var existingParents=this.index[collectionId]||new SortedSet(ResourcePath.comparator);var added=!existingParents.has(parentPath);this.index[collectionId]=existingParents.add(parentPath);return added;}},{key:"has",value:function has(collectionPath){var collectionId=collectionPath.lastSegment();var parentPath=collectionPath.popLast();var existingParents=this.index[collectionId];return existingParents&&existingParents.has(parentPath);}},{key:"getEntries",value:function getEntries(collectionId){var parentPaths=this.index[collectionId]||new SortedSet(ResourcePath.comparator);return parentPaths.toArray();}}]);return MemoryCollectionParentIndex;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var Deferred=function Deferred(){var _this60=this;_classCallCheck(this,Deferred);this.promise=new Promise(function(resolve,reject){_this60.resolve=resolve;_this60.reject=reject;});};/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ // References to `window` are guarded by SimpleDb.isAvailable()
/* eslint-disable no-restricted-globals */var LOG_TAG$2='SimpleDb';/**
 * The maximum number of retry attempts for an IndexedDb transaction that fails
 * with a DOMException.
 */var TRANSACTION_RETRY_COUNT=3;/**
 * Provides a wrapper around IndexedDb with a simplified interface that uses
 * Promise-like return values to chain operations. Real promises cannot be used
 * since .then() continuations are executed asynchronously (e.g. via
 * .setImmediate), which would cause IndexedDB to end the transaction.
 * See PersistencePromise for more details.
 */var SimpleDb=/*#__PURE__*/function(){/*
     * Creates a new SimpleDb wrapper for IndexedDb database `name`.
     *
     * Note that `version` must not be a downgrade. IndexedDB does not support
     * downgrading the schema version. We currently do not support any way to do
     * versioning outside of IndexedDB's versioning mechanism, as only
     * version-upgrade transactions are allowed to do things like create
     * objectstores.
     */function SimpleDb(name,version,schemaConverter){_classCallCheck(this,SimpleDb);this.name=name;this.version=version;this.schemaConverter=schemaConverter;var iOSVersion=SimpleDb.getIOSVersion((0,_util2.getUA)());// NOTE: According to https://bugs.webkit.org/show_bug.cgi?id=197050, the
// bug we're checking for should exist in iOS >= 12.2 and < 13, but for
// whatever reason it's much harder to hit after 12.2 so we only proactively
// log on 12.2.
if(iOSVersion===12.2){logError('Firestore persistence suffers from a bug in iOS 12.2 '+'Safari that may cause your app to stop working. See '+'https://stackoverflow.com/q/56496296/110915 for details '+'and a potential workaround.');}}/** Deletes the specified database. */_createClass(SimpleDb,[{key:"ensureDb",/**
     * Opens the specified database, creating or upgrading it if necessary.
     */value:function ensureDb(){var _this61=this;return regeneratorRuntime.async(function ensureDb$(_context4){while(1){switch(_context4.prev=_context4.next){case 0:if(this.db){_context4.next=5;break;}logDebug(LOG_TAG$2,'Opening database:',this.name);_context4.next=4;return regeneratorRuntime.awrap(new Promise(function(resolve,reject){// TODO(mikelehen): Investigate browser compatibility.
// https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API/Using_IndexedDB
// suggests IE9 and older WebKit browsers handle upgrade
// differently. They expect setVersion, as described here:
// https://developer.mozilla.org/en-US/docs/Web/API/IDBVersionChangeRequest/setVersion
var request=indexedDB.open(_this61.name,_this61.version);request.onsuccess=function(event){var db=event.target.result;resolve(db);};request.onblocked=function(){reject(new IndexedDbTransactionError('Cannot upgrade IndexedDB schema while another tab is open. '+'Close all tabs that access Firestore and reload this page to proceed.'));};request.onerror=function(event){var error=event.target.error;if(error.name==='VersionError'){reject(new FirestoreError(Code.FAILED_PRECONDITION,'A newer version of the Firestore SDK was previously used and so the persisted '+'data is not compatible with the version of the SDK you are now using. The SDK '+'will operate with persistence disabled. If you need persistence, please '+'re-upgrade to a newer version of the SDK or else clear the persisted IndexedDB '+'data for your app to start fresh.'));}else{reject(new IndexedDbTransactionError(error));}};request.onupgradeneeded=function(event){logDebug(LOG_TAG$2,'Database "'+_this61.name+'" requires upgrade from version:',event.oldVersion);var db=event.target.result;_this61.schemaConverter.createOrUpgrade(db,request.transaction,event.oldVersion,_this61.version).next(function(){logDebug(LOG_TAG$2,'Database upgrade to version '+_this61.version+' complete');});};}));case 4:this.db=_context4.sent;case 5:if(this.versionchangelistener){this.db.onversionchange=function(event){return _this61.versionchangelistener(event);};}return _context4.abrupt("return",this.db);case 7:case"end":return _context4.stop();}}},null,this);}},{key:"setVersionChangeListener",value:function setVersionChangeListener(versionChangeListener){this.versionchangelistener=versionChangeListener;if(this.db){this.db.onversionchange=function(event){return versionChangeListener(event);};}}},{key:"runTransaction",value:function runTransaction(mode,objectStores,transactionFn){var _this62=this;var readonly,attemptNumber,_ret,retryable;return regeneratorRuntime.async(function runTransaction$(_context6){while(1){switch(_context6.prev=_context6.next){case 0:readonly=mode==='readonly';attemptNumber=0;case 2:if(!true){_context6.next=21;break;}++attemptNumber;_context6.prev=4;_context6.next=7;return regeneratorRuntime.awrap(function _callee2(){var transaction,transactionFnResult;return regeneratorRuntime.async(function _callee2$(_context5){while(1){switch(_context5.prev=_context5.next){case 0:_context5.next=2;return regeneratorRuntime.awrap(_this62.ensureDb());case 2:_this62.db=_context5.sent;transaction=SimpleDbTransaction.open(_this62.db,readonly?'readonly':'readwrite',objectStores);transactionFnResult=transactionFn(transaction)["catch"](function(error){// Abort the transaction if there was an error.
transaction.abort(error);// We cannot actually recover, and calling `abort()` will cause the transaction's
// completion promise to be rejected. This in turn means that we won't use
// `transactionFnResult` below. We return a rejection here so that we don't add the
// possibility of returning `void` to the type of `transactionFnResult`.
return PersistencePromise.reject(error);}).toPromise();// As noted above, errors are propagated by aborting the transaction. So
// we swallow any error here to avoid the browser logging it as unhandled.
transactionFnResult["catch"](function(){});// Wait for the transaction to complete (i.e. IndexedDb's onsuccess event to
// fire), but still return the original transactionFnResult back to the
// caller.
_context5.next=8;return regeneratorRuntime.awrap(transaction.completionPromise);case 8:return _context5.abrupt("return",{v:transactionFnResult});case 9:case"end":return _context5.stop();}}});}());case 7:_ret=_context6.sent;if(!(_typeof(_ret)==="object")){_context6.next=10;break;}return _context6.abrupt("return",_ret.v);case 10:_context6.next=19;break;case 12:_context6.prev=12;_context6.t0=_context6["catch"](4);// TODO(schmidt-sebastian): We could probably be smarter about this and
// not retry exceptions that are likely unrecoverable (such as quota
// exceeded errors).
// Note: We cannot use an instanceof check for FirestoreException, since the
// exception is wrapped in a generic error by our async/await handling.
retryable=_context6.t0.name!=='FirebaseError'&&attemptNumber<TRANSACTION_RETRY_COUNT;logDebug(LOG_TAG$2,'Transaction failed with error:',_context6.t0.message,'Retrying:',retryable);this.close();if(retryable){_context6.next=19;break;}return _context6.abrupt("return",Promise.reject(_context6.t0));case 19:_context6.next=2;break;case 21:case"end":return _context6.stop();}}},null,this,[[4,12]]);}},{key:"close",value:function close(){if(this.db){this.db.close();}this.db=undefined;}}],[{key:"delete",value:function _delete(name){logDebug(LOG_TAG$2,'Removing database:',name);return wrapRequest(window.indexedDB.deleteDatabase(name)).toPromise();}/** Returns true if IndexedDB is available in the current environment. */},{key:"isAvailable",value:function isAvailable(){if(typeof indexedDB==='undefined'){return false;}if(SimpleDb.isMockPersistence()){return true;}// We extensively use indexed array values and compound keys,
// which IE and Edge do not support. However, they still have indexedDB
// defined on the window, so we need to check for them here and make sure
// to return that persistence is not enabled for those browsers.
// For tracking support of this feature, see here:
// https://developer.microsoft.com/en-us/microsoft-edge/platform/status/indexeddbarraysandmultientrysupport/
// Check the UA string to find out the browser.
var ua=(0,_util2.getUA)();// IE 10
// ua = 'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Trident/6.0)';
// IE 11
// ua = 'Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko';
// Edge
// ua = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML,
// like Gecko) Chrome/39.0.2171.71 Safari/537.36 Edge/12.0';
// iOS Safari: Disable for users running iOS version < 10.
var iOSVersion=SimpleDb.getIOSVersion(ua);var isUnsupportedIOS=0<iOSVersion&&iOSVersion<10;// Android browser: Disable for userse running version < 4.5.
var androidVersion=SimpleDb.getAndroidVersion(ua);var isUnsupportedAndroid=0<androidVersion&&androidVersion<4.5;if(ua.indexOf('MSIE ')>0||ua.indexOf('Trident/')>0||ua.indexOf('Edge/')>0||isUnsupportedIOS||isUnsupportedAndroid){return false;}else{return true;}}/**
     * Returns true if the backing IndexedDB store is the Node IndexedDBShim
     * (see https://github.com/axemclion/IndexedDBShim).
     */},{key:"isMockPersistence",value:function isMockPersistence(){var _a;return typeof process!=='undefined'&&((_a=process.env)===null||_a===void 0?void 0:_a.USE_MOCK_PERSISTENCE)==='YES';}/** Helper to get a typed SimpleDbStore from a transaction. */},{key:"getStore",value:function getStore(txn,store){return txn.store(store);}// visible for testing
/** Parse User Agent to determine iOS version. Returns -1 if not found. */},{key:"getIOSVersion",value:function getIOSVersion(ua){var iOSVersionRegex=ua.match(/i(?:phone|pad|pod) os ([\d_]+)/i);var version=iOSVersionRegex?iOSVersionRegex[1].split('_').slice(0,2).join('.'):'-1';return Number(version);}// visible for testing
/** Parse User Agent to determine Android version. Returns -1 if not found. */},{key:"getAndroidVersion",value:function getAndroidVersion(ua){var androidVersionRegex=ua.match(/Android ([\d.]+)/i);var version=androidVersionRegex?androidVersionRegex[1].split('.').slice(0,2).join('.'):'-1';return Number(version);}}]);return SimpleDb;}();/**
 * A controller for iterating over a key range or index. It allows an iterate
 * callback to delete the currently-referenced object, or jump to a new key
 * within the key range or index.
 */var IterationController=/*#__PURE__*/function(){function IterationController(dbCursor){_classCallCheck(this,IterationController);this.dbCursor=dbCursor;this.shouldStop=false;this.nextKey=null;}_createClass(IterationController,[{key:"done",/**
     * This function can be called to stop iteration at any point.
     */value:function done(){this.shouldStop=true;}/**
     * This function can be called to skip to that next key, which could be
     * an index or a primary key.
     */},{key:"skip",value:function skip(key){this.nextKey=key;}/**
     * Delete the current cursor value from the object store.
     *
     * NOTE: You CANNOT do this with a keysOnly query.
     */},{key:"delete",value:function _delete(){return wrapRequest(this.dbCursor["delete"]());}},{key:"isDone",get:function get(){return this.shouldStop;}},{key:"skipToKey",get:function get(){return this.nextKey;}},{key:"cursor",set:function set(value){this.dbCursor=value;}}]);return IterationController;}();/** An error that wraps exceptions that thrown during IndexedDB execution. */var IndexedDbTransactionError=/*#__PURE__*/function(_FirestoreError){_inherits(IndexedDbTransactionError,_FirestoreError);function IndexedDbTransactionError(cause){var _this63;_classCallCheck(this,IndexedDbTransactionError);_this63=_possibleConstructorReturn(this,_getPrototypeOf(IndexedDbTransactionError).call(this,Code.UNAVAILABLE,'IndexedDB transaction failed: '+cause));_this63.name='IndexedDbTransactionError';return _this63;}return IndexedDbTransactionError;}(FirestoreError);/** Verifies whether `e` is an IndexedDbTransactionError. */function isIndexedDbTransactionError(e){// Use name equality, as instanceof checks on errors don't work with errors
// that wrap other errors.
return e.name==='IndexedDbTransactionError';}/**
 * Wraps an IDBTransaction and exposes a store() method to get a handle to a
 * specific object store.
 */var SimpleDbTransaction=/*#__PURE__*/function(){function SimpleDbTransaction(transaction){var _this64=this;_classCallCheck(this,SimpleDbTransaction);this.transaction=transaction;this.aborted=false;/**
         * A promise that resolves with the result of the IndexedDb transaction.
         */this.completionDeferred=new Deferred();this.transaction.oncomplete=function(){_this64.completionDeferred.resolve();};this.transaction.onabort=function(){if(transaction.error){_this64.completionDeferred.reject(new IndexedDbTransactionError(transaction.error));}else{_this64.completionDeferred.resolve();}};this.transaction.onerror=function(event){var error=checkForAndReportiOSError(event.target.error);_this64.completionDeferred.reject(new IndexedDbTransactionError(error));};}_createClass(SimpleDbTransaction,[{key:"abort",value:function abort(error){if(error){this.completionDeferred.reject(error);}if(!this.aborted){logDebug(LOG_TAG$2,'Aborting transaction:',error?error.message:'Client-initiated abort');this.aborted=true;this.transaction.abort();}}/**
     * Returns a SimpleDbStore<KeyType, ValueType> for the specified store. All
     * operations performed on the SimpleDbStore happen within the context of this
     * transaction and it cannot be used anymore once the transaction is
     * completed.
     *
     * Note that we can't actually enforce that the KeyType and ValueType are
     * correct, but they allow type safety through the rest of the consuming code.
     */},{key:"store",value:function store(storeName){var store=this.transaction.objectStore(storeName);return new SimpleDbStore(store);}},{key:"completionPromise",get:function get(){return this.completionDeferred.promise;}}],[{key:"open",value:function open(db,mode,objectStoreNames){try{return new SimpleDbTransaction(db.transaction(objectStoreNames,mode));}catch(e){throw new IndexedDbTransactionError(e);}}}]);return SimpleDbTransaction;}();/**
 * A wrapper around an IDBObjectStore providing an API that:
 *
 * 1) Has generic KeyType / ValueType parameters to provide strongly-typed
 * methods for acting against the object store.
 * 2) Deals with IndexedDB's onsuccess / onerror event callbacks, making every
 * method return a PersistencePromise instead.
 * 3) Provides a higher-level API to avoid needing to do excessive wrapping of
 * intermediate IndexedDB types (IDBCursorWithValue, etc.)
 */var SimpleDbStore=/*#__PURE__*/function(){function SimpleDbStore(store){_classCallCheck(this,SimpleDbStore);this.store=store;}_createClass(SimpleDbStore,[{key:"put",value:function put(keyOrValue,value){var request;if(value!==undefined){logDebug(LOG_TAG$2,'PUT',this.store.name,keyOrValue,value);request=this.store.put(value,keyOrValue);}else{logDebug(LOG_TAG$2,'PUT',this.store.name,'<auto-key>',keyOrValue);request=this.store.put(keyOrValue);}return wrapRequest(request);}/**
     * Adds a new value into an Object Store and returns the new key. Similar to
     * IndexedDb's `add()`, this method will fail on primary key collisions.
     *
     * @param value The object to write.
     * @return The key of the value to add.
     */},{key:"add",value:function add(value){logDebug(LOG_TAG$2,'ADD',this.store.name,value,value);var request=this.store.add(value);return wrapRequest(request);}/**
     * Gets the object with the specified key from the specified store, or null
     * if no object exists with the specified key.
     *
     * @key The key of the object to get.
     * @return The object with the specified key or null if no object exists.
     */},{key:"get",value:function get(key){var _this65=this;var request=this.store.get(key);// We're doing an unsafe cast to ValueType.
// eslint-disable-next-line @typescript-eslint/no-explicit-any
return wrapRequest(request).next(function(result){// Normalize nonexistence to null.
if(result===undefined){result=null;}logDebug(LOG_TAG$2,'GET',_this65.store.name,key,result);return result;});}},{key:"delete",value:function _delete(key){logDebug(LOG_TAG$2,'DELETE',this.store.name,key);var request=this.store["delete"](key);return wrapRequest(request);}/**
     * If we ever need more of the count variants, we can add overloads. For now,
     * all we need is to count everything in a store.
     *
     * Returns the number of rows in the store.
     */},{key:"count",value:function count(){logDebug(LOG_TAG$2,'COUNT',this.store.name);var request=this.store.count();return wrapRequest(request);}},{key:"loadAll",value:function loadAll(indexOrRange,range){var cursor=this.cursor(this.options(indexOrRange,range));var results=[];return this.iterateCursor(cursor,function(key,value){results.push(value);}).next(function(){return results;});}},{key:"deleteAll",value:function deleteAll(indexOrRange,range){logDebug(LOG_TAG$2,'DELETE ALL',this.store.name);var options=this.options(indexOrRange,range);options.keysOnly=false;var cursor=this.cursor(options);return this.iterateCursor(cursor,function(key,value,control){// NOTE: Calling delete() on a cursor is documented as more efficient than
// calling delete() on an object store with a single key
// (https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/delete),
// however, this requires us *not* to use a keysOnly cursor
// (https://developer.mozilla.org/en-US/docs/Web/API/IDBCursor/delete). We
// may want to compare the performance of each method.
return control["delete"]();});}},{key:"iterate",value:function iterate(optionsOrCallback,callback){var options;if(!callback){options={};callback=optionsOrCallback;}else{options=optionsOrCallback;}var cursor=this.cursor(options);return this.iterateCursor(cursor,callback);}/**
     * Iterates over a store, but waits for the given callback to complete for
     * each entry before iterating the next entry. This allows the callback to do
     * asynchronous work to determine if this iteration should continue.
     *
     * The provided callback should return `true` to continue iteration, and
     * `false` otherwise.
     */},{key:"iterateSerial",value:function iterateSerial(callback){var cursorRequest=this.cursor({});return new PersistencePromise(function(resolve,reject){cursorRequest.onerror=function(event){var error=checkForAndReportiOSError(event.target.error);reject(error);};cursorRequest.onsuccess=function(event){var cursor=event.target.result;if(!cursor){resolve();return;}callback(cursor.primaryKey,cursor.value).next(function(shouldContinue){if(shouldContinue){cursor["continue"]();}else{resolve();}});};});}},{key:"iterateCursor",value:function iterateCursor(cursorRequest,fn){var results=[];return new PersistencePromise(function(resolve,reject){cursorRequest.onerror=function(event){reject(event.target.error);};cursorRequest.onsuccess=function(event){var cursor=event.target.result;if(!cursor){resolve();return;}var controller=new IterationController(cursor);var userResult=fn(cursor.primaryKey,cursor.value,controller);if(userResult instanceof PersistencePromise){var userPromise=userResult["catch"](function(err){controller.done();return PersistencePromise.reject(err);});results.push(userPromise);}if(controller.isDone){resolve();}else if(controller.skipToKey===null){cursor["continue"]();}else{cursor["continue"](controller.skipToKey);}};}).next(function(){return PersistencePromise.waitFor(results);});}},{key:"options",value:function options(indexOrRange,range){var indexName=undefined;if(indexOrRange!==undefined){if(typeof indexOrRange==='string'){indexName=indexOrRange;}else{range=indexOrRange;}}return{index:indexName,range:range};}},{key:"cursor",value:function cursor(options){var direction='next';if(options.reverse){direction='prev';}if(options.index){var index=this.store.index(options.index);if(options.keysOnly){return index.openKeyCursor(options.range,direction);}else{return index.openCursor(options.range,direction);}}else{return this.store.openCursor(options.range,direction);}}}]);return SimpleDbStore;}();/**
 * Wraps an IDBRequest in a PersistencePromise, using the onsuccess / onerror
 * handlers to resolve / reject the PersistencePromise as appropriate.
 */function wrapRequest(request){return new PersistencePromise(function(resolve,reject){request.onsuccess=function(event){var result=event.target.result;resolve(result);};request.onerror=function(event){var error=checkForAndReportiOSError(event.target.error);reject(error);};});}// Guard so we only report the error once.
var reportedIOSError=false;function checkForAndReportiOSError(error){var iOSVersion=SimpleDb.getIOSVersion((0,_util2.getUA)());if(iOSVersion>=12.2&&iOSVersion<13){var IOS_ERROR='An internal error was encountered in the Indexed Database server';if(error.message.indexOf(IOS_ERROR)>=0){// Wrap error in a more descriptive one.
var newError=new FirestoreError('internal',"IOS_INDEXEDDB_BUG1: IndexedDb has thrown '".concat(IOS_ERROR,"'. This is likely ")+"due to an unavoidable bug in iOS. See https://stackoverflow.com/q/56496296/110915 "+"for details and a potential workaround.");if(!reportedIOSError){reportedIOSError=true;// Throw a global exception outside of this promise chain, for the user to
// potentially catch.
setTimeout(function(){throw newError;},0);}return newError;}}return error;}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Schema Version for the Web client:
 * 1.  Initial version including Mutation Queue, Query Cache, and Remote
 *     Document Cache
 * 2.  Used to ensure a targetGlobal object exists and add targetCount to it. No
 *     longer required because migration 3 unconditionally clears it.
 * 3.  Dropped and re-created Query Cache to deal with cache corruption related
 *     to limbo resolution. Addresses
 *     https://github.com/firebase/firebase-ios-sdk/issues/1548
 * 4.  Multi-Tab Support.
 * 5.  Removal of held write acks.
 * 6.  Create document global for tracking document cache size.
 * 7.  Ensure every cached document has a sentinel row with a sequence number.
 * 8.  Add collection-parent index for Collection Group queries.
 * 9.  Change RemoteDocumentChanges store to be keyed by readTime rather than
 *     an auto-incrementing ID. This is required for Index-Free queries.
 * 10. Rewrite the canonical IDs to the explicit Protobuf-based format.
 */var SCHEMA_VERSION=10;/** Performs database creation and schema upgrades. */var SchemaConverter=/*#__PURE__*/function(){function SchemaConverter(serializer){_classCallCheck(this,SchemaConverter);this.serializer=serializer;}/**
     * Performs database creation and schema upgrades.
     *
     * Note that in production, this method is only ever used to upgrade the schema
     * to SCHEMA_VERSION. Different values of toVersion are only used for testing
     * and local feature development.
     */_createClass(SchemaConverter,[{key:"createOrUpgrade",value:function createOrUpgrade(db,txn,fromVersion,toVersion){var _this66=this;hardAssert(fromVersion<toVersion&&fromVersion>=0&&toVersion<=SCHEMA_VERSION);var simpleDbTransaction=new SimpleDbTransaction(txn);if(fromVersion<1&&toVersion>=1){createPrimaryClientStore(db);createMutationQueue(db);createQueryCache(db);createRemoteDocumentCache(db);}// Migration 2 to populate the targetGlobal object no longer needed since
// migration 3 unconditionally clears it.
var p=PersistencePromise.resolve();if(fromVersion<3&&toVersion>=3){// Brand new clients don't need to drop and recreate--only clients that
// potentially have corrupt data.
if(fromVersion!==0){dropQueryCache(db);createQueryCache(db);}p=p.next(function(){return writeEmptyTargetGlobalEntry(simpleDbTransaction);});}if(fromVersion<4&&toVersion>=4){if(fromVersion!==0){// Schema version 3 uses auto-generated keys to generate globally unique
// mutation batch IDs (this was previously ensured internally by the
// client). To migrate to the new schema, we have to read all mutations
// and write them back out. We preserve the existing batch IDs to guarantee
// consistency with other object stores. Any further mutation batch IDs will
// be auto-generated.
p=p.next(function(){return upgradeMutationBatchSchemaAndMigrateData(db,simpleDbTransaction);});}p=p.next(function(){createClientMetadataStore(db);});}if(fromVersion<5&&toVersion>=5){p=p.next(function(){return _this66.removeAcknowledgedMutations(simpleDbTransaction);});}if(fromVersion<6&&toVersion>=6){p=p.next(function(){createDocumentGlobalStore(db);return _this66.addDocumentGlobal(simpleDbTransaction);});}if(fromVersion<7&&toVersion>=7){p=p.next(function(){return _this66.ensureSequenceNumbers(simpleDbTransaction);});}if(fromVersion<8&&toVersion>=8){p=p.next(function(){return _this66.createCollectionParentIndex(db,simpleDbTransaction);});}if(fromVersion<9&&toVersion>=9){p=p.next(function(){// Multi-Tab used to manage its own changelog, but this has been moved
// to the DbRemoteDocument object store itself. Since the previous change
// log only contained transient data, we can drop its object store.
dropRemoteDocumentChangesStore(db);createRemoteDocumentReadTimeIndex(txn);});}if(fromVersion<10&&toVersion>=10){p=p.next(function(){return _this66.rewriteCanonicalIds(simpleDbTransaction);});}return p;}},{key:"addDocumentGlobal",value:function addDocumentGlobal(txn){var byteCount=0;return txn.store(DbRemoteDocument.store).iterate(function(_,doc){byteCount+=dbDocumentSize(doc);}).next(function(){var metadata=new DbRemoteDocumentGlobal(byteCount);return txn.store(DbRemoteDocumentGlobal.store).put(DbRemoteDocumentGlobal.key,metadata);});}},{key:"removeAcknowledgedMutations",value:function removeAcknowledgedMutations(txn){var _this67=this;var queuesStore=txn.store(DbMutationQueue.store);var mutationsStore=txn.store(DbMutationBatch.store);return queuesStore.loadAll().next(function(queues){return PersistencePromise.forEach(queues,function(queue){var range=IDBKeyRange.bound([queue.userId,BATCHID_UNKNOWN],[queue.userId,queue.lastAcknowledgedBatchId]);return mutationsStore.loadAll(DbMutationBatch.userMutationsIndex,range).next(function(dbBatches){return PersistencePromise.forEach(dbBatches,function(dbBatch){hardAssert(dbBatch.userId===queue.userId);var batch=fromDbMutationBatch(_this67.serializer,dbBatch);return _removeMutationBatch(txn,queue.userId,batch).next(function(){});});});});});}/**
     * Ensures that every document in the remote document cache has a corresponding sentinel row
     * with a sequence number. Missing rows are given the most recently used sequence number.
     */},{key:"ensureSequenceNumbers",value:function ensureSequenceNumbers(txn){var documentTargetStore=txn.store(DbTargetDocument.store);var documentsStore=txn.store(DbRemoteDocument.store);var globalTargetStore=txn.store(DbTargetGlobal.store);return globalTargetStore.get(DbTargetGlobal.key).next(function(metadata){var writeSentinelKey=function writeSentinelKey(path){return documentTargetStore.put(new DbTargetDocument(0,encodeResourcePath(path),metadata.highestListenSequenceNumber));};var promises=[];return documentsStore.iterate(function(key,doc){var path=new ResourcePath(key);var docSentinelKey=sentinelKey(path);promises.push(documentTargetStore.get(docSentinelKey).next(function(maybeSentinel){if(!maybeSentinel){return writeSentinelKey(path);}else{return PersistencePromise.resolve();}}));}).next(function(){return PersistencePromise.waitFor(promises);});});}},{key:"createCollectionParentIndex",value:function createCollectionParentIndex(db,txn){// Create the index.
db.createObjectStore(DbCollectionParent.store,{keyPath:DbCollectionParent.keyPath});var collectionParentsStore=txn.store(DbCollectionParent.store);// Helper to add an index entry iff we haven't already written it.
var cache=new MemoryCollectionParentIndex();var addEntry=function addEntry(collectionPath){if(cache.add(collectionPath)){var collectionId=collectionPath.lastSegment();var parentPath=collectionPath.popLast();return collectionParentsStore.put({collectionId:collectionId,parent:encodeResourcePath(parentPath)});}};// Index existing remote documents.
return txn.store(DbRemoteDocument.store).iterate({keysOnly:true},function(pathSegments,_){var path=new ResourcePath(pathSegments);return addEntry(path.popLast());}).next(function(){// Index existing mutations.
return txn.store(DbDocumentMutation.store).iterate({keysOnly:true},function(_ref2,_){var _ref3=_slicedToArray(_ref2,3),userID=_ref3[0],encodedPath=_ref3[1],batchId=_ref3[2];var path=decodeResourcePath(encodedPath);return addEntry(path.popLast());});});}},{key:"rewriteCanonicalIds",value:function rewriteCanonicalIds(txn){var _this68=this;var targetStore=txn.store(DbTarget.store);return targetStore.iterate(function(key,originalDbTarget){var originalTargetData=fromDbTarget(originalDbTarget);var updatedDbTarget=toDbTarget(_this68.serializer,originalTargetData);return targetStore.put(updatedDbTarget);});}}]);return SchemaConverter;}();function sentinelKey(path){return[0,encodeResourcePath(path)];}/**
 * Wrapper class to store timestamps (seconds and nanos) in IndexedDb objects.
 */var DbTimestamp=function DbTimestamp(seconds,nanoseconds){_classCallCheck(this,DbTimestamp);this.seconds=seconds;this.nanoseconds=nanoseconds;};/**
 * A singleton object to be stored in the 'owner' store in IndexedDb.
 *
 * A given database can have a single primary tab assigned at a given time. That
 * tab must validate that it is still holding the primary lease before every
 * operation that requires locked access. The primary tab should regularly
 * write an updated timestamp to this lease to prevent other tabs from
 * "stealing" the primary lease
 */var DbPrimaryClient=function DbPrimaryClient(ownerId,/** Whether to allow shared access from multiple tabs. */allowTabSynchronization,leaseTimestampMs){_classCallCheck(this,DbPrimaryClient);this.ownerId=ownerId;this.allowTabSynchronization=allowTabSynchronization;this.leaseTimestampMs=leaseTimestampMs;};/**
 * Name of the IndexedDb object store.
 *
 * Note that the name 'owner' is chosen to ensure backwards compatibility with
 * older clients that only supported single locked access to the persistence
 * layer.
 */DbPrimaryClient.store='owner';/**
 * The key string used for the single object that exists in the
 * DbPrimaryClient store.
 */DbPrimaryClient.key='owner';function createPrimaryClientStore(db){db.createObjectStore(DbPrimaryClient.store);}/**
 * An object to be stored in the 'mutationQueues' store in IndexedDb.
 *
 * Each user gets a single queue of MutationBatches to apply to the server.
 * DbMutationQueue tracks the metadata about the queue.
 */var DbMutationQueue=function DbMutationQueue(/**
     * The normalized user ID to which this queue belongs.
     */userId,/**
     * An identifier for the highest numbered batch that has been acknowledged
     * by the server. All MutationBatches in this queue with batchIds less
     * than or equal to this value are considered to have been acknowledged by
     * the server.
     *
     * NOTE: this is deprecated and no longer used by the code.
     */lastAcknowledgedBatchId,/**
     * A stream token that was previously sent by the server.
     *
     * See StreamingWriteRequest in datastore.proto for more details about
     * usage.
     *
     * After sending this token, earlier tokens may not be used anymore so
     * only a single stream token is retained.
     *
     * NOTE: this is deprecated and no longer used by the code.
     */lastStreamToken){_classCallCheck(this,DbMutationQueue);this.userId=userId;this.lastAcknowledgedBatchId=lastAcknowledgedBatchId;this.lastStreamToken=lastStreamToken;};/** Name of the IndexedDb object store.  */DbMutationQueue.store='mutationQueues';/** Keys are automatically assigned via the userId property. */DbMutationQueue.keyPath='userId';/**
 * An object to be stored in the 'mutations' store in IndexedDb.
 *
 * Represents a batch of user-level mutations intended to be sent to the server
 * in a single write. Each user-level batch gets a separate DbMutationBatch
 * with a new batchId.
 */var DbMutationBatch=function DbMutationBatch(/**
     * The normalized user ID to which this batch belongs.
     */userId,/**
     * An identifier for this batch, allocated using an auto-generated key.
     */batchId,/**
     * The local write time of the batch, stored as milliseconds since the
     * epoch.
     */localWriteTimeMs,/**
     * A list of "mutations" that represent a partial base state from when this
     * write batch was initially created. During local application of the write
     * batch, these baseMutations are applied prior to the real writes in order
     * to override certain document fields from the remote document cache. This
     * is necessary in the case of non-idempotent writes (e.g. `increment()`
     * transforms) to make sure that the local view of the modified documents
     * doesn't flicker if the remote document cache receives the result of the
     * non-idempotent write before the write is removed from the queue.
     *
     * These mutations are never sent to the backend.
     */baseMutations,/**
     * A list of mutations to apply. All mutations will be applied atomically.
     *
     * Mutations are serialized via toMutation().
     */mutations){_classCallCheck(this,DbMutationBatch);this.userId=userId;this.batchId=batchId;this.localWriteTimeMs=localWriteTimeMs;this.baseMutations=baseMutations;this.mutations=mutations;};/** Name of the IndexedDb object store.  */DbMutationBatch.store='mutations';/** Keys are automatically assigned via the userId, batchId properties. */DbMutationBatch.keyPath='batchId';/** The index name for lookup of mutations by user. */DbMutationBatch.userMutationsIndex='userMutationsIndex';/** The user mutations index is keyed by [userId, batchId] pairs. */DbMutationBatch.userMutationsKeyPath=['userId','batchId'];function createMutationQueue(db){db.createObjectStore(DbMutationQueue.store,{keyPath:DbMutationQueue.keyPath});var mutationBatchesStore=db.createObjectStore(DbMutationBatch.store,{keyPath:DbMutationBatch.keyPath,autoIncrement:true});mutationBatchesStore.createIndex(DbMutationBatch.userMutationsIndex,DbMutationBatch.userMutationsKeyPath,{unique:true});db.createObjectStore(DbDocumentMutation.store);}/**
 * Upgrade function to migrate the 'mutations' store from V1 to V3. Loads
 * and rewrites all data.
 */function upgradeMutationBatchSchemaAndMigrateData(db,txn){var v1MutationsStore=txn.store(DbMutationBatch.store);return v1MutationsStore.loadAll().next(function(existingMutations){db.deleteObjectStore(DbMutationBatch.store);var mutationsStore=db.createObjectStore(DbMutationBatch.store,{keyPath:DbMutationBatch.keyPath,autoIncrement:true});mutationsStore.createIndex(DbMutationBatch.userMutationsIndex,DbMutationBatch.userMutationsKeyPath,{unique:true});var v3MutationsStore=txn.store(DbMutationBatch.store);var writeAll=existingMutations.map(function(mutation){return v3MutationsStore.put(mutation);});return PersistencePromise.waitFor(writeAll);});}/**
 * An object to be stored in the 'documentMutations' store in IndexedDb.
 *
 * A manually maintained index of all the mutation batches that affect a given
 * document key. The rows in this table are references based on the contents of
 * DbMutationBatch.mutations.
 */var DbDocumentMutation=/*#__PURE__*/function(){function DbDocumentMutation(){_classCallCheck(this,DbDocumentMutation);}/**
     * Creates a [userId] key for use in the DbDocumentMutations index to iterate
     * over all of a user's document mutations.
     */_createClass(DbDocumentMutation,null,[{key:"prefixForUser",value:function prefixForUser(userId){return[userId];}/**
     * Creates a [userId, encodedPath] key for use in the DbDocumentMutations
     * index to iterate over all at document mutations for a given path or lower.
     */},{key:"prefixForPath",value:function prefixForPath(userId,path){return[userId,encodeResourcePath(path)];}/**
     * Creates a full index key of [userId, encodedPath, batchId] for inserting
     * and deleting into the DbDocumentMutations index.
     */},{key:"key",value:function key(userId,path,batchId){return[userId,encodeResourcePath(path),batchId];}}]);return DbDocumentMutation;}();DbDocumentMutation.store='documentMutations';/**
 * Because we store all the useful information for this store in the key,
 * there is no useful information to store as the value. The raw (unencoded)
 * path cannot be stored because IndexedDb doesn't store prototype
 * information.
 */DbDocumentMutation.PLACEHOLDER=new DbDocumentMutation();function createRemoteDocumentCache(db){db.createObjectStore(DbRemoteDocument.store);}/**
 * Represents the known absence of a document at a particular version.
 * Stored in IndexedDb as part of a DbRemoteDocument object.
 */var DbNoDocument=function DbNoDocument(path,readTime){_classCallCheck(this,DbNoDocument);this.path=path;this.readTime=readTime;};/**
 * Represents a document that is known to exist but whose data is unknown.
 * Stored in IndexedDb as part of a DbRemoteDocument object.
 */var DbUnknownDocument=function DbUnknownDocument(path,version){_classCallCheck(this,DbUnknownDocument);this.path=path;this.version=version;};/**
 * An object to be stored in the 'remoteDocuments' store in IndexedDb.
 * It represents either:
 *
 * - A complete document.
 * - A "no document" representing a document that is known not to exist (at
 * some version).
 * - An "unknown document" representing a document that is known to exist (at
 * some version) but whose contents are unknown.
 *
 * Note: This is the persisted equivalent of a MaybeDocument and could perhaps
 * be made more general if necessary.
 */var DbRemoteDocument=// TODO: We are currently storing full document keys almost three times
// (once as part of the primary key, once - partly - as `parentPath` and once
// inside the encoded documents). During our next migration, we should
// rewrite the primary key as parentPath + document ID which would allow us
// to drop one value.
function DbRemoteDocument(/**
     * Set to an instance of DbUnknownDocument if the data for a document is
     * not known, but it is known that a document exists at the specified
     * version (e.g. it had a successful update applied to it)
     */unknownDocument,/**
     * Set to an instance of a DbNoDocument if it is known that no document
     * exists.
     */noDocument,/**
     * Set to an instance of a Document if there's a cached version of the
     * document.
     */document,/**
     * Documents that were written to the remote document store based on
     * a write acknowledgment are marked with `hasCommittedMutations`. These
     * documents are potentially inconsistent with the backend's copy and use
     * the write's commit version as their document version.
     */hasCommittedMutations,/**
     * When the document was read from the backend. Undefined for data written
     * prior to schema version 9.
     */readTime,/**
     * The path of the collection this document is part of. Undefined for data
     * written prior to schema version 9.
     */parentPath){_classCallCheck(this,DbRemoteDocument);this.unknownDocument=unknownDocument;this.noDocument=noDocument;this.document=document;this.hasCommittedMutations=hasCommittedMutations;this.readTime=readTime;this.parentPath=parentPath;};DbRemoteDocument.store='remoteDocuments';/**
 * An index that provides access to all entries sorted by read time (which
 * corresponds to the last modification time of each row).
 *
 * This index is used to provide a changelog for Multi-Tab.
 */DbRemoteDocument.readTimeIndex='readTimeIndex';DbRemoteDocument.readTimeIndexPath='readTime';/**
 * An index that provides access to documents in a collection sorted by read
 * time.
 *
 * This index is used to allow the RemoteDocumentCache to fetch newly changed
 * documents in a collection.
 */DbRemoteDocument.collectionReadTimeIndex='collectionReadTimeIndex';DbRemoteDocument.collectionReadTimeIndexPath=['parentPath','readTime'];/**
 * Contains a single entry that has metadata about the remote document cache.
 */var DbRemoteDocumentGlobal=/**
     * @param byteSize Approximately the total size in bytes of all the documents in the document
     * cache.
     */function DbRemoteDocumentGlobal(byteSize){_classCallCheck(this,DbRemoteDocumentGlobal);this.byteSize=byteSize;};DbRemoteDocumentGlobal.store='remoteDocumentGlobal';DbRemoteDocumentGlobal.key='remoteDocumentGlobalKey';function createDocumentGlobalStore(db){db.createObjectStore(DbRemoteDocumentGlobal.store);}/**
 * An object to be stored in the 'targets' store in IndexedDb.
 *
 * This is based on and should be kept in sync with the proto used in the iOS
 * client.
 *
 * Each query the client listens to against the server is tracked on disk so
 * that the query can be efficiently resumed on restart.
 */var DbTarget=function DbTarget(/**
     * An auto-generated sequential numeric identifier for the query.
     *
     * Queries are stored using their canonicalId as the key, but these
     * canonicalIds can be quite long so we additionally assign a unique
     * queryId which can be used by referenced data structures (e.g.
     * indexes) to minimize the on-disk cost.
     */targetId,/**
     * The canonical string representing this query. This is not unique.
     */canonicalId,/**
     * The last readTime received from the Watch Service for this query.
     *
     * This is the same value as TargetChange.read_time in the protos.
     */readTime,/**
     * An opaque, server-assigned token that allows watching a query to be
     * resumed after disconnecting without retransmitting all the data
     * that matches the query. The resume token essentially identifies a
     * point in time from which the server should resume sending results.
     *
     * This is related to the snapshotVersion in that the resumeToken
     * effectively also encodes that value, but the resumeToken is opaque
     * and sometimes encodes additional information.
     *
     * A consequence of this is that the resumeToken should be used when
     * asking the server to reason about where this client is in the watch
     * stream, but the client should use the snapshotVersion for its own
     * purposes.
     *
     * This is the same value as TargetChange.resume_token in the protos.
     */resumeToken,/**
     * A sequence number representing the last time this query was
     * listened to, used for garbage collection purposes.
     *
     * Conventionally this would be a timestamp value, but device-local
     * clocks are unreliable and they must be able to create new listens
     * even while disconnected. Instead this should be a monotonically
     * increasing number that's incremented on each listen call.
     *
     * This is different from the queryId since the queryId is an
     * immutable identifier assigned to the Query on first use while
     * lastListenSequenceNumber is updated every time the query is
     * listened to.
     */lastListenSequenceNumber,/**
     * Denotes the maximum snapshot version at which the associated query view
     * contained no limbo documents.  Undefined for data written prior to
     * schema version 9.
     */lastLimboFreeSnapshotVersion,/**
     * The query for this target.
     *
     * Because canonical ids are not unique we must store the actual query. We
     * use the proto to have an object we can persist without having to
     * duplicate translation logic to and from a `Query` object.
     */query){_classCallCheck(this,DbTarget);this.targetId=targetId;this.canonicalId=canonicalId;this.readTime=readTime;this.resumeToken=resumeToken;this.lastListenSequenceNumber=lastListenSequenceNumber;this.lastLimboFreeSnapshotVersion=lastLimboFreeSnapshotVersion;this.query=query;};DbTarget.store='targets';/** Keys are automatically assigned via the targetId property. */DbTarget.keyPath='targetId';/** The name of the queryTargets index. */DbTarget.queryTargetsIndexName='queryTargetsIndex';/**
 * The index of all canonicalIds to the targets that they match. This is not
 * a unique mapping because canonicalId does not promise a unique name for all
 * possible queries, so we append the targetId to make the mapping unique.
 */DbTarget.queryTargetsKeyPath=['canonicalId','targetId'];/**
 * An object representing an association between a target and a document, or a
 * sentinel row marking the last sequence number at which a document was used.
 * Each document cached must have a corresponding sentinel row before lru
 * garbage collection is enabled.
 *
 * The target associations and sentinel rows are co-located so that orphaned
 * documents and their sequence numbers can be identified efficiently via a scan
 * of this store.
 */var DbTargetDocument=function DbTargetDocument(/**
     * The targetId identifying a target or 0 for a sentinel row.
     */targetId,/**
     * The path to the document, as encoded in the key.
     */path,/**
     * If this is a sentinel row, this should be the sequence number of the last
     * time the document specified by `path` was used. Otherwise, it should be
     * `undefined`.
     */sequenceNumber){_classCallCheck(this,DbTargetDocument);this.targetId=targetId;this.path=path;this.sequenceNumber=sequenceNumber;};/** Name of the IndexedDb object store.  */DbTargetDocument.store='targetDocuments';/** Keys are automatically assigned via the targetId, path properties. */DbTargetDocument.keyPath=['targetId','path'];/** The index name for the reverse index. */DbTargetDocument.documentTargetsIndex='documentTargetsIndex';/** We also need to create the reverse index for these properties. */DbTargetDocument.documentTargetsKeyPath=['path','targetId'];/**
 * A record of global state tracked across all Targets, tracked separately
 * to avoid the need for extra indexes.
 *
 * This should be kept in-sync with the proto used in the iOS client.
 */var DbTargetGlobal=function DbTargetGlobal(/**
     * The highest numbered target id across all targets.
     *
     * See DbTarget.targetId.
     */highestTargetId,/**
     * The highest numbered lastListenSequenceNumber across all targets.
     *
     * See DbTarget.lastListenSequenceNumber.
     */highestListenSequenceNumber,/**
     * A global snapshot version representing the last consistent snapshot we
     * received from the backend. This is monotonically increasing and any
     * snapshots received from the backend prior to this version (e.g. for
     * targets resumed with a resumeToken) should be suppressed (buffered)
     * until the backend has caught up to this snapshot version again. This
     * prevents our cache from ever going backwards in time.
     */lastRemoteSnapshotVersion,/**
     * The number of targets persisted.
     */targetCount){_classCallCheck(this,DbTargetGlobal);this.highestTargetId=highestTargetId;this.highestListenSequenceNumber=highestListenSequenceNumber;this.lastRemoteSnapshotVersion=lastRemoteSnapshotVersion;this.targetCount=targetCount;};/**
 * The key string used for the single object that exists in the
 * DbTargetGlobal store.
 */DbTargetGlobal.key='targetGlobalKey';DbTargetGlobal.store='targetGlobal';/**
 * An object representing an association between a Collection id (e.g. 'messages')
 * to a parent path (e.g. '/chats/123') that contains it as a (sub)collection.
 * This is used to efficiently find all collections to query when performing
 * a Collection Group query.
 */var DbCollectionParent=function DbCollectionParent(/**
     * The collectionId (e.g. 'messages')
     */collectionId,/**
     * The path to the parent (either a document location or an empty path for
     * a root-level collection).
     */parent){_classCallCheck(this,DbCollectionParent);this.collectionId=collectionId;this.parent=parent;};/** Name of the IndexedDb object store. */DbCollectionParent.store='collectionParents';/** Keys are automatically assigned via the collectionId, parent properties. */DbCollectionParent.keyPath=['collectionId','parent'];function createQueryCache(db){var targetDocumentsStore=db.createObjectStore(DbTargetDocument.store,{keyPath:DbTargetDocument.keyPath});targetDocumentsStore.createIndex(DbTargetDocument.documentTargetsIndex,DbTargetDocument.documentTargetsKeyPath,{unique:true});var targetStore=db.createObjectStore(DbTarget.store,{keyPath:DbTarget.keyPath});// NOTE: This is unique only because the TargetId is the suffix.
targetStore.createIndex(DbTarget.queryTargetsIndexName,DbTarget.queryTargetsKeyPath,{unique:true});db.createObjectStore(DbTargetGlobal.store);}function dropQueryCache(db){db.deleteObjectStore(DbTargetDocument.store);db.deleteObjectStore(DbTarget.store);db.deleteObjectStore(DbTargetGlobal.store);}function dropRemoteDocumentChangesStore(db){if(db.objectStoreNames.contains('remoteDocumentChanges')){db.deleteObjectStore('remoteDocumentChanges');}}/**
 * Creates the target global singleton row.
 *
 * @param {IDBTransaction} txn The version upgrade transaction for indexeddb
 */function writeEmptyTargetGlobalEntry(txn){var globalStore=txn.store(DbTargetGlobal.store);var metadata=new DbTargetGlobal(/*highestTargetId=*/0,/*lastListenSequenceNumber=*/0,SnapshotVersion.min().toTimestamp(),/*targetCount=*/0);return globalStore.put(DbTargetGlobal.key,metadata);}/**
 * Creates indices on the RemoteDocuments store used for both multi-tab
 * and Index-Free queries.
 */function createRemoteDocumentReadTimeIndex(txn){var remoteDocumentStore=txn.objectStore(DbRemoteDocument.store);remoteDocumentStore.createIndex(DbRemoteDocument.readTimeIndex,DbRemoteDocument.readTimeIndexPath,{unique:false});remoteDocumentStore.createIndex(DbRemoteDocument.collectionReadTimeIndex,DbRemoteDocument.collectionReadTimeIndexPath,{unique:false});}/**
 * A record of the metadata state of each client.
 *
 * PORTING NOTE: This is used to synchronize multi-tab state and does not need
 * to be ported to iOS or Android.
 */var DbClientMetadata=function DbClientMetadata(// Note: Previous schema versions included a field
// "lastProcessedDocumentChangeId". Don't use anymore.
/** The auto-generated client id assigned at client startup. */clientId,/** The last time this state was updated. */updateTimeMs,/** Whether the client's network connection is enabled. */networkEnabled,/** Whether this client is running in a foreground tab. */inForeground){_classCallCheck(this,DbClientMetadata);this.clientId=clientId;this.updateTimeMs=updateTimeMs;this.networkEnabled=networkEnabled;this.inForeground=inForeground;};/** Name of the IndexedDb object store. */DbClientMetadata.store='clientMetadata';/** Keys are automatically assigned via the clientId properties. */DbClientMetadata.keyPath='clientId';function createClientMetadataStore(db){db.createObjectStore(DbClientMetadata.store,{keyPath:DbClientMetadata.keyPath});}// Visible for testing
var V1_STORES=[DbMutationQueue.store,DbMutationBatch.store,DbDocumentMutation.store,DbRemoteDocument.store,DbTarget.store,DbPrimaryClient.store,DbTargetGlobal.store,DbTargetDocument.store];// V2 is no longer usable (see comment at top of file)
// Visible for testing
var V3_STORES=V1_STORES;// Visible for testing
// Note: DbRemoteDocumentChanges is no longer used and dropped with v9.
var V4_STORES=[].concat(V3_STORES,[DbClientMetadata.store]);// V5 does not change the set of stores.
var V6_STORES=[].concat(_toConsumableArray(V4_STORES),[DbRemoteDocumentGlobal.store]);// V7 does not change the set of stores.
var V8_STORES=[].concat(_toConsumableArray(V6_STORES),[DbCollectionParent.store]);// V9 does not change the set of stores.
// V10 does not change the set of stores.
/**
 * The list of all default IndexedDB stores used throughout the SDK. This is
 * used when creating transactions so that access across all stores is done
 * atomically.
 */var ALL_STORES=V8_STORES;/**
 * @license
 * Copyright 2019 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * A persisted implementation of IndexManager.
 */var IndexedDbIndexManager=/*#__PURE__*/function(){function IndexedDbIndexManager(){_classCallCheck(this,IndexedDbIndexManager);/**
         * An in-memory copy of the index entries we've already written since the SDK
         * launched. Used to avoid re-writing the same entry repeatedly.
         *
         * This is *NOT* a complete cache of what's in persistence and so can never be used to
         * satisfy reads.
         */this.collectionParentsCache=new MemoryCollectionParentIndex();}/**
     * Adds a new entry to the collection parent index.
     *
     * Repeated calls for the same collectionPath should be avoided within a
     * transaction as IndexedDbIndexManager only caches writes once a transaction
     * has been committed.
     */_createClass(IndexedDbIndexManager,[{key:"addToCollectionParentIndex",value:function addToCollectionParentIndex(transaction,collectionPath){var _this69=this;if(!this.collectionParentsCache.has(collectionPath)){var collectionId=collectionPath.lastSegment();var parentPath=collectionPath.popLast();transaction.addOnCommittedListener(function(){// Add the collection to the in memory cache only if the transaction was
// successfully committed.
_this69.collectionParentsCache.add(collectionPath);});var collectionParent={collectionId:collectionId,parent:encodeResourcePath(parentPath)};return collectionParentsStore(transaction).put(collectionParent);}return PersistencePromise.resolve();}},{key:"getCollectionParents",value:function getCollectionParents(transaction,collectionId){var parentPaths=[];var range=IDBKeyRange.bound([collectionId,''],[immediateSuccessor(collectionId),''],/*lowerOpen=*/false,/*upperOpen=*/true);return collectionParentsStore(transaction).loadAll(range).next(function(entries){var _iteratorNormalCompletion34=true;var _didIteratorError34=false;var _iteratorError34=undefined;try{for(var _iterator34=entries[Symbol.iterator](),_step34;!(_iteratorNormalCompletion34=(_step34=_iterator34.next()).done);_iteratorNormalCompletion34=true){var entry=_step34.value;// This collectionId guard shouldn't be necessary (and isn't as long
// as we're running in a real browser), but there's a bug in
// indexeddbshim that breaks our range in our tests running in node:
// https://github.com/axemclion/IndexedDBShim/issues/334
if(entry.collectionId!==collectionId){break;}parentPaths.push(decodeResourcePath(entry.parent));}}catch(err){_didIteratorError34=true;_iteratorError34=err;}finally{try{if(!_iteratorNormalCompletion34&&_iterator34["return"]!=null){_iterator34["return"]();}}finally{if(_didIteratorError34){throw _iteratorError34;}}}return parentPaths;});}}]);return IndexedDbIndexManager;}();/**
 * Helper to get a typed SimpleDbStore for the collectionParents
 * document store.
 */function collectionParentsStore(txn){return IndexedDbPersistence.getStore(txn,DbCollectionParent.store);}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /** Offset to ensure non-overlapping target ids. */var OFFSET=2;/**
 * Generates monotonically increasing target IDs for sending targets to the
 * watch stream.
 *
 * The client constructs two generators, one for the target cache, and one for
 * for the sync engine (to generate limbo documents targets). These
 * generators produce non-overlapping IDs (by using even and odd IDs
 * respectively).
 *
 * By separating the target ID space, the query cache can generate target IDs
 * that persist across client restarts, while sync engine can independently
 * generate in-memory target IDs that are transient and can be reused after a
 * restart.
 */var TargetIdGenerator=/*#__PURE__*/function(){function TargetIdGenerator(lastId){_classCallCheck(this,TargetIdGenerator);this.lastId=lastId;}_createClass(TargetIdGenerator,[{key:"next",value:function next(){this.lastId+=OFFSET;return this.lastId;}}],[{key:"forTargetCache",value:function forTargetCache(){// The target cache generator must return '2' in its first call to `next()`
// as there is no differentiation in the protocol layer between an unset
// number and the number '0'. If we were to sent a target with target ID
// '0', the backend would consider it unset and replace it with its own ID.
return new TargetIdGenerator(2-OFFSET);}},{key:"forSyncEngine",value:function forSyncEngine(){// Sync engine assigns target IDs for limbo document detection.
return new TargetIdGenerator(1-OFFSET);}}]);return TargetIdGenerator;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var IndexedDbTargetCache=/*#__PURE__*/function(){function IndexedDbTargetCache(referenceDelegate,serializer){_classCallCheck(this,IndexedDbTargetCache);this.referenceDelegate=referenceDelegate;this.serializer=serializer;}// PORTING NOTE: We don't cache global metadata for the target cache, since
// some of it (in particular `highestTargetId`) can be modified by secondary
// tabs. We could perhaps be more granular (and e.g. still cache
// `lastRemoteSnapshotVersion` in memory) but for simplicity we currently go
// to IndexedDb whenever we need to read metadata. We can revisit if it turns
// out to have a meaningful performance impact.
_createClass(IndexedDbTargetCache,[{key:"allocateTargetId",value:function allocateTargetId(transaction){var _this70=this;return this.retrieveMetadata(transaction).next(function(metadata){var targetIdGenerator=new TargetIdGenerator(metadata.highestTargetId);metadata.highestTargetId=targetIdGenerator.next();return _this70.saveMetadata(transaction,metadata).next(function(){return metadata.highestTargetId;});});}},{key:"getLastRemoteSnapshotVersion",value:function getLastRemoteSnapshotVersion(transaction){return this.retrieveMetadata(transaction).next(function(metadata){return SnapshotVersion.fromTimestamp(new Timestamp(metadata.lastRemoteSnapshotVersion.seconds,metadata.lastRemoteSnapshotVersion.nanoseconds));});}},{key:"getHighestSequenceNumber",value:function getHighestSequenceNumber(transaction){return this.retrieveMetadata(transaction).next(function(targetGlobal){return targetGlobal.highestListenSequenceNumber;});}},{key:"setTargetsMetadata",value:function setTargetsMetadata(transaction,highestListenSequenceNumber,lastRemoteSnapshotVersion){var _this71=this;return this.retrieveMetadata(transaction).next(function(metadata){metadata.highestListenSequenceNumber=highestListenSequenceNumber;if(lastRemoteSnapshotVersion){metadata.lastRemoteSnapshotVersion=lastRemoteSnapshotVersion.toTimestamp();}if(highestListenSequenceNumber>metadata.highestListenSequenceNumber){metadata.highestListenSequenceNumber=highestListenSequenceNumber;}return _this71.saveMetadata(transaction,metadata);});}},{key:"addTargetData",value:function addTargetData(transaction,targetData){var _this72=this;return this.saveTargetData(transaction,targetData).next(function(){return _this72.retrieveMetadata(transaction).next(function(metadata){metadata.targetCount+=1;_this72.updateMetadataFromTargetData(targetData,metadata);return _this72.saveMetadata(transaction,metadata);});});}},{key:"updateTargetData",value:function updateTargetData(transaction,targetData){return this.saveTargetData(transaction,targetData);}},{key:"removeTargetData",value:function removeTargetData(transaction,targetData){var _this73=this;return this.removeMatchingKeysForTargetId(transaction,targetData.targetId).next(function(){return targetsStore(transaction)["delete"](targetData.targetId);}).next(function(){return _this73.retrieveMetadata(transaction);}).next(function(metadata){hardAssert(metadata.targetCount>0);metadata.targetCount-=1;return _this73.saveMetadata(transaction,metadata);});}/**
     * Drops any targets with sequence number less than or equal to the upper bound, excepting those
     * present in `activeTargetIds`. Document associations for the removed targets are also removed.
     * Returns the number of targets removed.
     */},{key:"removeTargets",value:function removeTargets(txn,upperBound,activeTargetIds){var _this74=this;var count=0;var promises=[];return targetsStore(txn).iterate(function(key,value){var targetData=fromDbTarget(value);if(targetData.sequenceNumber<=upperBound&&activeTargetIds.get(targetData.targetId)===null){count++;promises.push(_this74.removeTargetData(txn,targetData));}}).next(function(){return PersistencePromise.waitFor(promises);}).next(function(){return count;});}/**
     * Call provided function with each `TargetData` that we have cached.
     */},{key:"forEachTarget",value:function forEachTarget(txn,f){return targetsStore(txn).iterate(function(key,value){var targetData=fromDbTarget(value);f(targetData);});}},{key:"retrieveMetadata",value:function retrieveMetadata(transaction){return globalTargetStore(transaction).get(DbTargetGlobal.key).next(function(metadata){hardAssert(metadata!==null);return metadata;});}},{key:"saveMetadata",value:function saveMetadata(transaction,metadata){return globalTargetStore(transaction).put(DbTargetGlobal.key,metadata);}},{key:"saveTargetData",value:function saveTargetData(transaction,targetData){return targetsStore(transaction).put(toDbTarget(this.serializer,targetData));}/**
     * In-place updates the provided metadata to account for values in the given
     * TargetData. Saving is done separately. Returns true if there were any
     * changes to the metadata.
     */},{key:"updateMetadataFromTargetData",value:function updateMetadataFromTargetData(targetData,metadata){var updated=false;if(targetData.targetId>metadata.highestTargetId){metadata.highestTargetId=targetData.targetId;updated=true;}if(targetData.sequenceNumber>metadata.highestListenSequenceNumber){metadata.highestListenSequenceNumber=targetData.sequenceNumber;updated=true;}return updated;}},{key:"getTargetCount",value:function getTargetCount(transaction){return this.retrieveMetadata(transaction).next(function(metadata){return metadata.targetCount;});}},{key:"getTargetData",value:function getTargetData(transaction,target){// Iterating by the canonicalId may yield more than one result because
// canonicalId values are not required to be unique per target. This query
// depends on the queryTargets index to be efficient.
var canonicalId=canonifyTarget(target);var range=IDBKeyRange.bound([canonicalId,Number.NEGATIVE_INFINITY],[canonicalId,Number.POSITIVE_INFINITY]);var result=null;return targetsStore(transaction).iterate({range:range,index:DbTarget.queryTargetsIndexName},function(key,value,control){var found=fromDbTarget(value);// After finding a potential match, check that the target is
// actually equal to the requested target.
if(targetEquals(target,found.target)){result=found;control.done();}}).next(function(){return result;});}},{key:"addMatchingKeys",value:function addMatchingKeys(txn,keys,targetId){var _this75=this;// PORTING NOTE: The reverse index (documentsTargets) is maintained by
// IndexedDb.
var promises=[];var store=documentTargetStore(txn);keys.forEach(function(key){var path=encodeResourcePath(key.path);promises.push(store.put(new DbTargetDocument(targetId,path)));promises.push(_this75.referenceDelegate.addReference(txn,targetId,key));});return PersistencePromise.waitFor(promises);}},{key:"removeMatchingKeys",value:function removeMatchingKeys(txn,keys,targetId){var _this76=this;// PORTING NOTE: The reverse index (documentsTargets) is maintained by
// IndexedDb.
var store=documentTargetStore(txn);return PersistencePromise.forEach(keys,function(key){var path=encodeResourcePath(key.path);return PersistencePromise.waitFor([store["delete"]([targetId,path]),_this76.referenceDelegate.removeReference(txn,targetId,key)]);});}},{key:"removeMatchingKeysForTargetId",value:function removeMatchingKeysForTargetId(txn,targetId){var store=documentTargetStore(txn);var range=IDBKeyRange.bound([targetId],[targetId+1],/*lowerOpen=*/false,/*upperOpen=*/true);return store["delete"](range);}},{key:"getMatchingKeysForTargetId",value:function getMatchingKeysForTargetId(txn,targetId){var range=IDBKeyRange.bound([targetId],[targetId+1],/*lowerOpen=*/false,/*upperOpen=*/true);var store=documentTargetStore(txn);var result=documentKeySet();return store.iterate({range:range,keysOnly:true},function(key,_,control){var path=decodeResourcePath(key[1]);var docKey=new DocumentKey(path);result=result.add(docKey);}).next(function(){return result;});}},{key:"containsKey",value:function containsKey(txn,key){var path=encodeResourcePath(key.path);var range=IDBKeyRange.bound([path],[immediateSuccessor(path)],/*lowerOpen=*/false,/*upperOpen=*/true);var count=0;return documentTargetStore(txn).iterate({index:DbTargetDocument.documentTargetsIndex,keysOnly:true,range:range},function(_ref4,_,control){var _ref5=_slicedToArray(_ref4,2),targetId=_ref5[0],path=_ref5[1];// Having a sentinel row for a document does not count as containing that document;
// For the target cache, containing the document means the document is part of some
// target.
if(targetId!==0){count++;control.done();}}).next(function(){return count>0;});}/**
     * Looks up a TargetData entry by target ID.
     *
     * @param targetId The target ID of the TargetData entry to look up.
     * @return The cached TargetData entry, or null if the cache has no entry for
     * the target.
     */ // PORTING NOTE: Multi-tab only.
},{key:"getTargetDataForTarget",value:function getTargetDataForTarget(transaction,targetId){return targetsStore(transaction).get(targetId).next(function(found){if(found){return fromDbTarget(found);}else{return null;}});}}]);return IndexedDbTargetCache;}();/**
 * Helper to get a typed SimpleDbStore for the queries object store.
 */function targetsStore(txn){return IndexedDbPersistence.getStore(txn,DbTarget.store);}/**
 * Helper to get a typed SimpleDbStore for the target globals object store.
 */function globalTargetStore(txn){return IndexedDbPersistence.getStore(txn,DbTargetGlobal.store);}/**
 * Helper to get a typed SimpleDbStore for the document target object store.
 */function documentTargetStore(txn){return IndexedDbPersistence.getStore(txn,DbTargetDocument.store);}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$3='LruGarbageCollector';function bufferEntryComparator(_ref6,_ref7){var _ref8=_slicedToArray(_ref6,2),aSequence=_ref8[0],aIndex=_ref8[1];var _ref9=_slicedToArray(_ref7,2),bSequence=_ref9[0],bIndex=_ref9[1];var seqCmp=primitiveComparator(aSequence,bSequence);if(seqCmp===0){// This order doesn't matter, but we can bias against churn by sorting
// entries created earlier as less than newer entries.
return primitiveComparator(aIndex,bIndex);}else{return seqCmp;}}/**
 * Used to calculate the nth sequence number. Keeps a rolling buffer of the
 * lowest n values passed to `addElement`, and finally reports the largest of
 * them in `maxValue`.
 */var RollingSequenceNumberBuffer=/*#__PURE__*/function(){function RollingSequenceNumberBuffer(maxElements){_classCallCheck(this,RollingSequenceNumberBuffer);this.maxElements=maxElements;this.buffer=new SortedSet(bufferEntryComparator);this.previousIndex=0;}_createClass(RollingSequenceNumberBuffer,[{key:"nextIndex",value:function nextIndex(){return++this.previousIndex;}},{key:"addElement",value:function addElement(sequenceNumber){var entry=[sequenceNumber,this.nextIndex()];if(this.buffer.size<this.maxElements){this.buffer=this.buffer.add(entry);}else{var highestValue=this.buffer.last();if(bufferEntryComparator(entry,highestValue)<0){this.buffer=this.buffer["delete"](highestValue).add(entry);}}}},{key:"maxValue",get:function get(){// Guaranteed to be non-empty. If we decide we are not collecting any
// sequence numbers, nthSequenceNumber below short-circuits. If we have
// decided that we are collecting n sequence numbers, it's because n is some
// percentage of the existing sequence numbers. That means we should never
// be in a situation where we are collecting sequence numbers but don't
// actually have any.
return this.buffer.last()[0];}}]);return RollingSequenceNumberBuffer;}();var GC_DID_NOT_RUN={didRun:false,sequenceNumbersCollected:0,targetsRemoved:0,documentsRemoved:0};var LruParams=/*#__PURE__*/function(){function LruParams(// When we attempt to collect, we will only do so if the cache size is greater than this
// threshold. Passing `COLLECTION_DISABLED` here will cause collection to always be skipped.
cacheSizeCollectionThreshold,// The percentage of sequence numbers that we will attempt to collect
percentileToCollect,// A cap on the total number of sequence numbers that will be collected. This prevents
// us from collecting a huge number of sequence numbers if the cache has grown very large.
maximumSequenceNumbersToCollect){_classCallCheck(this,LruParams);this.cacheSizeCollectionThreshold=cacheSizeCollectionThreshold;this.percentileToCollect=percentileToCollect;this.maximumSequenceNumbersToCollect=maximumSequenceNumbersToCollect;}_createClass(LruParams,null,[{key:"withCacheSize",value:function withCacheSize(cacheSize){return new LruParams(cacheSize,LruParams.DEFAULT_COLLECTION_PERCENTILE,LruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT);}}]);return LruParams;}();LruParams.COLLECTION_DISABLED=-1;LruParams.MINIMUM_CACHE_SIZE_BYTES=1*1024*1024;LruParams.DEFAULT_CACHE_SIZE_BYTES=40*1024*1024;LruParams.DEFAULT_COLLECTION_PERCENTILE=10;LruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT=1000;LruParams.DEFAULT=new LruParams(LruParams.DEFAULT_CACHE_SIZE_BYTES,LruParams.DEFAULT_COLLECTION_PERCENTILE,LruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT);LruParams.DISABLED=new LruParams(LruParams.COLLECTION_DISABLED,0,0);/** How long we wait to try running LRU GC after SDK initialization. */var INITIAL_GC_DELAY_MS=1*60*1000;/** Minimum amount of time between GC checks, after the first one. */var REGULAR_GC_DELAY_MS=5*60*1000;/**
 * This class is responsible for the scheduling of LRU garbage collection. It handles checking
 * whether or not GC is enabled, as well as which delay to use before the next run.
 */var LruScheduler=/*#__PURE__*/function(){function LruScheduler(garbageCollector,asyncQueue){_classCallCheck(this,LruScheduler);this.garbageCollector=garbageCollector;this.asyncQueue=asyncQueue;this.hasRun=false;this.gcTask=null;}_createClass(LruScheduler,[{key:"start",value:function start(localStore){if(this.garbageCollector.params.cacheSizeCollectionThreshold!==LruParams.COLLECTION_DISABLED){this.scheduleGC(localStore);}}},{key:"stop",value:function stop(){if(this.gcTask){this.gcTask.cancel();this.gcTask=null;}}},{key:"scheduleGC",value:function scheduleGC(localStore){var _this77=this;var delay=this.hasRun?REGULAR_GC_DELAY_MS:INITIAL_GC_DELAY_MS;logDebug('LruGarbageCollector',"Garbage collection scheduled in ".concat(delay,"ms"));this.gcTask=this.asyncQueue.enqueueAfterDelay("lru_garbage_collection"/* LruGarbageCollection */,delay,function _callee3(){return regeneratorRuntime.async(function _callee3$(_context7){while(1){switch(_context7.prev=_context7.next){case 0:_this77.gcTask=null;_this77.hasRun=true;_context7.prev=2;_context7.next=5;return regeneratorRuntime.awrap(localStore.collectGarbage(_this77.garbageCollector));case 5:_context7.next=15;break;case 7:_context7.prev=7;_context7.t0=_context7["catch"](2);if(!isIndexedDbTransactionError(_context7.t0)){_context7.next=13;break;}logDebug(LOG_TAG$3,'Ignoring IndexedDB error during garbage collection: ',_context7.t0);_context7.next=15;break;case 13:_context7.next=15;return regeneratorRuntime.awrap(ignoreIfPrimaryLeaseLoss(_context7.t0));case 15:_context7.next=17;return regeneratorRuntime.awrap(_this77.scheduleGC(localStore));case 17:case"end":return _context7.stop();}}},null,null,[[2,7]]);});}},{key:"started",get:function get(){return this.gcTask!==null;}}]);return LruScheduler;}();/** Implements the steps for LRU garbage collection. */var LruGarbageCollector=/*#__PURE__*/function(){function LruGarbageCollector(delegate,params){_classCallCheck(this,LruGarbageCollector);this.delegate=delegate;this.params=params;}/** Given a percentile of target to collect, returns the number of targets to collect. */_createClass(LruGarbageCollector,[{key:"calculateTargetCount",value:function calculateTargetCount(txn,percentile){return this.delegate.getSequenceNumberCount(txn).next(function(targetCount){return Math.floor(percentile/100.0*targetCount);});}/** Returns the nth sequence number, counting in order from the smallest. */},{key:"nthSequenceNumber",value:function nthSequenceNumber(txn,n){var _this78=this;if(n===0){return PersistencePromise.resolve(ListenSequence.INVALID);}var buffer=new RollingSequenceNumberBuffer(n);return this.delegate.forEachTarget(txn,function(target){return buffer.addElement(target.sequenceNumber);}).next(function(){return _this78.delegate.forEachOrphanedDocumentSequenceNumber(txn,function(sequenceNumber){return buffer.addElement(sequenceNumber);});}).next(function(){return buffer.maxValue;});}/**
     * Removes targets with a sequence number equal to or less than the given upper bound, and removes
     * document associations with those targets.
     */},{key:"removeTargets",value:function removeTargets(txn,upperBound,activeTargetIds){return this.delegate.removeTargets(txn,upperBound,activeTargetIds);}/**
     * Removes documents that have a sequence number equal to or less than the upper bound and are not
     * otherwise pinned.
     */},{key:"removeOrphanedDocuments",value:function removeOrphanedDocuments(txn,upperBound){return this.delegate.removeOrphanedDocuments(txn,upperBound);}},{key:"collect",value:function collect(txn,activeTargetIds){var _this79=this;if(this.params.cacheSizeCollectionThreshold===LruParams.COLLECTION_DISABLED){logDebug('LruGarbageCollector','Garbage collection skipped; disabled');return PersistencePromise.resolve(GC_DID_NOT_RUN);}return this.getCacheSize(txn).next(function(cacheSize){if(cacheSize<_this79.params.cacheSizeCollectionThreshold){logDebug('LruGarbageCollector',"Garbage collection skipped; Cache size ".concat(cacheSize," ")+"is lower than threshold ".concat(_this79.params.cacheSizeCollectionThreshold));return GC_DID_NOT_RUN;}else{return _this79.runGarbageCollection(txn,activeTargetIds);}});}},{key:"getCacheSize",value:function getCacheSize(txn){return this.delegate.getCacheSize(txn);}},{key:"runGarbageCollection",value:function runGarbageCollection(txn,activeTargetIds){var _this80=this;var upperBoundSequenceNumber;var sequenceNumbersToCollect,targetsRemoved;// Timestamps for various pieces of the process
var countedTargetsTs,foundUpperBoundTs,removedTargetsTs,removedDocumentsTs;var startTs=Date.now();return this.calculateTargetCount(txn,this.params.percentileToCollect).next(function(sequenceNumbers){// Cap at the configured max
if(sequenceNumbers>_this80.params.maximumSequenceNumbersToCollect){logDebug('LruGarbageCollector','Capping sequence numbers to collect down '+"to the maximum of ".concat(_this80.params.maximumSequenceNumbersToCollect," ")+"from ".concat(sequenceNumbers));sequenceNumbersToCollect=_this80.params.maximumSequenceNumbersToCollect;}else{sequenceNumbersToCollect=sequenceNumbers;}countedTargetsTs=Date.now();return _this80.nthSequenceNumber(txn,sequenceNumbersToCollect);}).next(function(upperBound){upperBoundSequenceNumber=upperBound;foundUpperBoundTs=Date.now();return _this80.removeTargets(txn,upperBoundSequenceNumber,activeTargetIds);}).next(function(numTargetsRemoved){targetsRemoved=numTargetsRemoved;removedTargetsTs=Date.now();return _this80.removeOrphanedDocuments(txn,upperBoundSequenceNumber);}).next(function(documentsRemoved){removedDocumentsTs=Date.now();if(getLogLevel()<=_logger.LogLevel.DEBUG){var desc='LRU Garbage Collection\n'+"\tCounted targets in ".concat(countedTargetsTs-startTs,"ms\n")+"\tDetermined least recently used ".concat(sequenceNumbersToCollect," in ")+"".concat(foundUpperBoundTs-countedTargetsTs,"ms\n")+"\tRemoved ".concat(targetsRemoved," targets in ")+"".concat(removedTargetsTs-foundUpperBoundTs,"ms\n")+"\tRemoved ".concat(documentsRemoved," documents in ")+"".concat(removedDocumentsTs-removedTargetsTs,"ms\n")+"Total Duration: ".concat(removedDocumentsTs-startTs,"ms");logDebug('LruGarbageCollector',desc);}return PersistencePromise.resolve({didRun:true,sequenceNumbersCollected:sequenceNumbersToCollect,targetsRemoved:targetsRemoved,documentsRemoved:documentsRemoved});});}}]);return LruGarbageCollector;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$4='IndexedDbPersistence';/**
 * Oldest acceptable age in milliseconds for client metadata before the client
 * is considered inactive and its associated data is garbage collected.
 */var MAX_CLIENT_AGE_MS=30*60*1000;// 30 minutes
/**
 * Oldest acceptable metadata age for clients that may participate in the
 * primary lease election. Clients that have not updated their client metadata
 * within 5 seconds are not eligible to receive a primary lease.
 */var MAX_PRIMARY_ELIGIBLE_AGE_MS=5000;/**
 * The interval at which clients will update their metadata, including
 * refreshing their primary lease if held or potentially trying to acquire it if
 * not held.
 *
 * Primary clients may opportunistically refresh their metadata earlier
 * if they're already performing an IndexedDB operation.
 */var CLIENT_METADATA_REFRESH_INTERVAL_MS=4000;/** User-facing error when the primary lease is required but not available. */var PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG='Failed to obtain exclusive access to the persistence layer. '+'To allow shared access, make sure to invoke '+'`enablePersistence()` with `synchronizeTabs:true` in all tabs. '+'If you are using `experimentalForceOwningTab:true`, make sure that only '+'one tab has persistence enabled at any given time.';var UNSUPPORTED_PLATFORM_ERROR_MSG='This platform is either missing'+' IndexedDB or is known to have an incomplete implementation. Offline'+' persistence has been disabled.';// The format of the LocalStorage key that stores zombied client is:
//     firestore_zombie_<persistence_prefix>_<instance_key>
var ZOMBIED_CLIENTS_KEY_PREFIX='firestore_zombie';/**
 * The name of the main (and currently only) IndexedDB database. This name is
 * appended to the prefix provided to the IndexedDbPersistence constructor.
 */var MAIN_DATABASE='main';var IndexedDbTransaction=/*#__PURE__*/function(_PersistenceTransacti){_inherits(IndexedDbTransaction,_PersistenceTransacti);function IndexedDbTransaction(simpleDbTransaction,currentSequenceNumber){var _this81;_classCallCheck(this,IndexedDbTransaction);_this81=_possibleConstructorReturn(this,_getPrototypeOf(IndexedDbTransaction).call(this));_this81.simpleDbTransaction=simpleDbTransaction;_this81.currentSequenceNumber=currentSequenceNumber;return _this81;}return IndexedDbTransaction;}(PersistenceTransaction);/**
 * An IndexedDB-backed instance of Persistence. Data is stored persistently
 * across sessions.
 *
 * On Web only, the Firestore SDKs support shared access to its persistence
 * layer. This allows multiple browser tabs to read and write to IndexedDb and
 * to synchronize state even without network connectivity. Shared access is
 * currently optional and not enabled unless all clients invoke
 * `enablePersistence()` with `{synchronizeTabs:true}`.
 *
 * In multi-tab mode, if multiple clients are active at the same time, the SDK
 * will designate one client as the “primary client”. An effort is made to pick
 * a visible, network-connected and active client, and this client is
 * responsible for letting other clients know about its presence. The primary
 * client writes a unique client-generated identifier (the client ID) to
 * IndexedDb’s “owner” store every 4 seconds. If the primary client fails to
 * update this entry, another client can acquire the lease and take over as
 * primary.
 *
 * Some persistence operations in the SDK are designated as primary-client only
 * operations. This includes the acknowledgment of mutations and all updates of
 * remote documents. The effects of these operations are written to persistence
 * and then broadcast to other tabs via LocalStorage (see
 * `WebStorageSharedClientState`), which then refresh their state from
 * persistence.
 *
 * Similarly, the primary client listens to notifications sent by secondary
 * clients to discover persistence changes written by secondary clients, such as
 * the addition of new mutations and query targets.
 *
 * If multi-tab is not enabled and another tab already obtained the primary
 * lease, IndexedDbPersistence enters a failed state and all subsequent
 * operations will automatically fail.
 *
 * Additionally, there is an optimization so that when a tab is closed, the
 * primary lease is released immediately (this is especially important to make
 * sure that a refreshed tab is able to immediately re-acquire the primary
 * lease). Unfortunately, IndexedDB cannot be reliably used in window.unload
 * since it is an asynchronous API. So in addition to attempting to give up the
 * lease, the leaseholder writes its client ID to a "zombiedClient" entry in
 * LocalStorage which acts as an indicator that another tab should go ahead and
 * take the primary lease immediately regardless of the current lease timestamp.
 *
 * TODO(b/114226234): Remove `synchronizeTabs` section when multi-tab is no
 * longer optional.
 */var IndexedDbPersistence=/*#__PURE__*/function(){function IndexedDbPersistence(/**
     * Whether to synchronize the in-memory state of multiple tabs and share
     * access to local persistence.
     */allowTabSynchronization,persistenceKey,clientId,lruParams,queue,window,document,serializer,sequenceNumberSyncer,/**
     * If set to true, forcefully obtains database access. Existing tabs will
     * no longer be able to access IndexedDB.
     */forceOwningTab){_classCallCheck(this,IndexedDbPersistence);this.allowTabSynchronization=allowTabSynchronization;this.persistenceKey=persistenceKey;this.clientId=clientId;this.queue=queue;this.window=window;this.document=document;this.sequenceNumberSyncer=sequenceNumberSyncer;this.forceOwningTab=forceOwningTab;this.listenSequence=null;this._started=false;this.isPrimary=false;this.networkEnabled=true;/** Our window.unload handler, if registered. */this.windowUnloadHandler=null;this.inForeground=false;/** Our 'visibilitychange' listener if registered. */this.documentVisibilityHandler=null;/** The client metadata refresh task. */this.clientMetadataRefresher=null;/** The last time we garbage collected the client metadata object store. */this.lastGarbageCollectionTime=Number.NEGATIVE_INFINITY;/** A listener to notify on primary state changes. */this.primaryStateListener=function(_){return Promise.resolve();};if(!IndexedDbPersistence.isAvailable()){throw new FirestoreError(Code.UNIMPLEMENTED,UNSUPPORTED_PLATFORM_ERROR_MSG);}this.referenceDelegate=new IndexedDbLruDelegate(this,lruParams);this.dbName=persistenceKey+MAIN_DATABASE;this.serializer=new LocalSerializer(serializer);this.simpleDb=new SimpleDb(this.dbName,SCHEMA_VERSION,new SchemaConverter(this.serializer));this.targetCache=new IndexedDbTargetCache(this.referenceDelegate,this.serializer);this.indexManager=new IndexedDbIndexManager();this.remoteDocumentCache=new IndexedDbRemoteDocumentCache(this.serializer,this.indexManager);if(this.window&&this.window.localStorage){this.webStorage=this.window.localStorage;}else{this.webStorage=null;if(forceOwningTab===false){logError(LOG_TAG$4,'LocalStorage is unavailable. As a result, persistence may not work '+'reliably. In particular enablePersistence() could fail immediately '+'after refreshing the page.');}}}_createClass(IndexedDbPersistence,[{key:"start",/**
     * Attempt to start IndexedDb persistence.
     *
     * @return {Promise<void>} Whether persistence was enabled.
     */value:function start(){var _this82=this;// NOTE: This is expected to fail sometimes (in the case of another tab
// already having the persistence lock), so it's the first thing we should
// do.
return this.updateClientMetadataAndTryBecomePrimary().then(function(){if(!_this82.isPrimary&&!_this82.allowTabSynchronization){// Fail `start()` if `synchronizeTabs` is disabled and we cannot
// obtain the primary lease.
throw new FirestoreError(Code.FAILED_PRECONDITION,PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG);}_this82.attachVisibilityHandler();_this82.attachWindowUnloadHook();_this82.scheduleClientMetadataAndPrimaryLeaseRefreshes();return _this82.runTransaction('getHighestListenSequenceNumber','readonly',function(txn){return _this82.targetCache.getHighestSequenceNumber(txn);});}).then(function(highestListenSequenceNumber){_this82.listenSequence=new ListenSequence(highestListenSequenceNumber,_this82.sequenceNumberSyncer);}).then(function(){_this82._started=true;})["catch"](function(reason){_this82.simpleDb&&_this82.simpleDb.close();return Promise.reject(reason);});}/**
     * Registers a listener that gets called when the primary state of the
     * instance changes. Upon registering, this listener is invoked immediately
     * with the current primary state.
     *
     * PORTING NOTE: This is only used for Web multi-tab.
     */},{key:"setPrimaryStateListener",value:function setPrimaryStateListener(primaryStateListener){var _this83=this;this.primaryStateListener=function _callee4(primaryState){return regeneratorRuntime.async(function _callee4$(_context8){while(1){switch(_context8.prev=_context8.next){case 0:if(!_this83.started){_context8.next=2;break;}return _context8.abrupt("return",primaryStateListener(primaryState));case 2:case"end":return _context8.stop();}}});};return primaryStateListener(this.isPrimary);}/**
     * Registers a listener that gets called when the database receives a
     * version change event indicating that it has deleted.
     *
     * PORTING NOTE: This is only used for Web multi-tab.
     */},{key:"setDatabaseDeletedListener",value:function setDatabaseDeletedListener(databaseDeletedListener){this.simpleDb.setVersionChangeListener(function _callee5(event){return regeneratorRuntime.async(function _callee5$(_context9){while(1){switch(_context9.prev=_context9.next){case 0:if(!(event.newVersion===null)){_context9.next=3;break;}_context9.next=3;return regeneratorRuntime.awrap(databaseDeletedListener());case 3:case"end":return _context9.stop();}}});});}/**
     * Adjusts the current network state in the client's metadata, potentially
     * affecting the primary lease.
     *
     * PORTING NOTE: This is only used for Web multi-tab.
     */},{key:"setNetworkEnabled",value:function setNetworkEnabled(networkEnabled){var _this84=this;if(this.networkEnabled!==networkEnabled){this.networkEnabled=networkEnabled;// Schedule a primary lease refresh for immediate execution. The eventual
// lease update will be propagated via `primaryStateListener`.
this.queue.enqueueAndForget(function _callee6(){return regeneratorRuntime.async(function _callee6$(_context10){while(1){switch(_context10.prev=_context10.next){case 0:if(!_this84.started){_context10.next=3;break;}_context10.next=3;return regeneratorRuntime.awrap(_this84.updateClientMetadataAndTryBecomePrimary());case 3:case"end":return _context10.stop();}}});});}}/**
     * Updates the client metadata in IndexedDb and attempts to either obtain or
     * extend the primary lease for the local client. Asynchronously notifies the
     * primary state listener if the client either newly obtained or released its
     * primary lease.
     */},{key:"updateClientMetadataAndTryBecomePrimary",value:function updateClientMetadataAndTryBecomePrimary(){var _this85=this;return this.runTransaction('updateClientMetadataAndTryBecomePrimary','readwrite',function(txn){var metadataStore=clientMetadataStore(txn);return metadataStore.put(new DbClientMetadata(_this85.clientId,Date.now(),_this85.networkEnabled,_this85.inForeground)).next(function(){if(_this85.isPrimary){return _this85.verifyPrimaryLease(txn).next(function(success){if(!success){_this85.isPrimary=false;_this85.queue.enqueueRetryable(function(){return _this85.primaryStateListener(false);});}});}}).next(function(){return _this85.canActAsPrimary(txn);}).next(function(canActAsPrimary){if(_this85.isPrimary&&!canActAsPrimary){return _this85.releasePrimaryLeaseIfHeld(txn).next(function(){return false;});}else if(canActAsPrimary){return _this85.acquireOrExtendPrimaryLease(txn).next(function(){return true;});}else{return(/* canActAsPrimary= */false);}});})["catch"](function(e){if(isIndexedDbTransactionError(e)){logDebug(LOG_TAG$4,'Failed to extend owner lease: ',e);// Proceed with the existing state. Any subsequent access to
// IndexedDB will verify the lease.
return _this85.isPrimary;}if(!_this85.allowTabSynchronization){throw e;}logDebug(LOG_TAG$4,'Releasing owner lease after error during lease refresh',e);return(/* isPrimary= */false);}).then(function(isPrimary){if(_this85.isPrimary!==isPrimary){_this85.queue.enqueueRetryable(function(){return _this85.primaryStateListener(isPrimary);});}_this85.isPrimary=isPrimary;});}},{key:"verifyPrimaryLease",value:function verifyPrimaryLease(txn){var _this86=this;var store=primaryClientStore(txn);return store.get(DbPrimaryClient.key).next(function(primaryClient){return PersistencePromise.resolve(_this86.isLocalClient(primaryClient));});}},{key:"removeClientMetadata",value:function removeClientMetadata(txn){var metadataStore=clientMetadataStore(txn);return metadataStore["delete"](this.clientId);}/**
     * If the garbage collection threshold has passed, prunes the
     * RemoteDocumentChanges and the ClientMetadata store based on the last update
     * time of all clients.
     */},{key:"maybeGarbageCollectMultiClientState",value:function maybeGarbageCollectMultiClientState(){var _this87=this;var inactiveClients,_iteratorNormalCompletion35,_didIteratorError35,_iteratorError35,_iterator35,_step35,inactiveClient;return regeneratorRuntime.async(function maybeGarbageCollectMultiClientState$(_context11){while(1){switch(_context11.prev=_context11.next){case 0:if(!(this.isPrimary&&!this.isWithinAge(this.lastGarbageCollectionTime,MAX_CLIENT_AGE_MS))){_context11.next=25;break;}this.lastGarbageCollectionTime=Date.now();_context11.next=4;return regeneratorRuntime.awrap(this.runTransaction('maybeGarbageCollectMultiClientState','readwrite-primary',function(txn){var metadataStore=IndexedDbPersistence.getStore(txn,DbClientMetadata.store);return metadataStore.loadAll().next(function(existingClients){var active=_this87.filterActiveClients(existingClients,MAX_CLIENT_AGE_MS);var inactive=existingClients.filter(function(client){return active.indexOf(client)===-1;});// Delete metadata for clients that are no longer considered active.
return PersistencePromise.forEach(inactive,function(inactiveClient){return metadataStore["delete"](inactiveClient.clientId);}).next(function(){return inactive;});});})["catch"](function(){// Ignore primary lease violations or any other type of error. The next
// primary will run `maybeGarbageCollectMultiClientState()` again.
// We don't use `ignoreIfPrimaryLeaseLoss()` since we don't want to depend
// on LocalStore.
return[];}));case 4:inactiveClients=_context11.sent;if(!this.webStorage){_context11.next=25;break;}_iteratorNormalCompletion35=true;_didIteratorError35=false;_iteratorError35=undefined;_context11.prev=9;for(_iterator35=inactiveClients[Symbol.iterator]();!(_iteratorNormalCompletion35=(_step35=_iterator35.next()).done);_iteratorNormalCompletion35=true){inactiveClient=_step35.value;this.webStorage.removeItem(this.zombiedClientLocalStorageKey(inactiveClient.clientId));}_context11.next=17;break;case 13:_context11.prev=13;_context11.t0=_context11["catch"](9);_didIteratorError35=true;_iteratorError35=_context11.t0;case 17:_context11.prev=17;_context11.prev=18;if(!_iteratorNormalCompletion35&&_iterator35["return"]!=null){_iterator35["return"]();}case 20:_context11.prev=20;if(!_didIteratorError35){_context11.next=23;break;}throw _iteratorError35;case 23:return _context11.finish(20);case 24:return _context11.finish(17);case 25:case"end":return _context11.stop();}}},null,this,[[9,13,17,25],[18,,20,24]]);}/**
     * Schedules a recurring timer to update the client metadata and to either
     * extend or acquire the primary lease if the client is eligible.
     */},{key:"scheduleClientMetadataAndPrimaryLeaseRefreshes",value:function scheduleClientMetadataAndPrimaryLeaseRefreshes(){var _this88=this;this.clientMetadataRefresher=this.queue.enqueueAfterDelay("client_metadata_refresh"/* ClientMetadataRefresh */,CLIENT_METADATA_REFRESH_INTERVAL_MS,function(){return _this88.updateClientMetadataAndTryBecomePrimary().then(function(){return _this88.maybeGarbageCollectMultiClientState();}).then(function(){return _this88.scheduleClientMetadataAndPrimaryLeaseRefreshes();});});}/** Checks whether `client` is the local client. */},{key:"isLocalClient",value:function isLocalClient(client){return client?client.ownerId===this.clientId:false;}/**
     * Evaluate the state of all active clients and determine whether the local
     * client is or can act as the holder of the primary lease. Returns whether
     * the client is eligible for the lease, but does not actually acquire it.
     * May return 'false' even if there is no active leaseholder and another
     * (foreground) client should become leaseholder instead.
     */},{key:"canActAsPrimary",value:function canActAsPrimary(txn){var _this89=this;if(this.forceOwningTab){return PersistencePromise.resolve(true);}var store=primaryClientStore(txn);return store.get(DbPrimaryClient.key).next(function(currentPrimary){var currentLeaseIsValid=currentPrimary!==null&&_this89.isWithinAge(currentPrimary.leaseTimestampMs,MAX_PRIMARY_ELIGIBLE_AGE_MS)&&!_this89.isClientZombied(currentPrimary.ownerId);// A client is eligible for the primary lease if:
// - its network is enabled and the client's tab is in the foreground.
// - its network is enabled and no other client's tab is in the
//   foreground.
// - every clients network is disabled and the client's tab is in the
//   foreground.
// - every clients network is disabled and no other client's tab is in
//   the foreground.
// - the `forceOwningTab` setting was passed in.
if(currentLeaseIsValid){if(_this89.isLocalClient(currentPrimary)&&_this89.networkEnabled){return true;}if(!_this89.isLocalClient(currentPrimary)){if(!currentPrimary.allowTabSynchronization){// Fail the `canActAsPrimary` check if the current leaseholder has
// not opted into multi-tab synchronization. If this happens at
// client startup, we reject the Promise returned by
// `enablePersistence()` and the user can continue to use Firestore
// with in-memory persistence.
// If this fails during a lease refresh, we will instead block the
// AsyncQueue from executing further operations. Note that this is
// acceptable since mixing & matching different `synchronizeTabs`
// settings is not supported.
//
// TODO(b/114226234): Remove this check when `synchronizeTabs` can
// no longer be turned off.
throw new FirestoreError(Code.FAILED_PRECONDITION,PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG);}return false;}}if(_this89.networkEnabled&&_this89.inForeground){return true;}return clientMetadataStore(txn).loadAll().next(function(existingClients){// Process all existing clients and determine whether at least one of
// them is better suited to obtain the primary lease.
var preferredCandidate=_this89.filterActiveClients(existingClients,MAX_PRIMARY_ELIGIBLE_AGE_MS).find(function(otherClient){if(_this89.clientId!==otherClient.clientId){var otherClientHasBetterNetworkState=!_this89.networkEnabled&&otherClient.networkEnabled;var otherClientHasBetterVisibility=!_this89.inForeground&&otherClient.inForeground;var otherClientHasSameNetworkState=_this89.networkEnabled===otherClient.networkEnabled;if(otherClientHasBetterNetworkState||otherClientHasBetterVisibility&&otherClientHasSameNetworkState){return true;}}return false;});return preferredCandidate===undefined;});}).next(function(canActAsPrimary){if(_this89.isPrimary!==canActAsPrimary){logDebug(LOG_TAG$4,"Client ".concat(canActAsPrimary?'is':'is not'," eligible for a primary lease."));}return canActAsPrimary;});}},{key:"shutdown",value:function shutdown(){var _this90=this;return regeneratorRuntime.async(function shutdown$(_context12){while(1){switch(_context12.prev=_context12.next){case 0:// The shutdown() operations are idempotent and can be called even when
// start() aborted (e.g. because it couldn't acquire the persistence lease).
this._started=false;this.markClientZombied();if(this.clientMetadataRefresher){this.clientMetadataRefresher.cancel();this.clientMetadataRefresher=null;}this.detachVisibilityHandler();this.detachWindowUnloadHook();// Use `SimpleDb.runTransaction` directly to avoid failing if another tab
// has obtained the primary lease.
_context12.next=7;return regeneratorRuntime.awrap(this.simpleDb.runTransaction('readwrite',[DbPrimaryClient.store,DbClientMetadata.store],function(simpleDbTxn){var persistenceTransaction=new IndexedDbTransaction(simpleDbTxn,ListenSequence.INVALID);return _this90.releasePrimaryLeaseIfHeld(persistenceTransaction).next(function(){return _this90.removeClientMetadata(persistenceTransaction);});}));case 7:this.simpleDb.close();// Remove the entry marking the client as zombied from LocalStorage since
// we successfully deleted its metadata from IndexedDb.
this.removeClientZombiedEntry();case 9:case"end":return _context12.stop();}}},null,this);}/**
     * Returns clients that are not zombied and have an updateTime within the
     * provided threshold.
     */},{key:"filterActiveClients",value:function filterActiveClients(clients,activityThresholdMs){var _this91=this;return clients.filter(function(client){return _this91.isWithinAge(client.updateTimeMs,activityThresholdMs)&&!_this91.isClientZombied(client.clientId);});}/**
     * Returns the IDs of the clients that are currently active. If multi-tab
     * is not supported, returns an array that only contains the local client's
     * ID.
     *
     * PORTING NOTE: This is only used for Web multi-tab.
     */},{key:"getActiveClients",value:function getActiveClients(){var _this92=this;return this.runTransaction('getActiveClients','readonly',function(txn){return clientMetadataStore(txn).loadAll().next(function(clients){return _this92.filterActiveClients(clients,MAX_CLIENT_AGE_MS).map(function(clientMetadata){return clientMetadata.clientId;});});});}},{key:"getMutationQueue",value:function getMutationQueue(user){return IndexedDbMutationQueue.forUser(user,this.serializer,this.indexManager,this.referenceDelegate);}},{key:"getTargetCache",value:function getTargetCache(){return this.targetCache;}},{key:"getRemoteDocumentCache",value:function getRemoteDocumentCache(){return this.remoteDocumentCache;}},{key:"getIndexManager",value:function getIndexManager(){return this.indexManager;}},{key:"runTransaction",value:function runTransaction(action,mode,transactionOperation){var _this93=this;logDebug(LOG_TAG$4,'Starting transaction:',action);var simpleDbMode=mode==='readonly'?'readonly':'readwrite';var persistenceTransaction;// Do all transactions as readwrite against all object stores, since we
// are the only reader/writer.
return this.simpleDb.runTransaction(simpleDbMode,ALL_STORES,function(simpleDbTxn){persistenceTransaction=new IndexedDbTransaction(simpleDbTxn,_this93.listenSequence?_this93.listenSequence.next():ListenSequence.INVALID);if(mode==='readwrite-primary'){// While we merely verify that we have (or can acquire) the lease
// immediately, we wait to extend the primary lease until after
// executing transactionOperation(). This ensures that even if the
// transactionOperation takes a long time, we'll use a recent
// leaseTimestampMs in the extended (or newly acquired) lease.
return _this93.verifyPrimaryLease(persistenceTransaction).next(function(holdsPrimaryLease){if(holdsPrimaryLease){return(/* holdsPrimaryLease= */true);}return _this93.canActAsPrimary(persistenceTransaction);}).next(function(holdsPrimaryLease){if(!holdsPrimaryLease){logError("Failed to obtain primary lease for action '".concat(action,"'."));_this93.isPrimary=false;_this93.queue.enqueueRetryable(function(){return _this93.primaryStateListener(false);});throw new FirestoreError(Code.FAILED_PRECONDITION,PRIMARY_LEASE_LOST_ERROR_MSG);}return transactionOperation(persistenceTransaction);}).next(function(result){return _this93.acquireOrExtendPrimaryLease(persistenceTransaction).next(function(){return result;});});}else{return _this93.verifyAllowTabSynchronization(persistenceTransaction).next(function(){return transactionOperation(persistenceTransaction);});}}).then(function(result){persistenceTransaction.raiseOnCommittedEvent();return result;});}/**
     * Verifies that the current tab is the primary leaseholder or alternatively
     * that the leaseholder has opted into multi-tab synchronization.
     */ // TODO(b/114226234): Remove this check when `synchronizeTabs` can no longer
// be turned off.
},{key:"verifyAllowTabSynchronization",value:function verifyAllowTabSynchronization(txn){var _this94=this;var store=primaryClientStore(txn);return store.get(DbPrimaryClient.key).next(function(currentPrimary){var currentLeaseIsValid=currentPrimary!==null&&_this94.isWithinAge(currentPrimary.leaseTimestampMs,MAX_PRIMARY_ELIGIBLE_AGE_MS)&&!_this94.isClientZombied(currentPrimary.ownerId);if(currentLeaseIsValid&&!_this94.isLocalClient(currentPrimary)){if(!_this94.forceOwningTab&&(!_this94.allowTabSynchronization||!currentPrimary.allowTabSynchronization)){throw new FirestoreError(Code.FAILED_PRECONDITION,PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG);}}});}/**
     * Obtains or extends the new primary lease for the local client. This
     * method does not verify that the client is eligible for this lease.
     */},{key:"acquireOrExtendPrimaryLease",value:function acquireOrExtendPrimaryLease(txn){var newPrimary=new DbPrimaryClient(this.clientId,this.allowTabSynchronization,Date.now());return primaryClientStore(txn).put(DbPrimaryClient.key,newPrimary);}},{key:"releasePrimaryLeaseIfHeld",/** Checks the primary lease and removes it if we are the current primary. */value:function releasePrimaryLeaseIfHeld(txn){var _this95=this;var store=primaryClientStore(txn);return store.get(DbPrimaryClient.key).next(function(primaryClient){if(_this95.isLocalClient(primaryClient)){logDebug(LOG_TAG$4,'Releasing primary lease.');return store["delete"](DbPrimaryClient.key);}else{return PersistencePromise.resolve();}});}/** Verifies that `updateTimeMs` is within `maxAgeMs`. */},{key:"isWithinAge",value:function isWithinAge(updateTimeMs,maxAgeMs){var now=Date.now();var minAcceptable=now-maxAgeMs;var maxAcceptable=now;if(updateTimeMs<minAcceptable){return false;}else if(updateTimeMs>maxAcceptable){logError("Detected an update time that is in the future: ".concat(updateTimeMs," > ").concat(maxAcceptable));return false;}return true;}},{key:"attachVisibilityHandler",value:function attachVisibilityHandler(){var _this96=this;if(this.document!==null&&typeof this.document.addEventListener==='function'){this.documentVisibilityHandler=function(){_this96.queue.enqueueAndForget(function(){_this96.inForeground=_this96.document.visibilityState==='visible';return _this96.updateClientMetadataAndTryBecomePrimary();});};this.document.addEventListener('visibilitychange',this.documentVisibilityHandler);this.inForeground=this.document.visibilityState==='visible';}}},{key:"detachVisibilityHandler",value:function detachVisibilityHandler(){if(this.documentVisibilityHandler){this.document.removeEventListener('visibilitychange',this.documentVisibilityHandler);this.documentVisibilityHandler=null;}}/**
     * Attaches a window.unload handler that will synchronously write our
     * clientId to a "zombie client id" location in LocalStorage. This can be used
     * by tabs trying to acquire the primary lease to determine that the lease
     * is no longer valid even if the timestamp is recent. This is particularly
     * important for the refresh case (so the tab correctly re-acquires the
     * primary lease). LocalStorage is used for this rather than IndexedDb because
     * it is a synchronous API and so can be used reliably from  an unload
     * handler.
     */},{key:"attachWindowUnloadHook",value:function attachWindowUnloadHook(){var _this97=this;var _a;if(typeof((_a=this.window)===null||_a===void 0?void 0:_a.addEventListener)==='function'){this.windowUnloadHandler=function(){// Note: In theory, this should be scheduled on the AsyncQueue since it
// accesses internal state. We execute this code directly during shutdown
// to make sure it gets a chance to run.
_this97.markClientZombied();_this97.queue.enqueueAndForget(function(){// Attempt graceful shutdown (including releasing our primary lease),
// but there's no guarantee it will complete.
return _this97.shutdown();});};this.window.addEventListener('unload',this.windowUnloadHandler);}}},{key:"detachWindowUnloadHook",value:function detachWindowUnloadHook(){if(this.windowUnloadHandler){this.window.removeEventListener('unload',this.windowUnloadHandler);this.windowUnloadHandler=null;}}/**
     * Returns whether a client is "zombied" based on its LocalStorage entry.
     * Clients become zombied when their tab closes without running all of the
     * cleanup logic in `shutdown()`.
     */},{key:"isClientZombied",value:function isClientZombied(clientId){var _a;try{var isZombied=((_a=this.webStorage)===null||_a===void 0?void 0:_a.getItem(this.zombiedClientLocalStorageKey(clientId)))!==null;logDebug(LOG_TAG$4,"Client '".concat(clientId,"' ").concat(isZombied?'is':'is not'," zombied in LocalStorage"));return isZombied;}catch(e){// Gracefully handle if LocalStorage isn't working.
logError(LOG_TAG$4,'Failed to get zombied client id.',e);return false;}}/**
     * Record client as zombied (a client that had its tab closed). Zombied
     * clients are ignored during primary tab selection.
     */},{key:"markClientZombied",value:function markClientZombied(){if(!this.webStorage){return;}try{this.webStorage.setItem(this.zombiedClientLocalStorageKey(this.clientId),String(Date.now()));}catch(e){// Gracefully handle if LocalStorage isn't available / working.
logError('Failed to set zombie client id.',e);}}/** Removes the zombied client entry if it exists. */},{key:"removeClientZombiedEntry",value:function removeClientZombiedEntry(){if(!this.webStorage){return;}try{this.webStorage.removeItem(this.zombiedClientLocalStorageKey(this.clientId));}catch(e){// Ignore
}}},{key:"zombiedClientLocalStorageKey",value:function zombiedClientLocalStorageKey(clientId){return"".concat(ZOMBIED_CLIENTS_KEY_PREFIX,"_").concat(this.persistenceKey,"_").concat(clientId);}},{key:"started",get:function get(){return this._started;}}],[{key:"getStore",value:function getStore(txn,store){if(txn instanceof IndexedDbTransaction){return SimpleDb.getStore(txn.simpleDbTransaction,store);}else{throw fail();}}},{key:"isAvailable",value:function isAvailable(){return SimpleDb.isAvailable();}}]);return IndexedDbPersistence;}();/**
 * Helper to get a typed SimpleDbStore for the primary client object store.
 */function primaryClientStore(txn){return IndexedDbPersistence.getStore(txn,DbPrimaryClient.store);}/**
 * Helper to get a typed SimpleDbStore for the client metadata object store.
 */function clientMetadataStore(txn){return IndexedDbPersistence.getStore(txn,DbClientMetadata.store);}/** Provides LRU functionality for IndexedDB persistence. */var IndexedDbLruDelegate=/*#__PURE__*/function(){function IndexedDbLruDelegate(db,params){_classCallCheck(this,IndexedDbLruDelegate);this.db=db;this.garbageCollector=new LruGarbageCollector(this,params);}_createClass(IndexedDbLruDelegate,[{key:"getSequenceNumberCount",value:function getSequenceNumberCount(txn){var docCountPromise=this.orphanedDocumentCount(txn);var targetCountPromise=this.db.getTargetCache().getTargetCount(txn);return targetCountPromise.next(function(targetCount){return docCountPromise.next(function(docCount){return targetCount+docCount;});});}},{key:"orphanedDocumentCount",value:function orphanedDocumentCount(txn){var orphanedCount=0;return this.forEachOrphanedDocumentSequenceNumber(txn,function(_){orphanedCount++;}).next(function(){return orphanedCount;});}},{key:"forEachTarget",value:function forEachTarget(txn,f){return this.db.getTargetCache().forEachTarget(txn,f);}},{key:"forEachOrphanedDocumentSequenceNumber",value:function forEachOrphanedDocumentSequenceNumber(txn,f){return this.forEachOrphanedDocument(txn,function(docKey,sequenceNumber){return f(sequenceNumber);});}},{key:"addReference",value:function addReference(txn,targetId,key){return writeSentinelKey(txn,key);}},{key:"removeReference",value:function removeReference(txn,targetId,key){return writeSentinelKey(txn,key);}},{key:"removeTargets",value:function removeTargets(txn,upperBound,activeTargetIds){return this.db.getTargetCache().removeTargets(txn,upperBound,activeTargetIds);}},{key:"markPotentiallyOrphaned",value:function markPotentiallyOrphaned(txn,key){return writeSentinelKey(txn,key);}/**
     * Returns true if anything would prevent this document from being garbage
     * collected, given that the document in question is not present in any
     * targets and has a sequence number less than or equal to the upper bound for
     * the collection run.
     */},{key:"isPinned",value:function isPinned(txn,docKey){return mutationQueuesContainKey(txn,docKey);}},{key:"removeOrphanedDocuments",value:function removeOrphanedDocuments(txn,upperBound){var _this98=this;var documentCache=this.db.getRemoteDocumentCache();var changeBuffer=documentCache.newChangeBuffer();var promises=[];var documentCount=0;var iteration=this.forEachOrphanedDocument(txn,function(docKey,sequenceNumber){if(sequenceNumber<=upperBound){var p=_this98.isPinned(txn,docKey).next(function(isPinned){if(!isPinned){documentCount++;// Our size accounting requires us to read all documents before
// removing them.
return changeBuffer.getEntry(txn,docKey).next(function(){changeBuffer.removeEntry(docKey);return documentTargetStore(txn)["delete"](sentinelKey$1(docKey));});}});promises.push(p);}});return iteration.next(function(){return PersistencePromise.waitFor(promises);}).next(function(){return changeBuffer.apply(txn);}).next(function(){return documentCount;});}},{key:"removeTarget",value:function removeTarget(txn,targetData){var updated=targetData.withSequenceNumber(txn.currentSequenceNumber);return this.db.getTargetCache().updateTargetData(txn,updated);}},{key:"updateLimboDocument",value:function updateLimboDocument(txn,key){return writeSentinelKey(txn,key);}/**
     * Call provided function for each document in the cache that is 'orphaned'. Orphaned
     * means not a part of any target, so the only entry in the target-document index for
     * that document will be the sentinel row (targetId 0), which will also have the sequence
     * number for the last time the document was accessed.
     */},{key:"forEachOrphanedDocument",value:function forEachOrphanedDocument(txn,f){var store=documentTargetStore(txn);var nextToReport=ListenSequence.INVALID;var nextPath;return store.iterate({index:DbTargetDocument.documentTargetsIndex},function(_ref10,_ref11){var _ref12=_slicedToArray(_ref10,2),targetId=_ref12[0],docKey=_ref12[1];var path=_ref11.path,sequenceNumber=_ref11.sequenceNumber;if(targetId===0){// if nextToReport is valid, report it, this is a new key so the
// last one must not be a member of any targets.
if(nextToReport!==ListenSequence.INVALID){f(new DocumentKey(decodeResourcePath(nextPath)),nextToReport);}// set nextToReport to be this sequence number. It's the next one we
// might report, if we don't find any targets for this document.
// Note that the sequence number must be defined when the targetId
// is 0.
nextToReport=sequenceNumber;nextPath=path;}else{// set nextToReport to be invalid, we know we don't need to report
// this one since we found a target for it.
nextToReport=ListenSequence.INVALID;}}).next(function(){// Since we report sequence numbers after getting to the next key, we
// need to check if the last key we iterated over was an orphaned
// document and report it.
if(nextToReport!==ListenSequence.INVALID){f(new DocumentKey(decodeResourcePath(nextPath)),nextToReport);}});}},{key:"getCacheSize",value:function getCacheSize(txn){return this.db.getRemoteDocumentCache().getSize(txn);}}]);return IndexedDbLruDelegate;}();function sentinelKey$1(key){return[0,encodeResourcePath(key.path)];}/**
 * @return A value suitable for writing a sentinel row in the target-document
 * store.
 */function sentinelRow(key,sequenceNumber){return new DbTargetDocument(0,encodeResourcePath(key.path),sequenceNumber);}function writeSentinelKey(txn,key){return documentTargetStore(txn).put(sentinelRow(key,txn.currentSequenceNumber));}/**
 * Generates a string used as a prefix when storing data in IndexedDB and
 * LocalStorage.
 */function indexedDbStoragePrefix(databaseId,persistenceKey){// Use two different prefix formats:
//
//   * firestore / persistenceKey / projectID . databaseID / ...
//   * firestore / persistenceKey / projectID / ...
//
// projectIDs are DNS-compatible names and cannot contain dots
// so there's no danger of collisions.
var database=databaseId.projectId;if(!databaseId.isDefaultDatabase){database+='.'+databaseId.database;}return'firestore/'+persistenceKey+'/'+database+'/';}function indexedDbClearPersistence(persistenceKey){var dbName;return regeneratorRuntime.async(function indexedDbClearPersistence$(_context13){while(1){switch(_context13.prev=_context13.next){case 0:if(SimpleDb.isAvailable()){_context13.next=2;break;}return _context13.abrupt("return",Promise.resolve());case 2:dbName=persistenceKey+MAIN_DATABASE;_context13.next=5;return regeneratorRuntime.awrap(SimpleDb["delete"](dbName));case 5:case"end":return _context13.stop();}}});}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$5='LocalStore';/**
 * The maximum time to leave a resume token buffered without writing it out.
 * This value is arbitrary: it's long enough to avoid several writes
 * (possibly indefinitely if updates come more frequently than this) but
 * short enough that restarting after crashing will still have a pretty
 * recent resume token.
 */var RESUME_TOKEN_MAX_AGE_MICROS=5*60*1e6;/**
 * Implements `LocalStore` interface.
 *
 * Note: some field defined in this class might have public access level, but
 * the class is not exported so they are only accessible from this module.
 * This is useful to implement optional features (like bundles) in free
 * functions, such that they are tree-shakeable.
 */var LocalStoreImpl=/*#__PURE__*/function(){function LocalStoreImpl(/** Manages our in-memory or durable persistence. */persistence,queryEngine,initialUser){_classCallCheck(this,LocalStoreImpl);this.persistence=persistence;this.queryEngine=queryEngine;/**
         * Maps a targetID to data about its target.
         *
         * PORTING NOTE: We are using an immutable data structure on Web to make re-runs
         * of `applyRemoteEvent()` idempotent.
         */this.targetDataByTarget=new SortedMap(primitiveComparator);/** Maps a target to its targetID. */ // TODO(wuandy): Evaluate if TargetId can be part of Target.
this.targetIdByTarget=new ObjectMap(function(t){return canonifyTarget(t);},targetEquals);/**
         * The read time of the last entry processed by `getNewDocumentChanges()`.
         *
         * PORTING NOTE: This is only used for multi-tab synchronization.
         */this.lastDocumentChangeReadTime=SnapshotVersion.min();this.mutationQueue=persistence.getMutationQueue(initialUser);this.remoteDocuments=persistence.getRemoteDocumentCache();this.targetCache=persistence.getTargetCache();this.localDocuments=new LocalDocumentsView(this.remoteDocuments,this.mutationQueue,this.persistence.getIndexManager());this.queryEngine.setLocalDocumentsView(this.localDocuments);}_createClass(LocalStoreImpl,[{key:"collectGarbage",value:function collectGarbage(garbageCollector){var _this99=this;return this.persistence.runTransaction('Collect garbage','readwrite-primary',function(txn){return garbageCollector.collect(txn,_this99.targetDataByTarget);});}}]);return LocalStoreImpl;}();function newLocalStore(/** Manages our in-memory or durable persistence. */persistence,queryEngine,initialUser){return new LocalStoreImpl(persistence,queryEngine,initialUser);}/**
 * Tells the LocalStore that the currently authenticated user has changed.
 *
 * In response the local store switches the mutation queue to the new user and
 * returns any resulting document changes.
 */ // PORTING NOTE: Android and iOS only return the documents affected by the
// change.
function handleUserChange(localStore,user){var localStoreImpl,newMutationQueue,newLocalDocuments,result;return regeneratorRuntime.async(function handleUserChange$(_context14){while(1){switch(_context14.prev=_context14.next){case 0:localStoreImpl=debugCast(localStore);newMutationQueue=localStoreImpl.mutationQueue;newLocalDocuments=localStoreImpl.localDocuments;_context14.next=5;return regeneratorRuntime.awrap(localStoreImpl.persistence.runTransaction('Handle user change','readonly',function(txn){// Swap out the mutation queue, grabbing the pending mutation batches
// before and after.
var oldBatches;return localStoreImpl.mutationQueue.getAllMutationBatches(txn).next(function(promisedOldBatches){oldBatches=promisedOldBatches;newMutationQueue=localStoreImpl.persistence.getMutationQueue(user);// Recreate our LocalDocumentsView using the new
// MutationQueue.
newLocalDocuments=new LocalDocumentsView(localStoreImpl.remoteDocuments,newMutationQueue,localStoreImpl.persistence.getIndexManager());return newMutationQueue.getAllMutationBatches(txn);}).next(function(newBatches){var removedBatchIds=[];var addedBatchIds=[];// Union the old/new changed keys.
var changedKeys=documentKeySet();var _iteratorNormalCompletion36=true;var _didIteratorError36=false;var _iteratorError36=undefined;try{for(var _iterator36=oldBatches[Symbol.iterator](),_step36;!(_iteratorNormalCompletion36=(_step36=_iterator36.next()).done);_iteratorNormalCompletion36=true){var batch=_step36.value;removedBatchIds.push(batch.batchId);var _iteratorNormalCompletion38=true;var _didIteratorError38=false;var _iteratorError38=undefined;try{for(var _iterator38=batch.mutations[Symbol.iterator](),_step38;!(_iteratorNormalCompletion38=(_step38=_iterator38.next()).done);_iteratorNormalCompletion38=true){var mutation=_step38.value;changedKeys=changedKeys.add(mutation.key);}}catch(err){_didIteratorError38=true;_iteratorError38=err;}finally{try{if(!_iteratorNormalCompletion38&&_iterator38["return"]!=null){_iterator38["return"]();}}finally{if(_didIteratorError38){throw _iteratorError38;}}}}}catch(err){_didIteratorError36=true;_iteratorError36=err;}finally{try{if(!_iteratorNormalCompletion36&&_iterator36["return"]!=null){_iterator36["return"]();}}finally{if(_didIteratorError36){throw _iteratorError36;}}}var _iteratorNormalCompletion37=true;var _didIteratorError37=false;var _iteratorError37=undefined;try{for(var _iterator37=newBatches[Symbol.iterator](),_step37;!(_iteratorNormalCompletion37=(_step37=_iterator37.next()).done);_iteratorNormalCompletion37=true){var _batch=_step37.value;addedBatchIds.push(_batch.batchId);var _iteratorNormalCompletion39=true;var _didIteratorError39=false;var _iteratorError39=undefined;try{for(var _iterator39=_batch.mutations[Symbol.iterator](),_step39;!(_iteratorNormalCompletion39=(_step39=_iterator39.next()).done);_iteratorNormalCompletion39=true){var _mutation2=_step39.value;changedKeys=changedKeys.add(_mutation2.key);}}catch(err){_didIteratorError39=true;_iteratorError39=err;}finally{try{if(!_iteratorNormalCompletion39&&_iterator39["return"]!=null){_iterator39["return"]();}}finally{if(_didIteratorError39){throw _iteratorError39;}}}}// Return the set of all (potentially) changed documents and the list
// of mutation batch IDs that were affected by change.
}catch(err){_didIteratorError37=true;_iteratorError37=err;}finally{try{if(!_iteratorNormalCompletion37&&_iterator37["return"]!=null){_iterator37["return"]();}}finally{if(_didIteratorError37){throw _iteratorError37;}}}return newLocalDocuments.getDocuments(txn,changedKeys).next(function(affectedDocuments){return{affectedDocuments:affectedDocuments,removedBatchIds:removedBatchIds,addedBatchIds:addedBatchIds};});});}));case 5:result=_context14.sent;localStoreImpl.mutationQueue=newMutationQueue;localStoreImpl.localDocuments=newLocalDocuments;localStoreImpl.queryEngine.setLocalDocumentsView(localStoreImpl.localDocuments);return _context14.abrupt("return",result);case 10:case"end":return _context14.stop();}}});}/* Accepts locally generated Mutations and commit them to storage. */function localWrite(localStore,mutations){var localStoreImpl=debugCast(localStore);var localWriteTime=Timestamp.now();var keys=mutations.reduce(function(keys,m){return keys.add(m.key);},documentKeySet());var existingDocs;return localStoreImpl.persistence.runTransaction('Locally write mutations','readwrite',function(txn){// Load and apply all existing mutations. This lets us compute the
// current base state for all non-idempotent transforms before applying
// any additional user-provided writes.
return localStoreImpl.localDocuments.getDocuments(txn,keys).next(function(docs){existingDocs=docs;// For non-idempotent mutations (such as `FieldValue.increment()`),
// we record the base state in a separate patch mutation. This is
// later used to guarantee consistent values and prevents flicker
// even if the backend sends us an update that already includes our
// transform.
var baseMutations=[];var _iteratorNormalCompletion40=true;var _didIteratorError40=false;var _iteratorError40=undefined;try{for(var _iterator40=mutations[Symbol.iterator](),_step40;!(_iteratorNormalCompletion40=(_step40=_iterator40.next()).done);_iteratorNormalCompletion40=true){var mutation=_step40.value;var baseValue=extractMutationBaseValue(mutation,existingDocs.get(mutation.key));if(baseValue!=null){// NOTE: The base state should only be applied if there's some
// existing document to override, so use a Precondition of
// exists=true
baseMutations.push(new PatchMutation(mutation.key,baseValue,extractFieldMask(baseValue.proto.mapValue),Precondition.exists(true)));}}}catch(err){_didIteratorError40=true;_iteratorError40=err;}finally{try{if(!_iteratorNormalCompletion40&&_iterator40["return"]!=null){_iterator40["return"]();}}finally{if(_didIteratorError40){throw _iteratorError40;}}}return localStoreImpl.mutationQueue.addMutationBatch(txn,localWriteTime,baseMutations,mutations);});}).then(function(batch){var changes=batch.applyToLocalDocumentSet(existingDocs);return{batchId:batch.batchId,changes:changes};});}/**
 * Acknowledges the given batch.
 *
 * On the happy path when a batch is acknowledged, the local store will
 *
 *  + remove the batch from the mutation queue;
 *  + apply the changes to the remote document cache;
 *  + recalculate the latency compensated view implied by those changes (there
 *    may be mutations in the queue that affect the documents but haven't been
 *    acknowledged yet); and
 *  + give the changed documents back the sync engine
 *
 * @returns The resulting (modified) documents.
 */function acknowledgeBatch(localStore,batchResult){var localStoreImpl=debugCast(localStore);return localStoreImpl.persistence.runTransaction('Acknowledge batch','readwrite-primary',function(txn){var affected=batchResult.batch.keys();var documentBuffer=localStoreImpl.remoteDocuments.newChangeBuffer({trackRemovals:true// Make sure document removals show up in `getNewDocumentChanges()`
});return applyWriteToRemoteDocuments(localStoreImpl,txn,batchResult,documentBuffer).next(function(){return documentBuffer.apply(txn);}).next(function(){return localStoreImpl.mutationQueue.performConsistencyCheck(txn);}).next(function(){return localStoreImpl.localDocuments.getDocuments(txn,affected);});});}/**
 * Removes mutations from the MutationQueue for the specified batch;
 * LocalDocuments will be recalculated.
 *
 * @returns The resulting modified documents.
 */function rejectBatch(localStore,batchId){var localStoreImpl=debugCast(localStore);return localStoreImpl.persistence.runTransaction('Reject batch','readwrite-primary',function(txn){var affectedKeys;return localStoreImpl.mutationQueue.lookupMutationBatch(txn,batchId).next(function(batch){hardAssert(batch!==null);affectedKeys=batch.keys();return localStoreImpl.mutationQueue.removeMutationBatch(txn,batch);}).next(function(){return localStoreImpl.mutationQueue.performConsistencyCheck(txn);}).next(function(){return localStoreImpl.localDocuments.getDocuments(txn,affectedKeys);});});}/**
 * Returns the largest (latest) batch id in mutation queue that is pending
 * server response.
 *
 * Returns `BATCHID_UNKNOWN` if the queue is empty.
 */function getHighestUnacknowledgedBatchId(localStore){var localStoreImpl=debugCast(localStore);return localStoreImpl.persistence.runTransaction('Get highest unacknowledged batch id','readonly',function(txn){return localStoreImpl.mutationQueue.getHighestUnacknowledgedBatchId(txn);});}/**
 * Returns the last consistent snapshot processed (used by the RemoteStore to
 * determine whether to buffer incoming snapshots from the backend).
 */function getLastRemoteSnapshotVersion(localStore){var localStoreImpl=debugCast(localStore);return localStoreImpl.persistence.runTransaction('Get last remote snapshot version','readonly',function(txn){return localStoreImpl.targetCache.getLastRemoteSnapshotVersion(txn);});}/**
 * Updates the "ground-state" (remote) documents. We assume that the remote
 * event reflects any write batches that have been acknowledged or rejected
 * (i.e. we do not re-apply local mutations to updates from this event).
 *
 * LocalDocuments are re-calculated if there are remaining mutations in the
 * queue.
 */function applyRemoteEventToLocalCache(localStore,remoteEvent){var localStoreImpl=debugCast(localStore);var remoteVersion=remoteEvent.snapshotVersion;var newTargetDataByTargetMap=localStoreImpl.targetDataByTarget;return localStoreImpl.persistence.runTransaction('Apply remote event','readwrite-primary',function(txn){var documentBuffer=localStoreImpl.remoteDocuments.newChangeBuffer({trackRemovals:true// Make sure document removals show up in `getNewDocumentChanges()`
});// Reset newTargetDataByTargetMap in case this transaction gets re-run.
newTargetDataByTargetMap=localStoreImpl.targetDataByTarget;var promises=[];remoteEvent.targetChanges.forEach(function(change,targetId){var oldTargetData=newTargetDataByTargetMap.get(targetId);if(!oldTargetData){return;}// Only update the remote keys if the target is still active. This
// ensures that we can persist the updated target data along with
// the updated assignment.
promises.push(localStoreImpl.targetCache.removeMatchingKeys(txn,change.removedDocuments,targetId).next(function(){return localStoreImpl.targetCache.addMatchingKeys(txn,change.addedDocuments,targetId);}));var resumeToken=change.resumeToken;// Update the resume token if the change includes one.
if(resumeToken.approximateByteSize()>0){var newTargetData=oldTargetData.withResumeToken(resumeToken,remoteVersion).withSequenceNumber(txn.currentSequenceNumber);newTargetDataByTargetMap=newTargetDataByTargetMap.insert(targetId,newTargetData);// Update the target data if there are target changes (or if
// sufficient time has passed since the last update).
if(shouldPersistTargetData(oldTargetData,newTargetData,change)){promises.push(localStoreImpl.targetCache.updateTargetData(txn,newTargetData));}}});var changedDocs=maybeDocumentMap();var updatedKeys=documentKeySet();remoteEvent.documentUpdates.forEach(function(key,doc){updatedKeys=updatedKeys.add(key);});// Each loop iteration only affects its "own" doc, so it's safe to get all the remote
// documents in advance in a single call.
promises.push(documentBuffer.getEntries(txn,updatedKeys).next(function(existingDocs){remoteEvent.documentUpdates.forEach(function(key,doc){var existingDoc=existingDocs.get(key);// Note: The order of the steps below is important, since we want
// to ensure that rejected limbo resolutions (which fabricate
// NoDocuments with SnapshotVersion.min()) never add documents to
// cache.
if(doc instanceof NoDocument&&doc.version.isEqual(SnapshotVersion.min())){// NoDocuments with SnapshotVersion.min() are used in manufactured
// events. We remove these documents from cache since we lost
// access.
documentBuffer.removeEntry(key,remoteVersion);changedDocs=changedDocs.insert(key,doc);}else if(existingDoc==null||doc.version.compareTo(existingDoc.version)>0||doc.version.compareTo(existingDoc.version)===0&&existingDoc.hasPendingWrites){documentBuffer.addEntry(doc,remoteVersion);changedDocs=changedDocs.insert(key,doc);}else{logDebug(LOG_TAG$5,'Ignoring outdated watch update for ',key,'. Current version:',existingDoc.version,' Watch version:',doc.version);}if(remoteEvent.resolvedLimboDocuments.has(key)){promises.push(localStoreImpl.persistence.referenceDelegate.updateLimboDocument(txn,key));}});}));// HACK: The only reason we allow a null snapshot version is so that we
// can synthesize remote events when we get permission denied errors while
// trying to resolve the state of a locally cached document that is in
// limbo.
if(!remoteVersion.isEqual(SnapshotVersion.min())){var updateRemoteVersion=localStoreImpl.targetCache.getLastRemoteSnapshotVersion(txn).next(function(lastRemoteSnapshotVersion){return localStoreImpl.targetCache.setTargetsMetadata(txn,txn.currentSequenceNumber,remoteVersion);});promises.push(updateRemoteVersion);}return PersistencePromise.waitFor(promises).next(function(){return documentBuffer.apply(txn);}).next(function(){return localStoreImpl.localDocuments.getLocalViewOfDocuments(txn,changedDocs);});}).then(function(changedDocs){localStoreImpl.targetDataByTarget=newTargetDataByTargetMap;return changedDocs;});}/**
 * Returns true if the newTargetData should be persisted during an update of
 * an active target. TargetData should always be persisted when a target is
 * being released and should not call this function.
 *
 * While the target is active, TargetData updates can be omitted when nothing
 * about the target has changed except metadata like the resume token or
 * snapshot version. Occasionally it's worth the extra write to prevent these
 * values from getting too stale after a crash, but this doesn't have to be
 * too frequent.
 */function shouldPersistTargetData(oldTargetData,newTargetData,change){hardAssert(newTargetData.resumeToken.approximateByteSize()>0);// Always persist target data if we don't already have a resume token.
if(oldTargetData.resumeToken.approximateByteSize()===0){return true;}// Don't allow resume token changes to be buffered indefinitely. This
// allows us to be reasonably up-to-date after a crash and avoids needing
// to loop over all active queries on shutdown. Especially in the browser
// we may not get time to do anything interesting while the current tab is
// closing.
var timeDelta=newTargetData.snapshotVersion.toMicroseconds()-oldTargetData.snapshotVersion.toMicroseconds();if(timeDelta>=RESUME_TOKEN_MAX_AGE_MICROS){return true;}// Otherwise if the only thing that has changed about a target is its resume
// token it's not worth persisting. Note that the RemoteStore keeps an
// in-memory view of the currently active targets which includes the current
// resume token, so stream failure or user changes will still use an
// up-to-date resume token regardless of what we do here.
var changes=change.addedDocuments.size+change.modifiedDocuments.size+change.removedDocuments.size;return changes>0;}/**
 * Notifies local store of the changed views to locally pin documents.
 */function notifyLocalViewChanges(localStore,viewChanges){var localStoreImpl,_iteratorNormalCompletion41,_didIteratorError41,_iteratorError41,_iterator41,_step41,viewChange,targetId,targetData,lastLimboFreeSnapshotVersion,updatedTargetData;return regeneratorRuntime.async(function notifyLocalViewChanges$(_context15){while(1){switch(_context15.prev=_context15.next){case 0:localStoreImpl=debugCast(localStore);_context15.prev=1;_context15.next=4;return regeneratorRuntime.awrap(localStoreImpl.persistence.runTransaction('notifyLocalViewChanges','readwrite',function(txn){return PersistencePromise.forEach(viewChanges,function(viewChange){return PersistencePromise.forEach(viewChange.addedKeys,function(key){return localStoreImpl.persistence.referenceDelegate.addReference(txn,viewChange.targetId,key);}).next(function(){return PersistencePromise.forEach(viewChange.removedKeys,function(key){return localStoreImpl.persistence.referenceDelegate.removeReference(txn,viewChange.targetId,key);});});});}));case 4:_context15.next=13;break;case 6:_context15.prev=6;_context15.t0=_context15["catch"](1);if(!isIndexedDbTransactionError(_context15.t0)){_context15.next=12;break;}// If `notifyLocalViewChanges` fails, we did not advance the sequence
// number for the documents that were included in this transaction.
// This might trigger them to be deleted earlier than they otherwise
// would have, but it should not invalidate the integrity of the data.
logDebug(LOG_TAG$5,'Failed to update sequence numbers: '+_context15.t0);_context15.next=13;break;case 12:throw _context15.t0;case 13:_iteratorNormalCompletion41=true;_didIteratorError41=false;_iteratorError41=undefined;_context15.prev=16;for(_iterator41=viewChanges[Symbol.iterator]();!(_iteratorNormalCompletion41=(_step41=_iterator41.next()).done);_iteratorNormalCompletion41=true){viewChange=_step41.value;targetId=viewChange.targetId;if(!viewChange.fromCache){targetData=localStoreImpl.targetDataByTarget.get(targetId);// Advance the last limbo free snapshot version
lastLimboFreeSnapshotVersion=targetData.snapshotVersion;updatedTargetData=targetData.withLastLimboFreeSnapshotVersion(lastLimboFreeSnapshotVersion);localStoreImpl.targetDataByTarget=localStoreImpl.targetDataByTarget.insert(targetId,updatedTargetData);}}_context15.next=24;break;case 20:_context15.prev=20;_context15.t1=_context15["catch"](16);_didIteratorError41=true;_iteratorError41=_context15.t1;case 24:_context15.prev=24;_context15.prev=25;if(!_iteratorNormalCompletion41&&_iterator41["return"]!=null){_iterator41["return"]();}case 27:_context15.prev=27;if(!_didIteratorError41){_context15.next=30;break;}throw _iteratorError41;case 30:return _context15.finish(27);case 31:return _context15.finish(24);case 32:case"end":return _context15.stop();}}},null,null,[[1,6],[16,20,24,32],[25,,27,31]]);}/**
 * Gets the mutation batch after the passed in batchId in the mutation queue
 * or null if empty.
 * @param afterBatchId If provided, the batch to search after.
 * @returns The next mutation or null if there wasn't one.
 */function nextMutationBatch(localStore,afterBatchId){var localStoreImpl=debugCast(localStore);return localStoreImpl.persistence.runTransaction('Get next mutation batch','readonly',function(txn){if(afterBatchId===undefined){afterBatchId=BATCHID_UNKNOWN;}return localStoreImpl.mutationQueue.getNextMutationBatchAfterBatchId(txn,afterBatchId);});}/**
 * Reads the current value of a Document with a given key or null if not
 * found - used for testing.
 */function readLocalDocument(localStore,key){var localStoreImpl=debugCast(localStore);return localStoreImpl.persistence.runTransaction('read document','readonly',function(txn){return localStoreImpl.localDocuments.getDocument(txn,key);});}/**
 * Assigns the given target an internal ID so that its results can be pinned so
 * they don't get GC'd. A target must be allocated in the local store before
 * the store can be used to manage its view.
 *
 * Allocating an already allocated `Target` will return the existing `TargetData`
 * for that `Target`.
 */function allocateTarget(localStore,target){var localStoreImpl=debugCast(localStore);return localStoreImpl.persistence.runTransaction('Allocate target','readwrite',function(txn){var targetData;return localStoreImpl.targetCache.getTargetData(txn,target).next(function(cached){if(cached){// This target has been listened to previously, so reuse the
// previous targetID.
// TODO(mcg): freshen last accessed date?
targetData=cached;return PersistencePromise.resolve(targetData);}else{return localStoreImpl.targetCache.allocateTargetId(txn).next(function(targetId){targetData=new TargetData(target,targetId,0/* Listen */,txn.currentSequenceNumber);return localStoreImpl.targetCache.addTargetData(txn,targetData).next(function(){return targetData;});});}});}).then(function(targetData){// If Multi-Tab is enabled, the existing target data may be newer than
// the in-memory data
var cachedTargetData=localStoreImpl.targetDataByTarget.get(targetData.targetId);if(cachedTargetData===null||targetData.snapshotVersion.compareTo(cachedTargetData.snapshotVersion)>0){localStoreImpl.targetDataByTarget=localStoreImpl.targetDataByTarget.insert(targetData.targetId,targetData);localStoreImpl.targetIdByTarget.set(target,targetData.targetId);}return targetData;});}/**
 * Returns the TargetData as seen by the LocalStore, including updates that may
 * have not yet been persisted to the TargetCache.
 */ // Visible for testing.
function getLocalTargetData(localStore,transaction,target){var localStoreImpl=debugCast(localStore);var targetId=localStoreImpl.targetIdByTarget.get(target);if(targetId!==undefined){return PersistencePromise.resolve(localStoreImpl.targetDataByTarget.get(targetId));}else{return localStoreImpl.targetCache.getTargetData(transaction,target);}}/**
 * Unpins all the documents associated with the given target. If
 * `keepPersistedTargetData` is set to false and Eager GC enabled, the method
 * directly removes the associated target data from the target cache.
 *
 * Releasing a non-existing `Target` is a no-op.
 */ // PORTING NOTE: `keepPersistedTargetData` is multi-tab only.
function releaseTarget(localStore,targetId,keepPersistedTargetData){var localStoreImpl,targetData,mode;return regeneratorRuntime.async(function releaseTarget$(_context16){while(1){switch(_context16.prev=_context16.next){case 0:localStoreImpl=debugCast(localStore);targetData=localStoreImpl.targetDataByTarget.get(targetId);mode=keepPersistedTargetData?'readwrite':'readwrite-primary';_context16.prev=3;if(keepPersistedTargetData){_context16.next=7;break;}_context16.next=7;return regeneratorRuntime.awrap(localStoreImpl.persistence.runTransaction('Release target',mode,function(txn){return localStoreImpl.persistence.referenceDelegate.removeTarget(txn,targetData);}));case 7:_context16.next=16;break;case 9:_context16.prev=9;_context16.t0=_context16["catch"](3);if(!isIndexedDbTransactionError(_context16.t0)){_context16.next=15;break;}// All `releaseTarget` does is record the final metadata state for the
// target, but we've been recording this periodically during target
// activity. If we lose this write this could cause a very slight
// difference in the order of target deletion during GC, but we
// don't define exact LRU semantics so this is acceptable.
logDebug(LOG_TAG$5,"Failed to update sequence numbers for target ".concat(targetId,": ").concat(_context16.t0));_context16.next=16;break;case 15:throw _context16.t0;case 16:localStoreImpl.targetDataByTarget=localStoreImpl.targetDataByTarget.remove(targetId);localStoreImpl.targetIdByTarget["delete"](targetData.target);case 18:case"end":return _context16.stop();}}},null,null,[[3,9]]);}/**
 * Runs the specified query against the local store and returns the results,
 * potentially taking advantage of query data from previous executions (such
 * as the set of remote keys).
 *
 * @param usePreviousResults Whether results from previous executions can
 * be used to optimize this query execution.
 */function executeQuery(localStore,query,usePreviousResults){var localStoreImpl=debugCast(localStore);var lastLimboFreeSnapshotVersion=SnapshotVersion.min();var remoteKeys=documentKeySet();return localStoreImpl.persistence.runTransaction('Execute query','readonly',function(txn){return getLocalTargetData(localStoreImpl,txn,queryToTarget(query)).next(function(targetData){if(targetData){lastLimboFreeSnapshotVersion=targetData.lastLimboFreeSnapshotVersion;return localStoreImpl.targetCache.getMatchingKeysForTargetId(txn,targetData.targetId).next(function(result){remoteKeys=result;});}}).next(function(){return localStoreImpl.queryEngine.getDocumentsMatchingQuery(txn,query,usePreviousResults?lastLimboFreeSnapshotVersion:SnapshotVersion.min(),usePreviousResults?remoteKeys:documentKeySet());}).next(function(documents){return{documents:documents,remoteKeys:remoteKeys};});});}function applyWriteToRemoteDocuments(localStoreImpl,txn,batchResult,documentBuffer){var batch=batchResult.batch;var docKeys=batch.keys();var promiseChain=PersistencePromise.resolve();docKeys.forEach(function(docKey){promiseChain=promiseChain.next(function(){return documentBuffer.getEntry(txn,docKey);}).next(function(remoteDoc){var doc=remoteDoc;var ackVersion=batchResult.docVersions.get(docKey);hardAssert(ackVersion!==null);if(!doc||doc.version.compareTo(ackVersion)<0){doc=batch.applyToRemoteDocument(docKey,doc,batchResult);if(!doc);else{// We use the commitVersion as the readTime rather than the
// document's updateTime since the updateTime is not advanced
// for updates that do not modify the underlying document.
documentBuffer.addEntry(doc,batchResult.commitVersion);}}});});return promiseChain.next(function(){return localStoreImpl.mutationQueue.removeMutationBatch(txn,batch);});}/** Returns the local view of the documents affected by a mutation batch. */ // PORTING NOTE: Multi-Tab only.
function lookupMutationDocuments(localStore,batchId){var localStoreImpl=debugCast(localStore);var mutationQueueImpl=debugCast(localStoreImpl.mutationQueue);return localStoreImpl.persistence.runTransaction('Lookup mutation documents','readonly',function(txn){return mutationQueueImpl.lookupMutationKeys(txn,batchId).next(function(keys){if(keys){return localStoreImpl.localDocuments.getDocuments(txn,keys);}else{return PersistencePromise.resolve(null);}});});}// PORTING NOTE: Multi-Tab only.
function removeCachedMutationBatchMetadata(localStore,batchId){var mutationQueueImpl=debugCast(debugCast(localStore,LocalStoreImpl).mutationQueue);mutationQueueImpl.removeCachedMutationKeys(batchId);}// PORTING NOTE: Multi-Tab only.
function getActiveClientsFromPersistence(localStore){var persistenceImpl=debugCast(debugCast(localStore,LocalStoreImpl).persistence);return persistenceImpl.getActiveClients();}// PORTING NOTE: Multi-Tab only.
function getCachedTarget(localStore,targetId){var localStoreImpl=debugCast(localStore);var targetCacheImpl=debugCast(localStoreImpl.targetCache);var cachedTargetData=localStoreImpl.targetDataByTarget.get(targetId);if(cachedTargetData){return Promise.resolve(cachedTargetData.target);}else{return localStoreImpl.persistence.runTransaction('Get target data','readonly',function(txn){return targetCacheImpl.getTargetDataForTarget(txn,targetId).next(function(targetData){return targetData?targetData.target:null;});});}}/**
 * Returns the set of documents that have been updated since the last call.
 * If this is the first call, returns the set of changes since client
 * initialization. Further invocations will return document that have changed
 * since the prior call.
 */ // PORTING NOTE: Multi-Tab only.
function getNewDocumentChanges(localStore){var localStoreImpl=debugCast(localStore);var remoteDocumentCacheImpl=debugCast(localStoreImpl.remoteDocuments);return localStoreImpl.persistence.runTransaction('Get new document changes','readonly',function(txn){return remoteDocumentCacheImpl.getNewDocumentChanges(txn,localStoreImpl.lastDocumentChangeReadTime);}).then(function(_ref13){var changedDocs=_ref13.changedDocs,readTime=_ref13.readTime;localStoreImpl.lastDocumentChangeReadTime=readTime;return changedDocs;});}/**
 * Reads the newest document change from persistence and moves the internal
 * synchronization marker forward so that calls to `getNewDocumentChanges()`
 * only return changes that happened after client initialization.
 */ // PORTING NOTE: Multi-Tab only.
function synchronizeLastDocumentChangeReadTime(localStore){var localStoreImpl,remoteDocumentCacheImpl;return regeneratorRuntime.async(function synchronizeLastDocumentChangeReadTime$(_context17){while(1){switch(_context17.prev=_context17.next){case 0:localStoreImpl=debugCast(localStore);remoteDocumentCacheImpl=debugCast(localStoreImpl.remoteDocuments);return _context17.abrupt("return",localStoreImpl.persistence.runTransaction('Synchronize last document change read time','readonly',function(txn){return remoteDocumentCacheImpl.getLastReadTime(txn);}).then(function(readTime){localStoreImpl.lastDocumentChangeReadTime=readTime;}));case 3:case"end":return _context17.stop();}}});}/**
 * Verifies the error thrown by a LocalStore operation. If a LocalStore
 * operation fails because the primary lease has been taken by another client,
 * we ignore the error (the persistence layer will immediately call
 * `applyPrimaryLease` to propagate the primary state change). All other errors
 * are re-thrown.
 *
 * @param err An error returned by a LocalStore operation.
 * @return A Promise that resolves after we recovered, or the original error.
 */function ignoreIfPrimaryLeaseLoss(err){return regeneratorRuntime.async(function ignoreIfPrimaryLeaseLoss$(_context18){while(1){switch(_context18.prev=_context18.next){case 0:if(!(err.code===Code.FAILED_PRECONDITION&&err.message===PRIMARY_LEASE_LOST_ERROR_MSG)){_context18.next=4;break;}logDebug(LOG_TAG$5,'Unexpectedly lost primary lease');_context18.next=5;break;case 4:throw err;case 5:case"end":return _context18.stop();}}});}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * A set of changes to what documents are currently in view and out of view for
 * a given query. These changes are sent to the LocalStore by the View (via
 * the SyncEngine) and are used to pin / unpin documents as appropriate.
 */var LocalViewChanges=/*#__PURE__*/function(){function LocalViewChanges(targetId,fromCache,addedKeys,removedKeys){_classCallCheck(this,LocalViewChanges);this.targetId=targetId;this.fromCache=fromCache;this.addedKeys=addedKeys;this.removedKeys=removedKeys;}_createClass(LocalViewChanges,null,[{key:"fromSnapshot",value:function fromSnapshot(targetId,viewSnapshot){var addedKeys=documentKeySet();var removedKeys=documentKeySet();var _iteratorNormalCompletion42=true;var _didIteratorError42=false;var _iteratorError42=undefined;try{for(var _iterator42=viewSnapshot.docChanges[Symbol.iterator](),_step42;!(_iteratorNormalCompletion42=(_step42=_iterator42.next()).done);_iteratorNormalCompletion42=true){var docChange=_step42.value;switch(docChange.type){case 0/* Added */:addedKeys=addedKeys.add(docChange.doc.key);break;case 1/* Removed */:removedKeys=removedKeys.add(docChange.doc.key);break;// do nothing
}}}catch(err){_didIteratorError42=true;_iteratorError42=err;}finally{try{if(!_iteratorNormalCompletion42&&_iterator42["return"]!=null){_iterator42["return"]();}}finally{if(_didIteratorError42){throw _iteratorError42;}}}return new LocalViewChanges(targetId,viewSnapshot.fromCache,addedKeys,removedKeys);}}]);return LocalViewChanges;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * A collection of references to a document from some kind of numbered entity
 * (either a target ID or batch ID). As references are added to or removed from
 * the set corresponding events are emitted to a registered garbage collector.
 *
 * Each reference is represented by a DocumentReference object. Each of them
 * contains enough information to uniquely identify the reference. They are all
 * stored primarily in a set sorted by key. A document is considered garbage if
 * there's no references in that set (this can be efficiently checked thanks to
 * sorting by key).
 *
 * ReferenceSet also keeps a secondary set that contains references sorted by
 * IDs. This one is used to efficiently implement removal of all references by
 * some target ID.
 */var ReferenceSet=/*#__PURE__*/function(){function ReferenceSet(){_classCallCheck(this,ReferenceSet);// A set of outstanding references to a document sorted by key.
this.refsByKey=new SortedSet(DocReference.compareByKey);// A set of outstanding references to a document sorted by target id.
this.refsByTarget=new SortedSet(DocReference.compareByTargetId);}/** Returns true if the reference set contains no references. */_createClass(ReferenceSet,[{key:"isEmpty",value:function isEmpty(){return this.refsByKey.isEmpty();}/** Adds a reference to the given document key for the given ID. */},{key:"addReference",value:function addReference(key,id){var ref=new DocReference(key,id);this.refsByKey=this.refsByKey.add(ref);this.refsByTarget=this.refsByTarget.add(ref);}/** Add references to the given document keys for the given ID. */},{key:"addReferences",value:function addReferences(keys,id){var _this100=this;keys.forEach(function(key){return _this100.addReference(key,id);});}/**
     * Removes a reference to the given document key for the given
     * ID.
     */},{key:"removeReference",value:function removeReference(key,id){this.removeRef(new DocReference(key,id));}},{key:"removeReferences",value:function removeReferences(keys,id){var _this101=this;keys.forEach(function(key){return _this101.removeReference(key,id);});}/**
     * Clears all references with a given ID. Calls removeRef() for each key
     * removed.
     */},{key:"removeReferencesForId",value:function removeReferencesForId(id){var _this102=this;var emptyKey=new DocumentKey(new ResourcePath([]));var startRef=new DocReference(emptyKey,id);var endRef=new DocReference(emptyKey,id+1);var keys=[];this.refsByTarget.forEachInRange([startRef,endRef],function(ref){_this102.removeRef(ref);keys.push(ref.key);});return keys;}},{key:"removeAllReferences",value:function removeAllReferences(){var _this103=this;this.refsByKey.forEach(function(ref){return _this103.removeRef(ref);});}},{key:"removeRef",value:function removeRef(ref){this.refsByKey=this.refsByKey["delete"](ref);this.refsByTarget=this.refsByTarget["delete"](ref);}},{key:"referencesForId",value:function referencesForId(id){var emptyKey=new DocumentKey(new ResourcePath([]));var startRef=new DocReference(emptyKey,id);var endRef=new DocReference(emptyKey,id+1);var keys=documentKeySet();this.refsByTarget.forEachInRange([startRef,endRef],function(ref){keys=keys.add(ref.key);});return keys;}},{key:"containsKey",value:function containsKey(key){var ref=new DocReference(key,0);var firstRef=this.refsByKey.firstAfterOrEqual(ref);return firstRef!==null&&key.isEqual(firstRef.key);}}]);return ReferenceSet;}();var DocReference=/*#__PURE__*/function(){function DocReference(key,targetOrBatchId){_classCallCheck(this,DocReference);this.key=key;this.targetOrBatchId=targetOrBatchId;}/** Compare by key then by ID */_createClass(DocReference,null,[{key:"compareByKey",value:function compareByKey(left,right){return DocumentKey.comparator(left.key,right.key)||primitiveComparator(left.targetOrBatchId,right.targetOrBatchId);}/** Compare by ID then by key */},{key:"compareByTargetId",value:function compareByTargetId(left,right){return primitiveComparator(left.targetOrBatchId,right.targetOrBatchId)||DocumentKey.comparator(left.key,right.key);}}]);return DocReference;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$6='ExponentialBackoff';/**
 * Initial backoff time in milliseconds after an error.
 * Set to 1s according to https://cloud.google.com/apis/design/errors.
 */var DEFAULT_BACKOFF_INITIAL_DELAY_MS=1000;var DEFAULT_BACKOFF_FACTOR=1.5;/** Maximum backoff time in milliseconds */var DEFAULT_BACKOFF_MAX_DELAY_MS=60*1000;/**
 * A helper for running delayed tasks following an exponential backoff curve
 * between attempts.
 *
 * Each delay is made up of a "base" delay which follows the exponential
 * backoff curve, and a +/- 50% "jitter" that is calculated and added to the
 * base delay. This prevents clients from accidentally synchronizing their
 * delays causing spikes of load to the backend.
 */var ExponentialBackoff=/*#__PURE__*/function(){function ExponentialBackoff(/**
     * The AsyncQueue to run backoff operations on.
     */queue,/**
     * The ID to use when scheduling backoff operations on the AsyncQueue.
     */timerId){var initialDelayMs=arguments.length>2&&arguments[2]!==undefined?arguments[2]:DEFAULT_BACKOFF_INITIAL_DELAY_MS;var backoffFactor=arguments.length>3&&arguments[3]!==undefined?arguments[3]:DEFAULT_BACKOFF_FACTOR;var maxDelayMs=arguments.length>4&&arguments[4]!==undefined?arguments[4]:DEFAULT_BACKOFF_MAX_DELAY_MS;_classCallCheck(this,ExponentialBackoff);this.queue=queue;this.timerId=timerId;this.initialDelayMs=initialDelayMs;this.backoffFactor=backoffFactor;this.maxDelayMs=maxDelayMs;this.currentBaseMs=0;this.timerPromise=null;/** The last backoff attempt, as epoch milliseconds. */this.lastAttemptTime=Date.now();this.reset();}/**
     * Resets the backoff delay.
     *
     * The very next backoffAndWait() will have no delay. If it is called again
     * (i.e. due to an error), initialDelayMs (plus jitter) will be used, and
     * subsequent ones will increase according to the backoffFactor.
     */_createClass(ExponentialBackoff,[{key:"reset",value:function reset(){this.currentBaseMs=0;}/**
     * Resets the backoff delay to the maximum delay (e.g. for use after a
     * RESOURCE_EXHAUSTED error).
     */},{key:"resetToMax",value:function resetToMax(){this.currentBaseMs=this.maxDelayMs;}/**
     * Returns a promise that resolves after currentDelayMs, and increases the
     * delay for any subsequent attempts. If there was a pending backoff operation
     * already, it will be canceled.
     */},{key:"backoffAndRun",value:function backoffAndRun(op){var _this104=this;// Cancel any pending backoff operation.
this.cancel();// First schedule using the current base (which may be 0 and should be
// honored as such).
var desiredDelayWithJitterMs=Math.floor(this.currentBaseMs+this.jitterDelayMs());// Guard against lastAttemptTime being in the future due to a clock change.
var delaySoFarMs=Math.max(0,Date.now()-this.lastAttemptTime);// Guard against the backoff delay already being past.
var remainingDelayMs=Math.max(0,desiredDelayWithJitterMs-delaySoFarMs);if(remainingDelayMs>0){logDebug(LOG_TAG$6,"Backing off for ".concat(remainingDelayMs," ms ")+"(base delay: ".concat(this.currentBaseMs," ms, ")+"delay with jitter: ".concat(desiredDelayWithJitterMs," ms, ")+"last attempt: ".concat(delaySoFarMs," ms ago)"));}this.timerPromise=this.queue.enqueueAfterDelay(this.timerId,remainingDelayMs,function(){_this104.lastAttemptTime=Date.now();return op();});// Apply backoff factor to determine next delay and ensure it is within
// bounds.
this.currentBaseMs*=this.backoffFactor;if(this.currentBaseMs<this.initialDelayMs){this.currentBaseMs=this.initialDelayMs;}if(this.currentBaseMs>this.maxDelayMs){this.currentBaseMs=this.maxDelayMs;}}},{key:"skipBackoff",value:function skipBackoff(){if(this.timerPromise!==null){this.timerPromise.skipDelay();this.timerPromise=null;}}},{key:"cancel",value:function cancel(){if(this.timerPromise!==null){this.timerPromise.cancel();this.timerPromise=null;}}/** Returns a random value in the range [-currentBaseMs/2, currentBaseMs/2] */},{key:"jitterDelayMs",value:function jitterDelayMs(){return(Math.random()-0.5)*this.currentBaseMs;}}]);return ExponentialBackoff;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$7='PersistentStream';/** The time a stream stays open after it is marked idle. */var IDLE_TIMEOUT_MS=60*1000;/**
 * A PersistentStream is an abstract base class that represents a streaming RPC
 * to the Firestore backend. It's built on top of the connections own support
 * for streaming RPCs, and adds several critical features for our clients:
 *
 *   - Exponential backoff on failure
 *   - Authentication via CredentialsProvider
 *   - Dispatching all callbacks into the shared worker queue
 *   - Closing idle streams after 60 seconds of inactivity
 *
 * Subclasses of PersistentStream implement serialization of models to and
 * from the JSON representation of the protocol buffers for a specific
 * streaming RPC.
 *
 * ## Starting and Stopping
 *
 * Streaming RPCs are stateful and need to be start()ed before messages can
 * be sent and received. The PersistentStream will call the onOpen() function
 * of the listener once the stream is ready to accept requests.
 *
 * Should a start() fail, PersistentStream will call the registered onClose()
 * listener with a FirestoreError indicating what went wrong.
 *
 * A PersistentStream can be started and stopped repeatedly.
 *
 * Generic types:
 *  SendType: The type of the outgoing message of the underlying
 *    connection stream
 *  ReceiveType: The type of the incoming message of the underlying
 *    connection stream
 *  ListenerType: The type of the listener that will be used for callbacks
 */var PersistentStream=/*#__PURE__*/function(){function PersistentStream(queue,connectionTimerId,idleTimerId,connection,credentialsProvider,listener){_classCallCheck(this,PersistentStream);this.queue=queue;this.idleTimerId=idleTimerId;this.connection=connection;this.credentialsProvider=credentialsProvider;this.listener=listener;this.state=0/* Initial */;/**
         * A close count that's incremented every time the stream is closed; used by
         * getCloseGuardedDispatcher() to invalidate callbacks that happen after
         * close.
         */this.closeCount=0;this.idleTimer=null;this.stream=null;this.backoff=new ExponentialBackoff(queue,connectionTimerId);}/**
     * Returns true if start() has been called and no error has occurred. True
     * indicates the stream is open or in the process of opening (which
     * encompasses respecting backoff, getting auth tokens, and starting the
     * actual RPC). Use isOpen() to determine if the stream is open and ready for
     * outbound requests.
     */_createClass(PersistentStream,[{key:"isStarted",value:function isStarted(){return this.state===1/* Starting */||this.state===2/* Open */||this.state===4/* Backoff */;}/**
     * Returns true if the underlying RPC is open (the onOpen() listener has been
     * called) and the stream is ready for outbound requests.
     */},{key:"isOpen",value:function isOpen(){return this.state===2/* Open */;}/**
     * Starts the RPC. Only allowed if isStarted() returns false. The stream is
     * not immediately ready for use: onOpen() will be invoked when the RPC is
     * ready for outbound requests, at which point isOpen() will return true.
     *
     * When start returns, isStarted() will return true.
     */},{key:"start",value:function start(){if(this.state===3/* Error */){this.performBackoff();return;}this.auth();}/**
     * Stops the RPC. This call is idempotent and allowed regardless of the
     * current isStarted() state.
     *
     * When stop returns, isStarted() and isOpen() will both return false.
     */},{key:"stop",value:function stop(){return regeneratorRuntime.async(function stop$(_context19){while(1){switch(_context19.prev=_context19.next){case 0:if(!this.isStarted()){_context19.next=3;break;}_context19.next=3;return regeneratorRuntime.awrap(this.close(0/* Initial */));case 3:case"end":return _context19.stop();}}},null,this);}/**
     * After an error the stream will usually back off on the next attempt to
     * start it. If the error warrants an immediate restart of the stream, the
     * sender can use this to indicate that the receiver should not back off.
     *
     * Each error will call the onClose() listener. That function can decide to
     * inhibit backoff if required.
     */},{key:"inhibitBackoff",value:function inhibitBackoff(){this.state=0/* Initial */;this.backoff.reset();}/**
     * Marks this stream as idle. If no further actions are performed on the
     * stream for one minute, the stream will automatically close itself and
     * notify the stream's onClose() handler with Status.OK. The stream will then
     * be in a !isStarted() state, requiring the caller to start the stream again
     * before further use.
     *
     * Only streams that are in state 'Open' can be marked idle, as all other
     * states imply pending network operations.
     */},{key:"markIdle",value:function markIdle(){var _this105=this;// Starts the idle time if we are in state 'Open' and are not yet already
// running a timer (in which case the previous idle timeout still applies).
if(this.isOpen()&&this.idleTimer===null){this.idleTimer=this.queue.enqueueAfterDelay(this.idleTimerId,IDLE_TIMEOUT_MS,function(){return _this105.handleIdleCloseTimer();});}}/** Sends a message to the underlying stream. */},{key:"sendRequest",value:function sendRequest(msg){this.cancelIdleCheck();this.stream.send(msg);}/** Called by the idle timer when the stream should close due to inactivity. */},{key:"handleIdleCloseTimer",value:function handleIdleCloseTimer(){return regeneratorRuntime.async(function handleIdleCloseTimer$(_context20){while(1){switch(_context20.prev=_context20.next){case 0:if(!this.isOpen()){_context20.next=2;break;}return _context20.abrupt("return",this.close(0/* Initial */));case 2:case"end":return _context20.stop();}}},null,this);}/** Marks the stream as active again. */},{key:"cancelIdleCheck",value:function cancelIdleCheck(){if(this.idleTimer){this.idleTimer.cancel();this.idleTimer=null;}}/**
     * Closes the stream and cleans up as necessary:
     *
     * * closes the underlying GRPC stream;
     * * calls the onClose handler with the given 'error';
     * * sets internal stream state to 'finalState';
     * * adjusts the backoff timer based on the error
     *
     * A new stream can be opened by calling start().
     *
     * @param finalState the intended state of the stream after closing.
     * @param error the error the connection was closed with.
     */},{key:"close",value:function close(finalState,error){return regeneratorRuntime.async(function close$(_context21){while(1){switch(_context21.prev=_context21.next){case 0:// Cancel any outstanding timers (they're guaranteed not to execute).
this.cancelIdleCheck();this.backoff.cancel();// Invalidates any stream-related callbacks (e.g. from auth or the
// underlying stream), guaranteeing they won't execute.
this.closeCount++;if(finalState!==3/* Error */){// If this is an intentional close ensure we don't delay our next connection attempt.
this.backoff.reset();}else if(error&&error.code===Code.RESOURCE_EXHAUSTED){// Log the error. (Probably either 'quota exceeded' or 'max queue length reached'.)
logError(error.toString());logError('Using maximum backoff delay to prevent overloading the backend.');this.backoff.resetToMax();}else if(error&&error.code===Code.UNAUTHENTICATED){// "unauthenticated" error means the token was rejected. Try force refreshing it in case it
// just expired.
this.credentialsProvider.invalidateToken();}// Clean up the underlying stream because we are no longer interested in events.
if(this.stream!==null){this.tearDown();this.stream.close();this.stream=null;}// This state must be assigned before calling onClose() to allow the callback to
// inhibit backoff or otherwise manipulate the state in its non-started state.
this.state=finalState;// Notify the listener that the stream closed.
_context21.next=8;return regeneratorRuntime.awrap(this.listener.onClose(error));case 8:case"end":return _context21.stop();}}},null,this);}/**
     * Can be overridden to perform additional cleanup before the stream is closed.
     * Calling super.tearDown() is not required.
     */},{key:"tearDown",value:function tearDown(){}},{key:"auth",value:function auth(){var _this106=this;this.state=1/* Starting */;var dispatchIfNotClosed=this.getCloseGuardedDispatcher(this.closeCount);// TODO(mikelehen): Just use dispatchIfNotClosed, but see TODO below.
var closeCount=this.closeCount;this.credentialsProvider.getToken().then(function(token){// Stream can be stopped while waiting for authentication.
// TODO(mikelehen): We really should just use dispatchIfNotClosed
// and let this dispatch onto the queue, but that opened a spec test can
// of worms that I don't want to deal with in this PR.
if(_this106.closeCount===closeCount){// Normally we'd have to schedule the callback on the AsyncQueue.
// However, the following calls are safe to be called outside the
// AsyncQueue since they don't chain asynchronous calls
_this106.startStream(token);}},function(error){dispatchIfNotClosed(function(){var rpcError=new FirestoreError(Code.UNKNOWN,'Fetching auth token failed: '+error.message);return _this106.handleStreamClose(rpcError);});});}},{key:"startStream",value:function startStream(token){var _this107=this;var dispatchIfNotClosed=this.getCloseGuardedDispatcher(this.closeCount);this.stream=this.startRpc(token);this.stream.onOpen(function(){dispatchIfNotClosed(function(){_this107.state=2/* Open */;return _this107.listener.onOpen();});});this.stream.onClose(function(error){dispatchIfNotClosed(function(){return _this107.handleStreamClose(error);});});this.stream.onMessage(function(msg){dispatchIfNotClosed(function(){return _this107.onMessage(msg);});});}},{key:"performBackoff",value:function performBackoff(){var _this108=this;this.state=4/* Backoff */;this.backoff.backoffAndRun(function _callee7(){return regeneratorRuntime.async(function _callee7$(_context22){while(1){switch(_context22.prev=_context22.next){case 0:_this108.state=0/* Initial */;_this108.start();case 2:case"end":return _context22.stop();}}});});}// Visible for tests
},{key:"handleStreamClose",value:function handleStreamClose(error){logDebug(LOG_TAG$7,"close with error: ".concat(error));this.stream=null;// In theory the stream could close cleanly, however, in our current model
// we never expect this to happen because if we stop a stream ourselves,
// this callback will never be called. To prevent cases where we retry
// without a backoff accidentally, we set the stream to error in all cases.
return this.close(3/* Error */,error);}/**
     * Returns a "dispatcher" function that dispatches operations onto the
     * AsyncQueue but only runs them if closeCount remains unchanged. This allows
     * us to turn auth / stream callbacks into no-ops if the stream is closed /
     * re-opened, etc.
     */},{key:"getCloseGuardedDispatcher",value:function getCloseGuardedDispatcher(startCloseCount){var _this109=this;return function(fn){_this109.queue.enqueueAndForget(function(){if(_this109.closeCount===startCloseCount){return fn();}else{logDebug(LOG_TAG$7,'stream callback skipped by getCloseGuardedDispatcher.');return Promise.resolve();}});};}}]);return PersistentStream;}();/**
 * A PersistentStream that implements the Listen RPC.
 *
 * Once the Listen stream has called the onOpen() listener, any number of
 * listen() and unlisten() calls can be made to control what changes will be
 * sent from the server for ListenResponses.
 */var PersistentListenStream=/*#__PURE__*/function(_PersistentStream){_inherits(PersistentListenStream,_PersistentStream);function PersistentListenStream(queue,connection,credentials,serializer,listener){var _this110;_classCallCheck(this,PersistentListenStream);_this110=_possibleConstructorReturn(this,_getPrototypeOf(PersistentListenStream).call(this,queue,"listen_stream_connection_backoff"/* ListenStreamConnectionBackoff */,"listen_stream_idle"/* ListenStreamIdle */,connection,credentials,listener));_this110.serializer=serializer;return _this110;}_createClass(PersistentListenStream,[{key:"startRpc",value:function startRpc(token){return this.connection.openStream('Listen',token);}},{key:"onMessage",value:function onMessage(watchChangeProto){// A successful response means the stream is healthy
this.backoff.reset();var watchChange=fromWatchChange(this.serializer,watchChangeProto);var snapshot=versionFromListenResponse(watchChangeProto);return this.listener.onWatchChange(watchChange,snapshot);}/**
     * Registers interest in the results of the given target. If the target
     * includes a resumeToken it will be included in the request. Results that
     * affect the target will be streamed back as WatchChange messages that
     * reference the targetId.
     */},{key:"watch",value:function watch(targetData){var request={};request.database=getEncodedDatabaseId(this.serializer);request.addTarget=toTarget(this.serializer,targetData);var labels=toListenRequestLabels(this.serializer,targetData);if(labels){request.labels=labels;}this.sendRequest(request);}/**
     * Unregisters interest in the results of the target associated with the
     * given targetId.
     */},{key:"unwatch",value:function unwatch(targetId){var request={};request.database=getEncodedDatabaseId(this.serializer);request.removeTarget=targetId;this.sendRequest(request);}}]);return PersistentListenStream;}(PersistentStream);/**
 * A Stream that implements the Write RPC.
 *
 * The Write RPC requires the caller to maintain special streamToken
 * state in between calls, to help the server understand which responses the
 * client has processed by the time the next request is made. Every response
 * will contain a streamToken; this value must be passed to the next
 * request.
 *
 * After calling start() on this stream, the next request must be a handshake,
 * containing whatever streamToken is on hand. Once a response to this
 * request is received, all pending mutations may be submitted. When
 * submitting multiple batches of mutations at the same time, it's
 * okay to use the same streamToken for the calls to writeMutations.
 *
 * TODO(b/33271235): Use proto types
 */var PersistentWriteStream=/*#__PURE__*/function(_PersistentStream2){_inherits(PersistentWriteStream,_PersistentStream2);function PersistentWriteStream(queue,connection,credentials,serializer,listener){var _this111;_classCallCheck(this,PersistentWriteStream);_this111=_possibleConstructorReturn(this,_getPrototypeOf(PersistentWriteStream).call(this,queue,"write_stream_connection_backoff"/* WriteStreamConnectionBackoff */,"write_stream_idle"/* WriteStreamIdle */,connection,credentials,listener));_this111.serializer=serializer;_this111.handshakeComplete_=false;return _this111;}/**
     * Tracks whether or not a handshake has been successfully exchanged and
     * the stream is ready to accept mutations.
     */_createClass(PersistentWriteStream,[{key:"start",// Override of PersistentStream.start
value:function start(){this.handshakeComplete_=false;this.lastStreamToken=undefined;_get(_getPrototypeOf(PersistentWriteStream.prototype),"start",this).call(this);}},{key:"tearDown",value:function tearDown(){if(this.handshakeComplete_){this.writeMutations([]);}}},{key:"startRpc",value:function startRpc(token){return this.connection.openStream('Write',token);}},{key:"onMessage",value:function onMessage(responseProto){// Always capture the last stream token.
hardAssert(!!responseProto.streamToken);this.lastStreamToken=responseProto.streamToken;if(!this.handshakeComplete_){// The first response is always the handshake response
hardAssert(!responseProto.writeResults||responseProto.writeResults.length===0);this.handshakeComplete_=true;return this.listener.onHandshakeComplete();}else{// A successful first write response means the stream is healthy,
// Note, that we could consider a successful handshake healthy, however,
// the write itself might be causing an error we want to back off from.
this.backoff.reset();var results=fromWriteResults(responseProto.writeResults,responseProto.commitTime);var commitVersion=fromVersion(responseProto.commitTime);return this.listener.onMutationResult(commitVersion,results);}}/**
     * Sends an initial streamToken to the server, performing the handshake
     * required to make the StreamingWrite RPC work. Subsequent
     * calls should wait until onHandshakeComplete was called.
     */},{key:"writeHandshake",value:function writeHandshake(){// TODO(dimond): Support stream resumption. We intentionally do not set the
// stream token on the handshake, ignoring any stream token we might have.
var request={};request.database=getEncodedDatabaseId(this.serializer);this.sendRequest(request);}/** Sends a group of mutations to the Firestore backend to apply. */},{key:"writeMutations",value:function writeMutations(mutations){var _this112=this;var request={streamToken:this.lastStreamToken,writes:mutations.map(function(mutation){return toMutation(_this112.serializer,mutation);})};this.sendRequest(request);}},{key:"handshakeComplete",get:function get(){return this.handshakeComplete_;}}]);return PersistentWriteStream;}(PersistentStream);/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Datastore and its related methods are a wrapper around the external Google
 * Cloud Datastore grpc API, which provides an interface that is more convenient
 * for the rest of the client SDK architecture to consume.
 */var Datastore=function Datastore(){_classCallCheck(this,Datastore);};/**
 * An implementation of Datastore that exposes additional state for internal
 * consumption.
 */var DatastoreImpl=/*#__PURE__*/function(_Datastore){_inherits(DatastoreImpl,_Datastore);function DatastoreImpl(credentials,connection,serializer){var _this113;_classCallCheck(this,DatastoreImpl);_this113=_possibleConstructorReturn(this,_getPrototypeOf(DatastoreImpl).call(this));_this113.credentials=credentials;_this113.connection=connection;_this113.serializer=serializer;_this113.terminated=false;return _this113;}_createClass(DatastoreImpl,[{key:"verifyInitialized",value:function verifyInitialized(){if(this.terminated){throw new FirestoreError(Code.FAILED_PRECONDITION,'The client has already been terminated.');}}/** Gets an auth token and invokes the provided RPC. */},{key:"invokeRPC",value:function invokeRPC(rpcName,path,request){var _this114=this;this.verifyInitialized();return this.credentials.getToken().then(function(token){return _this114.connection.invokeRPC(rpcName,path,request,token);})["catch"](function(error){if(error.code===Code.UNAUTHENTICATED){_this114.credentials.invalidateToken();}throw error;});}/** Gets an auth token and invokes the provided RPC with streamed results. */},{key:"invokeStreamingRPC",value:function invokeStreamingRPC(rpcName,path,request){var _this115=this;this.verifyInitialized();return this.credentials.getToken().then(function(token){return _this115.connection.invokeStreamingRPC(rpcName,path,request,token);})["catch"](function(error){if(error.code===Code.UNAUTHENTICATED){_this115.credentials.invalidateToken();}throw error;});}},{key:"terminate",value:function terminate(){this.terminated=false;}}]);return DatastoreImpl;}(Datastore);// TODO(firestorexp): Make sure there is only one Datastore instance per
// firestore-exp client.
function newDatastore(credentials,connection,serializer){return new DatastoreImpl(credentials,connection,serializer);}function invokeCommitRpc(datastore,mutations){var datastoreImpl,path,request;return regeneratorRuntime.async(function invokeCommitRpc$(_context23){while(1){switch(_context23.prev=_context23.next){case 0:datastoreImpl=debugCast(datastore);path=getEncodedDatabaseId(datastoreImpl.serializer)+'/documents';request={writes:mutations.map(function(m){return toMutation(datastoreImpl.serializer,m);})};_context23.next=5;return regeneratorRuntime.awrap(datastoreImpl.invokeRPC('Commit',path,request));case 5:case"end":return _context23.stop();}}});}function invokeBatchGetDocumentsRpc(datastore,keys){var datastoreImpl,path,request,response,docs,result;return regeneratorRuntime.async(function invokeBatchGetDocumentsRpc$(_context24){while(1){switch(_context24.prev=_context24.next){case 0:datastoreImpl=debugCast(datastore);path=getEncodedDatabaseId(datastoreImpl.serializer)+'/documents';request={documents:keys.map(function(k){return toName(datastoreImpl.serializer,k);})};_context24.next=5;return regeneratorRuntime.awrap(datastoreImpl.invokeStreamingRPC('BatchGetDocuments',path,request));case 5:response=_context24.sent;docs=new Map();response.forEach(function(proto){var doc=fromMaybeDocument(datastoreImpl.serializer,proto);docs.set(doc.key.toString(),doc);});result=[];keys.forEach(function(key){var doc=docs.get(key.toString());hardAssert(!!doc);result.push(doc);});return _context24.abrupt("return",result);case 11:case"end":return _context24.stop();}}});}function newPersistentWriteStream(datastore,queue,listener){var datastoreImpl=debugCast(datastore);datastoreImpl.verifyInitialized();return new PersistentWriteStream(queue,datastoreImpl.connection,datastoreImpl.credentials,datastoreImpl.serializer,listener);}function newPersistentWatchStream(datastore,queue,listener){var datastoreImpl=debugCast(datastore);datastoreImpl.verifyInitialized();return new PersistentListenStream(queue,datastoreImpl.connection,datastoreImpl.credentials,datastoreImpl.serializer,listener);}/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$8='OnlineStateTracker';// To deal with transient failures, we allow multiple stream attempts before
// giving up and transitioning from OnlineState.Unknown to Offline.
// TODO(mikelehen): This used to be set to 2 as a mitigation for b/66228394.
// @jdimond thinks that bug is sufficiently fixed so that we can set this back
// to 1. If that works okay, we could potentially remove this logic entirely.
var MAX_WATCH_STREAM_FAILURES=1;// To deal with stream attempts that don't succeed or fail in a timely manner,
// we have a timeout for OnlineState to reach Online or Offline.
// If the timeout is reached, we transition to Offline rather than waiting
// indefinitely.
var ONLINE_STATE_TIMEOUT_MS=10*1000;/**
 * A component used by the RemoteStore to track the OnlineState (that is,
 * whether or not the client as a whole should be considered to be online or
 * offline), implementing the appropriate heuristics.
 *
 * In particular, when the client is trying to connect to the backend, we
 * allow up to MAX_WATCH_STREAM_FAILURES within ONLINE_STATE_TIMEOUT_MS for
 * a connection to succeed. If we have too many failures or the timeout elapses,
 * then we set the OnlineState to Offline, and the client will behave as if
 * it is offline (get()s will return cached data, etc.).
 */var OnlineStateTracker=/*#__PURE__*/function(){function OnlineStateTracker(asyncQueue,onlineStateHandler){_classCallCheck(this,OnlineStateTracker);this.asyncQueue=asyncQueue;this.onlineStateHandler=onlineStateHandler;/** The current OnlineState. */this.state="Unknown"/* Unknown */;/**
         * A count of consecutive failures to open the stream. If it reaches the
         * maximum defined by MAX_WATCH_STREAM_FAILURES, we'll set the OnlineState to
         * Offline.
         */this.watchStreamFailures=0;/**
         * A timer that elapses after ONLINE_STATE_TIMEOUT_MS, at which point we
         * transition from OnlineState.Unknown to OnlineState.Offline without waiting
         * for the stream to actually fail (MAX_WATCH_STREAM_FAILURES times).
         */this.onlineStateTimer=null;/**
         * Whether the client should log a warning message if it fails to connect to
         * the backend (initially true, cleared after a successful stream, or if we've
         * logged the message already).
         */this.shouldWarnClientIsOffline=true;}/**
     * Called by RemoteStore when a watch stream is started (including on each
     * backoff attempt).
     *
     * If this is the first attempt, it sets the OnlineState to Unknown and starts
     * the onlineStateTimer.
     */_createClass(OnlineStateTracker,[{key:"handleWatchStreamStart",value:function handleWatchStreamStart(){var _this116=this;if(this.watchStreamFailures===0){this.setAndBroadcast("Unknown"/* Unknown */);this.onlineStateTimer=this.asyncQueue.enqueueAfterDelay("online_state_timeout"/* OnlineStateTimeout */,ONLINE_STATE_TIMEOUT_MS,function(){_this116.onlineStateTimer=null;_this116.logClientOfflineWarningIfNecessary("Backend didn't respond within ".concat(ONLINE_STATE_TIMEOUT_MS/1000," ")+"seconds.");_this116.setAndBroadcast("Offline"/* Offline */);// NOTE: handleWatchStreamFailure() will continue to increment
// watchStreamFailures even though we are already marked Offline,
// but this is non-harmful.
return Promise.resolve();});}}/**
     * Updates our OnlineState as appropriate after the watch stream reports a
     * failure. The first failure moves us to the 'Unknown' state. We then may
     * allow multiple failures (based on MAX_WATCH_STREAM_FAILURES) before we
     * actually transition to the 'Offline' state.
     */},{key:"handleWatchStreamFailure",value:function handleWatchStreamFailure(error){if(this.state==="Online"/* Online */){this.setAndBroadcast("Unknown"/* Unknown */);}else{this.watchStreamFailures++;if(this.watchStreamFailures>=MAX_WATCH_STREAM_FAILURES){this.clearOnlineStateTimer();this.logClientOfflineWarningIfNecessary("Connection failed ".concat(MAX_WATCH_STREAM_FAILURES," ")+"times. Most recent error: ".concat(error.toString()));this.setAndBroadcast("Offline"/* Offline */);}}}/**
     * Explicitly sets the OnlineState to the specified state.
     *
     * Note that this resets our timers / failure counters, etc. used by our
     * Offline heuristics, so must not be used in place of
     * handleWatchStreamStart() and handleWatchStreamFailure().
     */},{key:"set",value:function set(newState){this.clearOnlineStateTimer();this.watchStreamFailures=0;if(newState==="Online"/* Online */){// We've connected to watch at least once. Don't warn the developer
// about being offline going forward.
this.shouldWarnClientIsOffline=false;}this.setAndBroadcast(newState);}},{key:"setAndBroadcast",value:function setAndBroadcast(newState){if(newState!==this.state){this.state=newState;this.onlineStateHandler(newState);}}},{key:"logClientOfflineWarningIfNecessary",value:function logClientOfflineWarningIfNecessary(details){var message="Could not reach Cloud Firestore backend. ".concat(details,"\n")+"This typically indicates that your device does not have a healthy "+"Internet connection at the moment. The client will operate in offline "+"mode until it is able to successfully connect to the backend.";if(this.shouldWarnClientIsOffline){logError(message);this.shouldWarnClientIsOffline=false;}else{logDebug(LOG_TAG$8,message);}}},{key:"clearOnlineStateTimer",value:function clearOnlineStateTimer(){if(this.onlineStateTimer!==null){this.onlineStateTimer.cancel();this.onlineStateTimer=null;}}}]);return OnlineStateTracker;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$9='RemoteStore';// TODO(b/35853402): Negotiate this with the stream.
var MAX_PENDING_WRITES=10;var RemoteStoreImpl=function RemoteStoreImpl(/**
     * The local store, used to fill the write pipeline with outbound mutations.
     */localStore,/** The client-side proxy for interacting with the backend. */datastore,asyncQueue,onlineStateHandler,connectivityMonitor){var _this117=this;_classCallCheck(this,RemoteStoreImpl);this.localStore=localStore;this.datastore=datastore;this.asyncQueue=asyncQueue;this.remoteSyncer={};/**
         * A list of up to MAX_PENDING_WRITES writes that we have fetched from the
         * LocalStore via fillWritePipeline() and have or will send to the write
         * stream.
         *
         * Whenever writePipeline.length > 0 the RemoteStore will attempt to start or
         * restart the write stream. When the stream is established the writes in the
         * pipeline will be sent in order.
         *
         * Writes remain in writePipeline until they are acknowledged by the backend
         * and thus will automatically be re-sent if the stream is interrupted /
         * restarted before they're acknowledged.
         *
         * Write responses from the backend are linked to their originating request
         * purely based on order, and so we can just shift() writes from the front of
         * the writePipeline as we receive responses.
         */this.writePipeline=[];/**
         * A mapping of watched targets that the client cares about tracking and the
         * user has explicitly called a 'listen' for this target.
         *
         * These targets may or may not have been sent to or acknowledged by the
         * server. On re-establishing the listen stream, these targets should be sent
         * to the server. The targets removed with unlistens are removed eagerly
         * without waiting for confirmation from the listen stream.
         */this.listenTargets=new Map();/**
         * A set of reasons for why the RemoteStore may be offline. If empty, the
         * RemoteStore may start its network connections.
         */this.offlineCauses=new Set();/**
         * Event handlers that get called when the network is disabled or enabled.
         *
         * PORTING NOTE: These functions are used on the Web client to create the
         * underlying streams (to support tree-shakeable streams). On Android and iOS,
         * the streams are created during construction of RemoteStore.
         */this.onNetworkStatusChange=[];this.connectivityMonitor=connectivityMonitor;this.connectivityMonitor.addCallback(function(_){asyncQueue.enqueueAndForget(function _callee8(){return regeneratorRuntime.async(function _callee8$(_context25){while(1){switch(_context25.prev=_context25.next){case 0:if(!canUseNetwork(_this117)){_context25.next=4;break;}logDebug(LOG_TAG$9,'Restarting streams for network reachability change.');_context25.next=4;return regeneratorRuntime.awrap(restartNetwork(_this117));case 4:case"end":return _context25.stop();}}});});});this.onlineStateTracker=new OnlineStateTracker(asyncQueue,onlineStateHandler);};function newRemoteStore(localStore,datastore,asyncQueue,onlineStateHandler,connectivityMonitor){return new RemoteStoreImpl(localStore,datastore,asyncQueue,onlineStateHandler,connectivityMonitor);}/** Re-enables the network. Idempotent. */function remoteStoreEnableNetwork(remoteStore){var remoteStoreImpl=debugCast(remoteStore);remoteStoreImpl.offlineCauses["delete"](0/* UserDisabled */);return enableNetworkInternal(remoteStoreImpl);}function enableNetworkInternal(remoteStoreImpl){var _iteratorNormalCompletion43,_didIteratorError43,_iteratorError43,_iterator43,_step43,networkStatusHandler;return regeneratorRuntime.async(function enableNetworkInternal$(_context26){while(1){switch(_context26.prev=_context26.next){case 0:if(!canUseNetwork(remoteStoreImpl)){_context26.next=27;break;}_iteratorNormalCompletion43=true;_didIteratorError43=false;_iteratorError43=undefined;_context26.prev=4;_iterator43=remoteStoreImpl.onNetworkStatusChange[Symbol.iterator]();case 6:if(_iteratorNormalCompletion43=(_step43=_iterator43.next()).done){_context26.next=13;break;}networkStatusHandler=_step43.value;_context26.next=10;return regeneratorRuntime.awrap(networkStatusHandler(/* enabled= */true));case 10:_iteratorNormalCompletion43=true;_context26.next=6;break;case 13:_context26.next=19;break;case 15:_context26.prev=15;_context26.t0=_context26["catch"](4);_didIteratorError43=true;_iteratorError43=_context26.t0;case 19:_context26.prev=19;_context26.prev=20;if(!_iteratorNormalCompletion43&&_iterator43["return"]!=null){_iterator43["return"]();}case 22:_context26.prev=22;if(!_didIteratorError43){_context26.next=25;break;}throw _iteratorError43;case 25:return _context26.finish(22);case 26:return _context26.finish(19);case 27:case"end":return _context26.stop();}}},null,null,[[4,15,19,27],[20,,22,26]]);}/**
 * Temporarily disables the network. The network can be re-enabled using
 * enableNetwork().
 */function remoteStoreDisableNetwork(remoteStore){var remoteStoreImpl;return regeneratorRuntime.async(function remoteStoreDisableNetwork$(_context27){while(1){switch(_context27.prev=_context27.next){case 0:remoteStoreImpl=debugCast(remoteStore);remoteStoreImpl.offlineCauses.add(0/* UserDisabled */);_context27.next=4;return regeneratorRuntime.awrap(disableNetworkInternal(remoteStoreImpl));case 4:// Set the OnlineState to Offline so get()s return from cache, etc.
remoteStoreImpl.onlineStateTracker.set("Offline"/* Offline */);case 5:case"end":return _context27.stop();}}});}function disableNetworkInternal(remoteStoreImpl){var _iteratorNormalCompletion44,_didIteratorError44,_iteratorError44,_iterator44,_step44,networkStatusHandler;return regeneratorRuntime.async(function disableNetworkInternal$(_context28){while(1){switch(_context28.prev=_context28.next){case 0:_iteratorNormalCompletion44=true;_didIteratorError44=false;_iteratorError44=undefined;_context28.prev=3;_iterator44=remoteStoreImpl.onNetworkStatusChange[Symbol.iterator]();case 5:if(_iteratorNormalCompletion44=(_step44=_iterator44.next()).done){_context28.next=12;break;}networkStatusHandler=_step44.value;_context28.next=9;return regeneratorRuntime.awrap(networkStatusHandler(/* enabled= */false));case 9:_iteratorNormalCompletion44=true;_context28.next=5;break;case 12:_context28.next=18;break;case 14:_context28.prev=14;_context28.t0=_context28["catch"](3);_didIteratorError44=true;_iteratorError44=_context28.t0;case 18:_context28.prev=18;_context28.prev=19;if(!_iteratorNormalCompletion44&&_iterator44["return"]!=null){_iterator44["return"]();}case 21:_context28.prev=21;if(!_didIteratorError44){_context28.next=24;break;}throw _iteratorError44;case 24:return _context28.finish(21);case 25:return _context28.finish(18);case 26:case"end":return _context28.stop();}}},null,null,[[3,14,18,26],[19,,21,25]]);}function remoteStoreShutdown(remoteStore){var remoteStoreImpl;return regeneratorRuntime.async(function remoteStoreShutdown$(_context29){while(1){switch(_context29.prev=_context29.next){case 0:remoteStoreImpl=debugCast(remoteStore);logDebug(LOG_TAG$9,'RemoteStore shutting down.');remoteStoreImpl.offlineCauses.add(5/* Shutdown */);_context29.next=5;return regeneratorRuntime.awrap(disableNetworkInternal(remoteStoreImpl));case 5:remoteStoreImpl.connectivityMonitor.shutdown();// Set the OnlineState to Unknown (rather than Offline) to avoid potentially
// triggering spurious listener events with cached data, etc.
remoteStoreImpl.onlineStateTracker.set("Unknown"/* Unknown */);case 7:case"end":return _context29.stop();}}});}/**
 * Starts new listen for the given target. Uses resume token if provided. It
 * is a no-op if the target of given `TargetData` is already being listened to.
 */function remoteStoreListen(remoteStore,targetData){var remoteStoreImpl=debugCast(remoteStore);if(remoteStoreImpl.listenTargets.has(targetData.targetId)){return;}// Mark this as something the client is currently listening for.
remoteStoreImpl.listenTargets.set(targetData.targetId,targetData);if(shouldStartWatchStream(remoteStoreImpl)){// The listen will be sent in onWatchStreamOpen
startWatchStream(remoteStoreImpl);}else if(ensureWatchStream(remoteStoreImpl).isOpen()){sendWatchRequest(remoteStoreImpl,targetData);}}/**
 * Removes the listen from server. It is a no-op if the given target id is
 * not being listened to.
 */function remoteStoreUnlisten(remoteStore,targetId){var remoteStoreImpl=debugCast(remoteStore);var watchStream=ensureWatchStream(remoteStoreImpl);remoteStoreImpl.listenTargets["delete"](targetId);if(watchStream.isOpen()){sendUnwatchRequest(remoteStoreImpl,targetId);}if(remoteStoreImpl.listenTargets.size===0){if(watchStream.isOpen()){watchStream.markIdle();}else if(canUseNetwork(remoteStoreImpl)){// Revert to OnlineState.Unknown if the watch stream is not open and we
// have no listeners, since without any listens to send we cannot
// confirm if the stream is healthy and upgrade to OnlineState.Online.
remoteStoreImpl.onlineStateTracker.set("Unknown"/* Unknown */);}}}/**
 * We need to increment the the expected number of pending responses we're due
 * from watch so we wait for the ack to process any messages from this target.
 */function sendWatchRequest(remoteStoreImpl,targetData){remoteStoreImpl.watchChangeAggregator.recordPendingTargetRequest(targetData.targetId);ensureWatchStream(remoteStoreImpl).watch(targetData);}/**
 * We need to increment the expected number of pending responses we're due
 * from watch so we wait for the removal on the server before we process any
 * messages from this target.
 */function sendUnwatchRequest(remoteStoreImpl,targetId){remoteStoreImpl.watchChangeAggregator.recordPendingTargetRequest(targetId);ensureWatchStream(remoteStoreImpl).unwatch(targetId);}function startWatchStream(remoteStoreImpl){remoteStoreImpl.watchChangeAggregator=new WatchChangeAggregator({getRemoteKeysForTarget:function getRemoteKeysForTarget(targetId){return remoteStoreImpl.remoteSyncer.getRemoteKeysForTarget(targetId);},getTargetDataForTarget:function getTargetDataForTarget(targetId){return remoteStoreImpl.listenTargets.get(targetId)||null;}});ensureWatchStream(remoteStoreImpl).start();remoteStoreImpl.onlineStateTracker.handleWatchStreamStart();}/**
 * Returns whether the watch stream should be started because it's necessary
 * and has not yet been started.
 */function shouldStartWatchStream(remoteStoreImpl){return canUseNetwork(remoteStoreImpl)&&!ensureWatchStream(remoteStoreImpl).isStarted()&&remoteStoreImpl.listenTargets.size>0;}function canUseNetwork(remoteStore){var remoteStoreImpl=debugCast(remoteStore);return remoteStoreImpl.offlineCauses.size===0;}function cleanUpWatchStreamState(remoteStoreImpl){remoteStoreImpl.watchChangeAggregator=undefined;}function onWatchStreamOpen(remoteStoreImpl){return regeneratorRuntime.async(function onWatchStreamOpen$(_context30){while(1){switch(_context30.prev=_context30.next){case 0:remoteStoreImpl.listenTargets.forEach(function(targetData,targetId){sendWatchRequest(remoteStoreImpl,targetData);});case 1:case"end":return _context30.stop();}}});}function onWatchStreamClose(remoteStoreImpl,error){return regeneratorRuntime.async(function onWatchStreamClose$(_context31){while(1){switch(_context31.prev=_context31.next){case 0:cleanUpWatchStreamState(remoteStoreImpl);// If we still need the watch stream, retry the connection.
if(shouldStartWatchStream(remoteStoreImpl)){remoteStoreImpl.onlineStateTracker.handleWatchStreamFailure(error);startWatchStream(remoteStoreImpl);}else{// No need to restart watch stream because there are no active targets.
// The online state is set to unknown because there is no active attempt
// at establishing a connection
remoteStoreImpl.onlineStateTracker.set("Unknown"/* Unknown */);}case 2:case"end":return _context31.stop();}}});}function onWatchStreamChange(remoteStoreImpl,watchChange,snapshotVersion){var lastRemoteSnapshotVersion;return regeneratorRuntime.async(function onWatchStreamChange$(_context32){while(1){switch(_context32.prev=_context32.next){case 0:// Mark the client as online since we got a message from the server
remoteStoreImpl.onlineStateTracker.set("Online"/* Online */);if(!(watchChange instanceof WatchTargetChange&&watchChange.state===2/* Removed */&&watchChange.cause)){_context32.next=13;break;}_context32.prev=2;_context32.next=5;return regeneratorRuntime.awrap(handleTargetError(remoteStoreImpl,watchChange));case 5:_context32.next=12;break;case 7:_context32.prev=7;_context32.t0=_context32["catch"](2);logDebug(LOG_TAG$9,'Failed to remove targets %s: %s ',watchChange.targetIds.join(','),_context32.t0);_context32.next=12;return regeneratorRuntime.awrap(disableNetworkUntilRecovery(remoteStoreImpl,_context32.t0));case 12:return _context32.abrupt("return");case 13:if(watchChange instanceof DocumentWatchChange){remoteStoreImpl.watchChangeAggregator.handleDocumentChange(watchChange);}else if(watchChange instanceof ExistenceFilterChange){remoteStoreImpl.watchChangeAggregator.handleExistenceFilter(watchChange);}else{remoteStoreImpl.watchChangeAggregator.handleTargetChange(watchChange);}if(snapshotVersion.isEqual(SnapshotVersion.min())){_context32.next=29;break;}_context32.prev=15;_context32.next=18;return regeneratorRuntime.awrap(getLastRemoteSnapshotVersion(remoteStoreImpl.localStore));case 18:lastRemoteSnapshotVersion=_context32.sent;if(!(snapshotVersion.compareTo(lastRemoteSnapshotVersion)>=0)){_context32.next=22;break;}_context32.next=22;return regeneratorRuntime.awrap(raiseWatchSnapshot(remoteStoreImpl,snapshotVersion));case 22:_context32.next=29;break;case 24:_context32.prev=24;_context32.t1=_context32["catch"](15);logDebug(LOG_TAG$9,'Failed to raise snapshot:',_context32.t1);_context32.next=29;return regeneratorRuntime.awrap(disableNetworkUntilRecovery(remoteStoreImpl,_context32.t1));case 29:case"end":return _context32.stop();}}},null,null,[[2,7],[15,24]]);}/**
 * Recovery logic for IndexedDB errors that takes the network offline until
 * `op` succeeds. Retries are scheduled with backoff using
 * `enqueueRetryable()`. If `op()` is not provided, IndexedDB access is
 * validated via a generic operation.
 *
 * The returned Promise is resolved once the network is disabled and before
 * any retry attempt.
 */function disableNetworkUntilRecovery(remoteStoreImpl,e,op){return regeneratorRuntime.async(function disableNetworkUntilRecovery$(_context34){while(1){switch(_context34.prev=_context34.next){case 0:if(!isIndexedDbTransactionError(e)){_context34.next=9;break;}remoteStoreImpl.offlineCauses.add(1/* IndexedDbFailed */);// Disable network and raise offline snapshots
_context34.next=4;return regeneratorRuntime.awrap(disableNetworkInternal(remoteStoreImpl));case 4:remoteStoreImpl.onlineStateTracker.set("Offline"/* Offline */);if(!op){// Use a simple read operation to determine if IndexedDB recovered.
// Ideally, we would expose a health check directly on SimpleDb, but
// RemoteStore only has access to persistence through LocalStore.
op=function op(){return getLastRemoteSnapshotVersion(remoteStoreImpl.localStore);};}// Probe IndexedDB periodically and re-enable network
remoteStoreImpl.asyncQueue.enqueueRetryable(function _callee9(){return regeneratorRuntime.async(function _callee9$(_context33){while(1){switch(_context33.prev=_context33.next){case 0:logDebug(LOG_TAG$9,'Retrying IndexedDB access');_context33.next=3;return regeneratorRuntime.awrap(op());case 3:remoteStoreImpl.offlineCauses["delete"](1/* IndexedDbFailed */);_context33.next=6;return regeneratorRuntime.awrap(enableNetworkInternal(remoteStoreImpl));case 6:case"end":return _context33.stop();}}});});_context34.next=10;break;case 9:throw e;case 10:case"end":return _context34.stop();}}});}/**
 * Executes `op`. If `op` fails, takes the network offline until `op`
 * succeeds. Returns after the first attempt.
 */function executeWithRecovery(remoteStoreImpl,op){return op()["catch"](function(e){return disableNetworkUntilRecovery(remoteStoreImpl,e,op);});}/**
 * Takes a batch of changes from the Datastore, repackages them as a
 * RemoteEvent, and passes that on to the listener, which is typically the
 * SyncEngine.
 */function raiseWatchSnapshot(remoteStoreImpl,snapshotVersion){var remoteEvent=remoteStoreImpl.watchChangeAggregator.createRemoteEvent(snapshotVersion);// Update in-memory resume tokens. LocalStore will update the
// persistent view of these when applying the completed RemoteEvent.
remoteEvent.targetChanges.forEach(function(change,targetId){if(change.resumeToken.approximateByteSize()>0){var targetData=remoteStoreImpl.listenTargets.get(targetId);// A watched target might have been removed already.
if(targetData){remoteStoreImpl.listenTargets.set(targetId,targetData.withResumeToken(change.resumeToken,snapshotVersion));}}});// Re-establish listens for the targets that have been invalidated by
// existence filter mismatches.
remoteEvent.targetMismatches.forEach(function(targetId){var targetData=remoteStoreImpl.listenTargets.get(targetId);if(!targetData){// A watched target might have been removed already.
return;}// Clear the resume token for the target, since we're in a known mismatch
// state.
remoteStoreImpl.listenTargets.set(targetId,targetData.withResumeToken(ByteString.EMPTY_BYTE_STRING,targetData.snapshotVersion));// Cause a hard reset by unwatching and rewatching immediately, but
// deliberately don't send a resume token so that we get a full update.
sendUnwatchRequest(remoteStoreImpl,targetId);// Mark the target we send as being on behalf of an existence filter
// mismatch, but don't actually retain that in listenTargets. This ensures
// that we flag the first re-listen this way without impacting future
// listens of this target (that might happen e.g. on reconnect).
var requestTargetData=new TargetData(targetData.target,targetId,1/* ExistenceFilterMismatch */,targetData.sequenceNumber);sendWatchRequest(remoteStoreImpl,requestTargetData);});return remoteStoreImpl.remoteSyncer.applyRemoteEvent(remoteEvent);}/** Handles an error on a target */function handleTargetError(remoteStoreImpl,watchChange){var error,_iteratorNormalCompletion45,_didIteratorError45,_iteratorError45,_iterator45,_step45,targetId;return regeneratorRuntime.async(function handleTargetError$(_context35){while(1){switch(_context35.prev=_context35.next){case 0:error=watchChange.cause;_iteratorNormalCompletion45=true;_didIteratorError45=false;_iteratorError45=undefined;_context35.prev=4;_iterator45=watchChange.targetIds[Symbol.iterator]();case 6:if(_iteratorNormalCompletion45=(_step45=_iterator45.next()).done){_context35.next=16;break;}targetId=_step45.value;if(!remoteStoreImpl.listenTargets.has(targetId)){_context35.next=13;break;}_context35.next=11;return regeneratorRuntime.awrap(remoteStoreImpl.remoteSyncer.rejectListen(targetId,error));case 11:remoteStoreImpl.listenTargets["delete"](targetId);remoteStoreImpl.watchChangeAggregator.removeTarget(targetId);case 13:_iteratorNormalCompletion45=true;_context35.next=6;break;case 16:_context35.next=22;break;case 18:_context35.prev=18;_context35.t0=_context35["catch"](4);_didIteratorError45=true;_iteratorError45=_context35.t0;case 22:_context35.prev=22;_context35.prev=23;if(!_iteratorNormalCompletion45&&_iterator45["return"]!=null){_iterator45["return"]();}case 25:_context35.prev=25;if(!_didIteratorError45){_context35.next=28;break;}throw _iteratorError45;case 28:return _context35.finish(25);case 29:return _context35.finish(22);case 30:case"end":return _context35.stop();}}},null,null,[[4,18,22,30],[23,,25,29]]);}/**
 * Attempts to fill our write pipeline with writes from the LocalStore.
 *
 * Called internally to bootstrap or refill the write pipeline and by
 * SyncEngine whenever there are new mutations to process.
 *
 * Starts the write stream if necessary.
 */function fillWritePipeline(remoteStore){var remoteStoreImpl,writeStream,lastBatchIdRetrieved,batch;return regeneratorRuntime.async(function fillWritePipeline$(_context36){while(1){switch(_context36.prev=_context36.next){case 0:remoteStoreImpl=debugCast(remoteStore);writeStream=ensureWriteStream(remoteStoreImpl);lastBatchIdRetrieved=remoteStoreImpl.writePipeline.length>0?remoteStoreImpl.writePipeline[remoteStoreImpl.writePipeline.length-1].batchId:BATCHID_UNKNOWN;case 3:if(!canAddToWritePipeline(remoteStoreImpl)){_context36.next=23;break;}_context36.prev=4;_context36.next=7;return regeneratorRuntime.awrap(nextMutationBatch(remoteStoreImpl.localStore,lastBatchIdRetrieved));case 7:batch=_context36.sent;if(!(batch===null)){_context36.next=13;break;}if(remoteStoreImpl.writePipeline.length===0){writeStream.markIdle();}return _context36.abrupt("break",23);case 13:lastBatchIdRetrieved=batch.batchId;addToWritePipeline(remoteStoreImpl,batch);case 15:_context36.next=21;break;case 17:_context36.prev=17;_context36.t0=_context36["catch"](4);_context36.next=21;return regeneratorRuntime.awrap(disableNetworkUntilRecovery(remoteStoreImpl,_context36.t0));case 21:_context36.next=3;break;case 23:if(shouldStartWriteStream(remoteStoreImpl)){startWriteStream(remoteStoreImpl);}case 24:case"end":return _context36.stop();}}},null,null,[[4,17]]);}/**
 * Returns true if we can add to the write pipeline (i.e. the network is
 * enabled and the write pipeline is not full).
 */function canAddToWritePipeline(remoteStoreImpl){return canUseNetwork(remoteStoreImpl)&&remoteStoreImpl.writePipeline.length<MAX_PENDING_WRITES;}/**
 * Queues additional writes to be sent to the write stream, sending them
 * immediately if the write stream is established.
 */function addToWritePipeline(remoteStoreImpl,batch){remoteStoreImpl.writePipeline.push(batch);var writeStream=ensureWriteStream(remoteStoreImpl);if(writeStream.isOpen()&&writeStream.handshakeComplete){writeStream.writeMutations(batch.mutations);}}function shouldStartWriteStream(remoteStoreImpl){return canUseNetwork(remoteStoreImpl)&&!ensureWriteStream(remoteStoreImpl).isStarted()&&remoteStoreImpl.writePipeline.length>0;}function startWriteStream(remoteStoreImpl){ensureWriteStream(remoteStoreImpl).start();}function onWriteStreamOpen(remoteStoreImpl){return regeneratorRuntime.async(function onWriteStreamOpen$(_context37){while(1){switch(_context37.prev=_context37.next){case 0:ensureWriteStream(remoteStoreImpl).writeHandshake();case 1:case"end":return _context37.stop();}}});}function onWriteHandshakeComplete(remoteStoreImpl){var writeStream,_iteratorNormalCompletion46,_didIteratorError46,_iteratorError46,_iterator46,_step46,batch;return regeneratorRuntime.async(function onWriteHandshakeComplete$(_context38){while(1){switch(_context38.prev=_context38.next){case 0:writeStream=ensureWriteStream(remoteStoreImpl);// Send the write pipeline now that the stream is established.
_iteratorNormalCompletion46=true;_didIteratorError46=false;_iteratorError46=undefined;_context38.prev=4;for(_iterator46=remoteStoreImpl.writePipeline[Symbol.iterator]();!(_iteratorNormalCompletion46=(_step46=_iterator46.next()).done);_iteratorNormalCompletion46=true){batch=_step46.value;writeStream.writeMutations(batch.mutations);}_context38.next=12;break;case 8:_context38.prev=8;_context38.t0=_context38["catch"](4);_didIteratorError46=true;_iteratorError46=_context38.t0;case 12:_context38.prev=12;_context38.prev=13;if(!_iteratorNormalCompletion46&&_iterator46["return"]!=null){_iterator46["return"]();}case 15:_context38.prev=15;if(!_didIteratorError46){_context38.next=18;break;}throw _iteratorError46;case 18:return _context38.finish(15);case 19:return _context38.finish(12);case 20:case"end":return _context38.stop();}}},null,null,[[4,8,12,20],[13,,15,19]]);}function onMutationResult(remoteStoreImpl,commitVersion,results){var batch,success;return regeneratorRuntime.async(function onMutationResult$(_context39){while(1){switch(_context39.prev=_context39.next){case 0:batch=remoteStoreImpl.writePipeline.shift();success=MutationBatchResult.from(batch,commitVersion,results);_context39.next=4;return regeneratorRuntime.awrap(executeWithRecovery(remoteStoreImpl,function(){return remoteStoreImpl.remoteSyncer.applySuccessfulWrite(success);}));case 4:_context39.next=6;return regeneratorRuntime.awrap(fillWritePipeline(remoteStoreImpl));case 6:case"end":return _context39.stop();}}});}function onWriteStreamClose(remoteStoreImpl,error){return regeneratorRuntime.async(function onWriteStreamClose$(_context40){while(1){switch(_context40.prev=_context40.next){case 0:if(!(error&&ensureWriteStream(remoteStoreImpl).handshakeComplete)){_context40.next=3;break;}_context40.next=3;return regeneratorRuntime.awrap(handleWriteError(remoteStoreImpl,error));case 3:// The write stream might have been started by refilling the write
// pipeline for failed writes
if(shouldStartWriteStream(remoteStoreImpl)){startWriteStream(remoteStoreImpl);}case 4:case"end":return _context40.stop();}}});}function handleWriteError(remoteStoreImpl,error){var batch;return regeneratorRuntime.async(function handleWriteError$(_context41){while(1){switch(_context41.prev=_context41.next){case 0:if(!isPermanentWriteError(error.code)){_context41.next=7;break;}// This was a permanent error, the request itself was the problem
// so it's not going to succeed if we resend it.
batch=remoteStoreImpl.writePipeline.shift();// In this case it's also unlikely that the server itself is melting
// down -- this was just a bad request so inhibit backoff on the next
// restart.
ensureWriteStream(remoteStoreImpl).inhibitBackoff();_context41.next=5;return regeneratorRuntime.awrap(executeWithRecovery(remoteStoreImpl,function(){return remoteStoreImpl.remoteSyncer.rejectFailedWrite(batch.batchId,error);}));case 5:_context41.next=7;return regeneratorRuntime.awrap(fillWritePipeline(remoteStoreImpl));case 7:case"end":return _context41.stop();}}});}function restartNetwork(remoteStore){var remoteStoreImpl;return regeneratorRuntime.async(function restartNetwork$(_context42){while(1){switch(_context42.prev=_context42.next){case 0:remoteStoreImpl=debugCast(remoteStore);remoteStoreImpl.offlineCauses.add(4/* ConnectivityChange */);_context42.next=4;return regeneratorRuntime.awrap(disableNetworkInternal(remoteStoreImpl));case 4:remoteStoreImpl.onlineStateTracker.set("Unknown"/* Unknown */);remoteStoreImpl.offlineCauses["delete"](4/* ConnectivityChange */);_context42.next=8;return regeneratorRuntime.awrap(enableNetworkInternal(remoteStoreImpl));case 8:case"end":return _context42.stop();}}});}function remoteStoreHandleCredentialChange(remoteStore,user){var remoteStoreImpl,usesNetwork;return regeneratorRuntime.async(function remoteStoreHandleCredentialChange$(_context43){while(1){switch(_context43.prev=_context43.next){case 0:remoteStoreImpl=debugCast(remoteStore);remoteStoreImpl.asyncQueue.verifyOperationInProgress();logDebug(LOG_TAG$9,'RemoteStore received new credentials');usesNetwork=canUseNetwork(remoteStoreImpl);// Tear down and re-create our network streams. This will ensure we get a
// fresh auth token for the new user and re-fill the write pipeline with
// new mutations from the LocalStore (since mutations are per-user).
remoteStoreImpl.offlineCauses.add(3/* CredentialChange */);_context43.next=7;return regeneratorRuntime.awrap(disableNetworkInternal(remoteStoreImpl));case 7:if(usesNetwork){// Don't set the network status to Unknown if we are offline.
remoteStoreImpl.onlineStateTracker.set("Unknown"/* Unknown */);}_context43.next=10;return regeneratorRuntime.awrap(remoteStoreImpl.remoteSyncer.handleCredentialChange(user));case 10:remoteStoreImpl.offlineCauses["delete"](3/* CredentialChange */);_context43.next=13;return regeneratorRuntime.awrap(enableNetworkInternal(remoteStoreImpl));case 13:case"end":return _context43.stop();}}});}/**
 * Toggles the network state when the client gains or loses its primary lease.
 */function remoteStoreApplyPrimaryState(remoteStore,isPrimary){var remoteStoreImpl;return regeneratorRuntime.async(function remoteStoreApplyPrimaryState$(_context44){while(1){switch(_context44.prev=_context44.next){case 0:remoteStoreImpl=debugCast(remoteStore);if(!isPrimary){_context44.next=7;break;}remoteStoreImpl.offlineCauses["delete"](2/* IsSecondary */);_context44.next=5;return regeneratorRuntime.awrap(enableNetworkInternal(remoteStoreImpl));case 5:_context44.next=12;break;case 7:if(isPrimary){_context44.next=12;break;}remoteStoreImpl.offlineCauses.add(2/* IsSecondary */);_context44.next=11;return regeneratorRuntime.awrap(disableNetworkInternal(remoteStoreImpl));case 11:remoteStoreImpl.onlineStateTracker.set("Unknown"/* Unknown */);case 12:case"end":return _context44.stop();}}});}/**
 * If not yet initialized, registers the WatchStream and its network state
 * callback with `remoteStoreImpl`. Returns the existing stream if one is
 * already available.
 *
 * PORTING NOTE: On iOS and Android, the WatchStream gets registered on startup.
 * This is not done on Web to allow it to be tree-shaken.
 */function ensureWatchStream(remoteStoreImpl){if(!remoteStoreImpl.watchStream){// Create stream (but note that it is not started yet).
remoteStoreImpl.watchStream=newPersistentWatchStream(remoteStoreImpl.datastore,remoteStoreImpl.asyncQueue,{onOpen:onWatchStreamOpen.bind(null,remoteStoreImpl),onClose:onWatchStreamClose.bind(null,remoteStoreImpl),onWatchChange:onWatchStreamChange.bind(null,remoteStoreImpl)});remoteStoreImpl.onNetworkStatusChange.push(function _callee10(enabled){return regeneratorRuntime.async(function _callee10$(_context45){while(1){switch(_context45.prev=_context45.next){case 0:if(!enabled){_context45.next=5;break;}remoteStoreImpl.watchStream.inhibitBackoff();if(shouldStartWatchStream(remoteStoreImpl)){startWatchStream(remoteStoreImpl);}else{remoteStoreImpl.onlineStateTracker.set("Unknown"/* Unknown */);}_context45.next=8;break;case 5:_context45.next=7;return regeneratorRuntime.awrap(remoteStoreImpl.watchStream.stop());case 7:cleanUpWatchStreamState(remoteStoreImpl);case 8:case"end":return _context45.stop();}}});});}return remoteStoreImpl.watchStream;}/**
 * If not yet initialized, registers the WriteStream and its network state
 * callback with `remoteStoreImpl`. Returns the existing stream if one is
 * already available.
 *
 * PORTING NOTE: On iOS and Android, the WriteStream gets registered on startup.
 * This is not done on Web to allow it to be tree-shaken.
 */function ensureWriteStream(remoteStoreImpl){if(!remoteStoreImpl.writeStream){// Create stream (but note that it is not started yet).
remoteStoreImpl.writeStream=newPersistentWriteStream(remoteStoreImpl.datastore,remoteStoreImpl.asyncQueue,{onOpen:onWriteStreamOpen.bind(null,remoteStoreImpl),onClose:onWriteStreamClose.bind(null,remoteStoreImpl),onHandshakeComplete:onWriteHandshakeComplete.bind(null,remoteStoreImpl),onMutationResult:onMutationResult.bind(null,remoteStoreImpl)});remoteStoreImpl.onNetworkStatusChange.push(function _callee11(enabled){return regeneratorRuntime.async(function _callee11$(_context46){while(1){switch(_context46.prev=_context46.next){case 0:if(!enabled){_context46.next=6;break;}remoteStoreImpl.writeStream.inhibitBackoff();// This will start the write stream if necessary.
_context46.next=4;return regeneratorRuntime.awrap(fillWritePipeline(remoteStoreImpl));case 4:_context46.next=9;break;case 6:_context46.next=8;return regeneratorRuntime.awrap(remoteStoreImpl.writeStream.stop());case 8:if(remoteStoreImpl.writePipeline.length>0){logDebug(LOG_TAG$9,"Stopping write stream with ".concat(remoteStoreImpl.writePipeline.length," pending writes"));remoteStoreImpl.writePipeline=[];}case 9:case"end":return _context46.stop();}}});});}return remoteStoreImpl.writeStream;}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * DocumentSet is an immutable (copy-on-write) collection that holds documents
 * in order specified by the provided comparator. We always add a document key
 * comparator on top of what is provided to guarantee document equality based on
 * the key.
 */var DocumentSet=/*#__PURE__*/function(){/** The default ordering is by key if the comparator is omitted */function DocumentSet(comp){_classCallCheck(this,DocumentSet);// We are adding document key comparator to the end as it's the only
// guaranteed unique property of a document.
if(comp){this.comparator=function(d1,d2){return comp(d1,d2)||DocumentKey.comparator(d1.key,d2.key);};}else{this.comparator=function(d1,d2){return DocumentKey.comparator(d1.key,d2.key);};}this.keyedMap=documentMap();this.sortedSet=new SortedMap(this.comparator);}/**
     * Returns an empty copy of the existing DocumentSet, using the same
     * comparator.
     */_createClass(DocumentSet,[{key:"has",value:function has(key){return this.keyedMap.get(key)!=null;}},{key:"get",value:function get(key){return this.keyedMap.get(key);}},{key:"first",value:function first(){return this.sortedSet.minKey();}},{key:"last",value:function last(){return this.sortedSet.maxKey();}},{key:"isEmpty",value:function isEmpty(){return this.sortedSet.isEmpty();}/**
     * Returns the index of the provided key in the document set, or -1 if the
     * document key is not present in the set;
     */},{key:"indexOf",value:function indexOf(key){var doc=this.keyedMap.get(key);return doc?this.sortedSet.indexOf(doc):-1;}},{key:"forEach",/** Iterates documents in order defined by "comparator" */value:function forEach(cb){this.sortedSet.inorderTraversal(function(k,v){cb(k);return false;});}/** Inserts or updates a document with the same key */},{key:"add",value:function add(doc){// First remove the element if we have it.
var set=this["delete"](doc.key);return set.copy(set.keyedMap.insert(doc.key,doc),set.sortedSet.insert(doc,null));}/** Deletes a document with a given key */},{key:"delete",value:function _delete(key){var doc=this.get(key);if(!doc){return this;}return this.copy(this.keyedMap.remove(key),this.sortedSet.remove(doc));}},{key:"isEqual",value:function isEqual(other){if(!(other instanceof DocumentSet)){return false;}if(this.size!==other.size){return false;}var thisIt=this.sortedSet.getIterator();var otherIt=other.sortedSet.getIterator();while(thisIt.hasNext()){var thisDoc=thisIt.getNext().key;var otherDoc=otherIt.getNext().key;if(!thisDoc.isEqual(otherDoc)){return false;}}return true;}},{key:"toString",value:function toString(){var docStrings=[];this.forEach(function(doc){docStrings.push(doc.toString());});if(docStrings.length===0){return'DocumentSet ()';}else{return'DocumentSet (\n  '+docStrings.join('  \n')+'\n)';}}},{key:"copy",value:function copy(keyedMap,sortedSet){var newSet=new DocumentSet();newSet.comparator=this.comparator;newSet.keyedMap=keyedMap;newSet.sortedSet=sortedSet;return newSet;}},{key:"size",get:function get(){return this.sortedSet.size;}}],[{key:"emptySet",value:function emptySet(oldSet){return new DocumentSet(oldSet.comparator);}}]);return DocumentSet;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * DocumentChangeSet keeps track of a set of changes to docs in a query, merging
 * duplicate events for the same doc.
 */var DocumentChangeSet=/*#__PURE__*/function(){function DocumentChangeSet(){_classCallCheck(this,DocumentChangeSet);this.changeMap=new SortedMap(DocumentKey.comparator);}_createClass(DocumentChangeSet,[{key:"track",value:function track(change){var key=change.doc.key;var oldChange=this.changeMap.get(key);if(!oldChange){this.changeMap=this.changeMap.insert(key,change);return;}// Merge the new change with the existing change.
if(change.type!==0/* Added */&&oldChange.type===3/* Metadata */){this.changeMap=this.changeMap.insert(key,change);}else if(change.type===3/* Metadata */&&oldChange.type!==1/* Removed */){this.changeMap=this.changeMap.insert(key,{type:oldChange.type,doc:change.doc});}else if(change.type===2/* Modified */&&oldChange.type===2/* Modified */){this.changeMap=this.changeMap.insert(key,{type:2/* Modified */,doc:change.doc});}else if(change.type===2/* Modified */&&oldChange.type===0/* Added */){this.changeMap=this.changeMap.insert(key,{type:0/* Added */,doc:change.doc});}else if(change.type===1/* Removed */&&oldChange.type===0/* Added */){this.changeMap=this.changeMap.remove(key);}else if(change.type===1/* Removed */&&oldChange.type===2/* Modified */){this.changeMap=this.changeMap.insert(key,{type:1/* Removed */,doc:oldChange.doc});}else if(change.type===0/* Added */&&oldChange.type===1/* Removed */){this.changeMap=this.changeMap.insert(key,{type:2/* Modified */,doc:change.doc});}else{// This includes these cases, which don't make sense:
// Added->Added
// Removed->Removed
// Modified->Added
// Removed->Modified
// Metadata->Added
// Removed->Metadata
fail();}}},{key:"getChanges",value:function getChanges(){var changes=[];this.changeMap.inorderTraversal(function(key,change){changes.push(change);});return changes;}}]);return DocumentChangeSet;}();var ViewSnapshot=/*#__PURE__*/function(){function ViewSnapshot(query,docs,oldDocs,docChanges,mutatedKeys,fromCache,syncStateChanged,excludesMetadataChanges){_classCallCheck(this,ViewSnapshot);this.query=query;this.docs=docs;this.oldDocs=oldDocs;this.docChanges=docChanges;this.mutatedKeys=mutatedKeys;this.fromCache=fromCache;this.syncStateChanged=syncStateChanged;this.excludesMetadataChanges=excludesMetadataChanges;}/** Returns a view snapshot as if all documents in the snapshot were added. */_createClass(ViewSnapshot,[{key:"isEqual",value:function isEqual(other){if(this.fromCache!==other.fromCache||this.syncStateChanged!==other.syncStateChanged||!this.mutatedKeys.isEqual(other.mutatedKeys)||!queryEquals(this.query,other.query)||!this.docs.isEqual(other.docs)||!this.oldDocs.isEqual(other.oldDocs)){return false;}var changes=this.docChanges;var otherChanges=other.docChanges;if(changes.length!==otherChanges.length){return false;}for(var i=0;i<changes.length;i++){if(changes[i].type!==otherChanges[i].type||!changes[i].doc.isEqual(otherChanges[i].doc)){return false;}}return true;}},{key:"hasPendingWrites",get:function get(){return!this.mutatedKeys.isEmpty();}}],[{key:"fromInitialDocuments",value:function fromInitialDocuments(query,documents,mutatedKeys,fromCache){var changes=[];documents.forEach(function(doc){changes.push({type:0/* Added */,doc:doc});});return new ViewSnapshot(query,documents,DocumentSet.emptySet(documents),changes,mutatedKeys,fromCache,/* syncStateChanged= */true,/* excludesMetadataChanges= */false);}}]);return ViewSnapshot;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var AddedLimboDocument=function AddedLimboDocument(key){_classCallCheck(this,AddedLimboDocument);this.key=key;};var RemovedLimboDocument=function RemovedLimboDocument(key){_classCallCheck(this,RemovedLimboDocument);this.key=key;};/**
 * View is responsible for computing the final merged truth of what docs are in
 * a query. It gets notified of local and remote changes to docs, and applies
 * the query filters and limits to determine the most correct possible results.
 */var View=/*#__PURE__*/function(){function View(query,/** Documents included in the remote target */_syncedDocuments){_classCallCheck(this,View);this.query=query;this._syncedDocuments=_syncedDocuments;this.syncState=null;/**
         * A flag whether the view is current with the backend. A view is considered
         * current after it has seen the current flag from the backend and did not
         * lose consistency within the watch stream (e.g. because of an existence
         * filter mismatch).
         */this.current=false;/** Documents in the view but not in the remote target */this.limboDocuments=documentKeySet();/** Document Keys that have local changes */this.mutatedKeys=documentKeySet();this.docComparator=newQueryComparator(query);this.documentSet=new DocumentSet(this.docComparator);}/**
     * The set of remote documents that the server has told us belongs to the target associated with
     * this view.
     */_createClass(View,[{key:"computeDocChanges",/**
     * Iterates over a set of doc changes, applies the query limit, and computes
     * what the new results should be, what the changes were, and whether we may
     * need to go back to the local cache for more results. Does not make any
     * changes to the view.
     * @param docChanges The doc changes to apply to this view.
     * @param previousChanges If this is being called with a refill, then start
     *        with this set of docs and changes instead of the current view.
     * @return a new set of docs, changes, and refill flag.
     */value:function computeDocChanges(docChanges,previousChanges){var _this118=this;var changeSet=previousChanges?previousChanges.changeSet:new DocumentChangeSet();var oldDocumentSet=previousChanges?previousChanges.documentSet:this.documentSet;var newMutatedKeys=previousChanges?previousChanges.mutatedKeys:this.mutatedKeys;var newDocumentSet=oldDocumentSet;var needsRefill=false;// Track the last doc in a (full) limit. This is necessary, because some
// update (a delete, or an update moving a doc past the old limit) might
// mean there is some other document in the local cache that either should
// come (1) between the old last limit doc and the new last document, in the
// case of updates, or (2) after the new last document, in the case of
// deletes. So we keep this doc at the old limit to compare the updates to.
//
// Note that this should never get used in a refill (when previousChanges is
// set), because there will only be adds -- no deletes or updates.
var lastDocInLimit=hasLimitToFirst(this.query)&&oldDocumentSet.size===this.query.limit?oldDocumentSet.last():null;var firstDocInLimit=hasLimitToLast(this.query)&&oldDocumentSet.size===this.query.limit?oldDocumentSet.first():null;docChanges.inorderTraversal(function(key,newMaybeDoc){var oldDoc=oldDocumentSet.get(key);var newDoc=newMaybeDoc instanceof Document?newMaybeDoc:null;if(newDoc){newDoc=queryMatches(_this118.query,newDoc)?newDoc:null;}var oldDocHadPendingMutations=oldDoc?_this118.mutatedKeys.has(oldDoc.key):false;var newDocHasPendingMutations=newDoc?newDoc.hasLocalMutations||// We only consider committed mutations for documents that were
// mutated during the lifetime of the view.
_this118.mutatedKeys.has(newDoc.key)&&newDoc.hasCommittedMutations:false;var changeApplied=false;// Calculate change
if(oldDoc&&newDoc){var docsEqual=oldDoc.data().isEqual(newDoc.data());if(!docsEqual){if(!_this118.shouldWaitForSyncedDocument(oldDoc,newDoc)){changeSet.track({type:2/* Modified */,doc:newDoc});changeApplied=true;if(lastDocInLimit&&_this118.docComparator(newDoc,lastDocInLimit)>0||firstDocInLimit&&_this118.docComparator(newDoc,firstDocInLimit)<0){// This doc moved from inside the limit to outside the limit.
// That means there may be some other doc in the local cache
// that should be included instead.
needsRefill=true;}}}else if(oldDocHadPendingMutations!==newDocHasPendingMutations){changeSet.track({type:3/* Metadata */,doc:newDoc});changeApplied=true;}}else if(!oldDoc&&newDoc){changeSet.track({type:0/* Added */,doc:newDoc});changeApplied=true;}else if(oldDoc&&!newDoc){changeSet.track({type:1/* Removed */,doc:oldDoc});changeApplied=true;if(lastDocInLimit||firstDocInLimit){// A doc was removed from a full limit query. We'll need to
// requery from the local cache to see if we know about some other
// doc that should be in the results.
needsRefill=true;}}if(changeApplied){if(newDoc){newDocumentSet=newDocumentSet.add(newDoc);if(newDocHasPendingMutations){newMutatedKeys=newMutatedKeys.add(key);}else{newMutatedKeys=newMutatedKeys["delete"](key);}}else{newDocumentSet=newDocumentSet["delete"](key);newMutatedKeys=newMutatedKeys["delete"](key);}}});// Drop documents out to meet limit/limitToLast requirement.
if(hasLimitToFirst(this.query)||hasLimitToLast(this.query)){while(newDocumentSet.size>this.query.limit){var oldDoc=hasLimitToFirst(this.query)?newDocumentSet.last():newDocumentSet.first();newDocumentSet=newDocumentSet["delete"](oldDoc.key);newMutatedKeys=newMutatedKeys["delete"](oldDoc.key);changeSet.track({type:1/* Removed */,doc:oldDoc});}}return{documentSet:newDocumentSet,changeSet:changeSet,needsRefill:needsRefill,mutatedKeys:newMutatedKeys};}},{key:"shouldWaitForSyncedDocument",value:function shouldWaitForSyncedDocument(oldDoc,newDoc){// We suppress the initial change event for documents that were modified as
// part of a write acknowledgment (e.g. when the value of a server transform
// is applied) as Watch will send us the same document again.
// By suppressing the event, we only raise two user visible events (one with
// `hasPendingWrites` and the final state of the document) instead of three
// (one with `hasPendingWrites`, the modified document with
// `hasPendingWrites` and the final state of the document).
return oldDoc.hasLocalMutations&&newDoc.hasCommittedMutations&&!newDoc.hasLocalMutations;}/**
     * Updates the view with the given ViewDocumentChanges and optionally updates
     * limbo docs and sync state from the provided target change.
     * @param docChanges The set of changes to make to the view's docs.
     * @param updateLimboDocuments Whether to update limbo documents based on this
     *        change.
     * @param targetChange A target change to apply for computing limbo docs and
     *        sync state.
     * @return A new ViewChange with the given docs, changes, and sync state.
     */ // PORTING NOTE: The iOS/Android clients always compute limbo document changes.
},{key:"applyChanges",value:function applyChanges(docChanges,updateLimboDocuments,targetChange){var _this119=this;var oldDocs=this.documentSet;this.documentSet=docChanges.documentSet;this.mutatedKeys=docChanges.mutatedKeys;// Sort changes based on type and query comparator
var changes=docChanges.changeSet.getChanges();changes.sort(function(c1,c2){return compareChangeType(c1.type,c2.type)||_this119.docComparator(c1.doc,c2.doc);});this.applyTargetChange(targetChange);var limboChanges=updateLimboDocuments?this.updateLimboDocuments():[];var synced=this.limboDocuments.size===0&&this.current;var newSyncState=synced?1/* Synced */:0/* Local */;var syncStateChanged=newSyncState!==this.syncState;this.syncState=newSyncState;if(changes.length===0&&!syncStateChanged){// no changes
return{limboChanges:limboChanges};}else{var snap=new ViewSnapshot(this.query,docChanges.documentSet,oldDocs,changes,docChanges.mutatedKeys,newSyncState===0/* Local */,syncStateChanged,/* excludesMetadataChanges= */false);return{snapshot:snap,limboChanges:limboChanges};}}/**
     * Applies an OnlineState change to the view, potentially generating a
     * ViewChange if the view's syncState changes as a result.
     */},{key:"applyOnlineStateChange",value:function applyOnlineStateChange(onlineState){if(this.current&&onlineState==="Offline"/* Offline */){// If we're offline, set `current` to false and then call applyChanges()
// to refresh our syncState and generate a ViewChange as appropriate. We
// are guaranteed to get a new TargetChange that sets `current` back to
// true once the client is back online.
this.current=false;return this.applyChanges({documentSet:this.documentSet,changeSet:new DocumentChangeSet(),mutatedKeys:this.mutatedKeys,needsRefill:false},/* updateLimboDocuments= */false);}else{// No effect, just return a no-op ViewChange.
return{limboChanges:[]};}}/**
     * Returns whether the doc for the given key should be in limbo.
     */},{key:"shouldBeInLimbo",value:function shouldBeInLimbo(key){// If the remote end says it's part of this query, it's not in limbo.
if(this._syncedDocuments.has(key)){return false;}// The local store doesn't think it's a result, so it shouldn't be in limbo.
if(!this.documentSet.has(key)){return false;}// If there are local changes to the doc, they might explain why the server
// doesn't know that it's part of the query. So don't put it in limbo.
// TODO(klimt): Ideally, we would only consider changes that might actually
// affect this specific query.
if(this.documentSet.get(key).hasLocalMutations){return false;}// Everything else is in limbo.
return true;}/**
     * Updates syncedDocuments, current, and limbo docs based on the given change.
     * Returns the list of changes to which docs are in limbo.
     */},{key:"applyTargetChange",value:function applyTargetChange(targetChange){var _this120=this;if(targetChange){targetChange.addedDocuments.forEach(function(key){return _this120._syncedDocuments=_this120._syncedDocuments.add(key);});targetChange.modifiedDocuments.forEach(function(key){});targetChange.removedDocuments.forEach(function(key){return _this120._syncedDocuments=_this120._syncedDocuments["delete"](key);});this.current=targetChange.current;}}},{key:"updateLimboDocuments",value:function updateLimboDocuments(){var _this121=this;// We can only determine limbo documents when we're in-sync with the server.
if(!this.current){return[];}// TODO(klimt): Do this incrementally so that it's not quadratic when
// updating many documents.
var oldLimboDocuments=this.limboDocuments;this.limboDocuments=documentKeySet();this.documentSet.forEach(function(doc){if(_this121.shouldBeInLimbo(doc.key)){_this121.limboDocuments=_this121.limboDocuments.add(doc.key);}});// Diff the new limbo docs with the old limbo docs.
var changes=[];oldLimboDocuments.forEach(function(key){if(!_this121.limboDocuments.has(key)){changes.push(new RemovedLimboDocument(key));}});this.limboDocuments.forEach(function(key){if(!oldLimboDocuments.has(key)){changes.push(new AddedLimboDocument(key));}});return changes;}/**
     * Update the in-memory state of the current view with the state read from
     * persistence.
     *
     * We update the query view whenever a client's primary status changes:
     * - When a client transitions from primary to secondary, it can miss
     *   LocalStorage updates and its query views may temporarily not be
     *   synchronized with the state on disk.
     * - For secondary to primary transitions, the client needs to update the list
     *   of `syncedDocuments` since secondary clients update their query views
     *   based purely on synthesized RemoteEvents.
     *
     * @param queryResult.documents - The documents that match the query according
     * to the LocalStore.
     * @param queryResult.remoteKeys - The keys of the documents that match the
     * query according to the backend.
     *
     * @return The ViewChange that resulted from this synchronization.
     */ // PORTING NOTE: Multi-tab only.
},{key:"synchronizeWithPersistedState",value:function synchronizeWithPersistedState(queryResult){this._syncedDocuments=queryResult.remoteKeys;this.limboDocuments=documentKeySet();var docChanges=this.computeDocChanges(queryResult.documents);return this.applyChanges(docChanges,/*updateLimboDocuments=*/true);}/**
     * Returns a view snapshot as if this query was just listened to. Contains
     * a document add for every existing document and the `fromCache` and
     * `hasPendingWrites` status of the already established view.
     */ // PORTING NOTE: Multi-tab only.
},{key:"computeInitialSnapshot",value:function computeInitialSnapshot(){return ViewSnapshot.fromInitialDocuments(this.query,this.documentSet,this.mutatedKeys,this.syncState===0/* Local */);}},{key:"syncedDocuments",get:function get(){return this._syncedDocuments;}}]);return View;}();function compareChangeType(c1,c2){var order=function order(change){switch(change){case 0/* Added */:return 1;case 2/* Modified */:return 2;case 3/* Metadata */:// A metadata change is converted to a modified change at the public
// api layer.  Since we sort by document key and then change type,
// metadata and modified changes must be sorted equivalently.
return 2;case 1/* Removed */:return 0;default:return fail();}};return order(c1)-order(c2);}/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /** The Platform's 'window' implementation or null if not available. */function getWindow(){if(process.env.USE_MOCK_PERSISTENCE==='YES'){// eslint-disable-next-line no-restricted-globals
return window;}return null;}/** The Platform's 'document' implementation or null if not available. */function getDocument(){return null;}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$a='AsyncQueue';/**
 * Represents an operation scheduled to be run in the future on an AsyncQueue.
 *
 * It is created via DelayedOperation.createAndSchedule().
 *
 * Supports cancellation (via cancel()) and early execution (via skipDelay()).
 *
 * Note: We implement `PromiseLike` instead of `Promise`, as the `Promise` type
 * in newer versions of TypeScript defines `finally`, which is not available in
 * IE.
 */var DelayedOperation=/*#__PURE__*/function(){function DelayedOperation(asyncQueue,timerId,targetTimeMs,op,removalCallback){_classCallCheck(this,DelayedOperation);this.asyncQueue=asyncQueue;this.timerId=timerId;this.targetTimeMs=targetTimeMs;this.op=op;this.removalCallback=removalCallback;this.deferred=new Deferred();this.then=this.deferred.promise.then.bind(this.deferred.promise);// It's normal for the deferred promise to be canceled (due to cancellation)
// and so we attach a dummy catch callback to avoid
// 'UnhandledPromiseRejectionWarning' log spam.
this.deferred.promise["catch"](function(err){});}/**
     * Creates and returns a DelayedOperation that has been scheduled to be
     * executed on the provided asyncQueue after the provided delayMs.
     *
     * @param asyncQueue The queue to schedule the operation on.
     * @param id A Timer ID identifying the type of operation this is.
     * @param delayMs The delay (ms) before the operation should be scheduled.
     * @param op The operation to run.
     * @param removalCallback A callback to be called synchronously once the
     *   operation is executed or canceled, notifying the AsyncQueue to remove it
     *   from its delayedOperations list.
     *   PORTING NOTE: This exists to prevent making removeDelayedOperation() and
     *   the DelayedOperation class public.
     */_createClass(DelayedOperation,[{key:"start",/**
     * Starts the timer. This is called immediately after construction by
     * createAndSchedule().
     */value:function start(delayMs){var _this122=this;this.timerHandle=setTimeout(function(){return _this122.handleDelayElapsed();},delayMs);}/**
     * Queues the operation to run immediately (if it hasn't already been run or
     * canceled).
     */},{key:"skipDelay",value:function skipDelay(){return this.handleDelayElapsed();}/**
     * Cancels the operation if it hasn't already been executed or canceled. The
     * promise will be rejected.
     *
     * As long as the operation has not yet been run, calling cancel() provides a
     * guarantee that the operation will not be run.
     */},{key:"cancel",value:function cancel(reason){if(this.timerHandle!==null){this.clearTimeout();this.deferred.reject(new FirestoreError(Code.CANCELLED,'Operation cancelled'+(reason?': '+reason:'')));}}},{key:"handleDelayElapsed",value:function handleDelayElapsed(){var _this123=this;this.asyncQueue.enqueueAndForget(function(){if(_this123.timerHandle!==null){_this123.clearTimeout();return _this123.op().then(function(result){return _this123.deferred.resolve(result);});}else{return Promise.resolve();}});}},{key:"clearTimeout",value:function(_clearTimeout){function clearTimeout(){return _clearTimeout.apply(this,arguments);}clearTimeout.toString=function(){return _clearTimeout.toString();};return clearTimeout;}(function(){if(this.timerHandle!==null){this.removalCallback(this);clearTimeout(this.timerHandle);this.timerHandle=null;}})}],[{key:"createAndSchedule",value:function createAndSchedule(asyncQueue,timerId,delayMs,op,removalCallback){var targetTime=Date.now()+delayMs;var delayedOp=new DelayedOperation(asyncQueue,timerId,targetTime,op,removalCallback);delayedOp.start(delayMs);return delayedOp;}}]);return DelayedOperation;}();var AsyncQueue=/*#__PURE__*/function(){function AsyncQueue(){var _this124=this;_classCallCheck(this,AsyncQueue);// The last promise in the queue.
this.tail=Promise.resolve();// A list of retryable operations. Retryable operations are run in order and
// retried with backoff.
this.retryableOps=[];// Is this AsyncQueue being shut down? Once it is set to true, it will not
// be changed again.
this._isShuttingDown=false;// Operations scheduled to be queued in the future. Operations are
// automatically removed after they are run or canceled.
this.delayedOperations=[];// visible for testing
this.failure=null;// Flag set while there's an outstanding AsyncQueue operation, used for
// assertion sanity-checks.
this.operationInProgress=false;// List of TimerIds to fast-forward delays for.
this.timerIdsToSkip=[];// Backoff timer used to schedule retries for retryable operations
this.backoff=new ExponentialBackoff(this,"async_queue_retry"/* AsyncQueueRetry */);// Visibility handler that triggers an immediate retry of all retryable
// operations. Meant to speed up recovery when we regain file system access
// after page comes into foreground.
this.visibilityHandler=function(){_this124.backoff.skipBackoff();};}// Is this AsyncQueue being shut down? If true, this instance will not enqueue
// any new operations, Promises from enqueue requests will not resolve.
_createClass(AsyncQueue,[{key:"enqueueAndForget",/**
     * Adds a new operation to the queue without waiting for it to complete (i.e.
     * we ignore the Promise result).
     */value:function enqueueAndForget(op){// eslint-disable-next-line @typescript-eslint/no-floating-promises
this.enqueue(op);}/**
     * Regardless if the queue has initialized shutdown, adds a new operation to the
     * queue without waiting for it to complete (i.e. we ignore the Promise result).
     */},{key:"enqueueAndForgetEvenWhileRestricted",value:function enqueueAndForgetEvenWhileRestricted(op){this.verifyNotFailed();// eslint-disable-next-line @typescript-eslint/no-floating-promises
this.enqueueInternal(op);}/**
     * Initialize the shutdown of this queue. Once this method is called, the
     * only possible way to request running an operation is through
     * `enqueueEvenWhileRestricted()`.
     */},{key:"enterRestrictedMode",value:function enterRestrictedMode(){if(!this._isShuttingDown){this._isShuttingDown=true;}}/**
     * Adds a new operation to the queue. Returns a promise that will be resolved
     * when the promise returned by the new operation is (with its value).
     */},{key:"enqueue",value:function enqueue(op){this.verifyNotFailed();if(this._isShuttingDown){// Return a Promise which never resolves.
return new Promise(function(resolve){});}return this.enqueueInternal(op);}/**
     * Enqueue a retryable operation.
     *
     * A retryable operation is rescheduled with backoff if it fails with a
     * IndexedDbTransactionError (the error type used by SimpleDb). All
     * retryable operations are executed in order and only run if all prior
     * operations were retried successfully.
     */},{key:"enqueueRetryable",value:function enqueueRetryable(op){var _this125=this;this.retryableOps.push(op);this.enqueueAndForget(function(){return _this125.retryNextOp();});}/**
     * Runs the next operation from the retryable queue. If the operation fails,
     * reschedules with backoff.
     */},{key:"retryNextOp",value:function retryNextOp(){var _this126=this;return regeneratorRuntime.async(function retryNextOp$(_context47){while(1){switch(_context47.prev=_context47.next){case 0:if(!(this.retryableOps.length===0)){_context47.next=2;break;}return _context47.abrupt("return");case 2:_context47.prev=2;_context47.next=5;return regeneratorRuntime.awrap(this.retryableOps[0]());case 5:this.retryableOps.shift();this.backoff.reset();_context47.next=16;break;case 9:_context47.prev=9;_context47.t0=_context47["catch"](2);if(!isIndexedDbTransactionError(_context47.t0)){_context47.next=15;break;}logDebug(LOG_TAG$a,'Operation failed with retryable error: '+_context47.t0);_context47.next=16;break;case 15:throw _context47.t0;case 16:if(this.retryableOps.length>0){// If there are additional operations, we re-schedule `retryNextOp()`.
// This is necessary to run retryable operations that failed during
// their initial attempt since we don't know whether they are already
// enqueued. If, for example, `op1`, `op2`, `op3` are enqueued and `op1`
// needs to  be re-run, we will run `op1`, `op1`, `op2` using the
// already enqueued calls to `retryNextOp()`. `op3()` will then run in the
// call scheduled here.
// Since `backoffAndRun()` cancels an existing backoff and schedules a
// new backoff on every call, there is only ever a single additional
// operation in the queue.
this.backoff.backoffAndRun(function(){return _this126.retryNextOp();});}case 17:case"end":return _context47.stop();}}},null,this,[[2,9]]);}},{key:"enqueueInternal",value:function enqueueInternal(op){var _this127=this;var newTail=this.tail.then(function(){_this127.operationInProgress=true;return op()["catch"](function(error){_this127.failure=error;_this127.operationInProgress=false;var message=getMessageOrStack(error);logError('INTERNAL UNHANDLED ERROR: ',message);// Re-throw the error so that this.tail becomes a rejected Promise and
// all further attempts to chain (via .then) will just short-circuit
// and return the rejected Promise.
throw error;}).then(function(result){_this127.operationInProgress=false;return result;});});this.tail=newTail;return newTail;}/**
     * Schedules an operation to be queued on the AsyncQueue once the specified
     * `delayMs` has elapsed. The returned DelayedOperation can be used to cancel
     * or fast-forward the operation prior to its running.
     */},{key:"enqueueAfterDelay",value:function enqueueAfterDelay(timerId,delayMs,op){var _this128=this;this.verifyNotFailed();// Fast-forward delays for timerIds that have been overriden.
if(this.timerIdsToSkip.indexOf(timerId)>-1){delayMs=0;}var delayedOp=DelayedOperation.createAndSchedule(this,timerId,delayMs,op,function(removedOp){return _this128.removeDelayedOperation(removedOp);});this.delayedOperations.push(delayedOp);return delayedOp;}},{key:"verifyNotFailed",value:function verifyNotFailed(){if(this.failure){fail();}}/**
     * Verifies there's an operation currently in-progress on the AsyncQueue.
     * Unfortunately we can't verify that the running code is in the promise chain
     * of that operation, so this isn't a foolproof check, but it should be enough
     * to catch some bugs.
     */},{key:"verifyOperationInProgress",value:function verifyOperationInProgress(){}/**
     * Waits until all currently queued tasks are finished executing. Delayed
     * operations are not run.
     */},{key:"drain",value:function drain(){var currentTail;return regeneratorRuntime.async(function drain$(_context48){while(1){switch(_context48.prev=_context48.next){case 0:currentTail=this.tail;_context48.next=3;return regeneratorRuntime.awrap(currentTail);case 3:if(currentTail!==this.tail){_context48.next=0;break;}case 4:case"end":return _context48.stop();}}},null,this);}/**
     * For Tests: Determine if a delayed operation with a particular TimerId
     * exists.
     */},{key:"containsDelayedOperation",value:function containsDelayedOperation(timerId){var _iteratorNormalCompletion47=true;var _didIteratorError47=false;var _iteratorError47=undefined;try{for(var _iterator47=this.delayedOperations[Symbol.iterator](),_step47;!(_iteratorNormalCompletion47=(_step47=_iterator47.next()).done);_iteratorNormalCompletion47=true){var op=_step47.value;if(op.timerId===timerId){return true;}}}catch(err){_didIteratorError47=true;_iteratorError47=err;}finally{try{if(!_iteratorNormalCompletion47&&_iterator47["return"]!=null){_iterator47["return"]();}}finally{if(_didIteratorError47){throw _iteratorError47;}}}return false;}/**
     * For Tests: Runs some or all delayed operations early.
     *
     * @param lastTimerId Delayed operations up to and including this TimerId will
     *  be drained. Pass TimerId.All to run all delayed operations.
     * @returns a Promise that resolves once all operations have been run.
     */},{key:"runAllDelayedOperationsUntil",value:function runAllDelayedOperationsUntil(lastTimerId){var _this129=this;// Note that draining may generate more delayed ops, so we do that first.
return this.drain().then(function(){// Run ops in the same order they'd run if they ran naturally.
_this129.delayedOperations.sort(function(a,b){return a.targetTimeMs-b.targetTimeMs;});var _iteratorNormalCompletion48=true;var _didIteratorError48=false;var _iteratorError48=undefined;try{for(var _iterator48=_this129.delayedOperations[Symbol.iterator](),_step48;!(_iteratorNormalCompletion48=(_step48=_iterator48.next()).done);_iteratorNormalCompletion48=true){var op=_step48.value;op.skipDelay();if(lastTimerId!=="all"/* All */&&op.timerId===lastTimerId){break;}}}catch(err){_didIteratorError48=true;_iteratorError48=err;}finally{try{if(!_iteratorNormalCompletion48&&_iterator48["return"]!=null){_iterator48["return"]();}}finally{if(_didIteratorError48){throw _iteratorError48;}}}return _this129.drain();});}/**
     * For Tests: Skip all subsequent delays for a timer id.
     */},{key:"skipDelaysForTimerId",value:function skipDelaysForTimerId(timerId){this.timerIdsToSkip.push(timerId);}/** Called once a DelayedOperation is run or canceled. */},{key:"removeDelayedOperation",value:function removeDelayedOperation(op){// NOTE: indexOf / slice are O(n), but delayedOperations is expected to be small.
var index=this.delayedOperations.indexOf(op);this.delayedOperations.splice(index,1);}},{key:"isShuttingDown",get:function get(){return this._isShuttingDown;}}]);return AsyncQueue;}();/**
 * Returns a FirestoreError that can be surfaced to the user if the provided
 * error is an IndexedDbTransactionError. Re-throws the error otherwise.
 */function wrapInUserErrorIfRecoverable(e,msg){logError(LOG_TAG$a,"".concat(msg,": ").concat(e));if(isIndexedDbTransactionError(e)){return new FirestoreError(Code.UNAVAILABLE,"".concat(msg,": ").concat(e));}else{throw e;}}/**
 * Chrome includes Error.message in Error.stack. Other browsers do not.
 * This returns expected output of message + stack when available.
 * @param error Error or FirestoreError
 */function getMessageOrStack(error){var message=error.message||'';if(error.stack){if(error.stack.includes(error.message)){message=error.stack;}else{message=error.message+'\n'+error.stack;}}return message;}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Holds the listeners and the last received ViewSnapshot for a query being
 * tracked by EventManager.
 */var QueryListenersInfo=function QueryListenersInfo(){_classCallCheck(this,QueryListenersInfo);this.viewSnap=undefined;this.listeners=[];};function newEventManager(){return new EventManagerImpl();}var EventManagerImpl=function EventManagerImpl(){_classCallCheck(this,EventManagerImpl);this.queries=new ObjectMap(function(q){return canonifyQuery(q);},queryEquals);this.onlineState="Unknown"/* Unknown */;this.snapshotsInSyncListeners=new Set();};function eventManagerListen(eventManager,listener){var eventManagerImpl,query,firstListen,queryInfo,firestoreError,raisedEvent,_raisedEvent;return regeneratorRuntime.async(function eventManagerListen$(_context49){while(1){switch(_context49.prev=_context49.next){case 0:eventManagerImpl=debugCast(eventManager);query=listener.query;firstListen=false;queryInfo=eventManagerImpl.queries.get(query);if(!queryInfo){firstListen=true;queryInfo=new QueryListenersInfo();}if(!firstListen){_context49.next=17;break;}_context49.prev=6;_context49.next=9;return regeneratorRuntime.awrap(eventManagerImpl.onListen(query));case 9:queryInfo.viewSnap=_context49.sent;_context49.next=17;break;case 12:_context49.prev=12;_context49.t0=_context49["catch"](6);firestoreError=wrapInUserErrorIfRecoverable(_context49.t0,"Initialization of query '".concat(stringifyQuery(listener.query),"' failed"));listener.onError(firestoreError);return _context49.abrupt("return");case 17:eventManagerImpl.queries.set(query,queryInfo);queryInfo.listeners.push(listener);// Run global snapshot listeners if a consistent snapshot has been emitted.
raisedEvent=listener.applyOnlineStateChange(eventManagerImpl.onlineState);if(queryInfo.viewSnap){_raisedEvent=listener.onViewSnapshot(queryInfo.viewSnap);if(_raisedEvent){raiseSnapshotsInSyncEvent(eventManagerImpl);}}case 21:case"end":return _context49.stop();}}},null,null,[[6,12]]);}function eventManagerUnlisten(eventManager,listener){var eventManagerImpl,query,lastListen,queryInfo,i;return regeneratorRuntime.async(function eventManagerUnlisten$(_context50){while(1){switch(_context50.prev=_context50.next){case 0:eventManagerImpl=debugCast(eventManager);query=listener.query;lastListen=false;queryInfo=eventManagerImpl.queries.get(query);if(queryInfo){i=queryInfo.listeners.indexOf(listener);if(i>=0){queryInfo.listeners.splice(i,1);lastListen=queryInfo.listeners.length===0;}}if(!lastListen){_context50.next=8;break;}eventManagerImpl.queries["delete"](query);return _context50.abrupt("return",eventManagerImpl.onUnlisten(query));case 8:case"end":return _context50.stop();}}});}function eventManagerOnWatchChange(eventManager,viewSnaps){var eventManagerImpl=debugCast(eventManager);var raisedEvent=false;var _iteratorNormalCompletion49=true;var _didIteratorError49=false;var _iteratorError49=undefined;try{for(var _iterator49=viewSnaps[Symbol.iterator](),_step49;!(_iteratorNormalCompletion49=(_step49=_iterator49.next()).done);_iteratorNormalCompletion49=true){var viewSnap=_step49.value;var query=viewSnap.query;var queryInfo=eventManagerImpl.queries.get(query);if(queryInfo){var _iteratorNormalCompletion50=true;var _didIteratorError50=false;var _iteratorError50=undefined;try{for(var _iterator50=queryInfo.listeners[Symbol.iterator](),_step50;!(_iteratorNormalCompletion50=(_step50=_iterator50.next()).done);_iteratorNormalCompletion50=true){var listener=_step50.value;if(listener.onViewSnapshot(viewSnap)){raisedEvent=true;}}}catch(err){_didIteratorError50=true;_iteratorError50=err;}finally{try{if(!_iteratorNormalCompletion50&&_iterator50["return"]!=null){_iterator50["return"]();}}finally{if(_didIteratorError50){throw _iteratorError50;}}}queryInfo.viewSnap=viewSnap;}}}catch(err){_didIteratorError49=true;_iteratorError49=err;}finally{try{if(!_iteratorNormalCompletion49&&_iterator49["return"]!=null){_iterator49["return"]();}}finally{if(_didIteratorError49){throw _iteratorError49;}}}if(raisedEvent){raiseSnapshotsInSyncEvent(eventManagerImpl);}}function eventManagerOnWatchError(eventManager,query,error){var eventManagerImpl=debugCast(eventManager);var queryInfo=eventManagerImpl.queries.get(query);if(queryInfo){var _iteratorNormalCompletion51=true;var _didIteratorError51=false;var _iteratorError51=undefined;try{for(var _iterator51=queryInfo.listeners[Symbol.iterator](),_step51;!(_iteratorNormalCompletion51=(_step51=_iterator51.next()).done);_iteratorNormalCompletion51=true){var listener=_step51.value;listener.onError(error);}}catch(err){_didIteratorError51=true;_iteratorError51=err;}finally{try{if(!_iteratorNormalCompletion51&&_iterator51["return"]!=null){_iterator51["return"]();}}finally{if(_didIteratorError51){throw _iteratorError51;}}}}// Remove all listeners. NOTE: We don't need to call syncEngine.unlisten()
// after an error.
eventManagerImpl.queries["delete"](query);}function eventManagerOnOnlineStateChange(eventManager,onlineState){var eventManagerImpl=debugCast(eventManager);eventManagerImpl.onlineState=onlineState;var raisedEvent=false;eventManagerImpl.queries.forEach(function(_,queryInfo){var _iteratorNormalCompletion52=true;var _didIteratorError52=false;var _iteratorError52=undefined;try{for(var _iterator52=queryInfo.listeners[Symbol.iterator](),_step52;!(_iteratorNormalCompletion52=(_step52=_iterator52.next()).done);_iteratorNormalCompletion52=true){var listener=_step52.value;// Run global snapshot listeners if a consistent snapshot has been emitted.
if(listener.applyOnlineStateChange(onlineState)){raisedEvent=true;}}}catch(err){_didIteratorError52=true;_iteratorError52=err;}finally{try{if(!_iteratorNormalCompletion52&&_iterator52["return"]!=null){_iterator52["return"]();}}finally{if(_didIteratorError52){throw _iteratorError52;}}}});if(raisedEvent){raiseSnapshotsInSyncEvent(eventManagerImpl);}}function _addSnapshotsInSyncListener(eventManager,observer){var eventManagerImpl=debugCast(eventManager);eventManagerImpl.snapshotsInSyncListeners.add(observer);// Immediately fire an initial event, indicating all existing listeners
// are in-sync.
observer.next();}function removeSnapshotsInSyncListener(eventManager,observer){var eventManagerImpl=debugCast(eventManager);eventManagerImpl.snapshotsInSyncListeners["delete"](observer);}// Call all global snapshot listeners that have been set.
function raiseSnapshotsInSyncEvent(eventManagerImpl){eventManagerImpl.snapshotsInSyncListeners.forEach(function(observer){observer.next();});}/**
 * QueryListener takes a series of internal view snapshots and determines
 * when to raise the event.
 *
 * It uses an Observer to dispatch events.
 */var QueryListener=/*#__PURE__*/function(){function QueryListener(query,queryObserver,options){_classCallCheck(this,QueryListener);this.query=query;this.queryObserver=queryObserver;/**
         * Initial snapshots (e.g. from cache) may not be propagated to the wrapped
         * observer. This flag is set to true once we've actually raised an event.
         */this.raisedInitialEvent=false;this.snap=null;this.onlineState="Unknown"/* Unknown */;this.options=options||{};}/**
     * Applies the new ViewSnapshot to this listener, raising a user-facing event
     * if applicable (depending on what changed, whether the user has opted into
     * metadata-only changes, etc.). Returns true if a user-facing event was
     * indeed raised.
     */_createClass(QueryListener,[{key:"onViewSnapshot",value:function onViewSnapshot(snap){if(!this.options.includeMetadataChanges){// Remove the metadata only changes.
var docChanges=[];var _iteratorNormalCompletion53=true;var _didIteratorError53=false;var _iteratorError53=undefined;try{for(var _iterator53=snap.docChanges[Symbol.iterator](),_step53;!(_iteratorNormalCompletion53=(_step53=_iterator53.next()).done);_iteratorNormalCompletion53=true){var docChange=_step53.value;if(docChange.type!==3/* Metadata */){docChanges.push(docChange);}}}catch(err){_didIteratorError53=true;_iteratorError53=err;}finally{try{if(!_iteratorNormalCompletion53&&_iterator53["return"]!=null){_iterator53["return"]();}}finally{if(_didIteratorError53){throw _iteratorError53;}}}snap=new ViewSnapshot(snap.query,snap.docs,snap.oldDocs,docChanges,snap.mutatedKeys,snap.fromCache,snap.syncStateChanged,/* excludesMetadataChanges= */true);}var raisedEvent=false;if(!this.raisedInitialEvent){if(this.shouldRaiseInitialEvent(snap,this.onlineState)){this.raiseInitialEvent(snap);raisedEvent=true;}}else if(this.shouldRaiseEvent(snap)){this.queryObserver.next(snap);raisedEvent=true;}this.snap=snap;return raisedEvent;}},{key:"onError",value:function onError(error){this.queryObserver.error(error);}/** Returns whether a snapshot was raised. */},{key:"applyOnlineStateChange",value:function applyOnlineStateChange(onlineState){this.onlineState=onlineState;var raisedEvent=false;if(this.snap&&!this.raisedInitialEvent&&this.shouldRaiseInitialEvent(this.snap,onlineState)){this.raiseInitialEvent(this.snap);raisedEvent=true;}return raisedEvent;}},{key:"shouldRaiseInitialEvent",value:function shouldRaiseInitialEvent(snap,onlineState){// Always raise the first event when we're synced
if(!snap.fromCache){return true;}// NOTE: We consider OnlineState.Unknown as online (it should become Offline
// or Online if we wait long enough).
var maybeOnline=onlineState!=="Offline"/* Offline */;// Don't raise the event if we're online, aren't synced yet (checked
// above) and are waiting for a sync.
if(this.options.waitForSyncWhenOnline&&maybeOnline){return false;}// Raise data from cache if we have any documents or we are offline
return!snap.docs.isEmpty()||onlineState==="Offline"/* Offline */;}},{key:"shouldRaiseEvent",value:function shouldRaiseEvent(snap){// We don't need to handle includeDocumentMetadataChanges here because
// the Metadata only changes have already been stripped out if needed.
// At this point the only changes we will see are the ones we should
// propagate.
if(snap.docChanges.length>0){return true;}var hasPendingWritesChanged=this.snap&&this.snap.hasPendingWrites!==snap.hasPendingWrites;if(snap.syncStateChanged||hasPendingWritesChanged){return this.options.includeMetadataChanges===true;}// Generally we should have hit one of the cases above, but it's possible
// to get here if there were only metadata docChanges and they got
// stripped out.
return false;}},{key:"raiseInitialEvent",value:function raiseInitialEvent(snap){snap=ViewSnapshot.fromInitialDocuments(snap.query,snap.docs,snap.mutatedKeys,snap.fromCache);this.raisedInitialEvent=true;this.queryObserver.next(snap);}}]);return QueryListener;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$b='SyncEngine';/**
 * QueryView contains all of the data that SyncEngine needs to keep track of for
 * a particular query.
 */var QueryView=function QueryView(/**
     * The query itself.
     */query,/**
     * The target number created by the client that is used in the watch
     * stream to identify this query.
     */targetId,/**
     * The view is responsible for computing the final merged truth of what
     * docs are in the query. It gets notified of local and remote changes,
     * and applies the query filters and limits to determine the most correct
     * possible results.
     */view){_classCallCheck(this,QueryView);this.query=query;this.targetId=targetId;this.view=view;};/** Tracks a limbo resolution. */var LimboResolution=function LimboResolution(key){_classCallCheck(this,LimboResolution);this.key=key;/**
         * Set to true once we've received a document. This is used in
         * getRemoteKeysForTarget() and ultimately used by WatchChangeAggregator to
         * decide whether it needs to manufacture a delete event for the target once
         * the target is CURRENT.
         */this.receivedDocument=false;};/**
 * An implementation of `SyncEngine` coordinating with other parts of SDK.
 *
 * The parts of SyncEngine that act as a callback to RemoteStore need to be
 * registered individually. This is done in `syncEngineWrite()` and
 * `syncEngineListen()` (as well as `applyPrimaryState()`) as these methods
 * serve as entry points to RemoteStore's functionality.
 *
 * Note: some field defined in this class might have public access level, but
 * the class is not exported so they are only accessible from this module.
 * This is useful to implement optional features (like bundles) in free
 * functions, such that they are tree-shakeable.
 */var SyncEngineImpl=/*#__PURE__*/function(){function SyncEngineImpl(localStore,remoteStore,eventManager,// PORTING NOTE: Manages state synchronization in multi-tab environments.
sharedClientState,currentUser,maxConcurrentLimboResolutions){_classCallCheck(this,SyncEngineImpl);this.localStore=localStore;this.remoteStore=remoteStore;this.eventManager=eventManager;this.sharedClientState=sharedClientState;this.currentUser=currentUser;this.maxConcurrentLimboResolutions=maxConcurrentLimboResolutions;this.syncEngineListener={};this.queryViewsByQuery=new ObjectMap(function(q){return canonifyQuery(q);},queryEquals);this.queriesByTarget=new Map();/**
         * The keys of documents that are in limbo for which we haven't yet started a
         * limbo resolution query.
         */this.enqueuedLimboResolutions=[];/**
         * Keeps track of the target ID for each document that is in limbo with an
         * active target.
         */this.activeLimboTargetsByKey=new SortedMap(DocumentKey.comparator);/**
         * Keeps track of the information about an active limbo resolution for each
         * active target ID that was started for the purpose of limbo resolution.
         */this.activeLimboResolutionsByTarget=new Map();this.limboDocumentRefs=new ReferenceSet();/** Stores user completion handlers, indexed by User and BatchId. */this.mutationUserCallbacks={};/** Stores user callbacks waiting for all pending writes to be acknowledged. */this.pendingWritesCallbacks=new Map();this.limboTargetIdGenerator=TargetIdGenerator.forSyncEngine();this.onlineState="Unknown"/* Unknown */;// The primary state is set to `true` or `false` immediately after Firestore
// startup. In the interim, a client should only be considered primary if
// `isPrimary` is true.
this._isPrimaryClient=undefined;}_createClass(SyncEngineImpl,[{key:"isPrimaryClient",get:function get(){return this._isPrimaryClient===true;}}]);return SyncEngineImpl;}();function newSyncEngine(localStore,remoteStore,eventManager,// PORTING NOTE: Manages state synchronization in multi-tab environments.
sharedClientState,currentUser,maxConcurrentLimboResolutions,isPrimary){var syncEngine=new SyncEngineImpl(localStore,remoteStore,eventManager,sharedClientState,currentUser,maxConcurrentLimboResolutions);if(isPrimary){syncEngine._isPrimaryClient=true;}return syncEngine;}/**
 * Initiates the new listen, resolves promise when listen enqueued to the
 * server. All the subsequent view snapshots or errors are sent to the
 * subscribed handlers. Returns the initial snapshot.
 */function syncEngineListen(syncEngine,query){var syncEngineImpl,targetId,viewSnapshot,queryView,targetData,status;return regeneratorRuntime.async(function syncEngineListen$(_context51){while(1){switch(_context51.prev=_context51.next){case 0:syncEngineImpl=ensureWatchCallbacks(syncEngine);queryView=syncEngineImpl.queryViewsByQuery.get(query);if(!queryView){_context51.next=8;break;}// PORTING NOTE: With Multi-Tab Web, it is possible that a query view
// already exists when EventManager calls us for the first time. This
// happens when the primary tab is already listening to this query on
// behalf of another tab and the user of the primary also starts listening
// to the query. EventManager will not have an assigned target ID in this
// case and calls `listen` to obtain this ID.
targetId=queryView.targetId;syncEngineImpl.sharedClientState.addLocalQueryTarget(targetId);viewSnapshot=queryView.view.computeInitialSnapshot();_context51.next=17;break;case 8:_context51.next=10;return regeneratorRuntime.awrap(allocateTarget(syncEngineImpl.localStore,queryToTarget(query)));case 10:targetData=_context51.sent;status=syncEngineImpl.sharedClientState.addLocalQueryTarget(targetData.targetId);targetId=targetData.targetId;_context51.next=15;return regeneratorRuntime.awrap(initializeViewAndComputeSnapshot(syncEngineImpl,query,targetId,status==='current'));case 15:viewSnapshot=_context51.sent;if(syncEngineImpl.isPrimaryClient){remoteStoreListen(syncEngineImpl.remoteStore,targetData);}case 17:return _context51.abrupt("return",viewSnapshot);case 18:case"end":return _context51.stop();}}});}/**
 * Registers a view for a previously unknown query and computes its initial
 * snapshot.
 */function initializeViewAndComputeSnapshot(syncEngineImpl,query,targetId,current){var queryResult,view,viewDocChanges,synthesizedTargetChange,viewChange,data;return regeneratorRuntime.async(function initializeViewAndComputeSnapshot$(_context52){while(1){switch(_context52.prev=_context52.next){case 0:// PORTING NOTE: On Web only, we inject the code that registers new Limbo
// targets based on view changes. This allows us to only depend on Limbo
// changes when user code includes queries.
syncEngineImpl.applyDocChanges=function(queryView,changes,remoteEvent){return applyDocChanges(syncEngineImpl,queryView,changes,remoteEvent);};_context52.next=3;return regeneratorRuntime.awrap(executeQuery(syncEngineImpl.localStore,query,/* usePreviousResults= */true));case 3:queryResult=_context52.sent;view=new View(query,queryResult.remoteKeys);viewDocChanges=view.computeDocChanges(queryResult.documents);synthesizedTargetChange=TargetChange.createSynthesizedTargetChangeForCurrentChange(targetId,current&&syncEngineImpl.onlineState!=="Offline"/* Offline */);viewChange=view.applyChanges(viewDocChanges,/* updateLimboDocuments= */syncEngineImpl.isPrimaryClient,synthesizedTargetChange);updateTrackedLimbos(syncEngineImpl,targetId,viewChange.limboChanges);data=new QueryView(query,targetId,view);syncEngineImpl.queryViewsByQuery.set(query,data);if(syncEngineImpl.queriesByTarget.has(targetId)){syncEngineImpl.queriesByTarget.get(targetId).push(query);}else{syncEngineImpl.queriesByTarget.set(targetId,[query]);}return _context52.abrupt("return",viewChange.snapshot);case 13:case"end":return _context52.stop();}}});}/** Stops listening to the query. */function syncEngineUnlisten(syncEngine,query){var syncEngineImpl,queryView,queries,targetRemainsActive;return regeneratorRuntime.async(function syncEngineUnlisten$(_context53){while(1){switch(_context53.prev=_context53.next){case 0:syncEngineImpl=debugCast(syncEngine);queryView=syncEngineImpl.queryViewsByQuery.get(query);// Only clean up the query view and target if this is the only query mapped
// to the target.
queries=syncEngineImpl.queriesByTarget.get(queryView.targetId);if(!(queries.length>1)){_context53.next=7;break;}syncEngineImpl.queriesByTarget.set(queryView.targetId,queries.filter(function(q){return!queryEquals(q,query);}));syncEngineImpl.queryViewsByQuery["delete"](query);return _context53.abrupt("return");case 7:if(!syncEngineImpl.isPrimaryClient){_context53.next=15;break;}// We need to remove the local query target first to allow us to verify
// whether any other client is still interested in this target.
syncEngineImpl.sharedClientState.removeLocalQueryTarget(queryView.targetId);targetRemainsActive=syncEngineImpl.sharedClientState.isActiveQueryTarget(queryView.targetId);if(targetRemainsActive){_context53.next=13;break;}_context53.next=13;return regeneratorRuntime.awrap(releaseTarget(syncEngineImpl.localStore,queryView.targetId,/*keepPersistedTargetData=*/false).then(function(){syncEngineImpl.sharedClientState.clearQueryState(queryView.targetId);remoteStoreUnlisten(syncEngineImpl.remoteStore,queryView.targetId);removeAndCleanupTarget(syncEngineImpl,queryView.targetId);})["catch"](ignoreIfPrimaryLeaseLoss));case 13:_context53.next=18;break;case 15:removeAndCleanupTarget(syncEngineImpl,queryView.targetId);_context53.next=18;return regeneratorRuntime.awrap(releaseTarget(syncEngineImpl.localStore,queryView.targetId,/*keepPersistedTargetData=*/true));case 18:case"end":return _context53.stop();}}});}/**
 * Initiates the write of local mutation batch which involves adding the
 * writes to the mutation queue, notifying the remote store about new
 * mutations and raising events for any changes this write caused.
 *
 * The promise returned by this call is resolved when the above steps
 * have completed, *not* when the write was acked by the backend. The
 * userCallback is resolved once the write was acked/rejected by the
 * backend (or failed locally for any other reason).
 */function syncEngineWrite(syncEngine,batch,userCallback){var syncEngineImpl,result,error;return regeneratorRuntime.async(function syncEngineWrite$(_context54){while(1){switch(_context54.prev=_context54.next){case 0:syncEngineImpl=ensureWriteCallbacks(syncEngine);_context54.prev=1;_context54.next=4;return regeneratorRuntime.awrap(localWrite(syncEngineImpl.localStore,batch));case 4:result=_context54.sent;syncEngineImpl.sharedClientState.addPendingMutation(result.batchId);addMutationCallback(syncEngineImpl,result.batchId,userCallback);_context54.next=9;return regeneratorRuntime.awrap(emitNewSnapsAndNotifyLocalStore(syncEngineImpl,result.changes));case 9:_context54.next=11;return regeneratorRuntime.awrap(fillWritePipeline(syncEngineImpl.remoteStore));case 11:_context54.next=17;break;case 13:_context54.prev=13;_context54.t0=_context54["catch"](1);// If we can't persist the mutation, we reject the user callback and
// don't send the mutation. The user can then retry the write.
error=wrapInUserErrorIfRecoverable(_context54.t0,"Failed to persist write");userCallback.reject(error);case 17:case"end":return _context54.stop();}}},null,null,[[1,13]]);}/**
 * Applies one remote event to the sync engine, notifying any views of the
 * changes, and releasing any pending mutation batches that would become
 * visible because of the snapshot version the remote event contains.
 */function applyRemoteEvent(syncEngine,remoteEvent){var syncEngineImpl,changes;return regeneratorRuntime.async(function applyRemoteEvent$(_context55){while(1){switch(_context55.prev=_context55.next){case 0:syncEngineImpl=debugCast(syncEngine);_context55.prev=1;_context55.next=4;return regeneratorRuntime.awrap(applyRemoteEventToLocalCache(syncEngineImpl.localStore,remoteEvent));case 4:changes=_context55.sent;// Update `receivedDocument` as appropriate for any limbo targets.
remoteEvent.targetChanges.forEach(function(targetChange,targetId){var limboResolution=syncEngineImpl.activeLimboResolutionsByTarget.get(targetId);if(limboResolution){// Since this is a limbo resolution lookup, it's for a single document
// and it could be added, modified, or removed, but not a combination.
hardAssert(targetChange.addedDocuments.size+targetChange.modifiedDocuments.size+targetChange.removedDocuments.size<=1);if(targetChange.addedDocuments.size>0){limboResolution.receivedDocument=true;}else if(targetChange.modifiedDocuments.size>0){hardAssert(limboResolution.receivedDocument);}else if(targetChange.removedDocuments.size>0){hardAssert(limboResolution.receivedDocument);limboResolution.receivedDocument=false;}else{// This was probably just a CURRENT targetChange or similar.
}}});_context55.next=8;return regeneratorRuntime.awrap(emitNewSnapsAndNotifyLocalStore(syncEngineImpl,changes,remoteEvent));case 8:_context55.next=14;break;case 10:_context55.prev=10;_context55.t0=_context55["catch"](1);_context55.next=14;return regeneratorRuntime.awrap(ignoreIfPrimaryLeaseLoss(_context55.t0));case 14:case"end":return _context55.stop();}}},null,null,[[1,10]]);}/**
 * Applies an OnlineState change to the sync engine and notifies any views of
 * the change.
 */function applyOnlineStateChange(syncEngine,onlineState,source){var syncEngineImpl=debugCast(syncEngine);// If we are the secondary client, we explicitly ignore the remote store's
// online state (the local client may go offline, even though the primary
// tab remains online) and only apply the primary tab's online state from
// SharedClientState.
if(syncEngineImpl.isPrimaryClient&&source===0/* RemoteStore */||!syncEngineImpl.isPrimaryClient&&source===1/* SharedClientState */){var newViewSnapshots=[];syncEngineImpl.queryViewsByQuery.forEach(function(query,queryView){var viewChange=queryView.view.applyOnlineStateChange(onlineState);if(viewChange.snapshot){newViewSnapshots.push(viewChange.snapshot);}});eventManagerOnOnlineStateChange(syncEngineImpl.eventManager,onlineState);if(newViewSnapshots.length){syncEngineImpl.syncEngineListener.onWatchChange(newViewSnapshots);}syncEngineImpl.onlineState=onlineState;if(syncEngineImpl.isPrimaryClient){syncEngineImpl.sharedClientState.setOnlineState(onlineState);}}}/**
 * Rejects the listen for the given targetID. This can be triggered by the
 * backend for any active target.
 *
 * @param syncEngine The sync engine implementation.
 * @param targetId The targetID corresponds to one previously initiated by the
 * user as part of TargetData passed to listen() on RemoteStore.
 * @param err A description of the condition that has forced the rejection.
 * Nearly always this will be an indication that the user is no longer
 * authorized to see the data matching the target.
 */function rejectListen(syncEngine,targetId,err){var syncEngineImpl,limboResolution,limboKey,documentUpdates,resolvedLimboDocuments,event;return regeneratorRuntime.async(function rejectListen$(_context56){while(1){switch(_context56.prev=_context56.next){case 0:syncEngineImpl=debugCast(syncEngine);// PORTING NOTE: Multi-tab only.
syncEngineImpl.sharedClientState.updateQueryState(targetId,'rejected',err);limboResolution=syncEngineImpl.activeLimboResolutionsByTarget.get(targetId);limboKey=limboResolution&&limboResolution.key;if(!limboKey){_context56.next=16;break;}// TODO(klimt): We really only should do the following on permission
// denied errors, but we don't have the cause code here.
// It's a limbo doc. Create a synthetic event saying it was deleted.
// This is kind of a hack. Ideally, we would have a method in the local
// store to purge a document. However, it would be tricky to keep all of
// the local store's invariants with another method.
documentUpdates=new SortedMap(DocumentKey.comparator);documentUpdates=documentUpdates.insert(limboKey,new NoDocument(limboKey,SnapshotVersion.min()));resolvedLimboDocuments=documentKeySet().add(limboKey);event=new RemoteEvent(SnapshotVersion.min(),/* targetChanges= */new Map(),/* targetMismatches= */new SortedSet(primitiveComparator),documentUpdates,resolvedLimboDocuments);_context56.next=11;return regeneratorRuntime.awrap(applyRemoteEvent(syncEngineImpl,event));case 11:// Since this query failed, we won't want to manually unlisten to it.
// We only remove it from bookkeeping after we successfully applied the
// RemoteEvent. If `applyRemoteEvent()` throws, we want to re-listen to
// this query when the RemoteStore restarts the Watch stream, which should
// re-trigger the target failure.
syncEngineImpl.activeLimboTargetsByKey=syncEngineImpl.activeLimboTargetsByKey.remove(limboKey);syncEngineImpl.activeLimboResolutionsByTarget["delete"](targetId);pumpEnqueuedLimboResolutions(syncEngineImpl);_context56.next=18;break;case 16:_context56.next=18;return regeneratorRuntime.awrap(releaseTarget(syncEngineImpl.localStore,targetId,/* keepPersistedTargetData */false).then(function(){return removeAndCleanupTarget(syncEngineImpl,targetId,err);})["catch"](ignoreIfPrimaryLeaseLoss));case 18:case"end":return _context56.stop();}}});}function applySuccessfulWrite(syncEngine,mutationBatchResult){var syncEngineImpl,batchId,changes;return regeneratorRuntime.async(function applySuccessfulWrite$(_context57){while(1){switch(_context57.prev=_context57.next){case 0:syncEngineImpl=debugCast(syncEngine);batchId=mutationBatchResult.batch.batchId;_context57.prev=2;_context57.next=5;return regeneratorRuntime.awrap(acknowledgeBatch(syncEngineImpl.localStore,mutationBatchResult));case 5:changes=_context57.sent;// The local store may or may not be able to apply the write result and
// raise events immediately (depending on whether the watcher is caught
// up), so we raise user callbacks first so that they consistently happen
// before listen events.
processUserCallback(syncEngineImpl,batchId,/*error=*/null);triggerPendingWritesCallbacks(syncEngineImpl,batchId);syncEngineImpl.sharedClientState.updateMutationState(batchId,'acknowledged');_context57.next=11;return regeneratorRuntime.awrap(emitNewSnapsAndNotifyLocalStore(syncEngineImpl,changes));case 11:_context57.next=17;break;case 13:_context57.prev=13;_context57.t0=_context57["catch"](2);_context57.next=17;return regeneratorRuntime.awrap(ignoreIfPrimaryLeaseLoss(_context57.t0));case 17:case"end":return _context57.stop();}}},null,null,[[2,13]]);}function rejectFailedWrite(syncEngine,batchId,error){var syncEngineImpl,changes;return regeneratorRuntime.async(function rejectFailedWrite$(_context58){while(1){switch(_context58.prev=_context58.next){case 0:syncEngineImpl=debugCast(syncEngine);_context58.prev=1;_context58.next=4;return regeneratorRuntime.awrap(rejectBatch(syncEngineImpl.localStore,batchId));case 4:changes=_context58.sent;// The local store may or may not be able to apply the write result and
// raise events immediately (depending on whether the watcher is caught up),
// so we raise user callbacks first so that they consistently happen before
// listen events.
processUserCallback(syncEngineImpl,batchId,error);triggerPendingWritesCallbacks(syncEngineImpl,batchId);syncEngineImpl.sharedClientState.updateMutationState(batchId,'rejected',error);_context58.next=10;return regeneratorRuntime.awrap(emitNewSnapsAndNotifyLocalStore(syncEngineImpl,changes));case 10:_context58.next=16;break;case 12:_context58.prev=12;_context58.t0=_context58["catch"](1);_context58.next=16;return regeneratorRuntime.awrap(ignoreIfPrimaryLeaseLoss(_context58.t0));case 16:case"end":return _context58.stop();}}},null,null,[[1,12]]);}/**
 * Registers a user callback that resolves when all pending mutations at the moment of calling
 * are acknowledged .
 */function registerPendingWritesCallback(syncEngine,callback){var syncEngineImpl,highestBatchId,callbacks,firestoreError;return regeneratorRuntime.async(function registerPendingWritesCallback$(_context59){while(1){switch(_context59.prev=_context59.next){case 0:syncEngineImpl=debugCast(syncEngine);if(!canUseNetwork(syncEngineImpl.remoteStore)){logDebug(LOG_TAG$b,'The network is disabled. The task returned by '+"'awaitPendingWrites()' will not complete until the network is enabled.");}_context59.prev=2;_context59.next=5;return regeneratorRuntime.awrap(getHighestUnacknowledgedBatchId(syncEngineImpl.localStore));case 5:highestBatchId=_context59.sent;if(!(highestBatchId===BATCHID_UNKNOWN)){_context59.next=9;break;}// Trigger the callback right away if there is no pending writes at the moment.
callback.resolve();return _context59.abrupt("return");case 9:callbacks=syncEngineImpl.pendingWritesCallbacks.get(highestBatchId)||[];callbacks.push(callback);syncEngineImpl.pendingWritesCallbacks.set(highestBatchId,callbacks);_context59.next=18;break;case 14:_context59.prev=14;_context59.t0=_context59["catch"](2);firestoreError=wrapInUserErrorIfRecoverable(_context59.t0,'Initialization of waitForPendingWrites() operation failed');callback.reject(firestoreError);case 18:case"end":return _context59.stop();}}},null,null,[[2,14]]);}/**
 * Triggers the callbacks that are waiting for this batch id to get acknowledged by server,
 * if there are any.
 */function triggerPendingWritesCallbacks(syncEngineImpl,batchId){(syncEngineImpl.pendingWritesCallbacks.get(batchId)||[]).forEach(function(callback){callback.resolve();});syncEngineImpl.pendingWritesCallbacks["delete"](batchId);}/** Reject all outstanding callbacks waiting for pending writes to complete. */function rejectOutstandingPendingWritesCallbacks(syncEngineImpl,errorMessage){syncEngineImpl.pendingWritesCallbacks.forEach(function(callbacks){callbacks.forEach(function(callback){callback.reject(new FirestoreError(Code.CANCELLED,errorMessage));});});syncEngineImpl.pendingWritesCallbacks.clear();}function addMutationCallback(syncEngineImpl,batchId,callback){var newCallbacks=syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()];if(!newCallbacks){newCallbacks=new SortedMap(primitiveComparator);}newCallbacks=newCallbacks.insert(batchId,callback);syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()]=newCallbacks;}/**
 * Resolves or rejects the user callback for the given batch and then discards
 * it.
 */function processUserCallback(syncEngine,batchId,error){var syncEngineImpl=debugCast(syncEngine);var newCallbacks=syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()];// NOTE: Mutations restored from persistence won't have callbacks, so it's
// okay for there to be no callback for this ID.
if(newCallbacks){var callback=newCallbacks.get(batchId);if(callback){if(error){callback.reject(error);}else{callback.resolve();}newCallbacks=newCallbacks.remove(batchId);}syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()]=newCallbacks;}}function removeAndCleanupTarget(syncEngineImpl,targetId){var error=arguments.length>2&&arguments[2]!==undefined?arguments[2]:null;syncEngineImpl.sharedClientState.removeLocalQueryTarget(targetId);var _iteratorNormalCompletion54=true;var _didIteratorError54=false;var _iteratorError54=undefined;try{for(var _iterator54=syncEngineImpl.queriesByTarget.get(targetId)[Symbol.iterator](),_step54;!(_iteratorNormalCompletion54=(_step54=_iterator54.next()).done);_iteratorNormalCompletion54=true){var query=_step54.value;syncEngineImpl.queryViewsByQuery["delete"](query);if(error){syncEngineImpl.syncEngineListener.onWatchError(query,error);}}}catch(err){_didIteratorError54=true;_iteratorError54=err;}finally{try{if(!_iteratorNormalCompletion54&&_iterator54["return"]!=null){_iterator54["return"]();}}finally{if(_didIteratorError54){throw _iteratorError54;}}}syncEngineImpl.queriesByTarget["delete"](targetId);if(syncEngineImpl.isPrimaryClient){var limboKeys=syncEngineImpl.limboDocumentRefs.removeReferencesForId(targetId);limboKeys.forEach(function(limboKey){var isReferenced=syncEngineImpl.limboDocumentRefs.containsKey(limboKey);if(!isReferenced){// We removed the last reference for this key
removeLimboTarget(syncEngineImpl,limboKey);}});}}function removeLimboTarget(syncEngineImpl,key){// It's possible that the target already got removed because the query failed. In that case,
// the key won't exist in `limboTargetsByKey`. Only do the cleanup if we still have the target.
var limboTargetId=syncEngineImpl.activeLimboTargetsByKey.get(key);if(limboTargetId===null){// This target already got removed, because the query failed.
return;}remoteStoreUnlisten(syncEngineImpl.remoteStore,limboTargetId);syncEngineImpl.activeLimboTargetsByKey=syncEngineImpl.activeLimboTargetsByKey.remove(key);syncEngineImpl.activeLimboResolutionsByTarget["delete"](limboTargetId);pumpEnqueuedLimboResolutions(syncEngineImpl);}function updateTrackedLimbos(syncEngineImpl,targetId,limboChanges){var _iteratorNormalCompletion55=true;var _didIteratorError55=false;var _iteratorError55=undefined;try{for(var _iterator55=limboChanges[Symbol.iterator](),_step55;!(_iteratorNormalCompletion55=(_step55=_iterator55.next()).done);_iteratorNormalCompletion55=true){var limboChange=_step55.value;if(limboChange instanceof AddedLimboDocument){syncEngineImpl.limboDocumentRefs.addReference(limboChange.key,targetId);trackLimboChange(syncEngineImpl,limboChange);}else if(limboChange instanceof RemovedLimboDocument){logDebug(LOG_TAG$b,'Document no longer in limbo: '+limboChange.key);syncEngineImpl.limboDocumentRefs.removeReference(limboChange.key,targetId);var isReferenced=syncEngineImpl.limboDocumentRefs.containsKey(limboChange.key);if(!isReferenced){// We removed the last reference for this key
removeLimboTarget(syncEngineImpl,limboChange.key);}}else{fail();}}}catch(err){_didIteratorError55=true;_iteratorError55=err;}finally{try{if(!_iteratorNormalCompletion55&&_iterator55["return"]!=null){_iterator55["return"]();}}finally{if(_didIteratorError55){throw _iteratorError55;}}}}function trackLimboChange(syncEngineImpl,limboChange){var key=limboChange.key;if(!syncEngineImpl.activeLimboTargetsByKey.get(key)){logDebug(LOG_TAG$b,'New document in limbo: '+key);syncEngineImpl.enqueuedLimboResolutions.push(key);pumpEnqueuedLimboResolutions(syncEngineImpl);}}/**
 * Starts listens for documents in limbo that are enqueued for resolution,
 * subject to a maximum number of concurrent resolutions.
 *
 * Without bounding the number of concurrent resolutions, the server can fail
 * with "resource exhausted" errors which can lead to pathological client
 * behavior as seen in https://github.com/firebase/firebase-js-sdk/issues/2683.
 */function pumpEnqueuedLimboResolutions(syncEngineImpl){while(syncEngineImpl.enqueuedLimboResolutions.length>0&&syncEngineImpl.activeLimboTargetsByKey.size<syncEngineImpl.maxConcurrentLimboResolutions){var key=syncEngineImpl.enqueuedLimboResolutions.shift();var limboTargetId=syncEngineImpl.limboTargetIdGenerator.next();syncEngineImpl.activeLimboResolutionsByTarget.set(limboTargetId,new LimboResolution(key));syncEngineImpl.activeLimboTargetsByKey=syncEngineImpl.activeLimboTargetsByKey.insert(key,limboTargetId);remoteStoreListen(syncEngineImpl.remoteStore,new TargetData(queryToTarget(newQueryForPath(key.path)),limboTargetId,2/* LimboResolution */,ListenSequence.INVALID));}}function emitNewSnapsAndNotifyLocalStore(syncEngine,changes,remoteEvent){var syncEngineImpl,newSnaps,docChangesInAllViews,queriesProcessed;return regeneratorRuntime.async(function emitNewSnapsAndNotifyLocalStore$(_context60){while(1){switch(_context60.prev=_context60.next){case 0:syncEngineImpl=debugCast(syncEngine);newSnaps=[];docChangesInAllViews=[];queriesProcessed=[];if(!syncEngineImpl.queryViewsByQuery.isEmpty()){_context60.next=6;break;}return _context60.abrupt("return");case 6:syncEngineImpl.queryViewsByQuery.forEach(function(_,queryView){queriesProcessed.push(syncEngineImpl.applyDocChanges(queryView,changes,remoteEvent).then(function(viewSnapshot){if(viewSnapshot){if(syncEngineImpl.isPrimaryClient){syncEngineImpl.sharedClientState.updateQueryState(queryView.targetId,viewSnapshot.fromCache?'not-current':'current');}newSnaps.push(viewSnapshot);var docChanges=LocalViewChanges.fromSnapshot(queryView.targetId,viewSnapshot);docChangesInAllViews.push(docChanges);}}));});_context60.next=9;return regeneratorRuntime.awrap(Promise.all(queriesProcessed));case 9:syncEngineImpl.syncEngineListener.onWatchChange(newSnaps);_context60.next=12;return regeneratorRuntime.awrap(notifyLocalViewChanges(syncEngineImpl.localStore,docChangesInAllViews));case 12:case"end":return _context60.stop();}}});}function applyDocChanges(syncEngineImpl,queryView,changes,remoteEvent){var viewDocChanges,targetChange,viewChange;return regeneratorRuntime.async(function applyDocChanges$(_context61){while(1){switch(_context61.prev=_context61.next){case 0:viewDocChanges=queryView.view.computeDocChanges(changes);if(!viewDocChanges.needsRefill){_context61.next=5;break;}_context61.next=4;return regeneratorRuntime.awrap(executeQuery(syncEngineImpl.localStore,queryView.query,/* usePreviousResults= */false).then(function(_ref14){var documents=_ref14.documents;return queryView.view.computeDocChanges(documents,viewDocChanges);}));case 4:viewDocChanges=_context61.sent;case 5:targetChange=remoteEvent&&remoteEvent.targetChanges.get(queryView.targetId);viewChange=queryView.view.applyChanges(viewDocChanges,/* updateLimboDocuments= */syncEngineImpl.isPrimaryClient,targetChange);updateTrackedLimbos(syncEngineImpl,queryView.targetId,viewChange.limboChanges);return _context61.abrupt("return",viewChange.snapshot);case 9:case"end":return _context61.stop();}}});}function syncEngineHandleCredentialChange(syncEngine,user){var syncEngineImpl,userChanged,result;return regeneratorRuntime.async(function syncEngineHandleCredentialChange$(_context62){while(1){switch(_context62.prev=_context62.next){case 0:syncEngineImpl=debugCast(syncEngine);userChanged=!syncEngineImpl.currentUser.isEqual(user);if(!userChanged){_context62.next=12;break;}logDebug(LOG_TAG$b,'User change. New user:',user.toKey());_context62.next=6;return regeneratorRuntime.awrap(handleUserChange(syncEngineImpl.localStore,user));case 6:result=_context62.sent;syncEngineImpl.currentUser=user;// Fails tasks waiting for pending writes requested by previous user.
rejectOutstandingPendingWritesCallbacks(syncEngineImpl,"'waitForPendingWrites' promise is rejected due to a user change.");// TODO(b/114226417): Consider calling this only in the primary tab.
syncEngineImpl.sharedClientState.handleUserChange(user,result.removedBatchIds,result.addedBatchIds);_context62.next=12;return regeneratorRuntime.awrap(emitNewSnapsAndNotifyLocalStore(syncEngineImpl,result.affectedDocuments));case 12:case"end":return _context62.stop();}}});}function getRemoteKeysForTarget(syncEngine,targetId){var syncEngineImpl=debugCast(syncEngine);var limboResolution=syncEngineImpl.activeLimboResolutionsByTarget.get(targetId);if(limboResolution&&limboResolution.receivedDocument){return documentKeySet().add(limboResolution.key);}else{var keySet=documentKeySet();var queries=syncEngineImpl.queriesByTarget.get(targetId);if(!queries){return keySet;}var _iteratorNormalCompletion56=true;var _didIteratorError56=false;var _iteratorError56=undefined;try{for(var _iterator56=queries[Symbol.iterator](),_step56;!(_iteratorNormalCompletion56=(_step56=_iterator56.next()).done);_iteratorNormalCompletion56=true){var query=_step56.value;var queryView=syncEngineImpl.queryViewsByQuery.get(query);keySet=keySet.unionWith(queryView.view.syncedDocuments);}}catch(err){_didIteratorError56=true;_iteratorError56=err;}finally{try{if(!_iteratorNormalCompletion56&&_iterator56["return"]!=null){_iterator56["return"]();}}finally{if(_didIteratorError56){throw _iteratorError56;}}}return keySet;}}/**
 * Reconcile the list of synced documents in an existing view with those
 * from persistence.
 */function synchronizeViewAndComputeSnapshot(syncEngine,queryView){var syncEngineImpl,queryResult,viewSnapshot;return regeneratorRuntime.async(function synchronizeViewAndComputeSnapshot$(_context63){while(1){switch(_context63.prev=_context63.next){case 0:syncEngineImpl=debugCast(syncEngine);_context63.next=3;return regeneratorRuntime.awrap(executeQuery(syncEngineImpl.localStore,queryView.query,/* usePreviousResults= */true));case 3:queryResult=_context63.sent;viewSnapshot=queryView.view.synchronizeWithPersistedState(queryResult);if(syncEngineImpl.isPrimaryClient){updateTrackedLimbos(syncEngineImpl,queryView.targetId,viewSnapshot.limboChanges);}return _context63.abrupt("return",viewSnapshot);case 7:case"end":return _context63.stop();}}});}/** Applies a mutation state to an existing batch.  */ // PORTING NOTE: Multi-Tab only.
function applyBatchState(syncEngine,batchId,batchState,error){var syncEngineImpl,documents;return regeneratorRuntime.async(function applyBatchState$(_context64){while(1){switch(_context64.prev=_context64.next){case 0:syncEngineImpl=debugCast(syncEngine);_context64.next=3;return regeneratorRuntime.awrap(lookupMutationDocuments(syncEngineImpl.localStore,batchId));case 3:documents=_context64.sent;if(!(documents===null)){_context64.next=7;break;}// A throttled tab may not have seen the mutation before it was completed
// and removed from the mutation queue, in which case we won't have cached
// the affected documents. In this case we can safely ignore the update
// since that means we didn't apply the mutation locally at all (if we
// had, we would have cached the affected documents), and so we will just
// see any resulting document changes via normal remote document updates
// as applicable.
logDebug(LOG_TAG$b,'Cannot apply mutation batch with id: '+batchId);return _context64.abrupt("return");case 7:if(!(batchState==='pending')){_context64.next=12;break;}_context64.next=10;return regeneratorRuntime.awrap(fillWritePipeline(syncEngineImpl.remoteStore));case 10:_context64.next=13;break;case 12:if(batchState==='acknowledged'||batchState==='rejected'){// NOTE: Both these methods are no-ops for batches that originated from
// other clients.
processUserCallback(syncEngineImpl,batchId,error?error:null);triggerPendingWritesCallbacks(syncEngineImpl,batchId);removeCachedMutationBatchMetadata(syncEngineImpl.localStore,batchId);}else{fail();}case 13:_context64.next=15;return regeneratorRuntime.awrap(emitNewSnapsAndNotifyLocalStore(syncEngineImpl,documents));case 15:case"end":return _context64.stop();}}});}/** Applies a query target change from a different tab. */ // PORTING NOTE: Multi-Tab only.
function applyPrimaryState(syncEngine,isPrimary){var syncEngineImpl,activeTargets,activeQueries,_iteratorNormalCompletion57,_didIteratorError57,_iteratorError57,_iterator57,_step57,targetData,_activeTargets,p;return regeneratorRuntime.async(function applyPrimaryState$(_context65){while(1){switch(_context65.prev=_context65.next){case 0:syncEngineImpl=debugCast(syncEngine);ensureWatchCallbacks(syncEngineImpl);ensureWriteCallbacks(syncEngineImpl);if(!(isPrimary===true&&syncEngineImpl._isPrimaryClient!==true)){_context65.next=32;break;}// Secondary tabs only maintain Views for their local listeners and the
// Views internal state may not be 100% populated (in particular
// secondary tabs don't track syncedDocuments, the set of documents the
// server considers to be in the target). So when a secondary becomes
// primary, we need to need to make sure that all views for all targets
// match the state on disk.
activeTargets=syncEngineImpl.sharedClientState.getAllActiveQueryTargets();_context65.next=7;return regeneratorRuntime.awrap(synchronizeQueryViewsAndRaiseSnapshots(syncEngineImpl,activeTargets.toArray()));case 7:activeQueries=_context65.sent;syncEngineImpl._isPrimaryClient=true;_context65.next=11;return regeneratorRuntime.awrap(remoteStoreApplyPrimaryState(syncEngineImpl.remoteStore,true));case 11:_iteratorNormalCompletion57=true;_didIteratorError57=false;_iteratorError57=undefined;_context65.prev=14;for(_iterator57=activeQueries[Symbol.iterator]();!(_iteratorNormalCompletion57=(_step57=_iterator57.next()).done);_iteratorNormalCompletion57=true){targetData=_step57.value;remoteStoreListen(syncEngineImpl.remoteStore,targetData);}_context65.next=22;break;case 18:_context65.prev=18;_context65.t0=_context65["catch"](14);_didIteratorError57=true;_iteratorError57=_context65.t0;case 22:_context65.prev=22;_context65.prev=23;if(!_iteratorNormalCompletion57&&_iterator57["return"]!=null){_iterator57["return"]();}case 25:_context65.prev=25;if(!_didIteratorError57){_context65.next=28;break;}throw _iteratorError57;case 28:return _context65.finish(25);case 29:return _context65.finish(22);case 30:_context65.next=44;break;case 32:if(!(isPrimary===false&&syncEngineImpl._isPrimaryClient!==false)){_context65.next=44;break;}_activeTargets=[];p=Promise.resolve();syncEngineImpl.queriesByTarget.forEach(function(_,targetId){if(syncEngineImpl.sharedClientState.isLocalQueryTarget(targetId)){_activeTargets.push(targetId);}else{p=p.then(function(){removeAndCleanupTarget(syncEngineImpl,targetId);return releaseTarget(syncEngineImpl.localStore,targetId,/*keepPersistedTargetData=*/true);});}remoteStoreUnlisten(syncEngineImpl.remoteStore,targetId);});_context65.next=38;return regeneratorRuntime.awrap(p);case 38:_context65.next=40;return regeneratorRuntime.awrap(synchronizeQueryViewsAndRaiseSnapshots(syncEngineImpl,_activeTargets));case 40:resetLimboDocuments(syncEngineImpl);syncEngineImpl._isPrimaryClient=false;_context65.next=44;return regeneratorRuntime.awrap(remoteStoreApplyPrimaryState(syncEngineImpl.remoteStore,false));case 44:case"end":return _context65.stop();}}},null,null,[[14,18,22,30],[23,,25,29]]);}// PORTING NOTE: Multi-Tab only.
function resetLimboDocuments(syncEngine){var syncEngineImpl=debugCast(syncEngine);syncEngineImpl.activeLimboResolutionsByTarget.forEach(function(_,targetId){remoteStoreUnlisten(syncEngineImpl.remoteStore,targetId);});syncEngineImpl.limboDocumentRefs.removeAllReferences();syncEngineImpl.activeLimboResolutionsByTarget=new Map();syncEngineImpl.activeLimboTargetsByKey=new SortedMap(DocumentKey.comparator);}/**
 * Reconcile the query views of the provided query targets with the state from
 * persistence. Raises snapshots for any changes that affect the local
 * client and returns the updated state of all target's query data.
 *
 * @param syncEngine The sync engine implementation
 * @param targets the list of targets with views that need to be recomputed
 * @param transitionToPrimary `true` iff the tab transitions from a secondary
 * tab to a primary tab
 */ // PORTING NOTE: Multi-Tab only.
function synchronizeQueryViewsAndRaiseSnapshots(syncEngine,targets,transitionToPrimary){var syncEngineImpl,activeQueries,newViewSnapshots,_iteratorNormalCompletion58,_didIteratorError58,_iteratorError58,_iterator58,_step58,targetId,targetData,queries,_iteratorNormalCompletion59,_didIteratorError59,_iteratorError59,_iterator59,_step59,query,queryView,viewChange,target;return regeneratorRuntime.async(function synchronizeQueryViewsAndRaiseSnapshots$(_context66){while(1){switch(_context66.prev=_context66.next){case 0:syncEngineImpl=debugCast(syncEngine);activeQueries=[];newViewSnapshots=[];_iteratorNormalCompletion58=true;_didIteratorError58=false;_iteratorError58=undefined;_context66.prev=6;_iterator58=targets[Symbol.iterator]();case 8:if(_iteratorNormalCompletion58=(_step58=_iterator58.next()).done){_context66.next=59;break;}targetId=_step58.value;targetData=void 0;queries=syncEngineImpl.queriesByTarget.get(targetId);if(!(queries&&queries.length!==0)){_context66.next=47;break;}_context66.next=15;return regeneratorRuntime.awrap(allocateTarget(syncEngineImpl.localStore,queryToTarget(queries[0])));case 15:targetData=_context66.sent;_iteratorNormalCompletion59=true;_didIteratorError59=false;_iteratorError59=undefined;_context66.prev=19;_iterator59=queries[Symbol.iterator]();case 21:if(_iteratorNormalCompletion59=(_step59=_iterator59.next()).done){_context66.next=31;break;}query=_step59.value;queryView=syncEngineImpl.queryViewsByQuery.get(query);_context66.next=26;return regeneratorRuntime.awrap(synchronizeViewAndComputeSnapshot(syncEngineImpl,queryView));case 26:viewChange=_context66.sent;if(viewChange.snapshot){newViewSnapshots.push(viewChange.snapshot);}case 28:_iteratorNormalCompletion59=true;_context66.next=21;break;case 31:_context66.next=37;break;case 33:_context66.prev=33;_context66.t0=_context66["catch"](19);_didIteratorError59=true;_iteratorError59=_context66.t0;case 37:_context66.prev=37;_context66.prev=38;if(!_iteratorNormalCompletion59&&_iterator59["return"]!=null){_iterator59["return"]();}case 40:_context66.prev=40;if(!_didIteratorError59){_context66.next=43;break;}throw _iteratorError59;case 43:return _context66.finish(40);case 44:return _context66.finish(37);case 45:_context66.next=55;break;case 47:_context66.next=49;return regeneratorRuntime.awrap(getCachedTarget(syncEngineImpl.localStore,targetId));case 49:target=_context66.sent;_context66.next=52;return regeneratorRuntime.awrap(allocateTarget(syncEngineImpl.localStore,target));case 52:targetData=_context66.sent;_context66.next=55;return regeneratorRuntime.awrap(initializeViewAndComputeSnapshot(syncEngineImpl,synthesizeTargetToQuery(target),targetId,/*current=*/false));case 55:activeQueries.push(targetData);case 56:_iteratorNormalCompletion58=true;_context66.next=8;break;case 59:_context66.next=65;break;case 61:_context66.prev=61;_context66.t1=_context66["catch"](6);_didIteratorError58=true;_iteratorError58=_context66.t1;case 65:_context66.prev=65;_context66.prev=66;if(!_iteratorNormalCompletion58&&_iterator58["return"]!=null){_iterator58["return"]();}case 68:_context66.prev=68;if(!_didIteratorError58){_context66.next=71;break;}throw _iteratorError58;case 71:return _context66.finish(68);case 72:return _context66.finish(65);case 73:syncEngineImpl.syncEngineListener.onWatchChange(newViewSnapshots);return _context66.abrupt("return",activeQueries);case 75:case"end":return _context66.stop();}}},null,null,[[6,61,65,73],[19,33,37,45],[38,,40,44],[66,,68,72]]);}/**
 * Creates a `Query` object from the specified `Target`. There is no way to
 * obtain the original `Query`, so we synthesize a `Query` from the `Target`
 * object.
 *
 * The synthesized result might be different from the original `Query`, but
 * since the synthesized `Query` should return the same results as the
 * original one (only the presentation of results might differ), the potential
 * difference will not cause issues.
 */ // PORTING NOTE: Multi-Tab only.
function synthesizeTargetToQuery(target){return newQuery(target.path,target.collectionGroup,target.orderBy,target.filters,target.limit,"F"/* First */,target.startAt,target.endAt);}/** Returns the IDs of the clients that are currently active. */ // PORTING NOTE: Multi-Tab only.
function getActiveClients(syncEngine){var syncEngineImpl=debugCast(syncEngine);return getActiveClientsFromPersistence(syncEngineImpl.localStore);}/** Applies a query target change from a different tab. */ // PORTING NOTE: Multi-Tab only.
function applyTargetState(syncEngine,targetId,state,error){var syncEngineImpl,changes,synthesizedRemoteEvent;return regeneratorRuntime.async(function applyTargetState$(_context67){while(1){switch(_context67.prev=_context67.next){case 0:syncEngineImpl=debugCast(syncEngine);if(!syncEngineImpl._isPrimaryClient){_context67.next=4;break;}// If we receive a target state notification via WebStorage, we are
// either already secondary or another tab has taken the primary lease.
logDebug(LOG_TAG$b,'Ignoring unexpected query state notification.');return _context67.abrupt("return");case 4:if(!syncEngineImpl.queriesByTarget.has(targetId)){_context67.next=20;break;}_context67.t0=state;_context67.next=_context67.t0==='current'?8:_context67.t0==='not-current'?8:_context67.t0==='rejected'?15:19;break;case 8:_context67.next=10;return regeneratorRuntime.awrap(getNewDocumentChanges(syncEngineImpl.localStore));case 10:changes=_context67.sent;synthesizedRemoteEvent=RemoteEvent.createSynthesizedRemoteEventForCurrentChange(targetId,state==='current');_context67.next=14;return regeneratorRuntime.awrap(emitNewSnapsAndNotifyLocalStore(syncEngineImpl,changes,synthesizedRemoteEvent));case 14:return _context67.abrupt("break",20);case 15:_context67.next=17;return regeneratorRuntime.awrap(releaseTarget(syncEngineImpl.localStore,targetId,/* keepPersistedTargetData */true));case 17:removeAndCleanupTarget(syncEngineImpl,targetId,error);return _context67.abrupt("break",20);case 19:fail();case 20:case"end":return _context67.stop();}}});}/** Adds or removes Watch targets for queries from different tabs. */function applyActiveTargetsChange(syncEngine,added,removed){var syncEngineImpl,_iteratorNormalCompletion60,_didIteratorError60,_iteratorError60,_iterator60,_step60,targetId,target,targetData,_iteratorNormalCompletion61,_didIteratorError61,_iteratorError61,_loop4,_iterator61,_step61,_ret2;return regeneratorRuntime.async(function applyActiveTargetsChange$(_context69){while(1){switch(_context69.prev=_context69.next){case 0:syncEngineImpl=ensureWatchCallbacks(syncEngine);if(syncEngineImpl._isPrimaryClient){_context69.next=3;break;}return _context69.abrupt("return");case 3:_iteratorNormalCompletion60=true;_didIteratorError60=false;_iteratorError60=undefined;_context69.prev=6;_iterator60=added[Symbol.iterator]();case 8:if(_iteratorNormalCompletion60=(_step60=_iterator60.next()).done){_context69.next=25;break;}targetId=_step60.value;if(!syncEngineImpl.queriesByTarget.has(targetId)){_context69.next=13;break;}// A target might have been added in a previous attempt
logDebug(LOG_TAG$b,'Adding an already active target '+targetId);return _context69.abrupt("continue",22);case 13:_context69.next=15;return regeneratorRuntime.awrap(getCachedTarget(syncEngineImpl.localStore,targetId));case 15:target=_context69.sent;_context69.next=18;return regeneratorRuntime.awrap(allocateTarget(syncEngineImpl.localStore,target));case 18:targetData=_context69.sent;_context69.next=21;return regeneratorRuntime.awrap(initializeViewAndComputeSnapshot(syncEngineImpl,synthesizeTargetToQuery(target),targetData.targetId,/*current=*/false));case 21:remoteStoreListen(syncEngineImpl.remoteStore,targetData);case 22:_iteratorNormalCompletion60=true;_context69.next=8;break;case 25:_context69.next=31;break;case 27:_context69.prev=27;_context69.t0=_context69["catch"](6);_didIteratorError60=true;_iteratorError60=_context69.t0;case 31:_context69.prev=31;_context69.prev=32;if(!_iteratorNormalCompletion60&&_iterator60["return"]!=null){_iterator60["return"]();}case 34:_context69.prev=34;if(!_didIteratorError60){_context69.next=37;break;}throw _iteratorError60;case 37:return _context69.finish(34);case 38:return _context69.finish(31);case 39:_iteratorNormalCompletion61=true;_didIteratorError61=false;_iteratorError61=undefined;_context69.prev=42;_loop4=function _loop4(){var targetId;return regeneratorRuntime.async(function _loop4$(_context68){while(1){switch(_context68.prev=_context68.next){case 0:targetId=_step61.value;if(syncEngineImpl.queriesByTarget.has(targetId)){_context68.next=3;break;}return _context68.abrupt("return","continue");case 3:_context68.next=5;return regeneratorRuntime.awrap(releaseTarget(syncEngineImpl.localStore,targetId,/* keepPersistedTargetData */false).then(function(){remoteStoreUnlisten(syncEngineImpl.remoteStore,targetId);removeAndCleanupTarget(syncEngineImpl,targetId);})["catch"](ignoreIfPrimaryLeaseLoss));case 5:case"end":return _context68.stop();}}});};_iterator61=removed[Symbol.iterator]();case 45:if(_iteratorNormalCompletion61=(_step61=_iterator61.next()).done){_context69.next=54;break;}_context69.next=48;return regeneratorRuntime.awrap(_loop4());case 48:_ret2=_context69.sent;if(!(_ret2==="continue")){_context69.next=51;break;}return _context69.abrupt("continue",51);case 51:_iteratorNormalCompletion61=true;_context69.next=45;break;case 54:_context69.next=60;break;case 56:_context69.prev=56;_context69.t1=_context69["catch"](42);_didIteratorError61=true;_iteratorError61=_context69.t1;case 60:_context69.prev=60;_context69.prev=61;if(!_iteratorNormalCompletion61&&_iterator61["return"]!=null){_iterator61["return"]();}case 63:_context69.prev=63;if(!_didIteratorError61){_context69.next=66;break;}throw _iteratorError61;case 66:return _context69.finish(63);case 67:return _context69.finish(60);case 68:case"end":return _context69.stop();}}},null,null,[[6,27,31,39],[32,,34,38],[42,56,60,68],[61,,63,67]]);}function ensureWatchCallbacks(syncEngine){var syncEngineImpl=debugCast(syncEngine);syncEngineImpl.remoteStore.remoteSyncer.applyRemoteEvent=applyRemoteEvent.bind(null,syncEngineImpl);syncEngineImpl.remoteStore.remoteSyncer.getRemoteKeysForTarget=getRemoteKeysForTarget.bind(null,syncEngineImpl);syncEngineImpl.remoteStore.remoteSyncer.rejectListen=rejectListen.bind(null,syncEngineImpl);syncEngineImpl.syncEngineListener.onWatchChange=eventManagerOnWatchChange.bind(null,syncEngineImpl.eventManager);syncEngineImpl.syncEngineListener.onWatchError=eventManagerOnWatchError.bind(null,syncEngineImpl.eventManager);return syncEngineImpl;}function ensureWriteCallbacks(syncEngine){var syncEngineImpl=debugCast(syncEngine);syncEngineImpl.remoteStore.remoteSyncer.applySuccessfulWrite=applySuccessfulWrite.bind(null,syncEngineImpl);syncEngineImpl.remoteStore.remoteSyncer.rejectFailedWrite=rejectFailedWrite.bind(null,syncEngineImpl);return syncEngineImpl;}/**
 * @license
 * Copyright 2019 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ // TOOD(b/140938512): Drop SimpleQueryEngine and rename IndexFreeQueryEngine.
/**
 * A query engine that takes advantage of the target document mapping in the
 * QueryCache. The IndexFreeQueryEngine optimizes query execution by only
 * reading the documents that previously matched a query plus any documents that were
 * edited after the query was last listened to.
 *
 * There are some cases where Index-Free queries are not guaranteed to produce
 * the same results as full collection scans. In these cases, the
 * IndexFreeQueryEngine falls back to full query processing. These cases are:
 *
 * - Limit queries where a document that matched the query previously no longer
 *   matches the query.
 *
 * - Limit queries where a document edit may cause the document to sort below
 *   another document that is in the local cache.
 *
 * - Queries that have never been CURRENT or free of Limbo documents.
 */var IndexFreeQueryEngine=/*#__PURE__*/function(){function IndexFreeQueryEngine(){_classCallCheck(this,IndexFreeQueryEngine);}_createClass(IndexFreeQueryEngine,[{key:"setLocalDocumentsView",value:function setLocalDocumentsView(localDocuments){this.localDocumentsView=localDocuments;}},{key:"getDocumentsMatchingQuery",value:function getDocumentsMatchingQuery(transaction,query,lastLimboFreeSnapshotVersion,remoteKeys){var _this130=this;// Queries that match all documents don't benefit from using
// IndexFreeQueries. It is more efficient to scan all documents in a
// collection, rather than to perform individual lookups.
if(matchesAllDocuments(query)){return this.executeFullCollectionScan(transaction,query);}// Queries that have never seen a snapshot without limbo free documents
// should also be run as a full collection scan.
if(lastLimboFreeSnapshotVersion.isEqual(SnapshotVersion.min())){return this.executeFullCollectionScan(transaction,query);}return this.localDocumentsView.getDocuments(transaction,remoteKeys).next(function(documents){var previousResults=_this130.applyQuery(query,documents);if((hasLimitToFirst(query)||hasLimitToLast(query))&&_this130.needsRefill(query.limitType,previousResults,remoteKeys,lastLimboFreeSnapshotVersion)){return _this130.executeFullCollectionScan(transaction,query);}if(getLogLevel()<=_logger.LogLevel.DEBUG){logDebug('IndexFreeQueryEngine','Re-using previous result from %s to execute query: %s',lastLimboFreeSnapshotVersion.toString(),stringifyQuery(query));}// Retrieve all results for documents that were updated since the last
// limbo-document free remote snapshot.
return _this130.localDocumentsView.getDocumentsMatchingQuery(transaction,query,lastLimboFreeSnapshotVersion).next(function(updatedResults){// We merge `previousResults` into `updateResults`, since
// `updateResults` is already a DocumentMap. If a document is
// contained in both lists, then its contents are the same.
previousResults.forEach(function(doc){updatedResults=updatedResults.insert(doc.key,doc);});return updatedResults;});});}/** Applies the query filter and sorting to the provided documents.  */},{key:"applyQuery",value:function applyQuery(query,documents){// Sort the documents and re-apply the query filter since previously
// matching documents do not necessarily still match the query.
var queryResults=new SortedSet(newQueryComparator(query));documents.forEach(function(_,maybeDoc){if(maybeDoc instanceof Document&&queryMatches(query,maybeDoc)){queryResults=queryResults.add(maybeDoc);}});return queryResults;}/**
     * Determines if a limit query needs to be refilled from cache, making it
     * ineligible for index-free execution.
     *
     * @param sortedPreviousResults The documents that matched the query when it
     * was last synchronized, sorted by the query's comparator.
     * @param remoteKeys The document keys that matched the query at the last
     * snapshot.
     * @param limboFreeSnapshotVersion The version of the snapshot when the query
     * was last synchronized.
     */},{key:"needsRefill",value:function needsRefill(limitType,sortedPreviousResults,remoteKeys,limboFreeSnapshotVersion){// The query needs to be refilled if a previously matching document no
// longer matches.
if(remoteKeys.size!==sortedPreviousResults.size){return true;}// Limit queries are not eligible for index-free query execution if there is
// a potential that an older document from cache now sorts before a document
// that was previously part of the limit. This, however, can only happen if
// the document at the edge of the limit goes out of limit.
// If a document that is not the limit boundary sorts differently,
// the boundary of the limit itself did not change and documents from cache
// will continue to be "rejected" by this boundary. Therefore, we can ignore
// any modifications that don't affect the last document.
var docAtLimitEdge=limitType==="F"/* First */?sortedPreviousResults.last():sortedPreviousResults.first();if(!docAtLimitEdge){// We don't need to refill the query if there were already no documents.
return false;}return docAtLimitEdge.hasPendingWrites||docAtLimitEdge.version.compareTo(limboFreeSnapshotVersion)>0;}},{key:"executeFullCollectionScan",value:function executeFullCollectionScan(transaction,query){if(getLogLevel()<=_logger.LogLevel.DEBUG){logDebug('IndexFreeQueryEngine','Using full collection scan to execute query:',stringifyQuery(query));}return this.localDocumentsView.getDocumentsMatchingQuery(transaction,query,SnapshotVersion.min());}}]);return IndexFreeQueryEngine;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var MemoryMutationQueue=/*#__PURE__*/function(){function MemoryMutationQueue(indexManager,referenceDelegate){_classCallCheck(this,MemoryMutationQueue);this.indexManager=indexManager;this.referenceDelegate=referenceDelegate;/**
         * The set of all mutations that have been sent but not yet been applied to
         * the backend.
         */this.mutationQueue=[];/** Next value to use when assigning sequential IDs to each mutation batch. */this.nextBatchId=1;/** An ordered mapping between documents and the mutations batch IDs. */this.batchesByDocumentKey=new SortedSet(DocReference.compareByKey);}_createClass(MemoryMutationQueue,[{key:"checkEmpty",value:function checkEmpty(transaction){return PersistencePromise.resolve(this.mutationQueue.length===0);}},{key:"addMutationBatch",value:function addMutationBatch(transaction,localWriteTime,baseMutations,mutations){var batchId=this.nextBatchId;this.nextBatchId++;if(this.mutationQueue.length>0){var prior=this.mutationQueue[this.mutationQueue.length-1];}var batch=new MutationBatch(batchId,localWriteTime,baseMutations,mutations);this.mutationQueue.push(batch);// Track references by document key and index collection parents.
var _iteratorNormalCompletion62=true;var _didIteratorError62=false;var _iteratorError62=undefined;try{for(var _iterator62=mutations[Symbol.iterator](),_step62;!(_iteratorNormalCompletion62=(_step62=_iterator62.next()).done);_iteratorNormalCompletion62=true){var mutation=_step62.value;this.batchesByDocumentKey=this.batchesByDocumentKey.add(new DocReference(mutation.key,batchId));this.indexManager.addToCollectionParentIndex(transaction,mutation.key.path.popLast());}}catch(err){_didIteratorError62=true;_iteratorError62=err;}finally{try{if(!_iteratorNormalCompletion62&&_iterator62["return"]!=null){_iterator62["return"]();}}finally{if(_didIteratorError62){throw _iteratorError62;}}}return PersistencePromise.resolve(batch);}},{key:"lookupMutationBatch",value:function lookupMutationBatch(transaction,batchId){return PersistencePromise.resolve(this.findMutationBatch(batchId));}},{key:"getNextMutationBatchAfterBatchId",value:function getNextMutationBatchAfterBatchId(transaction,batchId){var nextBatchId=batchId+1;// The requested batchId may still be out of range so normalize it to the
// start of the queue.
var rawIndex=this.indexOfBatchId(nextBatchId);var index=rawIndex<0?0:rawIndex;return PersistencePromise.resolve(this.mutationQueue.length>index?this.mutationQueue[index]:null);}},{key:"getHighestUnacknowledgedBatchId",value:function getHighestUnacknowledgedBatchId(){return PersistencePromise.resolve(this.mutationQueue.length===0?BATCHID_UNKNOWN:this.nextBatchId-1);}},{key:"getAllMutationBatches",value:function getAllMutationBatches(transaction){return PersistencePromise.resolve(this.mutationQueue.slice());}},{key:"getAllMutationBatchesAffectingDocumentKey",value:function getAllMutationBatchesAffectingDocumentKey(transaction,documentKey){var _this131=this;var start=new DocReference(documentKey,0);var end=new DocReference(documentKey,Number.POSITIVE_INFINITY);var result=[];this.batchesByDocumentKey.forEachInRange([start,end],function(ref){var batch=_this131.findMutationBatch(ref.targetOrBatchId);result.push(batch);});return PersistencePromise.resolve(result);}},{key:"getAllMutationBatchesAffectingDocumentKeys",value:function getAllMutationBatchesAffectingDocumentKeys(transaction,documentKeys){var _this132=this;var uniqueBatchIDs=new SortedSet(primitiveComparator);documentKeys.forEach(function(documentKey){var start=new DocReference(documentKey,0);var end=new DocReference(documentKey,Number.POSITIVE_INFINITY);_this132.batchesByDocumentKey.forEachInRange([start,end],function(ref){uniqueBatchIDs=uniqueBatchIDs.add(ref.targetOrBatchId);});});return PersistencePromise.resolve(this.findMutationBatches(uniqueBatchIDs));}},{key:"getAllMutationBatchesAffectingQuery",value:function getAllMutationBatchesAffectingQuery(transaction,query){// Use the query path as a prefix for testing if a document matches the
// query.
var prefix=query.path;var immediateChildrenPathLength=prefix.length+1;// Construct a document reference for actually scanning the index. Unlike
// the prefix the document key in this reference must have an even number of
// segments. The empty segment can be used a suffix of the query path
// because it precedes all other segments in an ordered traversal.
var startPath=prefix;if(!DocumentKey.isDocumentKey(startPath)){startPath=startPath.child('');}var start=new DocReference(new DocumentKey(startPath),0);// Find unique batchIDs referenced by all documents potentially matching the
// query.
var uniqueBatchIDs=new SortedSet(primitiveComparator);this.batchesByDocumentKey.forEachWhile(function(ref){var rowKeyPath=ref.key.path;if(!prefix.isPrefixOf(rowKeyPath)){return false;}else{// Rows with document keys more than one segment longer than the query
// path can't be matches. For example, a query on 'rooms' can't match
// the document /rooms/abc/messages/xyx.
// TODO(mcg): we'll need a different scanner when we implement
// ancestor queries.
if(rowKeyPath.length===immediateChildrenPathLength){uniqueBatchIDs=uniqueBatchIDs.add(ref.targetOrBatchId);}return true;}},start);return PersistencePromise.resolve(this.findMutationBatches(uniqueBatchIDs));}},{key:"findMutationBatches",value:function findMutationBatches(batchIDs){var _this133=this;// Construct an array of matching batches, sorted by batchID to ensure that
// multiple mutations affecting the same document key are applied in order.
var result=[];batchIDs.forEach(function(batchId){var batch=_this133.findMutationBatch(batchId);if(batch!==null){result.push(batch);}});return result;}},{key:"removeMutationBatch",value:function removeMutationBatch(transaction,batch){var _this134=this;// Find the position of the first batch for removal.
var batchIndex=this.indexOfExistingBatchId(batch.batchId,'removed');hardAssert(batchIndex===0);this.mutationQueue.shift();var references=this.batchesByDocumentKey;return PersistencePromise.forEach(batch.mutations,function(mutation){var ref=new DocReference(mutation.key,batch.batchId);references=references["delete"](ref);return _this134.referenceDelegate.markPotentiallyOrphaned(transaction,mutation.key);}).next(function(){_this134.batchesByDocumentKey=references;});}},{key:"removeCachedMutationKeys",value:function removeCachedMutationKeys(batchId){// No-op since the memory mutation queue does not maintain a separate cache.
}},{key:"containsKey",value:function containsKey(txn,key){var ref=new DocReference(key,0);var firstRef=this.batchesByDocumentKey.firstAfterOrEqual(ref);return PersistencePromise.resolve(key.isEqual(firstRef&&firstRef.key));}},{key:"performConsistencyCheck",value:function performConsistencyCheck(txn){if(this.mutationQueue.length===0);return PersistencePromise.resolve();}/**
     * Finds the index of the given batchId in the mutation queue and asserts that
     * the resulting index is within the bounds of the queue.
     *
     * @param batchId The batchId to search for
     * @param action A description of what the caller is doing, phrased in passive
     * form (e.g. "acknowledged" in a routine that acknowledges batches).
     */},{key:"indexOfExistingBatchId",value:function indexOfExistingBatchId(batchId,action){var index=this.indexOfBatchId(batchId);return index;}/**
     * Finds the index of the given batchId in the mutation queue. This operation
     * is O(1).
     *
     * @return The computed index of the batch with the given batchId, based on
     * the state of the queue. Note this index can be negative if the requested
     * batchId has already been remvoed from the queue or past the end of the
     * queue if the batchId is larger than the last added batch.
     */},{key:"indexOfBatchId",value:function indexOfBatchId(batchId){if(this.mutationQueue.length===0){// As an index this is past the end of the queue
return 0;}// Examine the front of the queue to figure out the difference between the
// batchId and indexes in the array. Note that since the queue is ordered
// by batchId, if the first batch has a larger batchId then the requested
// batchId doesn't exist in the queue.
var firstBatchId=this.mutationQueue[0].batchId;return batchId-firstBatchId;}/**
     * A version of lookupMutationBatch that doesn't return a promise, this makes
     * other functions that uses this code easier to read and more efficent.
     */},{key:"findMutationBatch",value:function findMutationBatch(batchId){var index=this.indexOfBatchId(batchId);if(index<0||index>=this.mutationQueue.length){return null;}var batch=this.mutationQueue[index];return batch;}}]);return MemoryMutationQueue;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */function documentEntryMap(){return new SortedMap(DocumentKey.comparator);}var MemoryRemoteDocumentCache=/*#__PURE__*/function(){/**
     * @param sizer Used to assess the size of a document. For eager GC, this is expected to just
     * return 0 to avoid unnecessarily doing the work of calculating the size.
     */function MemoryRemoteDocumentCache(indexManager,sizer){_classCallCheck(this,MemoryRemoteDocumentCache);this.indexManager=indexManager;this.sizer=sizer;/** Underlying cache of documents and their read times. */this.docs=documentEntryMap();/** Size of all cached documents. */this.size=0;}/**
     * Adds the supplied entry to the cache and updates the cache size as appropriate.
     *
     * All calls of `addEntry`  are required to go through the RemoteDocumentChangeBuffer
     * returned by `newChangeBuffer()`.
     */_createClass(MemoryRemoteDocumentCache,[{key:"addEntry",value:function addEntry(transaction,doc,readTime){var key=doc.key;var entry=this.docs.get(key);var previousSize=entry?entry.size:0;var currentSize=this.sizer(doc);this.docs=this.docs.insert(key,{maybeDocument:doc,size:currentSize,readTime:readTime});this.size+=currentSize-previousSize;return this.indexManager.addToCollectionParentIndex(transaction,key.path.popLast());}/**
     * Removes the specified entry from the cache and updates the cache size as appropriate.
     *
     * All calls of `removeEntry` are required to go through the RemoteDocumentChangeBuffer
     * returned by `newChangeBuffer()`.
     */},{key:"removeEntry",value:function removeEntry(documentKey){var entry=this.docs.get(documentKey);if(entry){this.docs=this.docs.remove(documentKey);this.size-=entry.size;}}},{key:"getEntry",value:function getEntry(transaction,documentKey){var entry=this.docs.get(documentKey);return PersistencePromise.resolve(entry?entry.maybeDocument:null);}},{key:"getEntries",value:function getEntries(transaction,documentKeys){var _this135=this;var results=nullableMaybeDocumentMap();documentKeys.forEach(function(documentKey){var entry=_this135.docs.get(documentKey);results=results.insert(documentKey,entry?entry.maybeDocument:null);});return PersistencePromise.resolve(results);}},{key:"getDocumentsMatchingQuery",value:function getDocumentsMatchingQuery(transaction,query,sinceReadTime){var results=documentMap();// Documents are ordered by key, so we can use a prefix scan to narrow down
// the documents we need to match the query against.
var prefix=new DocumentKey(query.path.child(''));var iterator=this.docs.getIteratorFrom(prefix);while(iterator.hasNext()){var _iterator$getNext=iterator.getNext(),key=_iterator$getNext.key,_iterator$getNext$val=_iterator$getNext.value,maybeDocument=_iterator$getNext$val.maybeDocument,readTime=_iterator$getNext$val.readTime;if(!query.path.isPrefixOf(key.path)){break;}if(readTime.compareTo(sinceReadTime)<=0){continue;}if(maybeDocument instanceof Document&&queryMatches(query,maybeDocument)){results=results.insert(maybeDocument.key,maybeDocument);}}return PersistencePromise.resolve(results);}},{key:"forEachDocumentKey",value:function forEachDocumentKey(transaction,f){return PersistencePromise.forEach(this.docs,function(key){return f(key);});}},{key:"newChangeBuffer",value:function newChangeBuffer(options){// `trackRemovals` is ignores since the MemoryRemoteDocumentCache keeps
// a separate changelog and does not need special handling for removals.
return new MemoryRemoteDocumentCache.RemoteDocumentChangeBuffer(this);}},{key:"getSize",value:function getSize(txn){return PersistencePromise.resolve(this.size);}}]);return MemoryRemoteDocumentCache;}();/**
 * Handles the details of adding and updating documents in the MemoryRemoteDocumentCache.
 */MemoryRemoteDocumentCache.RemoteDocumentChangeBuffer=/*#__PURE__*/function(_RemoteDocumentChange2){_inherits(_class2,_RemoteDocumentChange2);function _class2(documentCache){var _this136;_classCallCheck(this,_class2);_this136=_possibleConstructorReturn(this,_getPrototypeOf(_class2).call(this));_this136.documentCache=documentCache;return _this136;}_createClass(_class2,[{key:"applyChanges",value:function applyChanges(transaction){var _this137=this;var promises=[];this.changes.forEach(function(key,doc){if(doc){promises.push(_this137.documentCache.addEntry(transaction,doc,_this137.readTime));}else{_this137.documentCache.removeEntry(key);}});return PersistencePromise.waitFor(promises);}},{key:"getFromCache",value:function getFromCache(transaction,documentKey){return this.documentCache.getEntry(transaction,documentKey);}},{key:"getAllFromCache",value:function getAllFromCache(transaction,documentKeys){return this.documentCache.getEntries(transaction,documentKeys);}}]);return _class2;}(RemoteDocumentChangeBuffer);/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var MemoryTargetCache=/*#__PURE__*/function(){function MemoryTargetCache(persistence){_classCallCheck(this,MemoryTargetCache);this.persistence=persistence;/**
         * Maps a target to the data about that target
         */this.targets=new ObjectMap(function(t){return canonifyTarget(t);},targetEquals);/** The last received snapshot version. */this.lastRemoteSnapshotVersion=SnapshotVersion.min();/** The highest numbered target ID encountered. */this.highestTargetId=0;/** The highest sequence number encountered. */this.highestSequenceNumber=0;/**
         * A ordered bidirectional mapping between documents and the remote target
         * IDs.
         */this.references=new ReferenceSet();this.targetCount=0;this.targetIdGenerator=TargetIdGenerator.forTargetCache();}_createClass(MemoryTargetCache,[{key:"forEachTarget",value:function forEachTarget(txn,f){this.targets.forEach(function(_,targetData){return f(targetData);});return PersistencePromise.resolve();}},{key:"getLastRemoteSnapshotVersion",value:function getLastRemoteSnapshotVersion(transaction){return PersistencePromise.resolve(this.lastRemoteSnapshotVersion);}},{key:"getHighestSequenceNumber",value:function getHighestSequenceNumber(transaction){return PersistencePromise.resolve(this.highestSequenceNumber);}},{key:"allocateTargetId",value:function allocateTargetId(transaction){this.highestTargetId=this.targetIdGenerator.next();return PersistencePromise.resolve(this.highestTargetId);}},{key:"setTargetsMetadata",value:function setTargetsMetadata(transaction,highestListenSequenceNumber,lastRemoteSnapshotVersion){if(lastRemoteSnapshotVersion){this.lastRemoteSnapshotVersion=lastRemoteSnapshotVersion;}if(highestListenSequenceNumber>this.highestSequenceNumber){this.highestSequenceNumber=highestListenSequenceNumber;}return PersistencePromise.resolve();}},{key:"saveTargetData",value:function saveTargetData(targetData){this.targets.set(targetData.target,targetData);var targetId=targetData.targetId;if(targetId>this.highestTargetId){this.targetIdGenerator=new TargetIdGenerator(targetId);this.highestTargetId=targetId;}if(targetData.sequenceNumber>this.highestSequenceNumber){this.highestSequenceNumber=targetData.sequenceNumber;}}},{key:"addTargetData",value:function addTargetData(transaction,targetData){this.saveTargetData(targetData);this.targetCount+=1;return PersistencePromise.resolve();}},{key:"updateTargetData",value:function updateTargetData(transaction,targetData){this.saveTargetData(targetData);return PersistencePromise.resolve();}},{key:"removeTargetData",value:function removeTargetData(transaction,targetData){this.targets["delete"](targetData.target);this.references.removeReferencesForId(targetData.targetId);this.targetCount-=1;return PersistencePromise.resolve();}},{key:"removeTargets",value:function removeTargets(transaction,upperBound,activeTargetIds){var _this138=this;var count=0;var removals=[];this.targets.forEach(function(key,targetData){if(targetData.sequenceNumber<=upperBound&&activeTargetIds.get(targetData.targetId)===null){_this138.targets["delete"](key);removals.push(_this138.removeMatchingKeysForTargetId(transaction,targetData.targetId));count++;}});return PersistencePromise.waitFor(removals).next(function(){return count;});}},{key:"getTargetCount",value:function getTargetCount(transaction){return PersistencePromise.resolve(this.targetCount);}},{key:"getTargetData",value:function getTargetData(transaction,target){var targetData=this.targets.get(target)||null;return PersistencePromise.resolve(targetData);}},{key:"addMatchingKeys",value:function addMatchingKeys(txn,keys,targetId){this.references.addReferences(keys,targetId);return PersistencePromise.resolve();}},{key:"removeMatchingKeys",value:function removeMatchingKeys(txn,keys,targetId){this.references.removeReferences(keys,targetId);var referenceDelegate=this.persistence.referenceDelegate;var promises=[];if(referenceDelegate){keys.forEach(function(key){promises.push(referenceDelegate.markPotentiallyOrphaned(txn,key));});}return PersistencePromise.waitFor(promises);}},{key:"removeMatchingKeysForTargetId",value:function removeMatchingKeysForTargetId(txn,targetId){this.references.removeReferencesForId(targetId);return PersistencePromise.resolve();}},{key:"getMatchingKeysForTargetId",value:function getMatchingKeysForTargetId(txn,targetId){var matchingKeys=this.references.referencesForId(targetId);return PersistencePromise.resolve(matchingKeys);}},{key:"containsKey",value:function containsKey(txn,key){return PersistencePromise.resolve(this.references.containsKey(key));}}]);return MemoryTargetCache;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$c='MemoryPersistence';/**
 * A memory-backed instance of Persistence. Data is stored only in RAM and
 * not persisted across sessions.
 */var MemoryPersistence=/*#__PURE__*/function(){/**
     * The constructor accepts a factory for creating a reference delegate. This
     * allows both the delegate and this instance to have strong references to
     * each other without having nullable fields that would then need to be
     * checked or asserted on every access.
     */function MemoryPersistence(referenceDelegateFactory){var _this139=this;_classCallCheck(this,MemoryPersistence);this.mutationQueues={};this.listenSequence=new ListenSequence(0);this._started=false;this._started=true;this.referenceDelegate=referenceDelegateFactory(this);this.targetCache=new MemoryTargetCache(this);var sizer=function sizer(doc){return _this139.referenceDelegate.documentSize(doc);};this.indexManager=new MemoryIndexManager();this.remoteDocumentCache=new MemoryRemoteDocumentCache(this.indexManager,sizer);}_createClass(MemoryPersistence,[{key:"start",value:function start(){return Promise.resolve();}},{key:"shutdown",value:function shutdown(){// No durable state to ensure is closed on shutdown.
this._started=false;return Promise.resolve();}},{key:"setDatabaseDeletedListener",value:function setDatabaseDeletedListener(){// No op.
}},{key:"setNetworkEnabled",value:function setNetworkEnabled(){// No op.
}},{key:"getIndexManager",value:function getIndexManager(){return this.indexManager;}},{key:"getMutationQueue",value:function getMutationQueue(user){var queue=this.mutationQueues[user.toKey()];if(!queue){queue=new MemoryMutationQueue(this.indexManager,this.referenceDelegate);this.mutationQueues[user.toKey()]=queue;}return queue;}},{key:"getTargetCache",value:function getTargetCache(){return this.targetCache;}},{key:"getRemoteDocumentCache",value:function getRemoteDocumentCache(){return this.remoteDocumentCache;}},{key:"runTransaction",value:function runTransaction(action,mode,transactionOperation){var _this140=this;logDebug(LOG_TAG$c,'Starting transaction:',action);var txn=new MemoryTransaction(this.listenSequence.next());this.referenceDelegate.onTransactionStarted();return transactionOperation(txn).next(function(result){return _this140.referenceDelegate.onTransactionCommitted(txn).next(function(){return result;});}).toPromise().then(function(result){txn.raiseOnCommittedEvent();return result;});}},{key:"mutationQueuesContainKey",value:function mutationQueuesContainKey(transaction,key){return PersistencePromise.or(Object.values(this.mutationQueues).map(function(queue){return function(){return queue.containsKey(transaction,key);};}));}},{key:"started",get:function get(){return this._started;}}]);return MemoryPersistence;}();/**
 * Memory persistence is not actually transactional, but future implementations
 * may have transaction-scoped state.
 */var MemoryTransaction=/*#__PURE__*/function(_PersistenceTransacti2){_inherits(MemoryTransaction,_PersistenceTransacti2);function MemoryTransaction(currentSequenceNumber){var _this141;_classCallCheck(this,MemoryTransaction);_this141=_possibleConstructorReturn(this,_getPrototypeOf(MemoryTransaction).call(this));_this141.currentSequenceNumber=currentSequenceNumber;return _this141;}return MemoryTransaction;}(PersistenceTransaction);var MemoryEagerDelegate=/*#__PURE__*/function(){function MemoryEagerDelegate(persistence){_classCallCheck(this,MemoryEagerDelegate);this.persistence=persistence;/** Tracks all documents that are active in Query views. */this.localViewReferences=new ReferenceSet();/** The list of documents that are potentially GCed after each transaction. */this._orphanedDocuments=null;}_createClass(MemoryEagerDelegate,[{key:"addReference",value:function addReference(txn,targetId,key){this.localViewReferences.addReference(key,targetId);this.orphanedDocuments["delete"](key.toString());return PersistencePromise.resolve();}},{key:"removeReference",value:function removeReference(txn,targetId,key){this.localViewReferences.removeReference(key,targetId);this.orphanedDocuments.add(key.toString());return PersistencePromise.resolve();}},{key:"markPotentiallyOrphaned",value:function markPotentiallyOrphaned(txn,key){this.orphanedDocuments.add(key.toString());return PersistencePromise.resolve();}},{key:"removeTarget",value:function removeTarget(txn,targetData){var _this142=this;var orphaned=this.localViewReferences.removeReferencesForId(targetData.targetId);orphaned.forEach(function(key){return _this142.orphanedDocuments.add(key.toString());});var cache=this.persistence.getTargetCache();return cache.getMatchingKeysForTargetId(txn,targetData.targetId).next(function(keys){keys.forEach(function(key){return _this142.orphanedDocuments.add(key.toString());});}).next(function(){return cache.removeTargetData(txn,targetData);});}},{key:"onTransactionStarted",value:function onTransactionStarted(){this._orphanedDocuments=new Set();}},{key:"onTransactionCommitted",value:function onTransactionCommitted(txn){var _this143=this;// Remove newly orphaned documents.
var cache=this.persistence.getRemoteDocumentCache();var changeBuffer=cache.newChangeBuffer();return PersistencePromise.forEach(this.orphanedDocuments,function(path){var key=DocumentKey.fromPath(path);return _this143.isReferenced(txn,key).next(function(isReferenced){if(!isReferenced){changeBuffer.removeEntry(key);}});}).next(function(){_this143._orphanedDocuments=null;return changeBuffer.apply(txn);});}},{key:"updateLimboDocument",value:function updateLimboDocument(txn,key){var _this144=this;return this.isReferenced(txn,key).next(function(isReferenced){if(isReferenced){_this144.orphanedDocuments["delete"](key.toString());}else{_this144.orphanedDocuments.add(key.toString());}});}},{key:"documentSize",value:function documentSize(doc){// For eager GC, we don't care about the document size, there are no size thresholds.
return 0;}},{key:"isReferenced",value:function isReferenced(txn,key){var _this145=this;return PersistencePromise.or([function(){return PersistencePromise.resolve(_this145.localViewReferences.containsKey(key));},function(){return _this145.persistence.getTargetCache().containsKey(txn,key);},function(){return _this145.persistence.mutationQueuesContainKey(txn,key);}]);}},{key:"orphanedDocuments",get:function get(){if(!this._orphanedDocuments){throw fail();}else{return this._orphanedDocuments;}}}],[{key:"factory",value:function factory(persistence){return new MemoryEagerDelegate(persistence);}}]);return MemoryEagerDelegate;}();/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /** Used by tests so we can match @grpc/proto-loader behavior. */var protoLoaderOptions={longs:String,enums:String,defaults:true,oneofs:false};/**
 * Loads the protocol buffer definitions for Firestore.
 *
 * @returns The GrpcObject representing our protos.
 */function loadProtos(){var root=(0,_path3.resolve)(__dirname,"src/protos");var firestoreProtoFile=(0,_path3.join)(root,'google/firestore/v1/firestore.proto');var packageDefinition=(0,_protoLoader.loadSync)(firestoreProtoFile,Object.assign(Object.assign({},protoLoaderOptions),{includeDirs:[root]}));return(0,_grpcJs.loadPackageDefinition)(packageDefinition);}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Provides a simple helper class that implements the Stream interface to
 * bridge to other implementations that are streams but do not implement the
 * interface. The stream callbacks are invoked with the callOn... methods.
 */var StreamBridge=/*#__PURE__*/function(){function StreamBridge(args){_classCallCheck(this,StreamBridge);this.sendFn=args.sendFn;this.closeFn=args.closeFn;}_createClass(StreamBridge,[{key:"onOpen",value:function onOpen(callback){this.wrappedOnOpen=callback;}},{key:"onClose",value:function onClose(callback){this.wrappedOnClose=callback;}},{key:"onMessage",value:function onMessage(callback){this.wrappedOnMessage=callback;}},{key:"close",value:function close(){this.closeFn();}},{key:"send",value:function send(msg){this.sendFn(msg);}},{key:"callOnOpen",value:function callOnOpen(){this.wrappedOnOpen();}},{key:"callOnClose",value:function callOnClose(err){this.wrappedOnClose(err);}},{key:"callOnMessage",value:function callOnMessage(msg){this.wrappedOnMessage(msg);}}]);return StreamBridge;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /*
 * Utilities for dealing with node.js-style APIs. See nodePromise for more
 * details.
 */ /**
 * Creates a node-style callback that resolves or rejects a new Promise. The
 * callback is passed to the given action which can then use the callback as
 * a parameter to a node-style function.
 *
 * The intent is to directly bridge a node-style function (which takes a
 * callback) into a Promise without manually converting between the node-style
 * callback and the promise at each call.
 *
 * In effect it allows you to convert:
 *
 * @example
 * new Promise((resolve: (value?: fs.Stats) => void,
 *              reject: (error?: any) => void) => {
 *   fs.stat(path, (error?: any, stat?: fs.Stats) => {
 *     if (error) {
 *       reject(error);
 *     } else {
 *       resolve(stat);
 *     }
 *   });
 * });
 *
 * Into
 * @example
 * nodePromise((callback: NodeCallback<fs.Stats>) => {
 *   fs.stat(path, callback);
 * });
 *
 * @param action a function that takes a node-style callback as an argument and
 *     then uses that callback to invoke some node-style API.
 * @return a new Promise which will be rejected if the callback is given the
 *     first Error parameter or will resolve to the value given otherwise.
 */function nodePromise(action){return new Promise(function(resolve,reject){action(function(error,value){if(error){reject(error);}else{resolve(value);}});});}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$d='Connection';var X_GOOG_API_CLIENT_VALUE="gl-node/".concat(process.versions.node," fire/").concat(version," grpc/").concat(_package.version);function createMetadata(databasePath,token){hardAssert(token===null||token.type==='OAuth');var metadata=new _grpcJs.Metadata();if(token){for(var header in token.authHeaders){if(token.authHeaders.hasOwnProperty(header)){metadata.set(header,token.authHeaders[header]);}}}metadata.set('x-goog-api-client',X_GOOG_API_CLIENT_VALUE);// This header is used to improve routing and project isolation by the
// backend.
metadata.set('google-cloud-resource-prefix',databasePath);return metadata;}/**
 * A Connection implemented by GRPC-Node.
 */var GrpcConnection=/*#__PURE__*/function(){function GrpcConnection(protos,databaseInfo){_classCallCheck(this,GrpcConnection);this.databaseInfo=databaseInfo;// We cache stubs for the most-recently-used token.
this.cachedStub=null;// eslint-disable-next-line @typescript-eslint/no-explicit-any
this.firestore=protos['google']['firestore']['v1'];this.databasePath="projects/".concat(databaseInfo.databaseId.projectId,"/databases/").concat(databaseInfo.databaseId.database);}_createClass(GrpcConnection,[{key:"ensureActiveStub",value:function ensureActiveStub(){if(!this.cachedStub){logDebug(LOG_TAG$d,'Creating Firestore stub.');var credentials$1=this.databaseInfo.ssl?_grpcJs.credentials.createSsl():_grpcJs.credentials.createInsecure();this.cachedStub=new this.firestore.Firestore(this.databaseInfo.host,credentials$1);}return this.cachedStub;}},{key:"invokeRPC",value:function invokeRPC(rpcName,path,request,token){var stub=this.ensureActiveStub();var metadata=createMetadata(this.databasePath,token);var jsonRequest=Object.assign({database:this.databasePath},request);return nodePromise(function(callback){logDebug(LOG_TAG$d,"RPC '".concat(rpcName,"' invoked with request:"),request);return stub[rpcName](jsonRequest,metadata,function(grpcError,value){if(grpcError){logDebug(LOG_TAG$d,"RPC '".concat(rpcName,"' failed with error:"),grpcError);callback(new FirestoreError(mapCodeFromRpcCode(grpcError.code),grpcError.message));}else{logDebug(LOG_TAG$d,"RPC '".concat(rpcName,"' completed with response:"),value);callback(undefined,value);}});});}},{key:"invokeStreamingRPC",value:function invokeStreamingRPC(rpcName,path,request,token){var results=[];var responseDeferred=new Deferred();logDebug(LOG_TAG$d,"RPC '".concat(rpcName,"' invoked (streaming) with request:"),request);var stub=this.ensureActiveStub();var metadata=createMetadata(this.databasePath,token);var jsonRequest=Object.assign(Object.assign({},request),{database:this.databasePath});var stream=stub[rpcName](jsonRequest,metadata);stream.on('data',function(response){logDebug(LOG_TAG$d,"RPC ".concat(rpcName," received result:"),response);results.push(response);});stream.on('end',function(){logDebug(LOG_TAG$d,"RPC '".concat(rpcName,"' completed."));responseDeferred.resolve(results);});stream.on('error',function(grpcError){logDebug(LOG_TAG$d,"RPC '".concat(rpcName,"' failed with error:"),grpcError);var code=mapCodeFromRpcCode(grpcError.code);responseDeferred.reject(new FirestoreError(code,grpcError.message));});return responseDeferred.promise;}// TODO(mikelehen): This "method" is a monster. Should be refactored.
},{key:"openStream",value:function openStream(rpcName,token){var stub=this.ensureActiveStub();var metadata=createMetadata(this.databasePath,token);var grpcStream=stub[rpcName](metadata);var closed=false;var close=function close(err){if(!closed){closed=true;stream.callOnClose(err);grpcStream.end();}};var stream=new StreamBridge({sendFn:function sendFn(msg){if(!closed){logDebug(LOG_TAG$d,'GRPC stream sending:',msg);try{grpcStream.write(msg);}catch(e){// This probably means we didn't conform to the proto.  Make sure to
// log the message we sent.
logError('Failure sending:',msg);logError('Error:',e);throw e;}}else{logDebug(LOG_TAG$d,'Not sending because gRPC stream is closed:',msg);}},closeFn:function closeFn(){logDebug(LOG_TAG$d,'GRPC stream closed locally via close().');close();}});grpcStream.on('data',function(msg){if(!closed){logDebug(LOG_TAG$d,'GRPC stream received:',msg);stream.callOnMessage(msg);}});grpcStream.on('end',function(){logDebug(LOG_TAG$d,'GRPC stream ended.');close();});grpcStream.on('error',function(grpcError){if(!closed){logWarn(LOG_TAG$d,'GRPC stream error. Code:',grpcError.code,'Message:',grpcError.message);var code=mapCodeFromRpcCode(grpcError.code);close(new FirestoreError(code,grpcError.message));}});logDebug(LOG_TAG$d,'Opening GRPC stream');// TODO(dimond): Since grpc has no explicit open status (or does it?) we
// simulate an onOpen in the next loop after the stream had it's listeners
// registered
setTimeout(function(){stream.callOnOpen();},0);return stream;}}]);return GrpcConnection;}();/**
 * @license
 * Copyright 2019 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var NoopConnectivityMonitor=/*#__PURE__*/function(){function NoopConnectivityMonitor(){_classCallCheck(this,NoopConnectivityMonitor);}_createClass(NoopConnectivityMonitor,[{key:"addCallback",value:function addCallback(callback){// No-op.
}},{key:"shutdown",value:function shutdown(){// No-op.
}}]);return NoopConnectivityMonitor;}();/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /** Loads the GRPC stack */function newConnection(databaseInfo){var protos=loadProtos();return new GrpcConnection(protos,databaseInfo);}/** Return the Platform-specific connectivity monitor. */function newConnectivityMonitor(){return new NoopConnectivityMonitor();}/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */function newSerializer(databaseId){return new JsonProtoSerializer(databaseId,/* useProto3Json= */false);}/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var MEMORY_ONLY_PERSISTENCE_ERROR_MESSAGE='You are using the memory-only build of Firestore. Persistence support is '+'only available via the @firebase/firestore bundle or the '+'firebase-firestore.js build.';/**
 * Provides all components needed for Firestore with in-memory persistence.
 * Uses EagerGC garbage collection.
 */var MemoryOfflineComponentProvider=/*#__PURE__*/function(){function MemoryOfflineComponentProvider(){_classCallCheck(this,MemoryOfflineComponentProvider);}_createClass(MemoryOfflineComponentProvider,[{key:"initialize",value:function initialize(cfg){return regeneratorRuntime.async(function initialize$(_context70){while(1){switch(_context70.prev=_context70.next){case 0:this.sharedClientState=this.createSharedClientState(cfg);this.persistence=this.createPersistence(cfg);_context70.next=4;return regeneratorRuntime.awrap(this.persistence.start());case 4:this.gcScheduler=this.createGarbageCollectionScheduler(cfg);this.localStore=this.createLocalStore(cfg);case 6:case"end":return _context70.stop();}}},null,this);}},{key:"createGarbageCollectionScheduler",value:function createGarbageCollectionScheduler(cfg){return null;}},{key:"createLocalStore",value:function createLocalStore(cfg){return newLocalStore(this.persistence,new IndexFreeQueryEngine(),cfg.initialUser);}},{key:"createPersistence",value:function createPersistence(cfg){if(cfg.persistenceSettings.durable){throw new FirestoreError(Code.FAILED_PRECONDITION,MEMORY_ONLY_PERSISTENCE_ERROR_MESSAGE);}return new MemoryPersistence(MemoryEagerDelegate.factory);}},{key:"createSharedClientState",value:function createSharedClientState(cfg){return new MemorySharedClientState();}},{key:"terminate",value:function terminate(){return regeneratorRuntime.async(function terminate$(_context71){while(1){switch(_context71.prev=_context71.next){case 0:if(this.gcScheduler){this.gcScheduler.stop();}_context71.next=3;return regeneratorRuntime.awrap(this.sharedClientState.shutdown());case 3:_context71.next=5;return regeneratorRuntime.awrap(this.persistence.shutdown());case 5:case"end":return _context71.stop();}}},null,this);}},{key:"clearPersistence",value:function clearPersistence(databaseId,persistenceKey){throw new FirestoreError(Code.FAILED_PRECONDITION,MEMORY_ONLY_PERSISTENCE_ERROR_MESSAGE);}}]);return MemoryOfflineComponentProvider;}();/**
 * Provides all components needed for Firestore with IndexedDB persistence.
 */var IndexedDbOfflineComponentProvider=/*#__PURE__*/function(_MemoryOfflineCompone){_inherits(IndexedDbOfflineComponentProvider,_MemoryOfflineCompone);function IndexedDbOfflineComponentProvider(onlineComponentProvider){var _this146;_classCallCheck(this,IndexedDbOfflineComponentProvider);_this146=_possibleConstructorReturn(this,_getPrototypeOf(IndexedDbOfflineComponentProvider).call(this));_this146.onlineComponentProvider=onlineComponentProvider;return _this146;}_createClass(IndexedDbOfflineComponentProvider,[{key:"initialize",value:function initialize(cfg){return regeneratorRuntime.async(function initialize$(_context72){while(1){switch(_context72.prev=_context72.next){case 0:_context72.next=2;return regeneratorRuntime.awrap(_get(_getPrototypeOf(IndexedDbOfflineComponentProvider.prototype),"initialize",this).call(this,cfg));case 2:_context72.next=4;return regeneratorRuntime.awrap(synchronizeLastDocumentChangeReadTime(this.localStore));case 4:_context72.next=6;return regeneratorRuntime.awrap(this.onlineComponentProvider.initialize(this,cfg));case 6:_context72.next=8;return regeneratorRuntime.awrap(ensureWriteCallbacks(this.onlineComponentProvider.syncEngine));case 8:_context72.next=10;return regeneratorRuntime.awrap(fillWritePipeline(this.onlineComponentProvider.remoteStore));case 10:case"end":return _context72.stop();}}},null,this);}},{key:"createGarbageCollectionScheduler",value:function createGarbageCollectionScheduler(cfg){var garbageCollector=this.persistence.referenceDelegate.garbageCollector;return new LruScheduler(garbageCollector,cfg.asyncQueue);}},{key:"createPersistence",value:function createPersistence(cfg){var persistenceKey=indexedDbStoragePrefix(cfg.databaseInfo.databaseId,cfg.databaseInfo.persistenceKey);var serializer=newSerializer(cfg.databaseInfo.databaseId);return new IndexedDbPersistence(cfg.persistenceSettings.synchronizeTabs,persistenceKey,cfg.clientId,LruParams.withCacheSize(cfg.persistenceSettings.cacheSizeBytes),cfg.asyncQueue,getWindow(),getDocument(),serializer,this.sharedClientState,cfg.persistenceSettings.forceOwningTab);}},{key:"createSharedClientState",value:function createSharedClientState(cfg){return new MemorySharedClientState();}},{key:"clearPersistence",value:function clearPersistence(databaseId,persistenceKey){return indexedDbClearPersistence(indexedDbStoragePrefix(databaseId,persistenceKey));}}]);return IndexedDbOfflineComponentProvider;}(MemoryOfflineComponentProvider);/**
 * Provides all components needed for Firestore with multi-tab IndexedDB
 * persistence.
 *
 * In the legacy client, this provider is used to provide both multi-tab and
 * non-multi-tab persistence since we cannot tell at build time whether
 * `synchronizeTabs` will be enabled.
 */var MultiTabOfflineComponentProvider=/*#__PURE__*/function(_IndexedDbOfflineComp){_inherits(MultiTabOfflineComponentProvider,_IndexedDbOfflineComp);function MultiTabOfflineComponentProvider(){_classCallCheck(this,MultiTabOfflineComponentProvider);return _possibleConstructorReturn(this,_getPrototypeOf(MultiTabOfflineComponentProvider).apply(this,arguments));}_createClass(MultiTabOfflineComponentProvider,[{key:"initialize",value:function initialize(cfg){var _this147=this;var syncEngine;return regeneratorRuntime.async(function initialize$(_context74){while(1){switch(_context74.prev=_context74.next){case 0:_context74.next=2;return regeneratorRuntime.awrap(_get(_getPrototypeOf(MultiTabOfflineComponentProvider.prototype),"initialize",this).call(this,cfg));case 2:syncEngine=this.onlineComponentProvider.syncEngine;if(!(this.sharedClientState instanceof WebStorageSharedClientState)){_context74.next=7;break;}this.sharedClientState.syncEngine={applyBatchState:applyBatchState.bind(null,syncEngine),applyTargetState:applyTargetState.bind(null,syncEngine),applyActiveTargetsChange:applyActiveTargetsChange.bind(null,syncEngine),getActiveClients:getActiveClients.bind(null,syncEngine)};_context74.next=7;return regeneratorRuntime.awrap(this.sharedClientState.start());case 7:_context74.next=9;return regeneratorRuntime.awrap(this.persistence.setPrimaryStateListener(function _callee12(isPrimary){return regeneratorRuntime.async(function _callee12$(_context73){while(1){switch(_context73.prev=_context73.next){case 0:_context73.next=2;return regeneratorRuntime.awrap(applyPrimaryState(_this147.onlineComponentProvider.syncEngine,isPrimary));case 2:if(_this147.gcScheduler){if(isPrimary&&!_this147.gcScheduler.started){_this147.gcScheduler.start(_this147.localStore);}else if(!isPrimary){_this147.gcScheduler.stop();}}case 3:case"end":return _context73.stop();}}});}));case 9:case"end":return _context74.stop();}}},null,this);}},{key:"createSharedClientState",value:function createSharedClientState(cfg){if(cfg.persistenceSettings.durable&&cfg.persistenceSettings.synchronizeTabs){var _window=getWindow();if(!WebStorageSharedClientState.isAvailable(_window)){throw new FirestoreError(Code.UNIMPLEMENTED,'IndexedDB persistence is only available on platforms that support LocalStorage.');}var persistenceKey=indexedDbStoragePrefix(cfg.databaseInfo.databaseId,cfg.databaseInfo.persistenceKey);return new WebStorageSharedClientState(_window,cfg.asyncQueue,persistenceKey,cfg.clientId,cfg.initialUser);}return new MemorySharedClientState();}}]);return MultiTabOfflineComponentProvider;}(IndexedDbOfflineComponentProvider);/**
 * Initializes and wires the components that are needed to interface with the
 * network.
 */var OnlineComponentProvider=/*#__PURE__*/function(){function OnlineComponentProvider(){_classCallCheck(this,OnlineComponentProvider);}_createClass(OnlineComponentProvider,[{key:"initialize",value:function initialize(offlineComponentProvider,cfg){var _this148=this;return regeneratorRuntime.async(function initialize$(_context75){while(1){switch(_context75.prev=_context75.next){case 0:if(!this.localStore){_context75.next=2;break;}return _context75.abrupt("return");case 2:this.localStore=offlineComponentProvider.localStore;this.sharedClientState=offlineComponentProvider.sharedClientState;this.datastore=this.createDatastore(cfg);this.remoteStore=this.createRemoteStore(cfg);this.eventManager=this.createEventManager(cfg);this.syncEngine=this.createSyncEngine(cfg);this.sharedClientState.onlineStateHandler=function(onlineState){return applyOnlineStateChange(_this148.syncEngine,onlineState,1/* SharedClientState */);};this.remoteStore.remoteSyncer.handleCredentialChange=syncEngineHandleCredentialChange.bind(null,this.syncEngine);_context75.next=12;return regeneratorRuntime.awrap(remoteStoreApplyPrimaryState(this.remoteStore,this.syncEngine.isPrimaryClient));case 12:case"end":return _context75.stop();}}},null,this);}},{key:"createEventManager",value:function createEventManager(cfg){return newEventManager();}},{key:"createDatastore",value:function createDatastore(cfg){var serializer=newSerializer(cfg.databaseInfo.databaseId);var connection=newConnection(cfg.databaseInfo);return newDatastore(cfg.credentials,connection,serializer);}},{key:"createRemoteStore",value:function createRemoteStore(cfg){var _this149=this;return newRemoteStore(this.localStore,this.datastore,cfg.asyncQueue,function(onlineState){return applyOnlineStateChange(_this149.syncEngine,onlineState,0/* RemoteStore */);},newConnectivityMonitor());}},{key:"createSyncEngine",value:function createSyncEngine(cfg){return newSyncEngine(this.localStore,this.remoteStore,this.eventManager,this.sharedClientState,cfg.initialUser,cfg.maxConcurrentLimboResolutions,!cfg.persistenceSettings.durable||!cfg.persistenceSettings.synchronizeTabs);}},{key:"terminate",value:function terminate(){return remoteStoreShutdown(this.remoteStore);}}]);return OnlineComponentProvider;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /*
 * A wrapper implementation of Observer<T> that will dispatch events
 * asynchronously. To allow immediate silencing, a mute call is added which
 * causes events scheduled to no longer be raised.
 */var AsyncObserver=/*#__PURE__*/function(){function AsyncObserver(observer){_classCallCheck(this,AsyncObserver);this.observer=observer;/**
         * When set to true, will not raise future events. Necessary to deal with
         * async detachment of listener.
         */this.muted=false;}_createClass(AsyncObserver,[{key:"next",value:function next(value){if(this.observer.next){this.scheduleEvent(this.observer.next,value);}}},{key:"error",value:function error(_error){if(this.observer.error){this.scheduleEvent(this.observer.error,_error);}else{console.error('Uncaught Error in snapshot listener:',_error);}}},{key:"mute",value:function mute(){this.muted=true;}},{key:"scheduleEvent",value:function scheduleEvent(eventHandler,event){var _this150=this;if(!this.muted){setTimeout(function(){if(!_this150.muted){eventHandler(event);}},0);}}}]);return AsyncObserver;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Internal transaction object responsible for accumulating the mutations to
 * perform and the base versions for any documents read.
 */var Transaction=/*#__PURE__*/function(){function Transaction(datastore){_classCallCheck(this,Transaction);this.datastore=datastore;// The version of each document that was read during this transaction.
this.readVersions=new Map();this.mutations=[];this.committed=false;/**
         * A deferred usage error that occurred previously in this transaction that
         * will cause the transaction to fail once it actually commits.
         */this.lastWriteError=null;/**
         * Set of documents that have been written in the transaction.
         *
         * When there's more than one write to the same key in a transaction, any
         * writes after the first are handled differently.
         */this.writtenDocs=new Set();}_createClass(Transaction,[{key:"lookup",value:function lookup(keys){var _this151=this;var docs;return regeneratorRuntime.async(function lookup$(_context76){while(1){switch(_context76.prev=_context76.next){case 0:this.ensureCommitNotCalled();if(!(this.mutations.length>0)){_context76.next=3;break;}throw new FirestoreError(Code.INVALID_ARGUMENT,'Firestore transactions require all reads to be executed before all writes.');case 3:_context76.next=5;return regeneratorRuntime.awrap(invokeBatchGetDocumentsRpc(this.datastore,keys));case 5:docs=_context76.sent;docs.forEach(function(doc){if(doc instanceof NoDocument||doc instanceof Document){_this151.recordVersion(doc);}else{fail();}});return _context76.abrupt("return",docs);case 8:case"end":return _context76.stop();}}},null,this);}},{key:"set",value:function set(key,data){this.write(data.toMutations(key,this.precondition(key)));this.writtenDocs.add(key.toString());}},{key:"update",value:function update(key,data){try{this.write(data.toMutations(key,this.preconditionForUpdate(key)));}catch(e){this.lastWriteError=e;}this.writtenDocs.add(key.toString());}},{key:"delete",value:function _delete(key){this.write([new DeleteMutation(key,this.precondition(key))]);this.writtenDocs.add(key.toString());}},{key:"commit",value:function commit(){var _this152=this;var unwritten;return regeneratorRuntime.async(function commit$(_context77){while(1){switch(_context77.prev=_context77.next){case 0:this.ensureCommitNotCalled();if(!this.lastWriteError){_context77.next=3;break;}throw this.lastWriteError;case 3:unwritten=this.readVersions;// For each mutation, note that the doc was written.
this.mutations.forEach(function(mutation){unwritten["delete"](mutation.key.toString());});// For each document that was read but not written to, we want to perform
// a `verify` operation.
unwritten.forEach(function(_,path){var key=DocumentKey.fromPath(path);_this152.mutations.push(new VerifyMutation(key,_this152.precondition(key)));});_context77.next=8;return regeneratorRuntime.awrap(invokeCommitRpc(this.datastore,this.mutations));case 8:this.committed=true;case 9:case"end":return _context77.stop();}}},null,this);}},{key:"recordVersion",value:function recordVersion(doc){var docVersion;if(doc instanceof Document){docVersion=doc.version;}else if(doc instanceof NoDocument){// For deleted docs, we must use baseVersion 0 when we overwrite them.
docVersion=SnapshotVersion.min();}else{throw fail();}var existingVersion=this.readVersions.get(doc.key.toString());if(existingVersion){if(!docVersion.isEqual(existingVersion)){// This transaction will fail no matter what.
throw new FirestoreError(Code.ABORTED,'Document version changed between two reads.');}}else{this.readVersions.set(doc.key.toString(),docVersion);}}/**
     * Returns the version of this document when it was read in this transaction,
     * as a precondition, or no precondition if it was not read.
     */},{key:"precondition",value:function precondition(key){var version=this.readVersions.get(key.toString());if(!this.writtenDocs.has(key.toString())&&version){return Precondition.updateTime(version);}else{return Precondition.none();}}/**
     * Returns the precondition for a document if the operation is an update.
     */},{key:"preconditionForUpdate",value:function preconditionForUpdate(key){var version=this.readVersions.get(key.toString());// The first time a document is written, we want to take into account the
// read time and existence
if(!this.writtenDocs.has(key.toString())&&version){if(version.isEqual(SnapshotVersion.min())){// The document doesn't exist, so fail the transaction.
// This has to be validated locally because you can't send a
// precondition that a document does not exist without changing the
// semantics of the backend write to be an insert. This is the reverse
// of what we want, since we want to assert that the document doesn't
// exist but then send the update and have it fail. Since we can't
// express that to the backend, we have to validate locally.
// Note: this can change once we can send separate verify writes in the
// transaction.
throw new FirestoreError(Code.INVALID_ARGUMENT,"Can't update a document that doesn't exist.");}// Document exists, base precondition on document update time.
return Precondition.updateTime(version);}else{// Document was not read, so we just use the preconditions for a blind
// update.
return Precondition.exists(true);}}},{key:"write",value:function write(mutations){this.ensureCommitNotCalled();this.mutations=this.mutations.concat(mutations);}},{key:"ensureCommitNotCalled",value:function ensureCommitNotCalled(){}}]);return Transaction;}();/**
 * @license
 * Copyright 2019 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var RETRY_COUNT=5;/**
 * TransactionRunner encapsulates the logic needed to run and retry transactions
 * with backoff.
 */var TransactionRunner=/*#__PURE__*/function(){function TransactionRunner(asyncQueue,datastore,updateFunction,deferred){_classCallCheck(this,TransactionRunner);this.asyncQueue=asyncQueue;this.datastore=datastore;this.updateFunction=updateFunction;this.deferred=deferred;this.retries=RETRY_COUNT;this.backoff=new ExponentialBackoff(this.asyncQueue,"transaction_retry"/* TransactionRetry */);}/** Runs the transaction and sets the result on deferred. */_createClass(TransactionRunner,[{key:"run",value:function run(){this.runWithBackOff();}},{key:"runWithBackOff",value:function runWithBackOff(){var _this153=this;this.backoff.backoffAndRun(function _callee13(){var transaction,userPromise;return regeneratorRuntime.async(function _callee13$(_context78){while(1){switch(_context78.prev=_context78.next){case 0:transaction=new Transaction(_this153.datastore);userPromise=_this153.tryRunUpdateFunction(transaction);if(userPromise){userPromise.then(function(result){_this153.asyncQueue.enqueueAndForget(function(){return transaction.commit().then(function(){_this153.deferred.resolve(result);})["catch"](function(commitError){_this153.handleTransactionError(commitError);});});})["catch"](function(userPromiseError){_this153.handleTransactionError(userPromiseError);});}case 3:case"end":return _context78.stop();}}});});}},{key:"tryRunUpdateFunction",value:function tryRunUpdateFunction(transaction){try{var userPromise=this.updateFunction(transaction);if(isNullOrUndefined(userPromise)||!userPromise["catch"]||!userPromise.then){this.deferred.reject(Error('Transaction callback must return a Promise'));return null;}return userPromise;}catch(error){// Do not retry errors thrown by user provided updateFunction.
this.deferred.reject(error);return null;}}},{key:"handleTransactionError",value:function handleTransactionError(error){var _this154=this;if(this.retries>0&&this.isRetryableTransactionError(error)){this.retries-=1;this.asyncQueue.enqueueAndForget(function(){_this154.runWithBackOff();return Promise.resolve();});}else{this.deferred.reject(error);}}},{key:"isRetryableTransactionError",value:function isRetryableTransactionError(error){if(error.name==='FirebaseError'){// In transactions, the backend will fail outdated reads with FAILED_PRECONDITION and
// non-matching document versions with ABORTED. These errors should be retried.
var code=error.code;return code==='aborted'||code==='failed-precondition'||!isPermanentError(code);}return false;}}]);return TransactionRunner;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var LOG_TAG$e='FirestoreClient';var MAX_CONCURRENT_LIMBO_RESOLUTIONS=100;/** DOMException error code constants. */var DOM_EXCEPTION_INVALID_STATE=11;var DOM_EXCEPTION_ABORTED=20;var DOM_EXCEPTION_QUOTA_EXCEEDED=22;/**
 * FirestoreClient is a top-level class that constructs and owns all of the
 * pieces of the client SDK architecture. It is responsible for creating the
 * async queue that is shared by all of the other components in the system.
 */var FirestoreClient=/*#__PURE__*/function(){function FirestoreClient(credentials,/**
     * Asynchronous queue responsible for all of our internal processing. When
     * we get incoming work from the user (via public API) or the network
     * (incoming GRPC messages), we should always schedule onto this queue.
     * This ensures all of our work is properly serialized (e.g. we don't
     * start processing a new operation while the previous one is waiting for
     * an async I/O to complete).
     */asyncQueue){_classCallCheck(this,FirestoreClient);this.credentials=credentials;this.asyncQueue=asyncQueue;this.clientId=AutoId.newId();// We defer our initialization until we get the current user from
// setChangeListener(). We block the async queue until we got the initial
// user and the initialization is completed. This will prevent any scheduled
// work from happening before initialization is completed.
//
// If initializationDone resolved then the FirestoreClient is in a usable
// state.
this.initializationDone=new Deferred();}/**
     * Starts up the FirestoreClient, returning only whether or not enabling
     * persistence succeeded.
     *
     * The intent here is to "do the right thing" as far as users are concerned.
     * Namely, in cases where offline persistence is requested and possible,
     * enable it, but otherwise fall back to persistence disabled. For the most
     * part we expect this to succeed one way or the other so we don't expect our
     * users to actually wait on the firestore.enablePersistence Promise since
     * they generally won't care.
     *
     * Of course some users actually do care about whether or not persistence
     * was successfully enabled, so the Promise returned from this method
     * indicates this outcome.
     *
     * This presents a problem though: even before enablePersistence resolves or
     * rejects, users may have made calls to e.g. firestore.collection() which
     * means that the FirestoreClient in there will be available and will be
     * enqueuing actions on the async queue.
     *
     * Meanwhile any failure of an operation on the async queue causes it to
     * panic and reject any further work, on the premise that unhandled errors
     * are fatal.
     *
     * Consequently the fallback is handled internally here in start, and if the
     * fallback succeeds we signal success to the async queue even though the
     * start() itself signals failure.
     *
     * @param databaseInfo The connection information for the current instance.
     * @param offlineComponentProvider Provider that returns all components
     * required for memory-only or IndexedDB persistence.
     * @param onlineComponentProvider Provider that returns all components
     * required for online support.
     * @param persistenceSettings Settings object to configure offline
     *     persistence.
     * @returns A deferred result indicating the user-visible result of enabling
     *     offline persistence. This method will reject this if IndexedDB fails to
     *     start for any reason. If usePersistence is false this is
     *     unconditionally resolved.
     */_createClass(FirestoreClient,[{key:"start",value:function start(databaseInfo,offlineComponentProvider,onlineComponentProvider,persistenceSettings){var _this155=this;this.verifyNotTerminated();this.databaseInfo=databaseInfo;// If usePersistence is true, certain classes of errors while starting are
// recoverable but only by falling back to persistence disabled.
//
// If there's an error in the first case but not in recovery we cannot
// reject the promise blocking the async queue because this will cause the
// async queue to panic.
var persistenceResult=new Deferred();var initialized=false;this.credentials.setChangeListener(function(user){if(!initialized){initialized=true;logDebug(LOG_TAG$e,'Initializing. user=',user.uid);return _this155.initializeComponents(offlineComponentProvider,onlineComponentProvider,persistenceSettings,user,persistenceResult).then(_this155.initializationDone.resolve,_this155.initializationDone.reject);}else{_this155.asyncQueue.enqueueRetryable(function(){return remoteStoreHandleCredentialChange(_this155.remoteStore,user);});}});// Block the async queue until initialization is done
this.asyncQueue.enqueueAndForget(function(){return _this155.initializationDone.promise;});// Return only the result of enabling persistence. Note that this does not
// need to await the completion of initializationDone because the result of
// this method should not reflect any other kind of failure to start.
return persistenceResult.promise;}/** Enables the network connection and requeues all pending operations. */},{key:"enableNetwork",value:function enableNetwork(){var _this156=this;this.verifyNotTerminated();return this.asyncQueue.enqueue(function(){_this156.persistence.setNetworkEnabled(true);return remoteStoreEnableNetwork(_this156.remoteStore);});}/**
     * Initializes persistent storage, attempting to use IndexedDB if
     * usePersistence is true or memory-only if false.
     *
     * If IndexedDB fails because it's already open in another tab or because the
     * platform can't possibly support our implementation then this method rejects
     * the persistenceResult and falls back on memory-only persistence.
     *
     * @param offlineComponentProvider Provider that returns all components
     * required for memory-only or IndexedDB persistence.
     * @param onlineComponentProvider Provider that returns all components
     * required for online support.
     * @param persistenceSettings Settings object to configure offline persistence
     * @param user The initial user
     * @param persistenceResult A deferred result indicating the user-visible
     *     result of enabling offline persistence. This method will reject this if
     *     IndexedDB fails to start for any reason. If usePersistence is false
     *     this is unconditionally resolved.
     * @returns a Promise indicating whether or not initialization should
     *     continue, i.e. that one of the persistence implementations actually
     *     succeeded.
     */},{key:"initializeComponents",value:function initializeComponents(offlineComponentProvider,onlineComponentProvider,persistenceSettings,user,persistenceResult){var _this157=this;var componentConfiguration;return regeneratorRuntime.async(function initializeComponents$(_context80){while(1){switch(_context80.prev=_context80.next){case 0:_context80.prev=0;componentConfiguration={asyncQueue:this.asyncQueue,databaseInfo:this.databaseInfo,clientId:this.clientId,credentials:this.credentials,initialUser:user,maxConcurrentLimboResolutions:MAX_CONCURRENT_LIMBO_RESOLUTIONS,persistenceSettings:persistenceSettings};_context80.next=4;return regeneratorRuntime.awrap(offlineComponentProvider.initialize(componentConfiguration));case 4:_context80.next=6;return regeneratorRuntime.awrap(onlineComponentProvider.initialize(offlineComponentProvider,componentConfiguration));case 6:this.persistence=offlineComponentProvider.persistence;this.sharedClientState=offlineComponentProvider.sharedClientState;this.localStore=offlineComponentProvider.localStore;this.gcScheduler=offlineComponentProvider.gcScheduler;this.datastore=onlineComponentProvider.datastore;this.remoteStore=onlineComponentProvider.remoteStore;this.syncEngine=onlineComponentProvider.syncEngine;this.eventMgr=onlineComponentProvider.eventManager;this.eventMgr.onListen=syncEngineListen.bind(null,this.syncEngine);this.eventMgr.onUnlisten=syncEngineUnlisten.bind(null,this.syncEngine);// When a user calls clearPersistence() in one client, all other clients
// need to be terminated to allow the delete to succeed.
this.persistence.setDatabaseDeletedListener(function _callee14(){return regeneratorRuntime.async(function _callee14$(_context79){while(1){switch(_context79.prev=_context79.next){case 0:_context79.next=2;return regeneratorRuntime.awrap(_this157.terminate());case 2:case"end":return _context79.stop();}}});});persistenceResult.resolve();_context80.next=27;break;case 20:_context80.prev=20;_context80.t0=_context80["catch"](0);// Regardless of whether or not the retry succeeds, from an user
// perspective, offline persistence has failed.
persistenceResult.reject(_context80.t0);// An unknown failure on the first stage shuts everything down.
if(this.canFallback(_context80.t0)){_context80.next=25;break;}throw _context80.t0;case 25:console.warn('Error enabling offline persistence. Falling back to'+' persistence disabled: '+_context80.t0);return _context80.abrupt("return",this.initializeComponents(new MemoryOfflineComponentProvider(),new OnlineComponentProvider(),{durable:false},user,persistenceResult));case 27:case"end":return _context80.stop();}}},null,this,[[0,20]]);}/**
     * Decides whether the provided error allows us to gracefully disable
     * persistence (as opposed to crashing the client).
     */},{key:"canFallback",value:function canFallback(error){if(error.name==='FirebaseError'){return error.code===Code.FAILED_PRECONDITION||error.code===Code.UNIMPLEMENTED;}else if(typeof DOMException!=='undefined'&&error instanceof DOMException){// There are a few known circumstances where we can open IndexedDb but
// trying to read/write will fail (e.g. quota exceeded). For
// well-understood cases, we attempt to detect these and then gracefully
// fall back to memory persistence.
// NOTE: Rather than continue to add to this list, we could decide to
// always fall back, with the risk that we might accidentally hide errors
// representing actual SDK bugs.
return(// When the browser is out of quota we could get either quota exceeded
// or an aborted error depending on whether the error happened during
// schema migration.
error.code===DOM_EXCEPTION_QUOTA_EXCEEDED||error.code===DOM_EXCEPTION_ABORTED||// Firefox Private Browsing mode disables IndexedDb and returns
// INVALID_STATE for any usage.
error.code===DOM_EXCEPTION_INVALID_STATE);}return true;}/**
     * Checks that the client has not been terminated. Ensures that other methods on
     * this class cannot be called after the client is terminated.
     */},{key:"verifyNotTerminated",value:function verifyNotTerminated(){if(this.asyncQueue.isShuttingDown){throw new FirestoreError(Code.FAILED_PRECONDITION,'The client has already been terminated.');}}/** Disables the network connection. Pending operations will not complete. */},{key:"disableNetwork",value:function disableNetwork(){var _this158=this;this.verifyNotTerminated();return this.asyncQueue.enqueue(function(){_this158.persistence.setNetworkEnabled(false);return remoteStoreDisableNetwork(_this158.remoteStore);});}},{key:"terminate",value:function terminate(){var _this159=this;this.asyncQueue.enterRestrictedMode();var deferred=new Deferred();this.asyncQueue.enqueueAndForgetEvenWhileRestricted(function _callee15(){var firestoreError;return regeneratorRuntime.async(function _callee15$(_context81){while(1){switch(_context81.prev=_context81.next){case 0:_context81.prev=0;// PORTING NOTE: LocalStore does not need an explicit shutdown on web.
if(_this159.gcScheduler){_this159.gcScheduler.stop();}_context81.next=4;return regeneratorRuntime.awrap(remoteStoreShutdown(_this159.remoteStore));case 4:_context81.next=6;return regeneratorRuntime.awrap(_this159.sharedClientState.shutdown());case 6:_context81.next=8;return regeneratorRuntime.awrap(_this159.persistence.shutdown());case 8:// `removeChangeListener` must be called after shutting down the
// RemoteStore as it will prevent the RemoteStore from retrieving
// auth tokens.
_this159.credentials.removeChangeListener();deferred.resolve();_context81.next=16;break;case 12:_context81.prev=12;_context81.t0=_context81["catch"](0);firestoreError=wrapInUserErrorIfRecoverable(_context81.t0,"Failed to shutdown persistence");deferred.reject(firestoreError);case 16:case"end":return _context81.stop();}}},null,null,[[0,12]]);});return deferred.promise;}/**
     * Returns a Promise that resolves when all writes that were pending at the time this
     * method was called received server acknowledgement. An acknowledgement can be either acceptance
     * or rejection.
     */},{key:"waitForPendingWrites",value:function waitForPendingWrites(){var _this160=this;this.verifyNotTerminated();var deferred=new Deferred();this.asyncQueue.enqueueAndForget(function(){return registerPendingWritesCallback(_this160.syncEngine,deferred);});return deferred.promise;}},{key:"listen",value:function listen(query,options,observer){var _this161=this;this.verifyNotTerminated();var wrappedObserver=new AsyncObserver(observer);var listener=new QueryListener(query,wrappedObserver,options);this.asyncQueue.enqueueAndForget(function(){return eventManagerListen(_this161.eventMgr,listener);});return function(){wrappedObserver.mute();_this161.asyncQueue.enqueueAndForget(function(){return eventManagerUnlisten(_this161.eventMgr,listener);});};}},{key:"getDocumentFromLocalCache",value:function getDocumentFromLocalCache(docKey){var _this162=this;var deferred;return regeneratorRuntime.async(function getDocumentFromLocalCache$(_context82){while(1){switch(_context82.prev=_context82.next){case 0:this.verifyNotTerminated();_context82.next=3;return regeneratorRuntime.awrap(this.initializationDone.promise);case 3:deferred=new Deferred();this.asyncQueue.enqueueAndForget(function(){return readDocumentFromCache(_this162.localStore,docKey,deferred);});return _context82.abrupt("return",deferred.promise);case 6:case"end":return _context82.stop();}}},null,this);}},{key:"getDocumentViaSnapshotListener",value:function getDocumentViaSnapshotListener(key){var _this163=this;var options,deferred,_args83=arguments;return regeneratorRuntime.async(function getDocumentViaSnapshotListener$(_context83){while(1){switch(_context83.prev=_context83.next){case 0:options=_args83.length>1&&_args83[1]!==undefined?_args83[1]:{};this.verifyNotTerminated();_context83.next=4;return regeneratorRuntime.awrap(this.initializationDone.promise);case 4:deferred=new Deferred();this.asyncQueue.enqueueAndForget(function(){return readDocumentViaSnapshotListener(_this163.eventMgr,_this163.asyncQueue,key,options,deferred);});return _context83.abrupt("return",deferred.promise);case 7:case"end":return _context83.stop();}}},null,this);}},{key:"getDocumentsFromLocalCache",value:function getDocumentsFromLocalCache(query){var _this164=this;var deferred;return regeneratorRuntime.async(function getDocumentsFromLocalCache$(_context84){while(1){switch(_context84.prev=_context84.next){case 0:this.verifyNotTerminated();_context84.next=3;return regeneratorRuntime.awrap(this.initializationDone.promise);case 3:deferred=new Deferred();this.asyncQueue.enqueueAndForget(function(){return executeQueryFromCache(_this164.localStore,query,deferred);});return _context84.abrupt("return",deferred.promise);case 6:case"end":return _context84.stop();}}},null,this);}},{key:"getDocumentsViaSnapshotListener",value:function getDocumentsViaSnapshotListener(query){var _this165=this;var options,deferred,_args85=arguments;return regeneratorRuntime.async(function getDocumentsViaSnapshotListener$(_context85){while(1){switch(_context85.prev=_context85.next){case 0:options=_args85.length>1&&_args85[1]!==undefined?_args85[1]:{};this.verifyNotTerminated();_context85.next=4;return regeneratorRuntime.awrap(this.initializationDone.promise);case 4:deferred=new Deferred();this.asyncQueue.enqueueAndForget(function(){return executeQueryViaSnapshotListener(_this165.eventMgr,_this165.asyncQueue,query,options,deferred);});return _context85.abrupt("return",deferred.promise);case 7:case"end":return _context85.stop();}}},null,this);}},{key:"write",value:function write(mutations){var _this166=this;this.verifyNotTerminated();var deferred=new Deferred();this.asyncQueue.enqueueAndForget(function(){return syncEngineWrite(_this166.syncEngine,mutations,deferred);});return deferred.promise;}},{key:"databaseId",value:function databaseId(){return this.databaseInfo.databaseId;}},{key:"addSnapshotsInSyncListener",value:function addSnapshotsInSyncListener(observer){var _this167=this;this.verifyNotTerminated();var wrappedObserver=new AsyncObserver(observer);this.asyncQueue.enqueueAndForget(function _callee16(){return regeneratorRuntime.async(function _callee16$(_context86){while(1){switch(_context86.prev=_context86.next){case 0:return _context86.abrupt("return",_addSnapshotsInSyncListener(_this167.eventMgr,wrappedObserver));case 1:case"end":return _context86.stop();}}});});return function(){wrappedObserver.mute();_this167.asyncQueue.enqueueAndForget(function _callee17(){return regeneratorRuntime.async(function _callee17$(_context87){while(1){switch(_context87.prev=_context87.next){case 0:return _context87.abrupt("return",removeSnapshotsInSyncListener(_this167.eventMgr,wrappedObserver));case 1:case"end":return _context87.stop();}}});});};}},{key:"transaction",/**
     * Takes an updateFunction in which a set of reads and writes can be performed
     * atomically. In the updateFunction, the client can read and write values
     * using the supplied transaction object. After the updateFunction, all
     * changes will be committed. If a retryable error occurs (ex: some other
     * client has changed any of the data referenced), then the updateFunction
     * will be called again after a backoff. If the updateFunction still fails
     * after all retries, then the transaction will be rejected.
     *
     * The transaction object passed to the updateFunction contains methods for
     * accessing documents and collections. Unlike other datastore access, data
     * accessed with the transaction will not reflect local changes that have not
     * been committed. For this reason, it is required that all reads are
     * performed before any writes. Transactions must be performed while online.
     */value:function transaction(updateFunction){var _this168=this;this.verifyNotTerminated();var deferred=new Deferred();this.asyncQueue.enqueueAndForget(function(){new TransactionRunner(_this168.asyncQueue,_this168.datastore,updateFunction,deferred).run();return Promise.resolve();});return deferred.promise;}},{key:"clientTerminated",get:function get(){// Technically, the asyncQueue is still running, but only accepting operations
// related to termination or supposed to be run after termination. It is effectively
// terminated to the eyes of users.
return this.asyncQueue.isShuttingDown;}}]);return FirestoreClient;}();function readDocumentFromCache(localStore,docKey,result){var maybeDoc,firestoreError;return regeneratorRuntime.async(function readDocumentFromCache$(_context88){while(1){switch(_context88.prev=_context88.next){case 0:_context88.prev=0;_context88.next=3;return regeneratorRuntime.awrap(readLocalDocument(localStore,docKey));case 3:maybeDoc=_context88.sent;if(maybeDoc instanceof Document){result.resolve(maybeDoc);}else if(maybeDoc instanceof NoDocument){result.resolve(null);}else{result.reject(new FirestoreError(Code.UNAVAILABLE,'Failed to get document from cache. (However, this document may '+"exist on the server. Run again without setting 'source' in "+'the GetOptions to attempt to retrieve the document from the '+'server.)'));}_context88.next=11;break;case 7:_context88.prev=7;_context88.t0=_context88["catch"](0);firestoreError=wrapInUserErrorIfRecoverable(_context88.t0,"Failed to get document '".concat(docKey," from cache"));result.reject(firestoreError);case 11:case"end":return _context88.stop();}}},null,null,[[0,7]]);}/**
 * Retrieves a latency-compensated document from the backend via a
 * SnapshotListener.
 */function readDocumentViaSnapshotListener(eventManager,asyncQueue,key,options,result){var wrappedObserver=new AsyncObserver({next:function next(snap){// Remove query first before passing event to user to avoid
// user actions affecting the now stale query.
asyncQueue.enqueueAndForget(function(){return eventManagerUnlisten(eventManager,listener);});var exists=snap.docs.has(key);if(!exists&&snap.fromCache){// TODO(dimond): If we're online and the document doesn't
// exist then we resolve with a doc.exists set to false. If
// we're offline however, we reject the Promise in this
// case. Two options: 1) Cache the negative response from
// the server so we can deliver that even when you're
// offline 2) Actually reject the Promise in the online case
// if the document doesn't exist.
result.reject(new FirestoreError(Code.UNAVAILABLE,'Failed to get document because the client is offline.'));}else if(exists&&snap.fromCache&&options&&options.source==='server'){result.reject(new FirestoreError(Code.UNAVAILABLE,'Failed to get document from server. (However, this '+'document does exist in the local cache. Run again '+'without setting source to "server" to '+'retrieve the cached document.)'));}else{result.resolve(snap);}},error:function error(e){return result.reject(e);}});var listener=new QueryListener(newQueryForPath(key.path),wrappedObserver,{includeMetadataChanges:true,waitForSyncWhenOnline:true});return eventManagerListen(eventManager,listener);}function executeQueryFromCache(localStore,query,result){var queryResult,view,viewDocChanges,viewChange,firestoreError;return regeneratorRuntime.async(function executeQueryFromCache$(_context89){while(1){switch(_context89.prev=_context89.next){case 0:_context89.prev=0;_context89.next=3;return regeneratorRuntime.awrap(executeQuery(localStore,query,/* usePreviousResults= */true));case 3:queryResult=_context89.sent;view=new View(query,queryResult.remoteKeys);viewDocChanges=view.computeDocChanges(queryResult.documents);viewChange=view.applyChanges(viewDocChanges,/* updateLimboDocuments= */false);result.resolve(viewChange.snapshot);_context89.next=14;break;case 10:_context89.prev=10;_context89.t0=_context89["catch"](0);firestoreError=wrapInUserErrorIfRecoverable(_context89.t0,"Failed to execute query '".concat(query," against cache"));result.reject(firestoreError);case 14:case"end":return _context89.stop();}}},null,null,[[0,10]]);}/**
 * Retrieves a latency-compensated query snapshot from the backend via a
 * SnapshotListener.
 */function executeQueryViaSnapshotListener(eventManager,asyncQueue,query,options,result){var wrappedObserver=new AsyncObserver({next:function next(snapshot){// Remove query first before passing event to user to avoid
// user actions affecting the now stale query.
asyncQueue.enqueueAndForget(function(){return eventManagerUnlisten(eventManager,listener);});if(snapshot.fromCache&&options.source==='server'){result.reject(new FirestoreError(Code.UNAVAILABLE,'Failed to get documents from server. (However, these '+'documents may exist in the local cache. Run again '+'without setting source to "server" to '+'retrieve the cached documents.)'));}else{result.resolve(snapshot);}},error:function error(e){return result.reject(e);}});var listener=new QueryListener(query,wrappedObserver,{includeMetadataChanges:true,waitForSyncWhenOnline:true});return eventManagerListen(eventManager,listener);}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ // The objects that are a part of this API are exposed to third-parties as
// compiled javascript so we want to flag our private members with a leading
// underscore to discourage their use.
/**
 * A field class base class that is shared by the lite, full and legacy SDK,
 * which supports shared code that deals with FieldPaths.
 */ // Use underscore prefix to hide this class from our Public API.
// eslint-disable-next-line @typescript-eslint/naming-convention
var _BaseFieldPath=function _BaseFieldPath(fieldNames){_classCallCheck(this,_BaseFieldPath);validateNamedArrayAtLeastNumberOfElements('FieldPath',fieldNames,'fieldNames',1);for(var i=0;i<fieldNames.length;++i){validateArgType('FieldPath','string',i,fieldNames[i]);if(fieldNames[i].length===0){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid field name at argument $(i + 1). "+'Field names must not be empty.');}}this._internalPath=new FieldPath(fieldNames);};/**
 * A `FieldPath` refers to a field in a document. The path may consist of a
 * single field name (referring to a top-level field in the document), or a list
 * of field names (referring to a nested field in the document).
 */var FieldPath$1=/*#__PURE__*/function(_BaseFieldPath2){_inherits(FieldPath$1,_BaseFieldPath2);/**
     * Creates a FieldPath from the provided field names. If more than one field
     * name is provided, the path will point to a nested field in a document.
     *
     * @param fieldNames A list of field names.
     */function FieldPath$1(){_classCallCheck(this,FieldPath$1);for(var _len6=arguments.length,fieldNames=new Array(_len6),_key14=0;_key14<_len6;_key14++){fieldNames[_key14]=arguments[_key14];}return _possibleConstructorReturn(this,_getPrototypeOf(FieldPath$1).call(this,fieldNames));}_createClass(FieldPath$1,[{key:"isEqual",value:function isEqual(other){if(!(other instanceof FieldPath$1)){throw invalidClassError('isEqual','FieldPath',1,other);}return this._internalPath.isEqual(other._internalPath);}}],[{key:"documentId",value:function documentId(){/**
         * Internal Note: The backend doesn't technically support querying by
         * document ID. Instead it queries by the entire document name (full path
         * included), but in the cases we currently support documentId(), the net
         * effect is the same.
         */return new FieldPath$1(FieldPath.keyField().canonicalString());}}]);return FieldPath$1;}(_BaseFieldPath);/**
 * Matches any characters in a field path string that are reserved.
 */var RESERVED=new RegExp('[~\\*/\\[\\]]');/**
 * Parses a field path string into a FieldPath, treating dots as separators.
 */function fromDotSeparatedString(path){var found=path.search(RESERVED);if(found>=0){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid field path (".concat(path,"). Paths must not contain ")+"'~', '*', '/', '[', or ']'");}try{return _construct(FieldPath$1,_toConsumableArray(path.split('.')));}catch(e){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid field path (".concat(path,"). Paths must not be empty, ")+"begin with '.', end with '.', or contain '..'");}}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var OAuthToken=function OAuthToken(value,user){_classCallCheck(this,OAuthToken);this.user=user;this.type='OAuth';this.authHeaders={};// Set the headers using Object Literal notation to avoid minification
this.authHeaders['Authorization']="Bearer ".concat(value);};/** A CredentialsProvider that always yields an empty token. */var EmptyCredentialsProvider=/*#__PURE__*/function(){function EmptyCredentialsProvider(){_classCallCheck(this,EmptyCredentialsProvider);/**
         * Stores the listener registered with setChangeListener()
         * This isn't actually necessary since the UID never changes, but we use this
         * to verify the listen contract is adhered to in tests.
         */this.changeListener=null;}_createClass(EmptyCredentialsProvider,[{key:"getToken",value:function getToken(){return Promise.resolve(null);}},{key:"invalidateToken",value:function invalidateToken(){}},{key:"setChangeListener",value:function setChangeListener(changeListener){this.changeListener=changeListener;// Fire with initial user.
changeListener(User.UNAUTHENTICATED);}},{key:"removeChangeListener",value:function removeChangeListener(){this.changeListener=null;}}]);return EmptyCredentialsProvider;}();var FirebaseCredentialsProvider=/*#__PURE__*/function(){function FirebaseCredentialsProvider(authProvider){var _this169=this;_classCallCheck(this,FirebaseCredentialsProvider);/**
         * The auth token listener registered with FirebaseApp, retained here so we
         * can unregister it.
         */this.tokenListener=null;/** Tracks the current User. */this.currentUser=User.UNAUTHENTICATED;this.receivedInitialUser=false;/**
         * Counter used to detect if the token changed while a getToken request was
         * outstanding.
         */this.tokenCounter=0;/** The listener registered with setChangeListener(). */this.changeListener=null;this.forceRefresh=false;this.tokenListener=function(){_this169.tokenCounter++;_this169.currentUser=_this169.getUser();_this169.receivedInitialUser=true;if(_this169.changeListener){_this169.changeListener(_this169.currentUser);}};this.tokenCounter=0;this.auth=authProvider.getImmediate({optional:true});if(this.auth){this.auth.addAuthTokenListener(this.tokenListener);}else{// if auth is not available, invoke tokenListener once with null token
this.tokenListener(null);authProvider.get().then(function(auth){_this169.auth=auth;if(_this169.tokenListener){// tokenListener can be removed by removeChangeListener()
_this169.auth.addAuthTokenListener(_this169.tokenListener);}},function(){/* this.authProvider.get() never rejects */});}}_createClass(FirebaseCredentialsProvider,[{key:"getToken",value:function getToken(){var _this170=this;// Take note of the current value of the tokenCounter so that this method
// can fail (with an ABORTED error) if there is a token change while the
// request is outstanding.
var initialTokenCounter=this.tokenCounter;var forceRefresh=this.forceRefresh;this.forceRefresh=false;if(!this.auth){return Promise.resolve(null);}return this.auth.getToken(forceRefresh).then(function(tokenData){// Cancel the request since the token changed while the request was
// outstanding so the response is potentially for a previous user (which
// user, we can't be sure).
if(_this170.tokenCounter!==initialTokenCounter){logDebug('FirebaseCredentialsProvider','getToken aborted due to token change.');return _this170.getToken();}else{if(tokenData){hardAssert(typeof tokenData.accessToken==='string');return new OAuthToken(tokenData.accessToken,_this170.currentUser);}else{return null;}}});}},{key:"invalidateToken",value:function invalidateToken(){this.forceRefresh=true;}},{key:"setChangeListener",value:function setChangeListener(changeListener){this.changeListener=changeListener;// Fire the initial event
if(this.receivedInitialUser){changeListener(this.currentUser);}}},{key:"removeChangeListener",value:function removeChangeListener(){if(this.auth){this.auth.removeAuthTokenListener(this.tokenListener);}this.tokenListener=null;this.changeListener=null;}// Auth.getUid() can return null even with a user logged in. It is because
// getUid() is synchronous, but the auth code populating Uid is asynchronous.
// This method should only be called in the AuthTokenListener callback
// to guarantee to get the actual user.
},{key:"getUser",value:function getUser(){var currentUid=this.auth&&this.auth.getUid();hardAssert(currentUid===null||typeof currentUid==='string');return new User(currentUid);}}]);return FirebaseCredentialsProvider;}();/*
 * FirstPartyToken provides a fresh token each time its value
 * is requested, because if the token is too old, requests will be rejected.
 * Technically this may no longer be necessary since the SDK should gracefully
 * recover from unauthenticated errors (see b/33147818 for context), but it's
 * safer to keep the implementation as-is.
 */var FirstPartyToken=/*#__PURE__*/function(){function FirstPartyToken(gapi,sessionIndex){_classCallCheck(this,FirstPartyToken);this.gapi=gapi;this.sessionIndex=sessionIndex;this.type='FirstParty';this.user=User.FIRST_PARTY;}_createClass(FirstPartyToken,[{key:"authHeaders",get:function get(){var headers={'X-Goog-AuthUser':this.sessionIndex};// Use array notation to prevent minification
var authHeader=this.gapi['auth']['getAuthHeaderValueForFirstParty']([]);if(authHeader){headers['Authorization']=authHeader;}return headers;}}]);return FirstPartyToken;}();/*
 * Provides user credentials required for the Firestore JavaScript SDK
 * to authenticate the user, using technique that is only available
 * to applications hosted by Google.
 */var FirstPartyCredentialsProvider=/*#__PURE__*/function(){function FirstPartyCredentialsProvider(gapi,sessionIndex){_classCallCheck(this,FirstPartyCredentialsProvider);this.gapi=gapi;this.sessionIndex=sessionIndex;}_createClass(FirstPartyCredentialsProvider,[{key:"getToken",value:function getToken(){return Promise.resolve(new FirstPartyToken(this.gapi,this.sessionIndex));}},{key:"setChangeListener",value:function setChangeListener(changeListener){// Fire with initial uid.
changeListener(User.FIRST_PARTY);}},{key:"removeChangeListener",value:function removeChangeListener(){}},{key:"invalidateToken",value:function invalidateToken(){}}]);return FirstPartyCredentialsProvider;}();/**
 * Builds a CredentialsProvider depending on the type of
 * the credentials passed in.
 */function makeCredentialsProvider(credentials){if(!credentials){return new EmptyCredentialsProvider();}switch(credentials['type']){case'gapi':var client=credentials['client'];// Make sure this really is a Gapi client.
hardAssert(!!(_typeof(client)==='object'&&client!==null&&client['auth']&&client['auth']['getAuthHeaderValueForFirstParty']));return new FirstPartyCredentialsProvider(client,credentials['sessionIndex']||'0');case'provider':return credentials['client'];default:throw new FirestoreError(Code.INVALID_ARGUMENT,'makeCredentialsProvider failed due to invalid credential type');}}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */function isPartialObserver(obj){return implementsAnyMethods(obj,['next','error','complete']);}/**
 * Returns true if obj is an object and contains at least one of the specified
 * methods.
 */function implementsAnyMethods(obj,methods){if(_typeof(obj)!=='object'||obj===null){return false;}var object=obj;var _iteratorNormalCompletion63=true;var _didIteratorError63=false;var _iteratorError63=undefined;try{for(var _iterator63=methods[Symbol.iterator](),_step63;!(_iteratorNormalCompletion63=(_step63=_iterator63.next()).done);_iteratorNormalCompletion63=true){var method=_step63.value;if(method in object&&typeof object[method]==='function'){return true;}}}catch(err){_didIteratorError63=true;_iteratorError63=err;}finally{try{if(!_iteratorNormalCompletion63&&_iterator63["return"]!=null){_iterator63["return"]();}}finally{if(_didIteratorError63){throw _iteratorError63;}}}return false;}/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Sentinel values that can be used when writing document fields with `set()`
 * or `update()`.
 */var FieldValue=/**
     * @param _methodName The public API endpoint that returns this class.
     */function FieldValue(_methodName){_classCallCheck(this,FieldValue);this._methodName=_methodName;};/**
 * Returns a sentinel for use with {@link updateDoc()} or
 * {@link setDoc `setDoc({}, { merge: true })`} to mark a field for deletion.
 */function deleteField(){return new DeleteFieldValueImpl('deleteField');}/**
 * Returns a sentinel used with {@link setDoc()} or {@link updateDoc()} to
 * include a server-generated timestamp in the written data.
 */function serverTimestamp$1(){return new ServerTimestampFieldValueImpl('serverTimestamp');}/**
 * Returns a special value that can be used with {@link setDoc()} or {@link
 * updateDoc()} that tells the server to union the given elements with any array
 * value that already exists on the server. Each specified element that doesn't
 * already exist in the array will be added to the end. If the field being
 * modified is not already an array it will be overwritten with an array
 * containing exactly the specified elements.
 *
 * @param elements The elements to union into the array.
 * @return The `FieldValue` sentinel for use in a call to `setDoc()` or
 * `updateDoc()`.
 */function _arrayUnion(){for(var _len7=arguments.length,elements=new Array(_len7),_key15=0;_key15<_len7;_key15++){elements[_key15]=arguments[_key15];}validateAtLeastNumberOfArgs('arrayUnion()',arguments,1);// NOTE: We don't actually parse the data until it's used in set() or
// update() since we'd need the Firestore instance to do this.
return new ArrayUnionFieldValueImpl('arrayUnion',elements);}/**
 * Returns a special value that can be used with {@link setDoc()} or {@link
 * updateDoc()} that tells the server to remove the given elements from any
 * array value that already exists on the server. All instances of each element
 * specified will be removed from the array. If the field being modified is not
 * already an array it will be overwritten with an empty array.
 *
 * @param elements The elements to remove from the array.
 * @return The `FieldValue` sentinel for use in a call to `setDoc()` or
 * `updateDoc()`
 */function _arrayRemove(){for(var _len8=arguments.length,elements=new Array(_len8),_key16=0;_key16<_len8;_key16++){elements[_key16]=arguments[_key16];}validateAtLeastNumberOfArgs('arrayRemove()',arguments,1);// NOTE: We don't actually parse the data until it's used in set() or
// update() since we'd need the Firestore instance to do this.
return new ArrayRemoveFieldValueImpl('arrayRemove',elements);}/**
 * Returns a special value that can be used with {@link setDoc()} or {@link
 * updateDoc()} that tells the server to increment the field's current value by
 * the given value.
 *
 * If either the operand or the current field value uses floating point
 * precision, all arithmetic follows IEEE 754 semantics. If both values are
 * integers, values outside of JavaScript's safe number range
 * (`Number.MIN_SAFE_INTEGER` to `Number.MAX_SAFE_INTEGER`) are also subject to
 * precision loss. Furthermore, once processed by the Firestore backend, all
 * integer operations are capped between -2^63 and 2^63-1.
 *
 * If the current field value is not of type `number`, or if the field does not
 * yet exist, the transformation sets the field to the given value.
 *
 * @param n The value to increment by.
 * @return The `FieldValue` sentinel for use in a call to `setDoc()` or
 * `updateDoc()`
 */function _increment(n){return new NumericIncrementFieldValueImpl('increment',n);}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var DeleteFieldValueImpl=/*#__PURE__*/function(_FieldValue){_inherits(DeleteFieldValueImpl,_FieldValue);function DeleteFieldValueImpl(){_classCallCheck(this,DeleteFieldValueImpl);return _possibleConstructorReturn(this,_getPrototypeOf(DeleteFieldValueImpl).apply(this,arguments));}_createClass(DeleteFieldValueImpl,[{key:"_toFieldTransform",value:function _toFieldTransform(context){if(context.dataSource===2/* MergeSet */){// No transform to add for a delete, but we need to add it to our
// fieldMask so it gets deleted.
context.fieldMask.push(context.path);}else if(context.dataSource===1/* Update */){throw context.createError("".concat(this._methodName,"() can only appear at the top level ")+'of your update data');}else{// We shouldn't encounter delete sentinels for queries or non-merge set() calls.
throw context.createError("".concat(this._methodName,"() cannot be used with set() unless you pass ")+'{merge:true}');}return null;}},{key:"isEqual",value:function isEqual(other){return other instanceof DeleteFieldValueImpl;}}]);return DeleteFieldValueImpl;}(FieldValue);/**
 * Creates a child context for parsing SerializableFieldValues.
 *
 * This is different than calling `ParseContext.contextWith` because it keeps
 * the fieldTransforms and fieldMask separate.
 *
 * The created context has its `dataSource` set to `UserDataSource.Argument`.
 * Although these values are used with writes, any elements in these FieldValues
 * are not considered writes since they cannot contain any FieldValue sentinels,
 * etc.
 *
 * @param fieldValue The sentinel FieldValue for which to create a child
 *     context.
 * @param context The parent context.
 * @param arrayElement Whether or not the FieldValue has an array.
 */function createSentinelChildContext(fieldValue,context,arrayElement){return new ParseContext({dataSource:3/* Argument */,targetDoc:context.settings.targetDoc,methodName:fieldValue._methodName,arrayElement:arrayElement},context.databaseId,context.serializer,context.ignoreUndefinedProperties);}var ServerTimestampFieldValueImpl=/*#__PURE__*/function(_FieldValue2){_inherits(ServerTimestampFieldValueImpl,_FieldValue2);function ServerTimestampFieldValueImpl(){_classCallCheck(this,ServerTimestampFieldValueImpl);return _possibleConstructorReturn(this,_getPrototypeOf(ServerTimestampFieldValueImpl).apply(this,arguments));}_createClass(ServerTimestampFieldValueImpl,[{key:"_toFieldTransform",value:function _toFieldTransform(context){return new FieldTransform(context.path,new ServerTimestampTransform());}},{key:"isEqual",value:function isEqual(other){return other instanceof ServerTimestampFieldValueImpl;}}]);return ServerTimestampFieldValueImpl;}(FieldValue);var ArrayUnionFieldValueImpl=/*#__PURE__*/function(_FieldValue3){_inherits(ArrayUnionFieldValueImpl,_FieldValue3);function ArrayUnionFieldValueImpl(methodName,_elements){var _this171;_classCallCheck(this,ArrayUnionFieldValueImpl);_this171=_possibleConstructorReturn(this,_getPrototypeOf(ArrayUnionFieldValueImpl).call(this,methodName));_this171._elements=_elements;return _this171;}_createClass(ArrayUnionFieldValueImpl,[{key:"_toFieldTransform",value:function _toFieldTransform(context){var parseContext=createSentinelChildContext(this,context,/*array=*/true);var parsedElements=this._elements.map(function(element){return parseData(element,parseContext);});var arrayUnion=new ArrayUnionTransformOperation(parsedElements);return new FieldTransform(context.path,arrayUnion);}},{key:"isEqual",value:function isEqual(other){// TODO(mrschmidt): Implement isEquals
return this===other;}}]);return ArrayUnionFieldValueImpl;}(FieldValue);var ArrayRemoveFieldValueImpl=/*#__PURE__*/function(_FieldValue4){_inherits(ArrayRemoveFieldValueImpl,_FieldValue4);function ArrayRemoveFieldValueImpl(methodName,_elements){var _this172;_classCallCheck(this,ArrayRemoveFieldValueImpl);_this172=_possibleConstructorReturn(this,_getPrototypeOf(ArrayRemoveFieldValueImpl).call(this,methodName));_this172._elements=_elements;return _this172;}_createClass(ArrayRemoveFieldValueImpl,[{key:"_toFieldTransform",value:function _toFieldTransform(context){var parseContext=createSentinelChildContext(this,context,/*array=*/true);var parsedElements=this._elements.map(function(element){return parseData(element,parseContext);});var arrayUnion=new ArrayRemoveTransformOperation(parsedElements);return new FieldTransform(context.path,arrayUnion);}},{key:"isEqual",value:function isEqual(other){// TODO(mrschmidt): Implement isEquals
return this===other;}}]);return ArrayRemoveFieldValueImpl;}(FieldValue);var NumericIncrementFieldValueImpl=/*#__PURE__*/function(_FieldValue5){_inherits(NumericIncrementFieldValueImpl,_FieldValue5);function NumericIncrementFieldValueImpl(methodName,_operand){var _this173;_classCallCheck(this,NumericIncrementFieldValueImpl);_this173=_possibleConstructorReturn(this,_getPrototypeOf(NumericIncrementFieldValueImpl).call(this,methodName));_this173._operand=_operand;return _this173;}_createClass(NumericIncrementFieldValueImpl,[{key:"_toFieldTransform",value:function _toFieldTransform(context){var numericIncrement=new NumericIncrementTransformOperation(context.serializer,toNumber(context.serializer,this._operand));return new FieldTransform(context.path,numericIncrement);}},{key:"isEqual",value:function isEqual(other){// TODO(mrschmidt): Implement isEquals
return this===other;}}]);return NumericIncrementFieldValueImpl;}(FieldValue);/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * An immutable object representing a geographic location in Firestore. The
 * location is represented as latitude/longitude pair.
 *
 * Latitude values are in the range of [-90, 90].
 * Longitude values are in the range of [-180, 180].
 */var GeoPoint=/*#__PURE__*/function(){/**
     * Creates a new immutable `GeoPoint` object with the provided latitude and
     * longitude values.
     * @param latitude The latitude as number between -90 and 90.
     * @param longitude The longitude as number between -180 and 180.
     */function GeoPoint(latitude,longitude){_classCallCheck(this,GeoPoint);validateExactNumberOfArgs('GeoPoint',arguments,2);validateArgType('GeoPoint','number',1,latitude);validateArgType('GeoPoint','number',2,longitude);if(!isFinite(latitude)||latitude<-90||latitude>90){throw new FirestoreError(Code.INVALID_ARGUMENT,'Latitude must be a number between -90 and 90, but was: '+latitude);}if(!isFinite(longitude)||longitude<-180||longitude>180){throw new FirestoreError(Code.INVALID_ARGUMENT,'Longitude must be a number between -180 and 180, but was: '+longitude);}this._lat=latitude;this._long=longitude;}/**
     * The latitude of this `GeoPoint` instance.
     */_createClass(GeoPoint,[{key:"isEqual",/**
     * Returns true if this `GeoPoint` is equal to the provided one.
     *
     * @param other The `GeoPoint` to compare against.
     * @return true if this `GeoPoint` is equal to the provided one.
     */value:function isEqual(other){return this._lat===other._lat&&this._long===other._long;}},{key:"toJSON",value:function toJSON(){return{latitude:this._lat,longitude:this._long};}/**
     * Actually private to JS consumers of our API, so this function is prefixed
     * with an underscore.
     */},{key:"_compareTo",value:function _compareTo(other){return primitiveComparator(this._lat,other._lat)||primitiveComparator(this._long,other._long);}},{key:"latitude",get:function get(){return this._lat;}/**
     * The longitude of this `GeoPoint` instance.
     */},{key:"longitude",get:function get(){return this._long;}}]);return GeoPoint;}();/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * A class implemented by all API types of the legacy Firestore API which
 * contains a reference to the API type in the firestore-exp API. All internal
 * code unwraps these references, which allows us to only use firestore-exp
 * types in the SDK.
 */var Compat=function Compat(_delegate){_classCallCheck(this,Compat);this._delegate=_delegate;};/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var RESERVED_FIELD_REGEX=/^__.*__$/;/**
 * A reference to a document in a Firebase project.
 *
 * This class serves as a common base class for the public DocumentReferences
 * exposed in the lite, full and legacy SDK.
 */ // Use underscore prefix to hide this class from our Public API.
// eslint-disable-next-line @typescript-eslint/naming-convention
var _DocumentKeyReference=function _DocumentKeyReference(_databaseId,_key,_converter){_classCallCheck(this,_DocumentKeyReference);this._databaseId=_databaseId;this._key=_key;this._converter=_converter;};/** The result of parsing document data (e.g. for a setData call). */var ParsedSetData=/*#__PURE__*/function(){function ParsedSetData(data,fieldMask,fieldTransforms){_classCallCheck(this,ParsedSetData);this.data=data;this.fieldMask=fieldMask;this.fieldTransforms=fieldTransforms;}_createClass(ParsedSetData,[{key:"toMutations",value:function toMutations(key,precondition){var mutations=[];if(this.fieldMask!==null){mutations.push(new PatchMutation(key,this.data,this.fieldMask,precondition));}else{mutations.push(new SetMutation(key,this.data,precondition));}if(this.fieldTransforms.length>0){mutations.push(new TransformMutation(key,this.fieldTransforms));}return mutations;}}]);return ParsedSetData;}();/** The result of parsing "update" data (i.e. for an updateData call). */var ParsedUpdateData=/*#__PURE__*/function(){function ParsedUpdateData(data,fieldMask,fieldTransforms){_classCallCheck(this,ParsedUpdateData);this.data=data;this.fieldMask=fieldMask;this.fieldTransforms=fieldTransforms;}_createClass(ParsedUpdateData,[{key:"toMutations",value:function toMutations(key,precondition){var mutations=[new PatchMutation(key,this.data,this.fieldMask,precondition)];if(this.fieldTransforms.length>0){mutations.push(new TransformMutation(key,this.fieldTransforms));}return mutations;}}]);return ParsedUpdateData;}();function isWrite(dataSource){switch(dataSource){case 0/* Set */:// fall through
case 2/* MergeSet */:// fall through
case 1/* Update */:return true;case 3/* Argument */:case 4/* ArrayArgument */:return false;default:throw fail();}}/** A "context" object passed around while parsing user data. */var ParseContext=/*#__PURE__*/function(){/**
     * Initializes a ParseContext with the given source and path.
     *
     * @param settings The settings for the parser.
     * @param databaseId The database ID of the Firestore instance.
     * @param serializer The serializer to use to generate the Value proto.
     * @param ignoreUndefinedProperties Whether to ignore undefined properties
     * rather than throw.
     * @param fieldTransforms A mutable list of field transforms encountered while
     *     parsing the data.
     * @param fieldMask A mutable list of field paths encountered while parsing
     *     the data.
     *
     * TODO(b/34871131): We don't support array paths right now, so path can be
     * null to indicate the context represents any location within an array (in
     * which case certain features will not work and errors will be somewhat
     * compromised).
     */function ParseContext(settings,databaseId,serializer,ignoreUndefinedProperties,fieldTransforms,fieldMask){_classCallCheck(this,ParseContext);this.settings=settings;this.databaseId=databaseId;this.serializer=serializer;this.ignoreUndefinedProperties=ignoreUndefinedProperties;// Minor hack: If fieldTransforms is undefined, we assume this is an
// external call and we need to validate the entire path.
if(fieldTransforms===undefined){this.validatePath();}this.fieldTransforms=fieldTransforms||[];this.fieldMask=fieldMask||[];}_createClass(ParseContext,[{key:"contextWith",/** Returns a new context with the specified settings overwritten. */value:function contextWith(configuration){return new ParseContext(Object.assign(Object.assign({},this.settings),configuration),this.databaseId,this.serializer,this.ignoreUndefinedProperties,this.fieldTransforms,this.fieldMask);}},{key:"childContextForField",value:function childContextForField(field){var _a;var childPath=(_a=this.path)===null||_a===void 0?void 0:_a.child(field);var context=this.contextWith({path:childPath,arrayElement:false});context.validatePathSegment(field);return context;}},{key:"childContextForFieldPath",value:function childContextForFieldPath(field){var _a;var childPath=(_a=this.path)===null||_a===void 0?void 0:_a.child(field);var context=this.contextWith({path:childPath,arrayElement:false});context.validatePath();return context;}},{key:"childContextForArray",value:function childContextForArray(index){// TODO(b/34871131): We don't support array paths right now; so make path
// undefined.
return this.contextWith({path:undefined,arrayElement:true});}},{key:"createError",value:function createError(reason){return _createError(reason,this.settings.methodName,this.settings.hasConverter||false,this.path,this.settings.targetDoc);}/** Returns 'true' if 'fieldPath' was traversed when creating this context. */},{key:"contains",value:function contains(fieldPath){return this.fieldMask.find(function(field){return fieldPath.isPrefixOf(field);})!==undefined||this.fieldTransforms.find(function(transform){return fieldPath.isPrefixOf(transform.field);})!==undefined;}},{key:"validatePath",value:function validatePath(){// TODO(b/34871131): Remove null check once we have proper paths for fields
// within arrays.
if(!this.path){return;}for(var i=0;i<this.path.length;i++){this.validatePathSegment(this.path.get(i));}}},{key:"validatePathSegment",value:function validatePathSegment(segment){if(segment.length===0){throw this.createError('Document fields must not be empty');}if(isWrite(this.dataSource)&&RESERVED_FIELD_REGEX.test(segment)){throw this.createError('Document fields cannot begin and end with "__"');}}},{key:"path",get:function get(){return this.settings.path;}},{key:"dataSource",get:function get(){return this.settings.dataSource;}}]);return ParseContext;}();/**
 * Helper for parsing raw user input (provided via the API) into internal model
 * classes.
 */var UserDataReader=/*#__PURE__*/function(){function UserDataReader(databaseId,ignoreUndefinedProperties,serializer){_classCallCheck(this,UserDataReader);this.databaseId=databaseId;this.ignoreUndefinedProperties=ignoreUndefinedProperties;this.serializer=serializer||newSerializer(databaseId);}/** Creates a new top-level parse context. */_createClass(UserDataReader,[{key:"createContext",value:function createContext(dataSource,methodName,targetDoc){var hasConverter=arguments.length>3&&arguments[3]!==undefined?arguments[3]:false;return new ParseContext({dataSource:dataSource,methodName:methodName,targetDoc:targetDoc,path:FieldPath.emptyPath(),arrayElement:false,hasConverter:hasConverter},this.databaseId,this.serializer,this.ignoreUndefinedProperties);}}]);return UserDataReader;}();/** Parse document data from a set() call. */function parseSetData(userDataReader,methodName,targetDoc,input,hasConverter){var options=arguments.length>5&&arguments[5]!==undefined?arguments[5]:{};var context=userDataReader.createContext(options.merge||options.mergeFields?2/* MergeSet */:0/* Set */,methodName,targetDoc,hasConverter);validatePlainObject('Data must be an object, but it was:',context,input);var updateData=parseObject(input,context);var fieldMask;var fieldTransforms;if(options.merge){fieldMask=new FieldMask(context.fieldMask);fieldTransforms=context.fieldTransforms;}else if(options.mergeFields){var validatedFieldPaths=[];var _iteratorNormalCompletion64=true;var _didIteratorError64=false;var _iteratorError64=undefined;try{for(var _iterator64=options.mergeFields[Symbol.iterator](),_step64;!(_iteratorNormalCompletion64=(_step64=_iterator64.next()).done);_iteratorNormalCompletion64=true){var stringOrFieldPath=_step64.value;var fieldPath=void 0;if(stringOrFieldPath instanceof _BaseFieldPath){fieldPath=stringOrFieldPath._internalPath;}else if(typeof stringOrFieldPath==='string'){fieldPath=fieldPathFromDotSeparatedString(methodName,stringOrFieldPath,targetDoc);}else{throw fail();}if(!context.contains(fieldPath)){throw new FirestoreError(Code.INVALID_ARGUMENT,"Field '".concat(fieldPath,"' is specified in your field mask but missing from your input data."));}if(!fieldMaskContains(validatedFieldPaths,fieldPath)){validatedFieldPaths.push(fieldPath);}}}catch(err){_didIteratorError64=true;_iteratorError64=err;}finally{try{if(!_iteratorNormalCompletion64&&_iterator64["return"]!=null){_iterator64["return"]();}}finally{if(_didIteratorError64){throw _iteratorError64;}}}fieldMask=new FieldMask(validatedFieldPaths);fieldTransforms=context.fieldTransforms.filter(function(transform){return fieldMask.covers(transform.field);});}else{fieldMask=null;fieldTransforms=context.fieldTransforms;}return new ParsedSetData(new ObjectValue(updateData),fieldMask,fieldTransforms);}/** Parse update data from an update() call. */function parseUpdateData(userDataReader,methodName,targetDoc,input){var context=userDataReader.createContext(1/* Update */,methodName,targetDoc);validatePlainObject('Data must be an object, but it was:',context,input);var fieldMaskPaths=[];var updateData=new ObjectValueBuilder();_forEach(input,function(key,value){var path=fieldPathFromDotSeparatedString(methodName,key,targetDoc);var childContext=context.childContextForFieldPath(path);if(value instanceof DeleteFieldValueImpl||value instanceof Compat&&value._delegate instanceof DeleteFieldValueImpl){// Add it to the field mask, but don't add anything to updateData.
fieldMaskPaths.push(path);}else{var parsedValue=parseData(value,childContext);if(parsedValue!=null){fieldMaskPaths.push(path);updateData.set(path,parsedValue);}}});var mask=new FieldMask(fieldMaskPaths);return new ParsedUpdateData(updateData.build(),mask,context.fieldTransforms);}/** Parse update data from a list of field/value arguments. */function parseUpdateVarargs(userDataReader,methodName,targetDoc,field,value,moreFieldsAndValues){var context=userDataReader.createContext(1/* Update */,methodName,targetDoc);var keys=[fieldPathFromArgument(methodName,field,targetDoc)];var values=[value];if(moreFieldsAndValues.length%2!==0){throw new FirestoreError(Code.INVALID_ARGUMENT,"Function ".concat(methodName,"() needs to be called with an even number ")+'of arguments that alternate between field names and values.');}for(var i=0;i<moreFieldsAndValues.length;i+=2){keys.push(fieldPathFromArgument(methodName,moreFieldsAndValues[i]));values.push(moreFieldsAndValues[i+1]);}var fieldMaskPaths=[];var updateData=new ObjectValueBuilder();// We iterate in reverse order to pick the last value for a field if the
// user specified the field multiple times.
for(var _i4=keys.length-1;_i4>=0;--_i4){if(!fieldMaskContains(fieldMaskPaths,keys[_i4])){var path=keys[_i4];var _value=values[_i4];var childContext=context.childContextForFieldPath(path);if(_value instanceof DeleteFieldValueImpl||_value instanceof Compat&&_value._delegate instanceof DeleteFieldValueImpl){// Add it to the field mask, but don't add anything to updateData.
fieldMaskPaths.push(path);}else{var parsedValue=parseData(_value,childContext);if(parsedValue!=null){fieldMaskPaths.push(path);updateData.set(path,parsedValue);}}}}var mask=new FieldMask(fieldMaskPaths);return new ParsedUpdateData(updateData.build(),mask,context.fieldTransforms);}/**
 * Parse a "query value" (e.g. value in a where filter or a value in a cursor
 * bound).
 *
 * @param allowArrays Whether the query value is an array that may directly
 * contain additional arrays (e.g. the operand of an `in` query).
 */function parseQueryValue(userDataReader,methodName,input){var allowArrays=arguments.length>3&&arguments[3]!==undefined?arguments[3]:false;var context=userDataReader.createContext(allowArrays?4/* ArrayArgument */:3/* Argument */,methodName);var parsed=parseData(input,context);return parsed;}/**
 * Parses user data to Protobuf Values.
 *
 * @param input Data to be parsed.
 * @param context A context object representing the current path being parsed,
 * the source of the data being parsed, etc.
 * @return The parsed value, or null if the value was a FieldValue sentinel
 * that should not be included in the resulting parsed data.
 */function parseData(input,context){// Unwrap the API type from the Compat SDK. This will return the API type
// from firestore-exp.
if(input instanceof Compat){input=input._delegate;}if(looksLikeJsonObject(input)){validatePlainObject('Unsupported field value:',context,input);return parseObject(input,context);}else if(input instanceof FieldValue){// FieldValues usually parse into transforms (except FieldValue.delete())
// in which case we do not want to include this field in our parsed data
// (as doing so will overwrite the field directly prior to the transform
// trying to transform it). So we don't add this location to
// context.fieldMask and we return null as our parsing result.
parseSentinelFieldValue(input,context);return null;}else{// If context.path is null we are inside an array and we don't support
// field mask paths more granular than the top-level array.
if(context.path){context.fieldMask.push(context.path);}if(input instanceof Array){// TODO(b/34871131): Include the path containing the array in the error
// message.
// In the case of IN queries, the parsed data is an array (representing
// the set of values to be included for the IN query) that may directly
// contain additional arrays (each representing an individual field
// value), so we disable this validation.
if(context.settings.arrayElement&&context.dataSource!==4/* ArrayArgument */){throw context.createError('Nested arrays are not supported');}return parseArray(input,context);}else{return parseScalarValue(input,context);}}}function parseObject(obj,context){var fields={};if(_isEmpty(obj)){// If we encounter an empty object, we explicitly add it to the update
// mask to ensure that the server creates a map entry.
if(context.path&&context.path.length>0){context.fieldMask.push(context.path);}}else{_forEach(obj,function(key,val){var parsedValue=parseData(val,context.childContextForField(key));if(parsedValue!=null){fields[key]=parsedValue;}});}return{mapValue:{fields:fields}};}function parseArray(array,context){var values=[];var entryIndex=0;var _iteratorNormalCompletion65=true;var _didIteratorError65=false;var _iteratorError65=undefined;try{for(var _iterator65=array[Symbol.iterator](),_step65;!(_iteratorNormalCompletion65=(_step65=_iterator65.next()).done);_iteratorNormalCompletion65=true){var entry=_step65.value;var parsedEntry=parseData(entry,context.childContextForArray(entryIndex));if(parsedEntry==null){// Just include nulls in the array for fields being replaced with a
// sentinel.
parsedEntry={nullValue:'NULL_VALUE'};}values.push(parsedEntry);entryIndex++;}}catch(err){_didIteratorError65=true;_iteratorError65=err;}finally{try{if(!_iteratorNormalCompletion65&&_iterator65["return"]!=null){_iterator65["return"]();}}finally{if(_didIteratorError65){throw _iteratorError65;}}}return{arrayValue:{values:values}};}/**
 * "Parses" the provided FieldValueImpl, adding any necessary transforms to
 * context.fieldTransforms.
 */function parseSentinelFieldValue(value,context){// Sentinels are only supported with writes, and not within arrays.
if(!isWrite(context.dataSource)){throw context.createError("".concat(value._methodName,"() can only be used with update() and set()"));}if(!context.path){throw context.createError("".concat(value._methodName,"() is not currently supported inside arrays"));}var fieldTransform=value._toFieldTransform(context);if(fieldTransform){context.fieldTransforms.push(fieldTransform);}}/**
 * Helper to parse a scalar value (i.e. not an Object, Array, or FieldValue)
 *
 * @return The parsed value
 */function parseScalarValue(value,context){if(value===null){return{nullValue:'NULL_VALUE'};}else if(typeof value==='number'){return toNumber(context.serializer,value);}else if(typeof value==='boolean'){return{booleanValue:value};}else if(typeof value==='string'){return{stringValue:value};}else if(value instanceof Date){var timestamp=Timestamp.fromDate(value);return{timestampValue:toTimestamp(context.serializer,timestamp)};}else if(value instanceof Timestamp){// Firestore backend truncates precision down to microseconds. To ensure
// offline mode works the same with regards to truncation, perform the
// truncation immediately without waiting for the backend to do that.
var _timestamp=new Timestamp(value.seconds,Math.floor(value.nanoseconds/1000)*1000);return{timestampValue:toTimestamp(context.serializer,_timestamp)};}else if(value instanceof GeoPoint){return{geoPointValue:{latitude:value.latitude,longitude:value.longitude}};}else if(value instanceof Bytes){return{bytesValue:toBytes(context.serializer,value._byteString)};}else if(value instanceof _DocumentKeyReference){var thisDb=context.databaseId;var otherDb=value._databaseId;if(!otherDb.isEqual(thisDb)){throw context.createError('Document reference is for database '+"".concat(otherDb.projectId,"/").concat(otherDb.database," but should be ")+"for database ".concat(thisDb.projectId,"/").concat(thisDb.database));}return{referenceValue:toResourceName(value._databaseId||context.databaseId,value._key.path)};}else if(value===undefined&&context.ignoreUndefinedProperties){return null;}else{throw context.createError("Unsupported field value: ".concat(valueDescription(value)));}}/**
 * Checks whether an object looks like a JSON object that should be converted
 * into a struct. Normal class/prototype instances are considered to look like
 * JSON objects since they should be converted to a struct value. Arrays, Dates,
 * GeoPoints, etc. are not considered to look like JSON objects since they map
 * to specific FieldValue types other than ObjectValue.
 */function looksLikeJsonObject(input){return _typeof(input)==='object'&&input!==null&&!(input instanceof Array)&&!(input instanceof Date)&&!(input instanceof Timestamp)&&!(input instanceof GeoPoint)&&!(input instanceof Bytes)&&!(input instanceof _DocumentKeyReference)&&!(input instanceof FieldValue);}function validatePlainObject(message,context,input){if(!looksLikeJsonObject(input)||!isPlainObject(input)){var description=valueDescription(input);if(description==='an object'){// Massage the error if it was an object.
throw context.createError(message+' a custom object');}else{throw context.createError(message+' '+description);}}}/**
 * Helper that calls fromDotSeparatedString() but wraps any error thrown.
 */function fieldPathFromArgument(methodName,path,targetDoc){if(path instanceof _BaseFieldPath){return path._internalPath;}else if(typeof path==='string'){return fieldPathFromDotSeparatedString(methodName,path);}else{var message='Field path arguments must be of type string or FieldPath.';throw _createError(message,methodName,/* hasConverter= */false,/* path= */undefined,targetDoc);}}/**
 * Wraps fromDotSeparatedString with an error message about the method that
 * was thrown.
 * @param methodName The publicly visible method name
 * @param path The dot-separated string form of a field path which will be split
 * on dots.
 * @param targetDoc The document against which the field path will be evaluated.
 */function fieldPathFromDotSeparatedString(methodName,path,targetDoc){try{return fromDotSeparatedString(path)._internalPath;}catch(e){var message=errorMessage(e);throw _createError(message,methodName,/* hasConverter= */false,/* path= */undefined,targetDoc);}}function _createError(reason,methodName,hasConverter,path,targetDoc){var hasPath=path&&!path.isEmpty();var hasDocument=targetDoc!==undefined;var message="Function ".concat(methodName,"() called with invalid data");if(hasConverter){message+=' (via `toFirestore()`)';}message+='. ';var description='';if(hasPath||hasDocument){description+=' (found';if(hasPath){description+=" in field ".concat(path);}if(hasDocument){description+=" in document ".concat(targetDoc);}description+=')';}return new FirestoreError(Code.INVALID_ARGUMENT,message+reason+description);}/**
 * Extracts the message from a caught exception, which should be an Error object
 * though JS doesn't guarantee that.
 */function errorMessage(error){return error instanceof Error?error.message:error.toString();}/** Checks `haystack` if FieldPath `needle` is present. Runs in O(n). */function fieldMaskContains(haystack,needle){return haystack.some(function(v){return v.isEqual(needle);});}/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Converts Firestore's internal types to the JavaScript types that we expose
 * to the user.
 */var UserDataWriter=/*#__PURE__*/function(){function UserDataWriter(databaseId,timestampsInSnapshots,serverTimestampBehavior,referenceFactory,bytesFactory){_classCallCheck(this,UserDataWriter);this.databaseId=databaseId;this.timestampsInSnapshots=timestampsInSnapshots;this.serverTimestampBehavior=serverTimestampBehavior;this.referenceFactory=referenceFactory;this.bytesFactory=bytesFactory;}_createClass(UserDataWriter,[{key:"convertValue",value:function convertValue(value){switch(typeOrder(value)){case 0/* NullValue */:return null;case 1/* BooleanValue */:return value.booleanValue;case 2/* NumberValue */:return normalizeNumber(value.integerValue||value.doubleValue);case 3/* TimestampValue */:return this.convertTimestamp(value.timestampValue);case 4/* ServerTimestampValue */:return this.convertServerTimestamp(value);case 5/* StringValue */:return value.stringValue;case 6/* BlobValue */:return this.bytesFactory(normalizeByteString(value.bytesValue));case 7/* RefValue */:return this.convertReference(value.referenceValue);case 8/* GeoPointValue */:return this.convertGeoPoint(value.geoPointValue);case 9/* ArrayValue */:return this.convertArray(value.arrayValue);case 10/* ObjectValue */:return this.convertObject(value.mapValue);default:throw fail();}}},{key:"convertObject",value:function convertObject(mapValue){var _this174=this;var result={};_forEach(mapValue.fields||{},function(key,value){result[key]=_this174.convertValue(value);});return result;}},{key:"convertGeoPoint",value:function convertGeoPoint(value){return new GeoPoint(normalizeNumber(value.latitude),normalizeNumber(value.longitude));}},{key:"convertArray",value:function convertArray(arrayValue){var _this175=this;return(arrayValue.values||[]).map(function(value){return _this175.convertValue(value);});}},{key:"convertServerTimestamp",value:function convertServerTimestamp(value){switch(this.serverTimestampBehavior){case'previous':var previousValue=getPreviousValue(value);if(previousValue==null){return null;}return this.convertValue(previousValue);case'estimate':return this.convertTimestamp(getLocalWriteTime(value));default:return null;}}},{key:"convertTimestamp",value:function convertTimestamp(value){var normalizedValue=normalizeTimestamp(value);var timestamp=new Timestamp(normalizedValue.seconds,normalizedValue.nanos);if(this.timestampsInSnapshots){return timestamp;}else{return timestamp.toDate();}}},{key:"convertReference",value:function convertReference(name){var resourcePath=ResourcePath.fromString(name);hardAssert(isValidResourceName(resourcePath));var databaseId=new DatabaseId(resourcePath.get(1),resourcePath.get(3));var key=new DocumentKey(resourcePath.popFirst(5));if(!databaseId.isEqual(this.databaseId)){// TODO(b/64130202): Somehow support foreign references.
logError("Document ".concat(key," contains a document ")+"reference within a different database ("+"".concat(databaseId.projectId,"/").concat(databaseId.database,") which is not ")+"supported. It will be treated as a reference in the current "+"database (".concat(this.databaseId.projectId,"/").concat(this.databaseId.database,") ")+"instead.");}return this.referenceFactory(key);}}]);return UserDataWriter;}();/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ // settings() defaults:
var DEFAULT_HOST='firestore.googleapis.com';var DEFAULT_SSL=true;var DEFAULT_TIMESTAMPS_IN_SNAPSHOTS=true;var DEFAULT_FORCE_LONG_POLLING=false;var DEFAULT_IGNORE_UNDEFINED_PROPERTIES=false;/**
 * Constant used to indicate the LRU garbage collection should be disabled.
 * Set this value as the `cacheSizeBytes` on the settings passed to the
 * `Firestore` instance.
 */var CACHE_SIZE_UNLIMITED=LruParams.COLLECTION_DISABLED;// enablePersistence() defaults:
var DEFAULT_SYNCHRONIZE_TABS=false;/**
 * A concrete type describing all the values that can be applied via a
 * user-supplied firestore.Settings object. This is a separate type so that
 * defaults can be supplied and the value can be checked for equality.
 */var FirestoreSettings=/*#__PURE__*/function(){function FirestoreSettings(settings){_classCallCheck(this,FirestoreSettings);var _a,_b,_c,_d;if(settings.host===undefined){if(settings.ssl!==undefined){throw new FirestoreError(Code.INVALID_ARGUMENT,"Can't provide ssl option if host option is not set");}this.host=DEFAULT_HOST;this.ssl=DEFAULT_SSL;}else{validateNamedType('settings','non-empty string','host',settings.host);this.host=settings.host;validateNamedOptionalType('settings','boolean','ssl',settings.ssl);this.ssl=(_a=settings.ssl)!==null&&_a!==void 0?_a:DEFAULT_SSL;}validateOptionNames('settings',settings,['host','ssl','credentials','timestampsInSnapshots','cacheSizeBytes','experimentalForceLongPolling','ignoreUndefinedProperties']);validateNamedOptionalType('settings','object','credentials',settings.credentials);this.credentials=settings.credentials;validateNamedOptionalType('settings','boolean','timestampsInSnapshots',settings.timestampsInSnapshots);validateNamedOptionalType('settings','boolean','ignoreUndefinedProperties',settings.ignoreUndefinedProperties);// Nobody should set timestampsInSnapshots anymore, but the error depends on
// whether they set it to true or false...
if(settings.timestampsInSnapshots===true){logError("The setting 'timestampsInSnapshots: true' is no longer required "+'and should be removed.');}else if(settings.timestampsInSnapshots===false){logError("Support for 'timestampsInSnapshots: false' will be removed soon. "+'You must update your code to handle Timestamp objects.');}this.timestampsInSnapshots=(_b=settings.timestampsInSnapshots)!==null&&_b!==void 0?_b:DEFAULT_TIMESTAMPS_IN_SNAPSHOTS;this.ignoreUndefinedProperties=(_c=settings.ignoreUndefinedProperties)!==null&&_c!==void 0?_c:DEFAULT_IGNORE_UNDEFINED_PROPERTIES;validateNamedOptionalType('settings','number','cacheSizeBytes',settings.cacheSizeBytes);if(settings.cacheSizeBytes===undefined){this.cacheSizeBytes=LruParams.DEFAULT_CACHE_SIZE_BYTES;}else{if(settings.cacheSizeBytes!==CACHE_SIZE_UNLIMITED&&settings.cacheSizeBytes<LruParams.MINIMUM_CACHE_SIZE_BYTES){throw new FirestoreError(Code.INVALID_ARGUMENT,"cacheSizeBytes must be at least ".concat(LruParams.MINIMUM_CACHE_SIZE_BYTES));}else{this.cacheSizeBytes=settings.cacheSizeBytes;}}validateNamedOptionalType('settings','boolean','experimentalForceLongPolling',settings.experimentalForceLongPolling);this.experimentalForceLongPolling=(_d=settings.experimentalForceLongPolling)!==null&&_d!==void 0?_d:DEFAULT_FORCE_LONG_POLLING;}_createClass(FirestoreSettings,[{key:"isEqual",value:function isEqual(other){return this.host===other.host&&this.ssl===other.ssl&&this.timestampsInSnapshots===other.timestampsInSnapshots&&this.credentials===other.credentials&&this.cacheSizeBytes===other.cacheSizeBytes&&this.experimentalForceLongPolling===other.experimentalForceLongPolling&&this.ignoreUndefinedProperties===other.ignoreUndefinedProperties;}}]);return FirestoreSettings;}();/**
 * The root reference to the database.
 */var Firestore=/*#__PURE__*/function(){// Note: We are using `MemoryComponentProvider` as a default
// ComponentProvider to ensure backwards compatibility with the format
// expected by the console build.
function Firestore(databaseIdOrApp,authProvider){var _this176=this;var _offlineComponentProvider=arguments.length>2&&arguments[2]!==undefined?arguments[2]:new MemoryOfflineComponentProvider();var _onlineComponentProvider=arguments.length>3&&arguments[3]!==undefined?arguments[3]:new OnlineComponentProvider();_classCallCheck(this,Firestore);this._offlineComponentProvider=_offlineComponentProvider;this._onlineComponentProvider=_onlineComponentProvider;this._firebaseApp=null;// Public for use in tests.
// TODO(mikelehen): Use modularized initialization instead.
this._queue=new AsyncQueue();this.INTERNAL={"delete":function _delete(){return regeneratorRuntime.async(function _delete$(_context90){while(1){switch(_context90.prev=_context90.next){case 0:// The client must be initalized to ensure that all subsequent API usage
// throws an exception.
_this176.ensureClientConfigured();_context90.next=3;return regeneratorRuntime.awrap(_this176._firestoreClient.terminate());case 3:case"end":return _context90.stop();}}});}};if(_typeof(databaseIdOrApp.options)==='object'){// This is very likely a Firebase app object
// TODO(b/34177605): Can we somehow use instanceof?
var app=databaseIdOrApp;this._firebaseApp=app;this._databaseId=Firestore.databaseIdFromApp(app);this._persistenceKey=app.name;this._credentials=new FirebaseCredentialsProvider(authProvider);}else{var external=databaseIdOrApp;if(!external.projectId){throw new FirestoreError(Code.INVALID_ARGUMENT,'Must provide projectId');}this._databaseId=new DatabaseId(external.projectId,external.database);// Use a default persistenceKey that lines up with FirebaseApp.
this._persistenceKey='[DEFAULT]';this._credentials=new EmptyCredentialsProvider();}this._settings=new FirestoreSettings({});}_createClass(Firestore,[{key:"settings",value:function settings(settingsLiteral){validateExactNumberOfArgs('Firestore.settings',arguments,1);validateArgType('Firestore.settings','object',1,settingsLiteral);if(settingsLiteral.merge){settingsLiteral=Object.assign(Object.assign({},this._settings),settingsLiteral);// Remove the property from the settings once the merge is completed
delete settingsLiteral.merge;}var newSettings=new FirestoreSettings(settingsLiteral);if(this._firestoreClient&&!this._settings.isEqual(newSettings)){throw new FirestoreError(Code.FAILED_PRECONDITION,'Firestore has already been started and its settings can no longer '+'be changed. You can only call settings() before calling any other '+'methods on a Firestore object.');}this._settings=newSettings;if(newSettings.credentials!==undefined){this._credentials=makeCredentialsProvider(newSettings.credentials);}}},{key:"enableNetwork",value:function enableNetwork(){this.ensureClientConfigured();return this._firestoreClient.enableNetwork();}},{key:"disableNetwork",value:function disableNetwork(){this.ensureClientConfigured();return this._firestoreClient.disableNetwork();}},{key:"enablePersistence",value:function enablePersistence(settings){var _a,_b;if(this._firestoreClient){throw new FirestoreError(Code.FAILED_PRECONDITION,'Firestore has already been started and persistence can no longer '+'be enabled. You can only call enablePersistence() before calling '+'any other methods on a Firestore object.');}var synchronizeTabs=false;var experimentalForceOwningTab=false;if(settings){if(settings.experimentalTabSynchronization!==undefined){logError("The 'experimentalTabSynchronization' setting will be removed. Use 'synchronizeTabs' instead.");}synchronizeTabs=(_b=(_a=settings.synchronizeTabs)!==null&&_a!==void 0?_a:settings.experimentalTabSynchronization)!==null&&_b!==void 0?_b:DEFAULT_SYNCHRONIZE_TABS;experimentalForceOwningTab=settings.experimentalForceOwningTab?settings.experimentalForceOwningTab:false;if(synchronizeTabs&&experimentalForceOwningTab){throw new FirestoreError(Code.INVALID_ARGUMENT,"The 'experimentalForceOwningTab' setting cannot be used with 'synchronizeTabs'.");}}return this.configureClient(this._offlineComponentProvider,this._onlineComponentProvider,{durable:true,cacheSizeBytes:this._settings.cacheSizeBytes,synchronizeTabs:synchronizeTabs,forceOwningTab:experimentalForceOwningTab});}},{key:"clearPersistence",value:function clearPersistence(){var _this177=this;var deferred;return regeneratorRuntime.async(function clearPersistence$(_context92){while(1){switch(_context92.prev=_context92.next){case 0:if(!(this._firestoreClient!==undefined&&!this._firestoreClient.clientTerminated)){_context92.next=2;break;}throw new FirestoreError(Code.FAILED_PRECONDITION,'Persistence can only be cleared before a Firestore instance is '+'initialized or after it is terminated.');case 2:deferred=new Deferred();this._queue.enqueueAndForgetEvenWhileRestricted(function _callee18(){return regeneratorRuntime.async(function _callee18$(_context91){while(1){switch(_context91.prev=_context91.next){case 0:_context91.prev=0;_context91.next=3;return regeneratorRuntime.awrap(_this177._offlineComponentProvider.clearPersistence(_this177._databaseId,_this177._persistenceKey));case 3:deferred.resolve();_context91.next=9;break;case 6:_context91.prev=6;_context91.t0=_context91["catch"](0);deferred.reject(_context91.t0);case 9:case"end":return _context91.stop();}}},null,null,[[0,6]]);});return _context92.abrupt("return",deferred.promise);case 5:case"end":return _context92.stop();}}},null,this);}},{key:"terminate",value:function terminate(){this.app._removeServiceInstance('firestore');return this.INTERNAL["delete"]();}},{key:"waitForPendingWrites",value:function waitForPendingWrites(){this.ensureClientConfigured();return this._firestoreClient.waitForPendingWrites();}},{key:"onSnapshotsInSync",value:function onSnapshotsInSync(arg){this.ensureClientConfigured();if(isPartialObserver(arg)){return this._firestoreClient.addSnapshotsInSyncListener(arg);}else{validateArgType('Firestore.onSnapshotsInSync','function',1,arg);var observer={next:arg};return this._firestoreClient.addSnapshotsInSyncListener(observer);}}},{key:"ensureClientConfigured",value:function ensureClientConfigured(){if(!this._firestoreClient){// Kick off starting the client but don't actually wait for it.
// eslint-disable-next-line @typescript-eslint/no-floating-promises
this.configureClient(new MemoryOfflineComponentProvider(),new OnlineComponentProvider(),{durable:false});}return this._firestoreClient;}},{key:"makeDatabaseInfo",value:function makeDatabaseInfo(){return new DatabaseInfo(this._databaseId,this._persistenceKey,this._settings.host,this._settings.ssl,this._settings.experimentalForceLongPolling);}},{key:"configureClient",value:function configureClient(offlineComponentProvider,onlineComponentProvider,persistenceSettings){var databaseInfo=this.makeDatabaseInfo();this._firestoreClient=new FirestoreClient(this._credentials,this._queue);return this._firestoreClient.start(databaseInfo,offlineComponentProvider,onlineComponentProvider,persistenceSettings);}},{key:"collection",value:function collection(pathString){validateExactNumberOfArgs('Firestore.collection',arguments,1);validateArgType('Firestore.collection','non-empty string',1,pathString);this.ensureClientConfigured();return new CollectionReference(ResourcePath.fromString(pathString),this,/* converter= */null);}},{key:"doc",value:function doc(pathString){validateExactNumberOfArgs('Firestore.doc',arguments,1);validateArgType('Firestore.doc','non-empty string',1,pathString);this.ensureClientConfigured();return DocumentReference.forPath(ResourcePath.fromString(pathString),this,/* converter= */null);}},{key:"collectionGroup",value:function collectionGroup(collectionId){validateExactNumberOfArgs('Firestore.collectionGroup',arguments,1);validateArgType('Firestore.collectionGroup','non-empty string',1,collectionId);if(collectionId.indexOf('/')>=0){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid collection ID '".concat(collectionId,"' passed to function ")+"Firestore.collectionGroup(). Collection IDs must not contain '/'.");}this.ensureClientConfigured();return new Query(newQueryForCollectionGroup(collectionId),this,/* converter= */null);}},{key:"runTransaction",value:function runTransaction(updateFunction){var _this178=this;validateExactNumberOfArgs('Firestore.runTransaction',arguments,1);validateArgType('Firestore.runTransaction','function',1,updateFunction);return this.ensureClientConfigured().transaction(function(transaction){return updateFunction(new Transaction$1(_this178,transaction));});}},{key:"batch",value:function batch(){this.ensureClientConfigured();return new WriteBatch(this);}},{key:"_areTimestampsInSnapshotsEnabled",// Note: this is not a property because the minifier can't work correctly with
// the way TypeScript compiler outputs properties.
value:function _areTimestampsInSnapshotsEnabled(){return this._settings.timestampsInSnapshots;}// Visible for testing.
},{key:"_getSettings",value:function _getSettings(){return this._settings;}},{key:"_dataReader",get:function get(){if(!this._userDataReader){// Lazy initialize UserDataReader once the settings are frozen
this._userDataReader=new UserDataReader(this._databaseId,this._settings.ignoreUndefinedProperties);}return this._userDataReader;}},{key:"_isTerminated",get:function get(){this.ensureClientConfigured();return this._firestoreClient.clientTerminated;}},{key:"app",get:function get(){if(!this._firebaseApp){throw new FirestoreError(Code.FAILED_PRECONDITION,"Firestore was not initialized using the Firebase SDK. 'app' is "+'not available');}return this._firebaseApp;}}],[{key:"databaseIdFromApp",value:function databaseIdFromApp(app){if(!contains(app.options,'projectId')){throw new FirestoreError(Code.INVALID_ARGUMENT,'"projectId" not provided in firebase.initializeApp.');}var projectId=app.options.projectId;if(!projectId||typeof projectId!=='string'){throw new FirestoreError(Code.INVALID_ARGUMENT,'projectId must be a string in FirebaseApp.options');}return new DatabaseId(projectId);}},{key:"setLogLevel",value:function setLogLevel(level){validateExactNumberOfArgs('Firestore.setLogLevel',arguments,1);validateStringEnum('setLogLevel',['debug','error','silent','warn','info','verbose'],1,level);_setLogLevel(level);}},{key:"logLevel",get:function get(){switch(getLogLevel()){case _logger.LogLevel.DEBUG:return'debug';case _logger.LogLevel.ERROR:return'error';case _logger.LogLevel.SILENT:return'silent';case _logger.LogLevel.WARN:return'warn';case _logger.LogLevel.INFO:return'info';case _logger.LogLevel.VERBOSE:return'verbose';default:// The default log level is error
return'error';}}}]);return Firestore;}();/**
 * A reference to a transaction.
 */var Transaction$1=/*#__PURE__*/function(){function Transaction$1(_firestore,_transaction){_classCallCheck(this,Transaction$1);this._firestore=_firestore;this._transaction=_transaction;}_createClass(Transaction$1,[{key:"get",value:function get(documentRef){var _this179=this;validateExactNumberOfArgs('Transaction.get',arguments,1);var ref=validateReference('Transaction.get',documentRef,this._firestore);return this._transaction.lookup([ref._key]).then(function(docs){if(!docs||docs.length!==1){return fail();}var doc=docs[0];if(doc instanceof NoDocument){return new DocumentSnapshot(_this179._firestore,ref._key,null,/* fromCache= */false,/* hasPendingWrites= */false,ref._converter);}else if(doc instanceof Document){return new DocumentSnapshot(_this179._firestore,ref._key,doc,/* fromCache= */false,/* hasPendingWrites= */false,ref._converter);}else{throw fail();}});}},{key:"set",value:function set(documentRef,value,options){validateBetweenNumberOfArgs('Transaction.set',arguments,2,3);var ref=validateReference('Transaction.set',documentRef,this._firestore);options=validateSetOptions('Transaction.set',options);var convertedValue=applyFirestoreDataConverter(ref._converter,value,options);var parsed=parseSetData(this._firestore._dataReader,'Transaction.set',ref._key,convertedValue,ref._converter!==null,options);this._transaction.set(ref._key,parsed);return this;}},{key:"update",value:function update(documentRef,fieldOrUpdateData,value){for(var _len9=arguments.length,moreFieldsAndValues=new Array(_len9>3?_len9-3:0),_key17=3;_key17<_len9;_key17++){moreFieldsAndValues[_key17-3]=arguments[_key17];}var ref;var parsed;if(typeof fieldOrUpdateData==='string'||fieldOrUpdateData instanceof FieldPath$1){validateAtLeastNumberOfArgs('Transaction.update',arguments,3);ref=validateReference('Transaction.update',documentRef,this._firestore);parsed=parseUpdateVarargs(this._firestore._dataReader,'Transaction.update',ref._key,fieldOrUpdateData,value,moreFieldsAndValues);}else{validateExactNumberOfArgs('Transaction.update',arguments,2);ref=validateReference('Transaction.update',documentRef,this._firestore);parsed=parseUpdateData(this._firestore._dataReader,'Transaction.update',ref._key,fieldOrUpdateData);}this._transaction.update(ref._key,parsed);return this;}},{key:"delete",value:function _delete(documentRef){validateExactNumberOfArgs('Transaction.delete',arguments,1);var ref=validateReference('Transaction.delete',documentRef,this._firestore);this._transaction["delete"](ref._key);return this;}}]);return Transaction$1;}();var WriteBatch=/*#__PURE__*/function(){function WriteBatch(_firestore){_classCallCheck(this,WriteBatch);this._firestore=_firestore;this._mutations=[];this._committed=false;}_createClass(WriteBatch,[{key:"set",value:function set(documentRef,value,options){validateBetweenNumberOfArgs('WriteBatch.set',arguments,2,3);this.verifyNotCommitted();var ref=validateReference('WriteBatch.set',documentRef,this._firestore);options=validateSetOptions('WriteBatch.set',options);var convertedValue=applyFirestoreDataConverter(ref._converter,value,options);var parsed=parseSetData(this._firestore._dataReader,'WriteBatch.set',ref._key,convertedValue,ref._converter!==null,options);this._mutations=this._mutations.concat(parsed.toMutations(ref._key,Precondition.none()));return this;}},{key:"update",value:function update(documentRef,fieldOrUpdateData,value){for(var _len10=arguments.length,moreFieldsAndValues=new Array(_len10>3?_len10-3:0),_key18=3;_key18<_len10;_key18++){moreFieldsAndValues[_key18-3]=arguments[_key18];}this.verifyNotCommitted();var ref;var parsed;if(typeof fieldOrUpdateData==='string'||fieldOrUpdateData instanceof FieldPath$1){validateAtLeastNumberOfArgs('WriteBatch.update',arguments,3);ref=validateReference('WriteBatch.update',documentRef,this._firestore);parsed=parseUpdateVarargs(this._firestore._dataReader,'WriteBatch.update',ref._key,fieldOrUpdateData,value,moreFieldsAndValues);}else{validateExactNumberOfArgs('WriteBatch.update',arguments,2);ref=validateReference('WriteBatch.update',documentRef,this._firestore);parsed=parseUpdateData(this._firestore._dataReader,'WriteBatch.update',ref._key,fieldOrUpdateData);}this._mutations=this._mutations.concat(parsed.toMutations(ref._key,Precondition.exists(true)));return this;}},{key:"delete",value:function _delete(documentRef){validateExactNumberOfArgs('WriteBatch.delete',arguments,1);this.verifyNotCommitted();var ref=validateReference('WriteBatch.delete',documentRef,this._firestore);this._mutations=this._mutations.concat(new DeleteMutation(ref._key,Precondition.none()));return this;}},{key:"commit",value:function commit(){this.verifyNotCommitted();this._committed=true;if(this._mutations.length>0){return this._firestore.ensureClientConfigured().write(this._mutations);}return Promise.resolve();}},{key:"verifyNotCommitted",value:function verifyNotCommitted(){if(this._committed){throw new FirestoreError(Code.FAILED_PRECONDITION,'A write batch can no longer be used after commit() '+'has been called.');}}}]);return WriteBatch;}();/**
 * A reference to a particular document in a collection in the database.
 */var DocumentReference=/*#__PURE__*/function(_DocumentKeyReference2){_inherits(DocumentReference,_DocumentKeyReference2);function DocumentReference(_key,firestore,_converter){var _this180;_classCallCheck(this,DocumentReference);_this180=_possibleConstructorReturn(this,_getPrototypeOf(DocumentReference).call(this,firestore._databaseId,_key,_converter));_this180._key=_key;_this180.firestore=firestore;_this180._converter=_converter;_this180._firestoreClient=_this180.firestore.ensureClientConfigured();return _this180;}_createClass(DocumentReference,[{key:"collection",value:function collection(pathString){validateExactNumberOfArgs('DocumentReference.collection',arguments,1);validateArgType('DocumentReference.collection','non-empty string',1,pathString);if(!pathString){throw new FirestoreError(Code.INVALID_ARGUMENT,'Must provide a non-empty collection name to collection()');}var path=ResourcePath.fromString(pathString);return new CollectionReference(this._key.path.child(path),this.firestore,/* converter= */null);}},{key:"isEqual",value:function isEqual(other){if(!(other instanceof DocumentReference)){throw invalidClassError('isEqual','DocumentReference',1,other);}return this.firestore===other.firestore&&this._key.isEqual(other._key)&&this._converter===other._converter;}},{key:"set",value:function set(value,options){validateBetweenNumberOfArgs('DocumentReference.set',arguments,1,2);options=validateSetOptions('DocumentReference.set',options);var convertedValue=applyFirestoreDataConverter(this._converter,value,options);var parsed=parseSetData(this.firestore._dataReader,'DocumentReference.set',this._key,convertedValue,this._converter!==null,options);return this._firestoreClient.write(parsed.toMutations(this._key,Precondition.none()));}},{key:"update",value:function update(fieldOrUpdateData,value){for(var _len11=arguments.length,moreFieldsAndValues=new Array(_len11>2?_len11-2:0),_key19=2;_key19<_len11;_key19++){moreFieldsAndValues[_key19-2]=arguments[_key19];}var parsed;if(typeof fieldOrUpdateData==='string'||fieldOrUpdateData instanceof FieldPath$1){validateAtLeastNumberOfArgs('DocumentReference.update',arguments,2);parsed=parseUpdateVarargs(this.firestore._dataReader,'DocumentReference.update',this._key,fieldOrUpdateData,value,moreFieldsAndValues);}else{validateExactNumberOfArgs('DocumentReference.update',arguments,1);parsed=parseUpdateData(this.firestore._dataReader,'DocumentReference.update',this._key,fieldOrUpdateData);}return this._firestoreClient.write(parsed.toMutations(this._key,Precondition.exists(true)));}},{key:"delete",value:function _delete(){validateExactNumberOfArgs('DocumentReference.delete',arguments,0);return this._firestoreClient.write([new DeleteMutation(this._key,Precondition.none())]);}},{key:"onSnapshot",value:function onSnapshot(){var _this181=this;for(var _len12=arguments.length,args=new Array(_len12),_key20=0;_key20<_len12;_key20++){args[_key20]=arguments[_key20];}var _a,_b,_c;validateBetweenNumberOfArgs('DocumentReference.onSnapshot',arguments,1,4);var options={includeMetadataChanges:false};var currArg=0;if(_typeof(args[currArg])==='object'&&!isPartialObserver(args[currArg])){options=args[currArg];validateOptionNames('DocumentReference.onSnapshot',options,['includeMetadataChanges']);validateNamedOptionalType('DocumentReference.onSnapshot','boolean','includeMetadataChanges',options.includeMetadataChanges);currArg++;}var internalOptions={includeMetadataChanges:options.includeMetadataChanges};if(isPartialObserver(args[currArg])){var userObserver=args[currArg];args[currArg]=(_a=userObserver.next)===null||_a===void 0?void 0:_a.bind(userObserver);args[currArg+1]=(_b=userObserver.error)===null||_b===void 0?void 0:_b.bind(userObserver);args[currArg+2]=(_c=userObserver.complete)===null||_c===void 0?void 0:_c.bind(userObserver);}else{validateArgType('DocumentReference.onSnapshot','function',currArg,args[currArg]);validateOptionalArgType('DocumentReference.onSnapshot','function',currArg+1,args[currArg+1]);validateOptionalArgType('DocumentReference.onSnapshot','function',currArg+2,args[currArg+2]);}var observer={next:function next(snapshot){if(args[currArg]){args[currArg](_this181._convertToDocSnapshot(snapshot));}},error:args[currArg+1],complete:args[currArg+2]};return this._firestoreClient.listen(newQueryForPath(this._key.path),internalOptions,observer);}},{key:"get",value:function get(options){var _this182=this;validateBetweenNumberOfArgs('DocumentReference.get',arguments,0,1);validateGetOptions('DocumentReference.get',options);var firestoreClient=this.firestore.ensureClientConfigured();if(options&&options.source==='cache'){return firestoreClient.getDocumentFromLocalCache(this._key).then(function(doc){return new DocumentSnapshot(_this182.firestore,_this182._key,doc,/*fromCache=*/true,doc instanceof Document?doc.hasLocalMutations:false,_this182._converter);});}else{return firestoreClient.getDocumentViaSnapshotListener(this._key,options).then(function(snapshot){return _this182._convertToDocSnapshot(snapshot);});}}},{key:"withConverter",value:function withConverter(converter){return new DocumentReference(this._key,this.firestore,converter);}/**
     * Converts a ViewSnapshot that contains the current document to a
     * DocumentSnapshot.
     */},{key:"_convertToDocSnapshot",value:function _convertToDocSnapshot(snapshot){var doc=snapshot.docs.get(this._key);return new DocumentSnapshot(this.firestore,this._key,doc,snapshot.fromCache,snapshot.hasPendingWrites,this._converter);}},{key:"id",get:function get(){return this._key.path.lastSegment();}},{key:"parent",get:function get(){return new CollectionReference(this._key.path.popLast(),this.firestore,this._converter);}},{key:"path",get:function get(){return this._key.path.canonicalString();}}],[{key:"forPath",value:function forPath(path,firestore,converter){if(path.length%2!==0){throw new FirestoreError(Code.INVALID_ARGUMENT,'Invalid document reference. Document '+'references must have an even number of segments, but '+"".concat(path.canonicalString()," has ").concat(path.length));}return new DocumentReference(new DocumentKey(path),firestore,converter);}}]);return DocumentReference;}(_DocumentKeyReference);/**
 * Metadata about a snapshot, describing the state of the snapshot.
 */var SnapshotMetadata=/*#__PURE__*/function(){function SnapshotMetadata(hasPendingWrites,fromCache){_classCallCheck(this,SnapshotMetadata);this.hasPendingWrites=hasPendingWrites;this.fromCache=fromCache;}/**
     * Returns true if this `SnapshotMetadata` is equal to the provided one.
     *
     * @param other The `SnapshotMetadata` to compare against.
     * @return true if this `SnapshotMetadata` is equal to the provided one.
     */_createClass(SnapshotMetadata,[{key:"isEqual",value:function isEqual(other){return this.hasPendingWrites===other.hasPendingWrites&&this.fromCache===other.fromCache;}}]);return SnapshotMetadata;}();var DocumentSnapshot=/*#__PURE__*/function(){function DocumentSnapshot(_firestore,_key,_document,_fromCache,_hasPendingWrites,_converter){_classCallCheck(this,DocumentSnapshot);this._firestore=_firestore;this._key=_key;this._document=_document;this._fromCache=_fromCache;this._hasPendingWrites=_hasPendingWrites;this._converter=_converter;}_createClass(DocumentSnapshot,[{key:"data",value:function data(options){var _this183=this;validateBetweenNumberOfArgs('DocumentSnapshot.data',arguments,0,1);options=validateSnapshotOptions('DocumentSnapshot.data',options);if(!this._document){return undefined;}else{// We only want to use the converter and create a new DocumentSnapshot
// if a converter has been provided.
if(this._converter){var snapshot=new QueryDocumentSnapshot(this._firestore,this._key,this._document,this._fromCache,this._hasPendingWrites,/* converter= */null);return this._converter.fromFirestore(snapshot,options);}else{var userDataWriter=new UserDataWriter(this._firestore._databaseId,this._firestore._areTimestampsInSnapshotsEnabled(),options.serverTimestamps||'none',function(key){return new DocumentReference(key,_this183._firestore,/* converter= */null);},function(bytes){return new Blob(bytes);});return userDataWriter.convertValue(this._document.toProto());}}}},{key:"get",value:function get(fieldPath,options){var _this184=this;validateBetweenNumberOfArgs('DocumentSnapshot.get',arguments,1,2);options=validateSnapshotOptions('DocumentSnapshot.get',options);if(this._document){var value=this._document.data().field(fieldPathFromArgument('DocumentSnapshot.get',fieldPath,this._key));if(value!==null){var userDataWriter=new UserDataWriter(this._firestore._databaseId,this._firestore._areTimestampsInSnapshotsEnabled(),options.serverTimestamps||'none',function(key){return new DocumentReference(key,_this184._firestore,_this184._converter);},function(bytes){return new Blob(bytes);});return userDataWriter.convertValue(value);}}return undefined;}},{key:"isEqual",value:function isEqual(other){if(!(other instanceof DocumentSnapshot)){throw invalidClassError('isEqual','DocumentSnapshot',1,other);}return this._firestore===other._firestore&&this._fromCache===other._fromCache&&this._key.isEqual(other._key)&&(this._document===null?other._document===null:this._document.isEqual(other._document))&&this._converter===other._converter;}},{key:"id",get:function get(){return this._key.path.lastSegment();}},{key:"ref",get:function get(){return new DocumentReference(this._key,this._firestore,this._converter);}},{key:"exists",get:function get(){return this._document!==null;}},{key:"metadata",get:function get(){return new SnapshotMetadata(this._hasPendingWrites,this._fromCache);}}]);return DocumentSnapshot;}();var QueryDocumentSnapshot=/*#__PURE__*/function(_DocumentSnapshot){_inherits(QueryDocumentSnapshot,_DocumentSnapshot);function QueryDocumentSnapshot(){_classCallCheck(this,QueryDocumentSnapshot);return _possibleConstructorReturn(this,_getPrototypeOf(QueryDocumentSnapshot).apply(this,arguments));}_createClass(QueryDocumentSnapshot,[{key:"data",value:function data(options){var data=_get(_getPrototypeOf(QueryDocumentSnapshot.prototype),"data",this).call(this,options);return data;}}]);return QueryDocumentSnapshot;}(DocumentSnapshot);function newQueryFilter(query,methodName,dataReader,databaseId,fieldPath,op,value){var fieldValue;if(fieldPath.isKeyField()){if(op==="array-contains"/* ARRAY_CONTAINS */||op==="array-contains-any"/* ARRAY_CONTAINS_ANY */){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid Query. You can't perform '".concat(op,"' ")+'queries on FieldPath.documentId().');}else if(op==="in"/* IN */||op==="not-in"/* NOT_IN */){validateDisjunctiveFilterElements(value,op);var referenceList=[];var _iteratorNormalCompletion66=true;var _didIteratorError66=false;var _iteratorError66=undefined;try{for(var _iterator66=value[Symbol.iterator](),_step66;!(_iteratorNormalCompletion66=(_step66=_iterator66.next()).done);_iteratorNormalCompletion66=true){var arrayValue=_step66.value;referenceList.push(parseDocumentIdValue(databaseId,query,arrayValue));}}catch(err){_didIteratorError66=true;_iteratorError66=err;}finally{try{if(!_iteratorNormalCompletion66&&_iterator66["return"]!=null){_iterator66["return"]();}}finally{if(_didIteratorError66){throw _iteratorError66;}}}fieldValue={arrayValue:{values:referenceList}};}else{fieldValue=parseDocumentIdValue(databaseId,query,value);}}else{if(op==="in"/* IN */||op==="not-in"/* NOT_IN */||op==="array-contains-any"/* ARRAY_CONTAINS_ANY */){validateDisjunctiveFilterElements(value,op);}fieldValue=parseQueryValue(dataReader,methodName,value,/* allowArrays= */op==="in"/* IN */||op==="not-in"/* NOT_IN */);}var filter=FieldFilter.create(fieldPath,op,fieldValue);validateNewFilter(query,filter);return filter;}function newQueryOrderBy(query,fieldPath,direction){if(query.startAt!==null){throw new FirestoreError(Code.INVALID_ARGUMENT,'Invalid query. You must not call startAt() or startAfter() before '+'calling orderBy().');}if(query.endAt!==null){throw new FirestoreError(Code.INVALID_ARGUMENT,'Invalid query. You must not call endAt() or endBefore() before '+'calling orderBy().');}var orderBy=new OrderBy(fieldPath,direction);validateNewOrderBy(query,orderBy);return orderBy;}/**
 * Create a Bound from a query and a document.
 *
 * Note that the Bound will always include the key of the document
 * and so only the provided document will compare equal to the returned
 * position.
 *
 * Will throw if the document does not contain all fields of the order by
 * of the query or if any of the fields in the order by are an uncommitted
 * server timestamp.
 */function newQueryBoundFromDocument(query,databaseId,methodName,doc,before){if(!doc){throw new FirestoreError(Code.NOT_FOUND,"Can't use a DocumentSnapshot that doesn't exist for "+"".concat(methodName,"()."));}var components=[];// Because people expect to continue/end a query at the exact document
// provided, we need to use the implicit sort order rather than the explicit
// sort order, because it's guaranteed to contain the document key. That way
// the position becomes unambiguous and the query continues/ends exactly at
// the provided document. Without the key (by using the explicit sort
// orders), multiple documents could match the position, yielding duplicate
// results.
var _iteratorNormalCompletion67=true;var _didIteratorError67=false;var _iteratorError67=undefined;try{for(var _iterator67=queryOrderBy(query)[Symbol.iterator](),_step67;!(_iteratorNormalCompletion67=(_step67=_iterator67.next()).done);_iteratorNormalCompletion67=true){var orderBy=_step67.value;if(orderBy.field.isKeyField()){components.push(refValue(databaseId,doc.key));}else{var value=doc.field(orderBy.field);if(isServerTimestamp(value)){throw new FirestoreError(Code.INVALID_ARGUMENT,'Invalid query. You are trying to start or end a query using a '+'document for which the field "'+orderBy.field+'" is an uncommitted server timestamp. (Since the value of '+'this field is unknown, you cannot start/end a query with it.)');}else if(value!==null){components.push(value);}else{var field=orderBy.field.canonicalString();throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid query. You are trying to start or end a query using a "+"document for which the field '".concat(field,"' (used as the ")+"orderBy) does not exist.");}}}}catch(err){_didIteratorError67=true;_iteratorError67=err;}finally{try{if(!_iteratorNormalCompletion67&&_iterator67["return"]!=null){_iterator67["return"]();}}finally{if(_didIteratorError67){throw _iteratorError67;}}}return new Bound(components,before);}/**
 * Converts a list of field values to a Bound for the given query.
 */function newQueryBoundFromFields(query,databaseId,dataReader,methodName,values,before){// Use explicit order by's because it has to match the query the user made
var orderBy=query.explicitOrderBy;if(values.length>orderBy.length){throw new FirestoreError(Code.INVALID_ARGUMENT,"Too many arguments provided to ".concat(methodName,"(). ")+"The number of arguments must be less than or equal to the "+"number of orderBy() clauses");}var components=[];for(var i=0;i<values.length;i++){var rawValue=values[i];var orderByComponent=orderBy[i];if(orderByComponent.field.isKeyField()){if(typeof rawValue!=='string'){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid query. Expected a string for document ID in "+"".concat(methodName,"(), but got a ").concat(_typeof(rawValue)));}if(!isCollectionGroupQuery(query)&&rawValue.indexOf('/')!==-1){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid query. When querying a collection and ordering by FieldPath.documentId(), "+"the value passed to ".concat(methodName,"() must be a plain document ID, but ")+"'".concat(rawValue,"' contains a slash."));}var path=query.path.child(ResourcePath.fromString(rawValue));if(!DocumentKey.isDocumentKey(path)){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid query. When querying a collection group and ordering by "+"FieldPath.documentId(), the value passed to ".concat(methodName,"() must result in a ")+"valid document path, but '".concat(path,"' is not because it contains an odd number ")+"of segments.");}var key=new DocumentKey(path);components.push(refValue(databaseId,key));}else{var wrapped=parseQueryValue(dataReader,methodName,rawValue);components.push(wrapped);}}return new Bound(components,before);}/**
 * Parses the given documentIdValue into a ReferenceValue, throwing
 * appropriate errors if the value is anything other than a DocumentReference
 * or String, or if the string is malformed.
 */function parseDocumentIdValue(databaseId,query,documentIdValue){if(typeof documentIdValue==='string'){if(documentIdValue===''){throw new FirestoreError(Code.INVALID_ARGUMENT,'Invalid query. When querying with FieldPath.documentId(), you '+'must provide a valid document ID, but it was an empty string.');}if(!isCollectionGroupQuery(query)&&documentIdValue.indexOf('/')!==-1){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid query. When querying a collection by "+"FieldPath.documentId(), you must provide a plain document ID, but "+"'".concat(documentIdValue,"' contains a '/' character."));}var path=query.path.child(ResourcePath.fromString(documentIdValue));if(!DocumentKey.isDocumentKey(path)){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid query. When querying a collection group by "+"FieldPath.documentId(), the value provided must result in a valid document path, "+"but '".concat(path,"' is not because it has an odd number of segments (").concat(path.length,")."));}return refValue(databaseId,new DocumentKey(path));}else if(documentIdValue instanceof _DocumentKeyReference){return refValue(databaseId,documentIdValue._key);}else{throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid query. When querying with FieldPath.documentId(), you must provide a valid "+"string or a DocumentReference, but it was: "+"".concat(valueDescription(documentIdValue),"."));}}/**
 * Validates that the value passed into a disjunctive filter satisfies all
 * array requirements.
 */function validateDisjunctiveFilterElements(value,operator){if(!Array.isArray(value)||value.length===0){throw new FirestoreError(Code.INVALID_ARGUMENT,'Invalid Query. A non-empty array is required for '+"'".concat(operator.toString(),"' filters."));}if(value.length>10){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid Query. '".concat(operator.toString(),"' filters support a ")+'maximum of 10 elements in the value array.');}if(operator==="in"/* IN */||operator==="array-contains-any"/* ARRAY_CONTAINS_ANY */){if(value.indexOf(null)>=0){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid Query. '".concat(operator.toString(),"' filters cannot contain 'null' ")+'in the value array.');}if(value.filter(function(element){return Number.isNaN(element);}).length>0){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid Query. '".concat(operator.toString(),"' filters cannot contain 'NaN' ")+'in the value array.');}}}/**
 * Given an operator, returns the set of operators that cannot be used with it.
 *
 * Operators in a query must adhere to the following set of rules:
 * 1. Only one array operator is allowed.
 * 2. Only one disjunctive operator is allowed.
 * 3. NOT_EQUAL cannot be used with another NOT_EQUAL operator.
 * 4. NOT_IN cannot be used with array, disjunctive, or NOT_EQUAL operators.
 *
 * Array operators: ARRAY_CONTAINS, ARRAY_CONTAINS_ANY
 * Disjunctive operators: IN, ARRAY_CONTAINS_ANY, NOT_IN
 */function conflictingOps(op){switch(op){case"!="/* NOT_EQUAL */:return["!="/* NOT_EQUAL */,"not-in"/* NOT_IN */];case"array-contains"/* ARRAY_CONTAINS */:return["array-contains"/* ARRAY_CONTAINS */,"array-contains-any"/* ARRAY_CONTAINS_ANY */,"not-in"/* NOT_IN */];case"in"/* IN */:return["array-contains-any"/* ARRAY_CONTAINS_ANY */,"in"/* IN */,"not-in"/* NOT_IN */];case"array-contains-any"/* ARRAY_CONTAINS_ANY */:return["array-contains"/* ARRAY_CONTAINS */,"array-contains-any"/* ARRAY_CONTAINS_ANY */,"in"/* IN */,"not-in"/* NOT_IN */];case"not-in"/* NOT_IN */:return["array-contains"/* ARRAY_CONTAINS */,"array-contains-any"/* ARRAY_CONTAINS_ANY */,"in"/* IN */,"not-in"/* NOT_IN */,"!="/* NOT_EQUAL */];default:return[];}}function validateNewFilter(query,filter){if(filter.isInequality()){var existingField=getInequalityFilterField(query);if(existingField!==null&&!existingField.isEqual(filter.field)){throw new FirestoreError(Code.INVALID_ARGUMENT,'Invalid query. All where filters with an inequality'+' (<, <=, >, or >=) must be on the same field. But you have'+" inequality filters on '".concat(existingField.toString(),"'")+" and '".concat(filter.field.toString(),"'"));}var firstOrderByField=getFirstOrderByField(query);if(firstOrderByField!==null){validateOrderByAndInequalityMatch(query,filter.field,firstOrderByField);}}var conflictingOp=findFilterOperator(query,conflictingOps(filter.op));if(conflictingOp!==null){// Special case when it's a duplicate op to give a slightly clearer error message.
if(conflictingOp===filter.op){throw new FirestoreError(Code.INVALID_ARGUMENT,'Invalid query. You cannot use more than one '+"'".concat(filter.op.toString(),"' filter."));}else{throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid query. You cannot use '".concat(filter.op.toString(),"' filters ")+"with '".concat(conflictingOp.toString(),"' filters."));}}}function validateNewOrderBy(query,orderBy){if(getFirstOrderByField(query)===null){// This is the first order by. It must match any inequality.
var inequalityField=getInequalityFilterField(query);if(inequalityField!==null){validateOrderByAndInequalityMatch(query,inequalityField,orderBy.field);}}}function validateOrderByAndInequalityMatch(baseQuery,inequality,orderBy){if(!orderBy.isEqual(inequality)){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid query. You have a where filter with an inequality "+"(<, <=, >, or >=) on field '".concat(inequality.toString(),"' ")+"and so you must also use '".concat(inequality.toString(),"' ")+"as your first orderBy(), but your first orderBy() "+"is on field '".concat(orderBy.toString(),"' instead."));}}function validateHasExplicitOrderByForLimitToLast(query){if(hasLimitToLast(query)&&query.explicitOrderBy.length===0){throw new FirestoreError(Code.UNIMPLEMENTED,'limitToLast() queries require specifying at least one orderBy() clause');}}var Query=/*#__PURE__*/function(){function Query(_query,firestore,_converter){_classCallCheck(this,Query);this._query=_query;this.firestore=firestore;this._converter=_converter;}_createClass(Query,[{key:"where",value:function where(field,opStr,value){validateExactNumberOfArgs('Query.where',arguments,3);validateDefined('Query.where',3,value);// Enumerated from the WhereFilterOp type in index.d.ts.
var whereFilterOpEnums=["<"/* LESS_THAN */,"<="/* LESS_THAN_OR_EQUAL */,"=="/* EQUAL */,"!="/* NOT_EQUAL */,">="/* GREATER_THAN_OR_EQUAL */,">"/* GREATER_THAN */,"array-contains"/* ARRAY_CONTAINS */,"in"/* IN */,"array-contains-any"/* ARRAY_CONTAINS_ANY */,"not-in"/* NOT_IN */];var op=validateStringEnum('Query.where',whereFilterOpEnums,2,opStr);var fieldPath=fieldPathFromArgument('Query.where',field);var filter=newQueryFilter(this._query,'Query.where',this.firestore._dataReader,this.firestore._databaseId,fieldPath,op,value);return new Query(queryWithAddedFilter(this._query,filter),this.firestore,this._converter);}},{key:"orderBy",value:function orderBy(field,directionStr){validateBetweenNumberOfArgs('Query.orderBy',arguments,1,2);validateOptionalArgType('Query.orderBy','non-empty string',2,directionStr);var direction;if(directionStr===undefined||directionStr==='asc'){direction="asc"/* ASCENDING */;}else if(directionStr==='desc'){direction="desc"/* DESCENDING */;}else{throw new FirestoreError(Code.INVALID_ARGUMENT,"Function Query.orderBy() has unknown direction '".concat(directionStr,"', ")+"expected 'asc' or 'desc'.");}var fieldPath=fieldPathFromArgument('Query.orderBy',field);var orderBy=newQueryOrderBy(this._query,fieldPath,direction);return new Query(queryWithAddedOrderBy(this._query,orderBy),this.firestore,this._converter);}},{key:"limit",value:function limit(n){validateExactNumberOfArgs('Query.limit',arguments,1);validateArgType('Query.limit','number',1,n);validatePositiveNumber('Query.limit',1,n);return new Query(queryWithLimit(this._query,n,"F"/* First */),this.firestore,this._converter);}},{key:"limitToLast",value:function limitToLast(n){validateExactNumberOfArgs('Query.limitToLast',arguments,1);validateArgType('Query.limitToLast','number',1,n);validatePositiveNumber('Query.limitToLast',1,n);return new Query(queryWithLimit(this._query,n,"L"/* Last */),this.firestore,this._converter);}},{key:"startAt",value:function startAt(docOrField){for(var _len13=arguments.length,fields=new Array(_len13>1?_len13-1:0),_key21=1;_key21<_len13;_key21++){fields[_key21-1]=arguments[_key21];}validateAtLeastNumberOfArgs('Query.startAt',arguments,1);var bound=this.boundFromDocOrFields('Query.startAt',docOrField,fields,/*before=*/true);return new Query(queryWithStartAt(this._query,bound),this.firestore,this._converter);}},{key:"startAfter",value:function startAfter(docOrField){for(var _len14=arguments.length,fields=new Array(_len14>1?_len14-1:0),_key22=1;_key22<_len14;_key22++){fields[_key22-1]=arguments[_key22];}validateAtLeastNumberOfArgs('Query.startAfter',arguments,1);var bound=this.boundFromDocOrFields('Query.startAfter',docOrField,fields,/*before=*/false);return new Query(queryWithStartAt(this._query,bound),this.firestore,this._converter);}},{key:"endBefore",value:function endBefore(docOrField){for(var _len15=arguments.length,fields=new Array(_len15>1?_len15-1:0),_key23=1;_key23<_len15;_key23++){fields[_key23-1]=arguments[_key23];}validateAtLeastNumberOfArgs('Query.endBefore',arguments,1);var bound=this.boundFromDocOrFields('Query.endBefore',docOrField,fields,/*before=*/true);return new Query(queryWithEndAt(this._query,bound),this.firestore,this._converter);}},{key:"endAt",value:function endAt(docOrField){for(var _len16=arguments.length,fields=new Array(_len16>1?_len16-1:0),_key24=1;_key24<_len16;_key24++){fields[_key24-1]=arguments[_key24];}validateAtLeastNumberOfArgs('Query.endAt',arguments,1);var bound=this.boundFromDocOrFields('Query.endAt',docOrField,fields,/*before=*/false);return new Query(queryWithEndAt(this._query,bound),this.firestore,this._converter);}},{key:"isEqual",value:function isEqual(other){if(!(other instanceof Query)){throw invalidClassError('isEqual','Query',1,other);}return this.firestore===other.firestore&&queryEquals(this._query,other._query)&&this._converter===other._converter;}},{key:"withConverter",value:function withConverter(converter){return new Query(this._query,this.firestore,converter);}/** Helper function to create a bound from a document or fields */},{key:"boundFromDocOrFields",value:function boundFromDocOrFields(methodName,docOrField,fields,before){validateDefined(methodName,1,docOrField);if(docOrField instanceof DocumentSnapshot){validateExactNumberOfArgs(methodName,[docOrField].concat(_toConsumableArray(fields)),1);return newQueryBoundFromDocument(this._query,this.firestore._databaseId,methodName,docOrField._document,before);}else{var allFields=[docOrField].concat(fields);return newQueryBoundFromFields(this._query,this.firestore._databaseId,this.firestore._dataReader,methodName,allFields,before);}}},{key:"onSnapshot",value:function onSnapshot(){var _this185=this;for(var _len17=arguments.length,args=new Array(_len17),_key25=0;_key25<_len17;_key25++){args[_key25]=arguments[_key25];}var _a,_b,_c;validateBetweenNumberOfArgs('Query.onSnapshot',arguments,1,4);var options={};var currArg=0;if(_typeof(args[currArg])==='object'&&!isPartialObserver(args[currArg])){options=args[currArg];validateOptionNames('Query.onSnapshot',options,['includeMetadataChanges']);validateNamedOptionalType('Query.onSnapshot','boolean','includeMetadataChanges',options.includeMetadataChanges);currArg++;}if(isPartialObserver(args[currArg])){var userObserver=args[currArg];args[currArg]=(_a=userObserver.next)===null||_a===void 0?void 0:_a.bind(userObserver);args[currArg+1]=(_b=userObserver.error)===null||_b===void 0?void 0:_b.bind(userObserver);args[currArg+2]=(_c=userObserver.complete)===null||_c===void 0?void 0:_c.bind(userObserver);}else{validateArgType('Query.onSnapshot','function',currArg,args[currArg]);validateOptionalArgType('Query.onSnapshot','function',currArg+1,args[currArg+1]);validateOptionalArgType('Query.onSnapshot','function',currArg+2,args[currArg+2]);}var observer={next:function next(snapshot){if(args[currArg]){args[currArg](new QuerySnapshot(_this185.firestore,_this185._query,snapshot,_this185._converter));}},error:args[currArg+1],complete:args[currArg+2]};validateHasExplicitOrderByForLimitToLast(this._query);var firestoreClient=this.firestore.ensureClientConfigured();return firestoreClient.listen(this._query,options,observer);}},{key:"get",value:function get(options){var _this186=this;validateBetweenNumberOfArgs('Query.get',arguments,0,1);validateGetOptions('Query.get',options);validateHasExplicitOrderByForLimitToLast(this._query);var firestoreClient=this.firestore.ensureClientConfigured();return(options&&options.source==='cache'?firestoreClient.getDocumentsFromLocalCache(this._query):firestoreClient.getDocumentsViaSnapshotListener(this._query,options)).then(function(snap){return new QuerySnapshot(_this186.firestore,_this186._query,snap,_this186._converter);});}}]);return Query;}();var QuerySnapshot=/*#__PURE__*/function(){function QuerySnapshot(_firestore,_originalQuery,_snapshot,_converter){_classCallCheck(this,QuerySnapshot);this._firestore=_firestore;this._originalQuery=_originalQuery;this._snapshot=_snapshot;this._converter=_converter;this._cachedChanges=null;this._cachedChangesIncludeMetadataChanges=null;this.metadata=new SnapshotMetadata(_snapshot.hasPendingWrites,_snapshot.fromCache);}_createClass(QuerySnapshot,[{key:"forEach",value:function forEach(callback,thisArg){var _this187=this;validateBetweenNumberOfArgs('QuerySnapshot.forEach',arguments,1,2);validateArgType('QuerySnapshot.forEach','function',1,callback);this._snapshot.docs.forEach(function(doc){callback.call(thisArg,_this187.convertToDocumentImpl(doc,_this187.metadata.fromCache,_this187._snapshot.mutatedKeys.has(doc.key)));});}},{key:"docChanges",value:function docChanges(options){if(options){validateOptionNames('QuerySnapshot.docChanges',options,['includeMetadataChanges']);validateNamedOptionalType('QuerySnapshot.docChanges','boolean','includeMetadataChanges',options.includeMetadataChanges);}var includeMetadataChanges=!!(options&&options.includeMetadataChanges);if(includeMetadataChanges&&this._snapshot.excludesMetadataChanges){throw new FirestoreError(Code.INVALID_ARGUMENT,'To include metadata changes with your document changes, you must '+'also pass { includeMetadataChanges:true } to onSnapshot().');}if(!this._cachedChanges||this._cachedChangesIncludeMetadataChanges!==includeMetadataChanges){this._cachedChanges=changesFromSnapshot(this._snapshot,includeMetadataChanges,this.convertToDocumentImpl.bind(this));this._cachedChangesIncludeMetadataChanges=includeMetadataChanges;}return this._cachedChanges;}/** Check the equality. The call can be very expensive. */},{key:"isEqual",value:function isEqual(other){if(!(other instanceof QuerySnapshot)){throw invalidClassError('isEqual','QuerySnapshot',1,other);}return this._firestore===other._firestore&&queryEquals(this._originalQuery,other._originalQuery)&&this._snapshot.isEqual(other._snapshot)&&this._converter===other._converter;}},{key:"convertToDocumentImpl",value:function convertToDocumentImpl(doc,fromCache,hasPendingWrites){return new QueryDocumentSnapshot(this._firestore,doc.key,doc,fromCache,hasPendingWrites,this._converter);}},{key:"docs",get:function get(){var result=[];this.forEach(function(doc){return result.push(doc);});return result;}},{key:"empty",get:function get(){return this._snapshot.docs.isEmpty();}},{key:"size",get:function get(){return this._snapshot.docs.size;}},{key:"query",get:function get(){return new Query(this._originalQuery,this._firestore,this._converter);}}]);return QuerySnapshot;}();var CollectionReference=/*#__PURE__*/function(_Query){_inherits(CollectionReference,_Query);function CollectionReference(_path,firestore,_converter){var _this188;_classCallCheck(this,CollectionReference);_this188=_possibleConstructorReturn(this,_getPrototypeOf(CollectionReference).call(this,newQueryForPath(_path),firestore,_converter));_this188._path=_path;if(_path.length%2!==1){throw new FirestoreError(Code.INVALID_ARGUMENT,'Invalid collection reference. Collection '+'references must have an odd number of segments, but '+"".concat(_path.canonicalString()," has ").concat(_path.length));}return _this188;}_createClass(CollectionReference,[{key:"doc",value:function doc(pathString){validateBetweenNumberOfArgs('CollectionReference.doc',arguments,0,1);// We allow omission of 'pathString' but explicitly prohibit passing in both
// 'undefined' and 'null'.
if(arguments.length===0){pathString=AutoId.newId();}validateArgType('CollectionReference.doc','non-empty string',1,pathString);var path=ResourcePath.fromString(pathString);return DocumentReference.forPath(this._query.path.child(path),this.firestore,this._converter);}},{key:"add",value:function add(value){validateExactNumberOfArgs('CollectionReference.add',arguments,1);var convertedValue=this._converter?this._converter.toFirestore(value):value;validateArgType('CollectionReference.add','object',1,convertedValue);var docRef=this.doc();// Call set() with the converted value directly to avoid calling toFirestore() a second time.
return new DocumentReference(docRef._key,this.firestore,null).set(convertedValue).then(function(){return docRef;});}},{key:"withConverter",value:function withConverter(converter){return new CollectionReference(this._path,this.firestore,converter);}},{key:"id",get:function get(){return this._query.path.lastSegment();}},{key:"parent",get:function get(){var parentPath=this._query.path.popLast();if(parentPath.isEmpty()){return null;}else{return new DocumentReference(new DocumentKey(parentPath),this.firestore,/* converter= */null);}}},{key:"path",get:function get(){return this._query.path.canonicalString();}}]);return CollectionReference;}(Query);function validateSetOptions(methodName,options){if(options===undefined){return{merge:false};}validateOptionNames(methodName,options,['merge','mergeFields']);validateNamedOptionalType(methodName,'boolean','merge',options.merge);validateOptionalArrayElements(methodName,'mergeFields','a string or a FieldPath',options.mergeFields,function(element){return typeof element==='string'||element instanceof FieldPath$1;});if(options.mergeFields!==undefined&&options.merge!==undefined){throw new FirestoreError(Code.INVALID_ARGUMENT,"Invalid options passed to function ".concat(methodName,"(): You cannot specify both \"merge\" ")+"and \"mergeFields\".");}return options;}function validateSnapshotOptions(methodName,options){if(options===undefined){return{};}validateOptionNames(methodName,options,['serverTimestamps']);validateNamedOptionalPropertyEquals(methodName,'options','serverTimestamps',options.serverTimestamps,['estimate','previous','none']);return options;}function validateGetOptions(methodName,options){validateOptionalArgType(methodName,'object',1,options);if(options){validateOptionNames(methodName,options,['source']);validateNamedOptionalPropertyEquals(methodName,'options','source',options.source,['default','server','cache']);}}function validateReference(methodName,documentRef,firestore){if(!(documentRef instanceof _DocumentKeyReference)){throw invalidClassError(methodName,'DocumentReference',1,documentRef);}else if(documentRef.firestore!==firestore){throw new FirestoreError(Code.INVALID_ARGUMENT,'Provided document reference is from a different Firestore instance.');}else{return documentRef;}}/**
 * Calculates the array of DocumentChanges for a given ViewSnapshot.
 *
 * Exported for testing.
 *
 * @param snapshot The ViewSnapshot that represents the expected state.
 * @param includeMetadataChanges Whether to include metadata changes.
 * @param converter A factory function that returns a QueryDocumentSnapshot.
 * @return An object that matches the DocumentChange API.
 */function changesFromSnapshot(snapshot,includeMetadataChanges,converter){if(snapshot.oldDocs.isEmpty()){// Special case the first snapshot because index calculation is easy and
// fast
var lastDoc;var index=0;return snapshot.docChanges.map(function(change){var doc=converter(change.doc,snapshot.fromCache,snapshot.mutatedKeys.has(change.doc.key));lastDoc=change.doc;return{type:'added',doc:doc,oldIndex:-1,newIndex:index++};});}else{// A DocumentSet that is updated incrementally as changes are applied to use
// to lookup the index of a document.
var indexTracker=snapshot.oldDocs;return snapshot.docChanges.filter(function(change){return includeMetadataChanges||change.type!==3;}/* Metadata */).map(function(change){var doc=converter(change.doc,snapshot.fromCache,snapshot.mutatedKeys.has(change.doc.key));var oldIndex=-1;var newIndex=-1;if(change.type!==0/* Added */){oldIndex=indexTracker.indexOf(change.doc.key);indexTracker=indexTracker["delete"](change.doc.key);}if(change.type!==1/* Removed */){indexTracker=indexTracker.add(change.doc);newIndex=indexTracker.indexOf(change.doc.key);}return{type:resultChangeType(change.type),doc:doc,oldIndex:oldIndex,newIndex:newIndex};});}}function resultChangeType(type){switch(type){case 0/* Added */:return'added';case 2/* Modified */:case 3/* Metadata */:return'modified';case 1/* Removed */:return'removed';default:return fail();}}/**
 * Converts custom model object of type T into DocumentData by applying the
 * converter if it exists.
 *
 * This function is used when converting user objects to DocumentData
 * because we want to provide the user with a more specific error message if
 * their set() or fails due to invalid data originating from a toFirestore()
 * call.
 */function applyFirestoreDataConverter(converter,value,options){var convertedValue;if(converter){if(options&&(options.merge||options.mergeFields)){// Cast to `any` in order to satisfy the union type constraint on
// toFirestore().
// eslint-disable-next-line @typescript-eslint/no-explicit-any
convertedValue=converter.toFirestore(value,options);}else{convertedValue=converter.toFirestore(value);}}else{convertedValue=value;}return convertedValue;}function contains(obj,key){return Object.prototype.hasOwnProperty.call(obj,key);}var name="@firebase/firestore";var version$1="1.17.2";/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var FieldValue$1=/*#__PURE__*/function(_Compat){_inherits(FieldValue$1,_Compat);function FieldValue$1(){_classCallCheck(this,FieldValue$1);return _possibleConstructorReturn(this,_getPrototypeOf(FieldValue$1).apply(this,arguments));}_createClass(FieldValue$1,[{key:"isEqual",value:function isEqual(other){return this._delegate.isEqual(other._delegate);}}],[{key:"serverTimestamp",value:function serverTimestamp(){validateNoArgs('FieldValue.serverTimestamp',arguments);var delegate=serverTimestamp$1();delegate._methodName='FieldValue.serverTimestamp';return new FieldValue$1(delegate);}},{key:"delete",value:function _delete(){validateNoArgs('FieldValue.delete',arguments);var delegate=deleteField();delegate._methodName='FieldValue.delete';return new FieldValue$1(delegate);}},{key:"arrayUnion",value:function arrayUnion(){for(var _len18=arguments.length,elements=new Array(_len18),_key26=0;_key26<_len18;_key26++){elements[_key26]=arguments[_key26];}validateAtLeastNumberOfArgs('FieldValue.arrayUnion',arguments,1);var delegate=_arrayUnion.apply(void 0,elements);delegate._methodName='FieldValue.arrayUnion';return new FieldValue$1(delegate);}},{key:"arrayRemove",value:function arrayRemove(){for(var _len19=arguments.length,elements=new Array(_len19),_key27=0;_key27<_len19;_key27++){elements[_key27]=arguments[_key27];}validateAtLeastNumberOfArgs('FieldValue.arrayRemove',arguments,1);var delegate=_arrayRemove.apply(void 0,elements);delegate._methodName='FieldValue.arrayRemove';return new FieldValue$1(delegate);}},{key:"increment",value:function increment(n){validateArgType('FieldValue.increment','number',1,n);validateExactNumberOfArgs('FieldValue.increment',arguments,1);var delegate=_increment(n);delegate._methodName='FieldValue.increment';return new FieldValue$1(delegate);}}]);return FieldValue$1;}(Compat);/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */var firestoreNamespace={Firestore:Firestore,GeoPoint:GeoPoint,Timestamp:Timestamp,Blob:Blob,Transaction:Transaction$1,WriteBatch:WriteBatch,DocumentReference:DocumentReference,DocumentSnapshot:DocumentSnapshot,Query:Query,QueryDocumentSnapshot:QueryDocumentSnapshot,QuerySnapshot:QuerySnapshot,CollectionReference:CollectionReference,FieldPath:FieldPath$1,FieldValue:FieldValue$1,setLogLevel:Firestore.setLogLevel,CACHE_SIZE_UNLIMITED:CACHE_SIZE_UNLIMITED};/**
 * Configures Firestore as part of the Firebase SDK by calling registerService.
 *
 * @param firebase The FirebaseNamespace to register Firestore with
 * @param firestoreFactory A factory function that returns a new Firestore
 *    instance.
 */function configureForFirebase(firebase,firestoreFactory){firebase.INTERNAL.registerComponent(new _component.Component('firestore',function(container){var app=container.getProvider('app').getImmediate();return firestoreFactory(app,container.getProvider('auth-internal'));},"PUBLIC"/* PUBLIC */).setServiceProps(Object.assign({},firestoreNamespace)));}/**
 * @license
 * Copyright 2017 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ /**
 * Registers the main Firestore Node build with the components framework.
 * Persistence can be enabled via `firebase.firestore().enablePersistence()`.
 */function registerFirestore(instance){configureForFirebase(instance,function(app,auth){var onlineComponentProvider=new OnlineComponentProvider();var offlineComponentProvider=new MultiTabOfflineComponentProvider(onlineComponentProvider);return new Firestore(app,auth,offlineComponentProvider,onlineComponentProvider);});instance.registerVersion(name,version$1,'node');}registerFirestore(_app["default"]);