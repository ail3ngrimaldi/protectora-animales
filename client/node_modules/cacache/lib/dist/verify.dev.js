'use strict';

var util = require('util');

var pMap = require('p-map');

var contentPath = require('./content/path');

var figgyPudding = require('figgy-pudding');

var fixOwner = require('./util/fix-owner');

var fs = require('graceful-fs');

var fsm = require('fs-minipass');

var glob = util.promisify(require('glob'));

var index = require('./entry-index');

var path = require('path');

var rimraf = util.promisify(require('rimraf'));

var ssri = require('ssri');

var hasOwnProperty = function hasOwnProperty(obj, key) {
  return Object.prototype.hasOwnProperty.call(obj, key);
};

var stat = util.promisify(fs.stat);
var truncate = util.promisify(fs.truncate);
var writeFile = util.promisify(fs.writeFile);
var readFile = util.promisify(fs.readFile);
var VerifyOpts = figgyPudding({
  concurrency: {
    "default": 20
  },
  filter: {},
  log: {
    "default": {
      silly: function silly() {}
    }
  }
});
module.exports = verify;

function verify(cache, opts) {
  opts = VerifyOpts(opts);
  opts.log.silly('verify', 'verifying cache at', cache);
  var steps = [markStartTime, fixPerms, garbageCollect, rebuildIndex, cleanTmp, writeVerifile, markEndTime];
  return steps.reduce(function (promise, step, i) {
    var label = step.name || "step #".concat(i);
    var start = new Date();
    return promise.then(function (stats) {
      return step(cache, opts).then(function (s) {
        s && Object.keys(s).forEach(function (k) {
          stats[k] = s[k];
        });
        var end = new Date();

        if (!stats.runTime) {
          stats.runTime = {};
        }

        stats.runTime[label] = end - start;
        return Promise.resolve(stats);
      });
    });
  }, Promise.resolve({})).then(function (stats) {
    stats.runTime.total = stats.endTime - stats.startTime;
    opts.log.silly('verify', 'verification finished for', cache, 'in', "".concat(stats.runTime.total, "ms"));
    return stats;
  });
}

function markStartTime(cache, opts) {
  return Promise.resolve({
    startTime: new Date()
  });
}

function markEndTime(cache, opts) {
  return Promise.resolve({
    endTime: new Date()
  });
}

function fixPerms(cache, opts) {
  opts.log.silly('verify', 'fixing cache permissions');
  return fixOwner.mkdirfix(cache, cache).then(function () {
    // TODO - fix file permissions too
    return fixOwner.chownr(cache, cache);
  }).then(function () {
    return null;
  });
} // Implements a naive mark-and-sweep tracing garbage collector.
//
// The algorithm is basically as follows:
// 1. Read (and filter) all index entries ("pointers")
// 2. Mark each integrity value as "live"
// 3. Read entire filesystem tree in `content-vX/` dir
// 4. If content is live, verify its checksum and delete it if it fails
// 5. If content is not marked as live, rimraf it.
//


function garbageCollect(cache, opts) {
  opts.log.silly('verify', 'garbage collecting content');
  var indexStream = index.lsStream(cache);
  var liveContent = new Set();
  indexStream.on('data', function (entry) {
    if (opts.filter && !opts.filter(entry)) {
      return;
    }

    liveContent.add(entry.integrity.toString());
  });
  return new Promise(function (resolve, reject) {
    indexStream.on('end', resolve).on('error', reject);
  }).then(function () {
    var contentDir = contentPath.contentDir(cache);
    return glob(path.join(contentDir, '**'), {
      follow: false,
      nodir: true,
      nosort: true
    }).then(function (files) {
      return Promise.resolve({
        verifiedContent: 0,
        reclaimedCount: 0,
        reclaimedSize: 0,
        badContentCount: 0,
        keptSize: 0
      }).then(function (stats) {
        return pMap(files, function (f) {
          var split = f.split(/[/\\]/);
          var digest = split.slice(split.length - 3).join('');
          var algo = split[split.length - 4];
          var integrity = ssri.fromHex(digest, algo);

          if (liveContent.has(integrity.toString())) {
            return verifyContent(f, integrity).then(function (info) {
              if (!info.valid) {
                stats.reclaimedCount++;
                stats.badContentCount++;
                stats.reclaimedSize += info.size;
              } else {
                stats.verifiedContent++;
                stats.keptSize += info.size;
              }

              return stats;
            });
          } else {
            // No entries refer to this content. We can delete.
            stats.reclaimedCount++;
            return stat(f).then(function (s) {
              return rimraf(f).then(function () {
                stats.reclaimedSize += s.size;
                return stats;
              });
            });
          }
        }, {
          concurrency: opts.concurrency
        }).then(function () {
          return stats;
        });
      });
    });
  });
}

function verifyContent(filepath, sri) {
  return stat(filepath).then(function (s) {
    var contentInfo = {
      size: s.size,
      valid: true
    };
    return ssri.checkStream(new fsm.ReadStream(filepath), sri)["catch"](function (err) {
      if (err.code !== 'EINTEGRITY') {
        throw err;
      }

      return rimraf(filepath).then(function () {
        contentInfo.valid = false;
      });
    }).then(function () {
      return contentInfo;
    });
  })["catch"](function (err) {
    if (err.code === 'ENOENT') {
      return {
        size: 0,
        valid: false
      };
    }

    throw err;
  });
}

function rebuildIndex(cache, opts) {
  opts.log.silly('verify', 'rebuilding index');
  return index.ls(cache).then(function (entries) {
    var stats = {
      missingContent: 0,
      rejectedEntries: 0,
      totalEntries: 0
    };
    var buckets = {};

    for (var k in entries) {
      if (hasOwnProperty(entries, k)) {
        var hashed = index.hashKey(k);
        var entry = entries[k];
        var excluded = opts.filter && !opts.filter(entry);
        excluded && stats.rejectedEntries++;

        if (buckets[hashed] && !excluded) {
          buckets[hashed].push(entry);
        } else if (buckets[hashed] && excluded) {// skip
        } else if (excluded) {
          buckets[hashed] = [];
          buckets[hashed]._path = index.bucketPath(cache, k);
        } else {
          buckets[hashed] = [entry];
          buckets[hashed]._path = index.bucketPath(cache, k);
        }
      }
    }

    return pMap(Object.keys(buckets), function (key) {
      return rebuildBucket(cache, buckets[key], stats, opts);
    }, {
      concurrency: opts.concurrency
    }).then(function () {
      return stats;
    });
  });
}

function rebuildBucket(cache, bucket, stats, opts) {
  return truncate(bucket._path).then(function () {
    // This needs to be serialized because cacache explicitly
    // lets very racy bucket conflicts clobber each other.
    return bucket.reduce(function (promise, entry) {
      return promise.then(function () {
        var content = contentPath(cache, entry.integrity);
        return stat(content).then(function () {
          return index.insert(cache, entry.key, entry.integrity, {
            metadata: entry.metadata,
            size: entry.size
          }).then(function () {
            stats.totalEntries++;
          });
        })["catch"](function (err) {
          if (err.code === 'ENOENT') {
            stats.rejectedEntries++;
            stats.missingContent++;
            return;
          }

          throw err;
        });
      });
    }, Promise.resolve());
  });
}

function cleanTmp(cache, opts) {
  opts.log.silly('verify', 'cleaning tmp directory');
  return rimraf(path.join(cache, 'tmp'));
}

function writeVerifile(cache, opts) {
  var verifile = path.join(cache, '_lastverified');
  opts.log.silly('verify', 'writing verifile to ' + verifile);

  try {
    return writeFile(verifile, '' + +new Date());
  } finally {
    fixOwner.chownr.sync(cache, verifile);
  }
}

module.exports.lastRun = lastRun;

function lastRun(cache) {
  return readFile(path.join(cache, '_lastverified'), 'utf8').then(function (data) {
    return new Date(+data);
  });
}